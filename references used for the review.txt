FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Wu, JZ
   Li, B
   Qin, Y
   Ni, WP
   Zhang, H
   Fu, RG
   Sun, YL
AF Wu, Junzheng
   Li, Biao
   Qin, Yao
   Ni, Weiping
   Zhang, Han
   Fu, Ruigang
   Sun, Yuli
TI A multiscale graph convolutional network for change detection in
   homogeneous and heterogeneous remote sensing images
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Change detection; Graph convolutional network; Multiscale segmentation;
   Semisupervised; Remote sensing images
ID UNSUPERVISED CHANGE DETECTION; CHANGE-VECTOR ANALYSIS; NEURAL-NETWORK;
   FUSION
AB To date, although numerous methods of Change detection (CD) in remote sensing images have been proposed, accurately identifying changes is still a great challenge, due to the difficulties in effectively modeling the features from ground objects with different patterns. In this paper, a novel CD method based on the graph convolutional network (GCN) and multiscale object-based technique is proposed for both homogeneous and heterogeneous images. First, the object-wise high level features are obtained through a pre-trained U-net and the multiscale segmentations. Second, by treating each parcel as a node, the graph representations can be formed and then fed into the proposed multiscale graph convolutional network with each channel corresponding to one scale. The multiscale GCN propagates the label information from a small amount of labeled nodes to the other unlabeled ones. Finally, to comprehensively incorporate the information from the output channels of multiscale GCN, a fusion strategy is designed using the parent-child relationships between scales. Extensive experiments on optical, SAR and heterogeneous optical/SAR data sets demonstrate that the proposed method outperforms some state-ofthe-art methods in both qualitative and quantitative evaluations.
C1 [Wu, Junzheng; Li, Biao; Fu, Ruigang; Sun, Yuli] Natl Univ Def Technol, Coll Elect Sci, Changsha, Peoples R China.
   [Wu, Junzheng; Qin, Yao; Ni, Weiping; Zhang, Han] Northwest Inst Nucl Technol, Xian 710024, Peoples R China.
RP Wu, JZ (corresponding author), Natl Univ Def Technol, Coll Elect Sci, Changsha, Peoples R China.; Wu, JZ (corresponding author), Northwest Inst Nucl Technol, Xian 710024, Peoples R China.
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62001482]
FX This study is supported by National Natural Science Foundation of China
   under Grant 62001482.
CR Baatz M., 2000, P AGIS, P12, DOI DOI 10.1207/S15326888CHC1304_3
   Ban YF, 2016, REMOTE SENS DIGIT IM, V20, P19, DOI 10.1007/978-3-319-47037-5_2
   Bruna Joan, 2014, P ICLR
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3170427.3188467, 10.1109/INTMAG.2018.8508564]
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Kim Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12121978
   Kipf Thomas N., 2017, P 5 INT C LEARN REPR, DOI DOI 10.1051/0004-6361/201527329
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Liu GC, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106971
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun YL, 2021, IEEE T IMAGE PROCESS, V30, P6277, DOI 10.1109/TIP.2021.3093766
   Sun YL, 2021, IEEE T GEOSCI REMOTE, V59, P4841, DOI 10.1109/TGRS.2020.3013673
   Sun YL, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107598
   Sun YL, 2020, IEEE J-STARS, V13, P293, DOI 10.1109/JSTARS.2019.2960518
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Wan S, 2020, IEEE T GEOSCI REMOTE, V58, P3162, DOI 10.1109/TGRS.2019.2949180
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wang YH, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010020
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yan XF, 2019, ISPRS J PHOTOGRAMM, V150, P259, DOI 10.1016/j.isprsjprs.2019.02.010
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
NR 48
TC 0
Z9 0
U1 21
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 25
PY 2021
VL 105
AR 102615
DI 10.1016/j.jag.2021.102615
PG 12
WC Remote Sensing
SC Remote Sensing
GA WZ8TL
UT WOS:000720234100001
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Song, L
   Xia, M
   Jin, JL
   Qian, M
   Zhang, YH
AF Song, Lei
   Xia, Min
   Jin, Junlan
   Qian, Ming
   Zhang, Yonghong
TI SUACDNet: Attentional change detection network based on siamese U-shaped
   structure
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Change detection; Remote sensing image; Deep learning; Multi-scale
   convolution
ID IMAGES
AB Remote sensing image change detection is an essential aspect of remote sensing technology application. Existing change detection algorithms based on deep learning do not distinguish between changed and unchanged areas explicitly, resulting in serious loss of edge detail information during detection. Therefore, a new attentional change detection network based on Siamese U-shaped structure (SUACDNet) is proposed in this paper. In the feature encoding stage, three branches are introduced between the Siamese structure to focus on the global information, difference information and similarity information of bitemporal images respectively. In the feature decoding stage, an U-shaped structure is constructed for upsampling and recovery layer by layer. Multi-scale Convolution Residual Module (MCRM) is a new convolution structure designed for multi-scale feature extrac-tion in the network. In addition, this work also proposes three auxiliary modules to optimize the network, namely Spatial Attention Module (SAM), Feature Fusion Module (FFM) and Cross-scale Global Context Semantic In-formation Aggregation Module (CGCAM), making the network more sensitive to the changed area while filtering out the background noise. Comparative experiments on three datasets show that our method is superior to the existing methods.
C1 [Song, Lei; Xia, Min] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Peoples R China.
   [Xia, Min; Jin, Junlan; Zhang, Yonghong] Nanjing Univ Informat Sci & Technol, Jiangsu Key Lab Big Data Anal Technol, Nanjing 210044, Peoples R China.
   [Qian, Ming] Wuhan Univ, State Key Lab LIESMARS, Wuhan 430072, Peoples R China.
RP Xia, M (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Peoples R China.
EM xiamin@nuist.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42075130]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 42075130.
CR Abdi G, 2021, CAN J REMOTE SENS, V47, P337, DOI 10.1080/07038992.2021.1925530
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen BY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040731
   Chen H, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3095166
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Diakogiannis FI, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183707
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Eisavi V, 2016, J FAC FOR-ISTANB UNI, V66, P524, DOI 10.17099/jffiu.90466
   Fang S, 2021, IEEE GEOSCI REMOTE S, DOI 10.1109/LGRS.2021.3056416
   Ferraris V, 2018, IEEE T GEOSCI REMOTE, V56, P1566, DOI 10.1109/TGRS.2017.2765348
   Hamunyela E, 2020, INT J APPL EARTH OBS, V88, DOI 10.1016/j.jag.2020.102063
   He CY, 2011, INT J APPL EARTH OBS, V13, P572, DOI 10.1016/j.jag.2011.03.002
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jabari S, 2016, PHOTOGRAMM ENG REM S, V82, P521, DOI 10.14358/PERS.82.7.521
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Ke L, 2018, IEEE ACCESS, V6, P27442, DOI 10.1109/ACCESS.2018.2807380
   Liu MX, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3091758
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pitts DAD, 2017, INT J APPL EARTH OBS, V63, P167, DOI 10.1016/j.jag.2017.07.010
   Qian JH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172669
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   SINGH A., 2018, EGYPTIAN J REMOTE SE, V21, P345, DOI [10.1016/j.ejrs.2018.01.006, DOI 10.1016/J.EJRS.2018.01.006]
   Su Juan, 2008, Acta Automatica Sinica, V34, P1040, DOI 10.3724/SP.J.1004.2008.01040
   Wang DC, 2021, INT J APPL EARTH OBS, V101, DOI 10.1016/j.jag.2021.102348
   Wang F, 2013, IEEE GEOSCI REMOTE S, V10, P697, DOI 10.1109/LGRS.2012.2219494
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   WEISMILLER RA, 1977, PHOTOGRAMM ENG REM S, V43, P1533
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zheng J, 2013, IEEE GEOSCI REMOTE S, V10, P91, DOI 10.1109/LGRS.2012.2193659
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 49
TC 1
Z9 1
U1 25
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 25
PY 2021
VL 105
AR 102597
DI 10.1016/j.jag.2021.102597
PG 14
WC Remote Sensing
SC Remote Sensing
GA WU9ZA
UT WOS:000716894800002
OA gold
DA 2022-01-04
ER

PT J
AU Ding, Q
   Shao, ZF
   Huang, X
   Altan, O
AF Ding, Qing
   Shao, Zhenfeng
   Huang, Xiao
   Altan, Orhan
TI DSA-Net: A novel deeply supervised attention-guided network for building
   change detection in high-resolution remote sensing images
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Building change detection; Deep learning; DSA-Net; CLA-Con-SAM; Deep
   supervision
AB Building change detection (BCD) plays a crucial role in urban planning and development and has received extensive attention. However, existing deep learning-based change detection methods suffer from limited accuracy, mainly due to the information loss and inadequate capability in feature extraction. To overcome these shortcomings, we propose a novel deeply supervised attention-guided network (DSA-Net) for BCD tasks in highresolution images. In the DSA-Net, we innovatively introduce a spatial attention mechanism-guided cross-layer addition and skip-connection (CLA-Con-SAM) module to aggregate multi-level contextual information, weaken the heterogeneity between raw image features and difference features, and direct the network's attention to changed regions. We also introduce an atrous spatial pyramid pooling (ASPP) module to extract multi-scale features. To further improve detection performance, we implement a new deep supervision module to enhance the ability of middle layers to extract more distinctive features. We conduct quantitative and qualitative experiments on the two publicly available datasets, i.e., the LEVIR-CD and the WHU Building datasets. Compared with the competing methods, the proposed DSA-Net achieves the best performance in all evaluation metrics. The efficiency analysis reveals that the proposed DSA-Net achieves a great balance between BCD performance and complexity/efficiency, with faster convergence and higher robustness.
C1 [Ding, Qing; Shao, Zhenfeng] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Huang, Xiao] Univ Arkansas, Dept Geosci, Fayetteville, AR 72701 USA.
   [Altan, Orhan] Istanbul Tech Univ, Dept Geomat Engn, TR-36626 Istanbul, Turkey.
RP Shao, ZF (corresponding author), 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM dingqing@whu.edu.cn; shaozhenfeng@whu.edu.cn; xh010@uark.edu;
   oaltan@itu.edu.tr
CR Abdi G, 2021, CAN J REMOTE SENS, V47, P337, DOI 10.1080/07038992.2021.1925530
   Awrangjeb M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101512
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cai SS, 2013, REMOTE SENS LETT, V4, P998, DOI 10.1080/2150704X.2013.828180
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chintala S., 2016, ARXIV151106434
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Daudt R.C., 2018, ARXIV181008452V1
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Hou X, 2021, ISPRS J PHOTOGRAMM, V177, P103, DOI 10.1016/j.isprsjprs.2021.05.001
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Johansen K, 2008, J SPAT SCI, V53, P43, DOI 10.1080/14498596.2008.9635134
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Mao TQ, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P633, DOI 10.1109/ICIVC.2018.8492796
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Pan D, 2021, IEEE J-STARS, V14, P2662, DOI 10.1109/JSTARS.2021.3058347
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Varghese A, 2019, LECT NOTES COMPUT SC, V11130, P129, DOI 10.1007/978-3-030-11012-3_10
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang Z., 2018, ARXIV PREPRINT ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng Z, 2021, ISPRS J PHOTOGRAMM, V175, P247, DOI 10.1016/j.isprsjprs.2021.03.005
NR 39
TC 0
Z9 0
U1 29
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 25
PY 2021
VL 105
AR 102591
DI 10.1016/j.jag.2021.102591
PG 12
WC Remote Sensing
SC Remote Sensing
GA WM4OQ
UT WOS:000711066700005
OA gold
DA 2022-01-04
ER

PT J
AU Wang, YH
   Gao, LR
   Hong, DF
   Sha, JJ
   Liu, L
   Zhang, B
   Rong, XH
   Zhang, YG
AF Wang, Yanheng
   Gao, Lianru
   Hong, Danfeng
   Sha, Jianjun
   Liu, Lian
   Zhang, Bing
   Rong, Xianhui
   Zhang, Yonggang
TI Mask DeepLab: End-to-end image segmentation for change detection in
   high-resolution remote sensing images
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Autoencoder; Change detection (CD); DeepLabV3+; High-resolution remote
   sensing images (HR); Mask
ID CHANGE VECTOR ANALYSIS; NETWORK; CLASSIFICATION; COVER
AB Traditional change detection (CD) algorithms cannot meet the requirements of today's high resolution remote sensing images (HR). Recently, deep learning-based CD has become a popular research topic. However, there are not many annotated samples for training deep learning (DL) models. Patch-based algorithm has become an important research direction in CD in response to the lack of training datasets, but the optimal patch size is relatively small and difficult to determine, which limits the use of spatial information and the extension of deep network. In this paper, we develop a feature-regularized mask DeepLab (FRM-DeepLab) for HRCD. First, a maskbased framework (MaskNet) that uses a few annotated samples to update model parameters is introduced. Based on MaskNet, we design a Mask-DeepLab to make full use of HR. Last, the deep features of unlabeled areas are extracted by an autoencoder as auxiliary information, and those features are concatenated in the middle-level features extracted by Mask-DeepLab to alleviate the influences of overfitting caused by small-scale samples. The algorithm is verified on three HRCD datasets. The visualization and quantitative analysis of the experiment results figure that this algorithm can implement significant performance improvement.
C1 [Wang, Yanheng; Sha, Jianjun; Zhang, Yonggang] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Wang, Yanheng; Gao, Lianru; Hong, Danfeng; Liu, Lian; Zhang, Bing] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Zhang, Bing] Univ Chinese Acad Sci, Coll Resources & Environm, Beijing 100049, Peoples R China.
   [Rong, Xianhui] Harbin Engn Univ, Coll Mat Sci & Chem Engn, Harbin 150001, Peoples R China.
RP Gao, LR (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
EM gaolr@aircas.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41722108]
FX This work was supported by the National Natural Science Foundation of
   China (42030111), and the National Natural Science Foundation of China
   (41722108).
CR Bergamasco L, 2019, PROC SPIE, V11155, DOI 10.1117/12.2533812
   Chanussot J., IEEE T GEOSCI ELECT, DOI [10.1109/TGRS.2021.3065990, DOI 10.1109/TGRS.2021.3065990]
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cui XM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192220
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   [冯文卿 Feng Wenqing], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1880
   Firdaus-Nawi M., 2011, Pertanika Journal of Tropical Agricultural Science, V34, P137
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Hang R., IEEE T GEOSCI ELECT, V59, P2281
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P1424, DOI 10.1109/TGRS.2020.3003341
   Hang RL, 2020, IEEE T GEOSCI REMOTE, V58, P4939, DOI 10.1109/TGRS.2020.2969024
   Hong DF, 2021, IEEE GEOSC REM SEN M, V9, P52, DOI 10.1109/MGRS.2021.3064051
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2020, ISPRS J PHOTOGRAMM, V167, P12, DOI 10.1016/j.isprsjprs.2020.06.014
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V147, P193, DOI 10.1016/j.isprsjprs.2018.10.006
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Lee YW, 2019, IEEE COMPUT SOC CONF, P752, DOI 10.1109/CVPRW.2019.00103
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu S., IEEE J-STARS, V14, P464
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Maiya S.R., 2018, SLUM SEGMENTATION CH, P1
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Salvucci M.D.D., 2005, P HUM FACT ERG SOC A, V49, P1965, DOI [10.1177/154193120504902217, DOI 10.1177/154193120504902217]
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song H., 2019, 2019 INT S REMOTE SE
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   [王艳恒 Wang Yanheng], 2020, [中国图象图形学报, Journal of Image and Graphics], V25, P1271
   Xu Y, 2013, PROC SPIE, V8919, DOI 10.1117/12.2031104
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
NR 41
TC 0
Z9 0
U1 19
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 15
PY 2021
VL 104
AR 102582
DI 10.1016/j.jag.2021.102582
PG 9
WC Remote Sensing
SC Remote Sensing
GA XC2KU
UT WOS:000721849200002
OA gold
DA 2022-01-04
ER

PT J
AU Kuck, TN
   Silva, PFF
   Sano, EE
   Bispo, PD
   Shiguemori, EH
   Dalagnol, R
AF Kuck, Tahisa Neitzel
   Silva Filho, Paulo Fernando Ferreira
   Sano, Edson Eyji
   Bispo, Polyanna da Conceicao
   Shiguemori, Elcio Hideiti
   Dalagnol, Ricardo
TI Change Detection of Selective Logging in the Brazilian Amazon Using
   X-Band SAR Data and Pre-Trained Convolutional Neural Networks
SO REMOTE SENSING
LA English
DT Article
DE selective logging; synthetic aperture radar; convolutional neural
   networks
ID FOREST DEGRADATION; BIOMASS ESTIMATION; CLASSIFICATION; DEFORESTATION;
   AREAS
AB It is estimated that, in the Brazilian Amazon, forest degradation contributes three times more than deforestation for the loss of gross above-ground biomass. Degradation, in particular those caused by selective logging, result in features whose detection is a challenge to remote sensing, due to its size, space configuration, and geographical distribution. From the available remote sensing technologies, SAR data allow monitoring even during adverse atmospheric conditions. The aim of this study was to test different pre-trained models of Convolutional Neural Networks (CNNs) for change detection associated with forest degradation in bitemporal products obtained from a pair of SAR COSMO-SkyMed images acquired before and after logging in the Jamari National Forest. This area contains areas of legal and illegal logging, and to test the influence of the speckle effect on the result of this classification by applying the classification methodology on previously filtered and unfiltered images, comparing the results. A method of cluster detections was also presented, based on density-based spatial clustering of applications with noise (DBSCAN), which would make it possible, for example, to guide inspection actions and allow the calculation of the intensity of exploitation (IEX). Although the differences between the tested models were in the order of less than 5%, the tests on the RGB composition (where R = coefficient of variation; G = minimum values; and B = gradient) presented a slightly better performance compared to the others in terms of the number of correct classifications for selective logging, in particular using the model Painters (accuracy = 92%) even in the generalization tests, which presented an overall accuracy of 87%, and in the test on RGB from the unfiltered image pair (accuracy of 90%). These results indicate that multitemporal X-band SAR data have the potential for monitoring selective logging in tropical forests, especially in combination with CNN techniques.
C1 [Kuck, Tahisa Neitzel; Silva Filho, Paulo Fernando Ferreira; Shiguemori, Elcio Hideiti] Inst Adv Studies IEAv, Command Control Commun Comp Intelligence Surveill, BR-12228001 Sao Jose Dos Campos, Brazil.
   [Kuck, Tahisa Neitzel; Sano, Edson Eyji] Univ Brasilia UnB, Geosci Inst, BR-70910900 Brasilia, Brazil.
   [Sano, Edson Eyji] Embrapa Cerrados, BR-73310970 Planaltina, Brazil.
   [Bispo, Polyanna da Conceicao; Dalagnol, Ricardo] Univ Manchester, Dept Geog, Sch Environm Educ & Dev, Manchester M13 9PL, Lancs, England.
   [Dalagnol, Ricardo] Natl Inst Space Res INPE, Earth Observat & Geoinformat Div, BR-12227010 Sao Jose Dos Campos, Brazil.
RP Bispo, PD (corresponding author), Univ Manchester, Dept Geog, Sch Environm Educ & Dev, Manchester M13 9PL, Lancs, England.
EM tahisa@ieav.cta.br; silvafilho@ieav.cta.br; edson.sano@embrapa.br;
   polyanna.bispo@manchester.ac.uk; elcio@ieav.cta.br; ricds@hotmail.com
FU Sao Paulo Research Foundation (FAPESP)Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [2019/21662-8]
FX R.D. was supported by Sao Paulo Research Foundation (FAPESP) grant
   #2019/21662-8.
CR Abo Gharbia Alshimaa Y., 2020, NRIAG Journal of Astronomy and Geophysics, V9, P106, DOI 10.1080/20909977.2020.1723199
   [Anonymous], SERVICO FLORESTAL BR
   [Anonymous], SEEG BRASIL SISTEMA
   Armenteros JJA, 2017, BIOINFORMATICS, V33, P3387, DOI 10.1093/bioinformatics/btx431
   Asner GP, 2001, INT J REMOTE SENS, V22, P3855, DOI 10.1080/01431160010006926
   Astrium, 2012, P GEO FCT 3 SCI DAT, P6
   Bispo PC, 2014, CAN J REMOTE SENS, V40, P26, DOI 10.1080/07038992.2014.913477
   Bispo PD, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172685
   Borderies, 2007, BACKSCATTERING BORDE, V3
   Bouvet A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081250
   Bullock EL, 2021, SCI TOTAL ENVIRON, V764, DOI 10.1016/j.scitotenv.2020.142839
   Bullock EL, 2020, GLOBAL CHANGE BIOL, V26, P2956, DOI 10.1111/gcb.15029
   Bullock EL, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2018.11.011
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Cheng G, 2020, IEEE J-STARS, V13, P3735, DOI 10.1109/JSTARS.2020.3005403
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Dalagnol R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070817
   Das A, 2016, PROCEEDINGS OF 2016 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   De S, 2017, INT GEOSCI REMOTE SE, P5193, DOI 10.1109/IGARSS.2017.8128171
   Delgado-Aguilar MJ, 2017, INT FOREST REV, V19, P102, DOI 10.1505/146554817820888636
   Demsar J, 2013, J MACH LEARN RES, V14, P2349
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deutscher J, 2013, REMOTE SENS-BASEL, V5, P648, DOI 10.3390/rs5020648
   Diniz CG, 2015, IEEE J-STARS, V8, P3619, DOI 10.1109/JSTARS.2015.2437075
   Doblas J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12233922
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Ghosh SM, 2018, APPL GEOGR, V96, P29, DOI 10.1016/j.apgeog.2018.05.011
   Honorio, 2021, IEEE GEOSCI REMOTE S, V99, P1, DOI [10.1109/LGRS.2021.3057263, DOI 10.1109/LGRS.2021.3057263]
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121444
   Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004
   Keutzer, 2016, ARXIV160207360, P1, DOI DOI 10.1007/978-3-319-24553-9
   Koeniguer EC, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132089
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuck TN, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13173341
   Lee YS, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050797
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Locks C.J., 2017, THESIS U BRASILIA BR
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   Mermoz S, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030217
   Mitchell AL, 2017, CARBON BAL MANAGE, V12, DOI 10.1186/s13021-017-0078-9
   Monteiro A., B DESMATAMENTO AMAZO
   Nichol, PAINTER NUMBERS KAGG
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Potapov P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030426
   QGIS.org, QGIS GEOGR INF SYST
   Qin YW, 2021, NAT CLIM CHANGE, V11, P442, DOI 10.1038/s41558-021-01026-5
   Santoro M, 2021, EARTH SYST SCI DATA, V13, P3927, DOI 10.5194/essd-13-3927-2021
   Schardt, 2017, P 2017 9 INT WORKSH, VVolume 2017, P1, DOI [10.1109/Multi-Temp.2017.8035264, DOI 10.1109/MULTI-TEMP.2017.8035264]
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Silva CHL, 2021, NAT GEOSCI, V14, P634, DOI 10.1038/s41561-021-00823-z
   Soares J.V., METODOLOGIA CALCULO
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Treuhaft R, 2017, FORESTS, V8, DOI 10.3390/f8080277
   Treuhaft R, 2015, IEEE GEOSCI REMOTE S, V12, P239, DOI 10.1109/LGRS.2014.2334140
   Matricardi EAT, 2020, SCIENCE, V369, P1378, DOI 10.1126/science.abb3021
   van Der Sanden, 1997, RADAR REMOTE SENSING
   Watanabe M, 2018, IEEE J-STARS, V11, P2127, DOI 10.1109/JSTARS.2018.2810857
   Xu X., 1996, P 2 INT C KNOWL DISC, P226, DOI [10.1.1.121.9220, DOI 10.5555/3001460.3001507, 10.1016/B978-044452701-1.00067-3]
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhuang HF, 2019, EUR J REMOTE SENS, V52, P484, DOI 10.1080/22797254.2019.1653226
   Zisserman, 2015, INT C LEARN REPR ICL
NR 67
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC
PY 2021
VL 13
IS 23
AR 4944
DI 10.3390/rs13234944
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA XV7BN
UT WOS:000735093000001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, Z
   Jiang, FL
   Liu, TF
   Xie, F
   Li, P
AF Wang, Zhao
   Jiang, Fenlong
   Liu, Tongfei
   Xie, Fei
   Li, Peng
TI Attention-Based Spatial and Spectral Network with PCA-Guided
   Self-Supervised Feature Extraction for Change Detection in Hyperspectral
   Images
SO REMOTE SENSING
LA English
DT Article
DE hyperspectral images; change detection; self-supervised learning;
   attention mechanism
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS
AB Joint analysis of spatial and spectral features has always been an important method for change detection in hyperspectral images. However, many existing methods cannot extract effective spatial features from the data itself. Moreover, when combining spatial and spectral features, a rough uniform global combination ratio is usually required. To address these problems, in this paper, we propose a novel attention-based spatial and spectral network with PCA-guided self-supervised feature extraction mechanism to detect changes in hyperspectral images. The whole framework is divided into two steps. First, a self-supervised mapping from each patch of the difference map to the principal components of the central pixel of each patch is established. By using the multi-layer convolutional neural network, the main spatial features of differences can be extracted. In the second step, the attention mechanism is introduced. Specifically, the weighting factor between the spatial and spectral features of each pixel is adaptively calculated from the concatenated spatial and spectral features. Then, the calculated factor is applied proportionally to the corresponding features. Finally, by the joint analysis of the weighted spatial and spectral features, the change status of pixels in different positions can be obtained. Experimental results on several real hyperspectral change detection data sets show the effectiveness and advancement of the proposed method.
C1 [Wang, Zhao; Jiang, Fenlong; Liu, Tongfei; Li, Peng] Xidian Univ, Sch Elect Engn, Key Lab Elect Informat Countermeasure & Simulat T, Minist Educ, 2 South TaiBai Rd, Xian 710075, Peoples R China.
   [Xie, Fei] Xidian Univ, Acad Adv Interdisciplinary Res, 2 South TaiBai Rd, Xian 710068, Peoples R China.
RP Xie, F (corresponding author), Xidian Univ, Acad Adv Interdisciplinary Res, 2 South TaiBai Rd, Xian 710068, Peoples R China.
EM wangzhao@xidian.edu.cn; fljiang@stu.xidian.edu.cn;
   ltfei@stu.xidian.edu.cn; fxie@xidian.edu.cn; penglixd@xidian.edu.cn
OI Liu, Tongfei/0000-0003-1394-4724
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bazi Y, 2009, INT J REMOTE SENS, V30, P6591, DOI 10.1080/01431160902882538
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen Q, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070549
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Ghaffarian S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13152965
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hou ZF, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3090802
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002
   Jiang FL, 2020, IEEE GEOSCI REMOTE S, V17, P1223, DOI 10.1109/LGRS.2019.2941318
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Jiang XM, 2018, IEEE T GEOSCI REMOTE, V56, P508, DOI 10.1109/TGRS.2017.2751060
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Jing LL, 2020, INT J OCCUP SAF ERGO, DOI [10.1109/TPAMI.2020.2992393, 10.1080/10803548.2020.1835234]
   Kuncheva LI, 2014, IEEE T NEUR NET LEAR, V25, P69, DOI 10.1109/TNNLS.2013.2248094
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101008
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Liu T., 2021, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/LGRS.2021.3078732, DOI 10.1109/LGRS.2021.3078732]
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lv ZY, 2020, IEEE T GEOSCI REMOTE, V58, P6524, DOI 10.1109/TGRS.2020.2977248
   Lv ZY, 2020, IEEE J-STARS, V13, P4575, DOI 10.1109/JSTARS.2020.2980895
   Lv ZY, 2021, IEEE T GEOSCI REMOTE, V59, P139, DOI 10.1109/TGRS.2020.2996064
   Marinelli D, 2019, IEEE T GEOSCI REMOTE, V57, P4913, DOI 10.1109/TGRS.2019.2894339
   Migas-Mazur R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163314
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shao P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163171
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wang D, 2021, IEEE T GEOSCI REMOTE, V59, P2461, DOI 10.1109/TGRS.2020.2999957
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2021, IEEE T CYBERNETICS, DOI 10.1109/TCYB.2021.3086884
   Wu C, 2018, ISPRS J PHOTOGRAMM, V146, P137, DOI 10.1016/j.isprsjprs.2018.09.005
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Yu CY, 2020, IEEE J-STARS, V13, P2485, DOI 10.1109/JSTARS.2020.2983224
   Yu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121233
   Zhan T, 2020, IEEE T GEOSCI REMOTE, V58, P5653, DOI 10.1109/TGRS.2020.2968098
   Zhan TM, 2021, IEEE J-STARS, V14, P377, DOI 10.1109/JSTARS.2020.3037070
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   ZhiYong L, 2021, IEEE GEOSC REM SEN M, DOI 10.1109/MGRS.2021.3088865
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 61
TC 0
Z9 0
U1 0
U2 0
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC
PY 2021
VL 13
IS 23
AR 4927
DI 10.3390/rs13234927
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA XV1CC
UT WOS:000734687900001
OA gold
DA 2022-01-04
ER

PT J
AU Ren, CJ
   Wang, XY
   Gao, J
   Zhou, XR
   Chen, HH
AF Ren, Caijun
   Wang, Xiangyu
   Gao, Jian
   Zhou, Xiren
   Chen, Huanhuan
TI Unsupervised Change Detection in Satellite Images With Generative
   Adversarial Network
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Generative adversarial networks; Deep learning;
   Satellites; Task analysis; Gallium nitride; Generators; Change
   detection; deep learning; generative adversarial networks (GANs);
   satellite images; unsupervised
ID CHANGE VECTOR ANALYSIS; SLOW FEATURE ANALYSIS
AB Detecting changed regions in paired satellite images plays a key role in many remote sensing applications. The evolution of recent techniques could provide satellite images with a very high spatial resolution (VHR) but made it challenging to apply image coregistration, and many change detection methods are dependent on its accuracy. Two images of the same scene taken at different times or from different angles would introduce unregistered objects and the existence of both unregistered areas and actual changed areas would lower the performance of many change detection algorithms in unsupervised conditions. To alleviate the effect of unregistered objects in the paired images, we propose a novel change detection framework utilizing a special neural network architecture Generative Adversarial Network (GAN) to generate many better coregistered images. In this article, we show that the GAN model can be trained upon a pair of images by using the proposed expanding strategy to create a training set and optimizing designed objective functions. The optimized GAN model would produce better coregistered images where changes can be easily spotted and then the change map can be presented through a comparison strategy using these generated images explicitly. Compared to other deep learning-based methods, our method is less sensitive to the problem of unregistered images and makes most of the deep learning structure. Experimental results on synthetic images and real data with many different scenes could demonstrate the effectiveness of the proposed approach.
C1 [Ren, Caijun; Wang, Xiangyu; Chen, Huanhuan] Univ Sci & Technol China USTC, Sch Comp Sci & Technol, UBRI, Hefei 230027, Peoples R China.
   [Gao, Jian] StarGIS Technol Dev Co Ltd, Tianjin 300384, Peoples R China.
   [Zhou, Xiren] Iflytek Co Ltd, Hefei 230088, Peoples R China.
RP Chen, HH (corresponding author), Univ Sci & Technol China USTC, Sch Comp Sci & Technol, UBRI, Hefei 230027, Peoples R China.
EM raggie@mail.ustc.edu.cn; sa321@mail.ustc.edu.cn; hchen@ustc.edu.cn
FU National Key Research and Development Program of China [2016YFB1000905];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91746209]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFB1000905, and in part by
   the National Natural Science Foundation of China under Grant 91746209.
CR Arjovsky M., 2017, ARXIV170104862
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bethge, 2015, ADV NEURAL INFORM PR, P219
   Blaschke T., 2001, ISPRS INT ARCH PHOTO, V34, P22
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Cao G, 2016, EUR J REMOTE SENS, V49, P225, DOI 10.5721/EuJRS20164913
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen HH, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P392
   Chen HH, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3387
   Chen HH, 2014, COMPUT CHEM ENG, V67, P33, DOI 10.1016/j.compchemeng.2014.03.015
   Chen HH, 2014, IEEE T NEUR NET LEAR, V25, P124, DOI 10.1109/TNNLS.2013.2256797
   Demir U, 2018, ARXIV180307422
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gamba P, 2006, IEEE T GEOSCI REMOTE, V44, P2820, DOI 10.1109/TGRS.2006.879498
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gong ZC, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1009, DOI 10.1145/2983323.2983784
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5767, DOI DOI 10.5555/3295222.3295327
   Hensel M, 2017, ADV NEUR IN, V30
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kingma D., 2014, 14126980 ARXIV
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Malila W.A, 1980, P LARS S, P385
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Miyato Takeru, 2018, ARXIV180205957
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Oliva, 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Solano-Correa YT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040533
   Su J., 2018, ARXIV181107296
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Tomioka, 2016, ADV NEURAL INFORM PR, P271
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu JQ, 2018, LECT NOTES COMPUT SC, V11209, P673, DOI 10.1007/978-3-030-01228-1_40
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang R, 2019, PR MACH LEARN RES, V97
NR 54
TC 2
Z9 2
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD DEC
PY 2021
VL 59
IS 12
BP 10047
EP 10061
DI 10.1109/TGRS.2020.3043766
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XC7DV
UT WOS:000722170500023
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Feizizadeh, B
   Alajujeh, KM
   Lakes, T
   Blaschke, T
   Omarzadeh, D
AF Feizizadeh, Bakhtiar
   Alajujeh, Keyvan Mohammadzade
   Lakes, Tobia
   Blaschke, Thomas
   Omarzadeh, Davoud
TI A comparison of the integrated fuzzy object-based deep learning approach
   and three machine learning techniques for land use/cover change
   monitoring and environmental impacts assessment
SO GISCIENCE & REMOTE SENSING
LA English
DT Article
DE Integrated approach; fuzzy object-base; deep learning CNN; machine
   learning algorithms; spatial uncertainty; land use; cover; change
   detection; urmia lake
ID CONVOLUTIONAL NEURAL-NETWORK; URMIA LAKE BASIN; IMAGE-ANALYSIS; COVER
   CLASSIFICATION; UNCERTAINTY ANALYSIS; RANDOM FOREST; OPTIMIZATION;
   SEGMENTATION; SENSITIVITY; PERFORMANCE
AB Recent improvements in the spatial, temporal, and spectral resolution of satellite images necessitate (semi-)automated classification and information extraction approaches. Therefore, we developed an integrated fuzzy object-based image analysis and deep learning (FOBIA-DL) approach for monitoring the land use/cover (LULC) and respective changes and compared it to three machine learning (ML) algorithms, namely the support vector machine (SVM), random forest (RF), and classification and regression tree (CART). We investigated LULC impacts on drought by analyzing Landsat satellite images from 1990 to 2020 for the Urmia Lake area in northern Iran. In the FOBIA-DL approach, following the initial segmentation steps, object features were identified for each LULC class. We then derived their respective attributes using fuzzy membership functions and deep convolutional neural networks (DCNNs), a deep learning method. The Fuzzy Synthetic Evaluation and Dempster-Shafer Theory (FSE-DST) also applied to validate and carryout the spatial uncertainties. Our results indicate that the FOBIA-DL, with an accuracy of 90.1% to 96.4% and a spatial certainty of 0.93 to 0.97, outperformed the other approaches, closely followed by the SVM. Our results also showed that the integration of Fuzzy-OBIA and DCNNs could improve the strength and robustness of the OBIA's decision rules, while the FSE-DST approach notably improved the spatial accuracy of the object-based classification maps. While object-based image analysis (OBIA) is already considered a paradigm shift in GIScience, the integration of OBIA with fuzzy and deep learning creates more flexibility and robust OBIA decision rules for image analysis and classification. This research integrated popular data-driven approaches and developed a novel methodology for image classification and spatial accuracy assessment. From the environmental perspective, the results of this research support lake restoration initiatives by decision-makers and authorities in applications such as drought mitigation, land use management and precision agriculture programs.
C1 [Feizizadeh, Bakhtiar; Alajujeh, Keyvan Mohammadzade; Omarzadeh, Davoud] Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.
   [Feizizadeh, Bakhtiar; Lakes, Tobia] Humboldt Univ, Dept Geog, Lab Geoinformat Sci, Berlin, Germany.
   [Blaschke, Thomas] Univ Salzburg, Dept Geoinformat Z GIS, Salzburg, Austria.
RP Feizizadeh, B (corresponding author), Univ Tabriz, Dept Remote Sensing & GIS, Tabriz, Iran.; Feizizadeh, B (corresponding author), Humboldt Univ, Dept Geog, Lab Geoinformat Sci, Berlin, Germany.
EM Feizizadeh@Tabrizu.ac.ir
OI Lakes, Tobia/0000-0001-8443-7899; omarzadeh, davoud/0000-0002-7904-6903
FU University of Tabriz [s818]; Alexander von Humboldt FoundationAlexander
   von Humboldt Foundation
FX This research was jointly funded by a research grant from the University
   of Tabriz (s818) and the Alexander von Humboldt Foundation.
CR AghaKouchak A, 2015, J GREAT LAKES RES, V41, P307, DOI 10.1016/j.jglr.2014.12.007
   Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   Alhassan V, 2020, NEURAL COMPUT APPL, V32, P8529, DOI 10.1007/s00521-019-04349-9
   Araki S, 2018, SCI TOTAL ENVIRON, V634, P1269, DOI 10.1016/j.scitotenv.2018.03.324
   ARONOFF S, 1985, PHOTOGRAMM ENG REM S, V51, P99
   BAATZ M, 2004, ECOGNITION PROFESSIO
   Balkanlou KR, 2020, SCI TOTAL ENVIRON, V716, DOI 10.1016/j.scitotenv.2020.137100
   Baraldi P, 2010, RISK ANAL, V30, P1139, DOI 10.1111/j.1539-6924.2010.01416.x
   Betts MG, 2017, NATURE, V547, P441, DOI 10.1038/nature23285
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T, 2014, IEEE J-STARS, V7, P4806, DOI 10.1109/JSTARS.2014.2350036
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Cai YP, 2018, REMOTE SENS ENVIRON, V210, P35, DOI 10.1016/j.rse.2018.02.045
   Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Comber A, 2012, REMOTE SENS ENVIRON, V127, P237, DOI 10.1016/j.rse.2012.09.005
   Cresson R., 2018, IEEE GEOSCI REMOTE S, V16, P1
   Das M, 2016, IEEE GEOSCI REMOTE S, V13, P1984, DOI 10.1109/LGRS.2016.2619984
   Delju AH, 2013, THEOR APPL CLIMATOL, V111, P285, DOI 10.1007/s00704-012-0651-9
   Bui DT, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/974638
   Doyle C, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030379
   Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
   Dutta D, 2019, ENVIRON MONIT ASSESS, V191, DOI 10.1007/s10661-019-7645-3
   Ebrahimy H, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110309
   Eisank C, 2014, GEOMORPHOLOGY, V214, P452, DOI 10.1016/j.geomorph.2014.02.028
   Feizizadeh B., 2021, GIS BASED ENSEMBLE M, DOI [10.1007/s11069-021-04673-1, DOI 10.1007/S11069-021-04673-1]
   FEIZIZADEH B, 2021, J ENVIRON PLANN MAN, DOI DOI 10.1080/15481603.2021.2000350
   Feizizadeh B, 2021, CATENA, V198, DOI 10.1016/j.catena.2020.105073
   Feizizadeh B, 2019, CAN J REMOTE SENS, V45, P847, DOI 10.1080/07038992.2019.1704622
   Feizizadeh B, 2018, IEEE GEOSCI REMOTE S, V15, P18, DOI 10.1109/LGRS.2017.2763979
   Feizizadeh B, 2017, GEOMORPHOLOGY, V293, P240, DOI 10.1016/j.geomorph.2017.06.002
   Feizizadeh B, 2017, J ENVIRON PLANN MAN, V60, P2013, DOI 10.1080/09640568.2016.1269643
   Feizizadeh B, 2014, INT J GEOGR INF SCI, V28, P610, DOI 10.1080/13658816.2013.869821
   Foody, 2006, 7 INT S SPAT ACC ASS, P18, DOI DOI 10.1016/J.JHSB.2006.07.007
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Garajeh MK, 2021, SCI TOTAL ENVIRON, V778, DOI 10.1016/j.scitotenv.2021.146253
   Ghasemi M, 2021, EARTH SCI INFORM, V14, P1745, DOI 10.1007/s12145-021-00617-2
   Ghorbanzadeh O., 2019, Journal of Ecotourism, V18, P261, DOI 10.1080/14724049.2019.1597876
   Ghorbanzadeh O, 2021, EUR J REMOTE SENS, V54, P127, DOI 10.1080/22797254.2020.1759456
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guirado E, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121220
   H?lbling D., 2010, GEOBIA 2010 GEOGRAPH, V38, P4
   Hamidi-Razi H, 2019, J GREAT LAKES RES, V45, P87, DOI 10.1016/j.jglr.2018.10.002
   Henry CJ, 2019, INT J REMOTE SENS, V40, P4416, DOI 10.1080/01431161.2018.1563840
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hofmann P, 2011, INT J REMOTE SENS, V32, P7359, DOI 10.1080/01431161.2010.523727
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   JANSSEN LLF, 1994, PHOTOGRAMM ENG REM S, V60, P419
   KAMRAN KV, 2021, APPL GEOMAT, DOI DOI 10.1007/2FS12518-021-00393-0
   Kassouk Z, 2014, GEOMORPHOLOGY, V221, P18, DOI 10.1016/j.geomorph.2014.04.022
   Kucharczyk M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122012
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Lees, 2006, APPL GIS, V2, DOI [10.2104/ag060014, DOI 10.2104/AG060014]
   Lillesand T.M., 2001, REMOTE SENSING IMAGE, Vfourth
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu ZG, 2017, IEEE T SYST MAN CY-S, V47, P2783, DOI 10.1109/TSMC.2016.2622247
   Liu ZG, 2015, KNOWL-BASED SYST, V74, P119, DOI 10.1016/j.knosys.2014.11.013
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6020051
   Maboudi M, 2018, ISPRS J PHOTOGRAMM, V138, P151, DOI 10.1016/j.isprsjprs.2017.11.014
   Mardi AH, 2018, SCI TOTAL ENVIRON, V633, P42, DOI 10.1016/j.scitotenv.2018.03.148
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Mas JF, 2017, EUR J REMOTE SENS, V50, P626, DOI 10.1080/22797254.2017.1387505
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   Moradpour H, 2020, GEOCARTO INT, DOI 10.1080/10106049.2020.1810327
   Naboureh A, 2017, ARAB J GEOSCI, V10, DOI 10.1007/s12517-017-3012-2
   Najafi P, 2018, INT J REMOTE SENS, V39, P6117, DOI 10.1080/01431161.2018.1454621
   Najafi P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050937
   Najafi P, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212583
   Namat~_vs, 2017, INFORM TECHNOL MANAG, V20, P40, DOI DOI 10.1515/ITMS-2017-0007
   Hoan NT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121965
   Nitze I, 2015, INT J APPL EARTH OBS, V34, P136, DOI 10.1016/j.jag.2014.08.001
   Omarzadeh D, 2021, J ENVIRON PLANN MAN, DOI 10.1080/09640568.2021.1887827
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Sarmento P, 2008, PROCEEDINGS OF THE 8TH INTERNATIONAL SYMPOSIUM ON SPATIAL ACCURACY ASSESSMENT IN NATURAL RESOURCES AND ENVIRONMENTAL SCIENCES, VOL I, P348
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Shen, 2018, LEARNING TRANSFERABL
   Shokati B, 2019, J ENVIRON PLANN MAN, V62, P517, DOI 10.1080/09640568.2018.1427561
   Singh P, 2016, ADV INTELL SYST, V434, P551, DOI 10.1007/978-81-322-2752-6_54
   Sudmanns M, 2020, INT J DIGIT EARTH, V13, P832, DOI 10.1080/17538947.2019.1585976
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071135
   Thenkabail, 2015, REMOTELY SENSED DATA, P273, DOI [10.1201/b19294-20, DOI 10.1201/B19294-20]
   Tsagkatakis G, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183929
   Vetrivel A, 2018, ISPRS J PHOTOGRAMM, V140, P45, DOI 10.1016/j.isprsjprs.2017.03.001
   Vieira S, 2017, NEUROSCI BIOBEHAV R, V74, P58, DOI 10.1016/j.neubiorev.2017.01.002
   Woznicki SA, 2019, SCI TOTAL ENVIRON, V647, P942, DOI 10.1016/j.scitotenv.2018.07.353
   Xia M, 2020, INT J REMOTE SENS, V41, P7779, DOI 10.1080/01431161.2020.1763511
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yu XR, 2017, GISCI REMOTE SENS, V54, P741, DOI 10.1080/15481603.2017.1323377
   Zhao WZ, 2017, ISPRS J PHOTOGRAMM, V132, P48, DOI 10.1016/j.isprsjprs.2017.08.011
   Zhou W, 2008, INT J REMOTE SENS, V29, P3119, DOI 10.1080/01431160701469065
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 97
TC 0
Z9 0
U1 6
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 1548-1603
EI 1943-7226
J9 GISCI REMOTE SENS
JI GISci. Remote Sens.
PD NOV 17
PY 2021
VL 58
IS 8
BP 1543
EP 1570
DI 10.1080/15481603.2021.2000350
EA DEC 2021
PG 28
WC Geography, Physical; Remote Sensing
SC Physical Geography; Remote Sensing
GA XN8NW
UT WOS:000724069000001
DA 2022-01-04
ER

PT J
AU Cheng, HQ
   Wu, HY
   Zheng, J
   Qi, KL
   Liu, WX
AF Cheng, Hongquan
   Wu, Huayi
   Zheng, Jie
   Qi, Kunlun
   Liu, Wenxuan
TI A hierarchical self-attention augmented Laplacian pyramid expanding
   network for change detection in high-resolution remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE High-resolution remote sensing image; Change detection; Convolutional
   neural network; Self-attention; Laplacian pyramid
ID CONVOLUTIONAL NEURAL-NETWORK; LAND-USE CHANGE; URBAN; CLASSIFICATION
AB Change detection methods can achieve high learning ability and recognition accuracy with the introduction of deep convolutional neural networks, but due to the influence of the convolution kernel and deep feature sampling, problems such as the limited feature extraction range and loss of information are inevitable. In addition, there can be severe imbalance in the proportions of changed and unchanged pixels compromising the stability of model training. To address these interrelated problems, we propose a hierarchical self-attention augmented Laplacian pyramid expanding network (H-SALENet) for supervised change detection in high-resolution remote sensing images. H-SALENet is composed of an encoder and a decoder. In the encoder, H-SALENet combines a deep convolutional module with a hierarchical and long-range context augmentation module (HLAM) to extract the deep features of bi-temporal images; the representation capability of multi-level and long-range dependent change features is enhanced through deep convolution and 2D transformer-structured multihead self-attention learning. In the decoder, a Laplacian pyramid expansion module (LPEM) is proposed to catch change information at different scales and reduce high-frequency information loss simultaneously, thus weakening the influence of deep feature resampling on the change map. In addition, a data-balanced loss function concentrating on both the quantity and the complexity of the pixels was designed to reduce the influence of the imbalance between changed and unchanged pixels. H-SALENet was tested on two kinds of public datasets; the qualitative and quantitative experimental results show that the proposed network outperformed three benchmark change detection networks in terms of the integrity of change objects and the capability to obtain change contours.
C1 [Cheng, Hongquan; Wu, Huayi; Zheng, Jie; Liu, Wenxuan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Wu, Huayi] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Qi, Kunlun] China Univ Geosci Wuhan, Sch Geog & Informat Engn, 388 Lumo Rd, Wuhan 430078, Hubei, Peoples R China.
RP Wu, HY (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM wuhuayi@whu.edu.cn
FU National Key Research and Development Program of China [2017YFB0503802]
FX We would like to express our sincere gratitude to the reviewers and
   editors for their valuable comments that help improve this paper. Thanks
   are due to Steve McClure for linguistic assistance and valuable
   discussion. The work was supported by the National Key Research and
   Development Program of China (No. 2017YFB0503802).
CR Alcantarilla PF, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Alexakis E.B., 2020, ISPRS INT ARCH, V43, P1507
   Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Bruzzone, 2020, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/ lgrs.2020.3043822, DOI 10.1109/LGRS.2020.3043822]
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   BYRNE GF, 1980, REMOTE SENS ENVIRON, V10, P175, DOI 10.1016/0034-4257(80)90021-8
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Cordonnier B., 2020, INT C LEARN REPR, P1
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   GORDON SI, 1980, REMOTE SENS ENVIRON, V9, P189, DOI 10.1016/0034-4257(80)90028-0
   Guo E., 2018, ARXIV181009111
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   He Q., 2021, IEEE T GEOSCI REMOTE, P1, DOI [10.1109/TGRS.2020.3045474, DOI 10.1109/TGRS.2020.3045]
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   HOWARTH PJ, 1983, REMOTE SENS ENVIRON, V13, P149, DOI 10.1016/0034-4257(83)90019-6
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   JENSEN JR, 1982, PHOTOGRAMM ENG REM S, V48, P629
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   NELSON RF, 1983, PHOTOGRAMM ENG REM S, V49, P1303
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Pfaff B., 1998, MULTISPECTRAL CHANGE
   Ramachandran P, 2019, ADV NEUR IN, V32
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stow D, 2008, REMOTE SENS ENVIRON, V112, P1051, DOI 10.1016/j.rse.2007.07.011
   Sui Haigang, 2018, Geomatics and Information Science of Wuhan University, V43, P1885, DOI 10.13203/j.whugis20180251
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   SWAIN PH, 1978, IEEE T SYST MAN CYB, V8, P879
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Wei JJ, 2020, CAN J REMOTE SENS, V46, P272, DOI 10.1080/07038992.2020.1783993
   WEISMILLER RA, 1977, PHOTOGRAMM ENG REM S, V43, P1533
   Wiemker R., 1997, LECT NOTES COMPUTER, P263, DOI [10.1007/3-540-63460-6_126, DOI 10.1007/3-540-63460-6_126]
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 59
TC 0
Z9 0
U1 22
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD DEC
PY 2021
VL 182
BP 52
EP 66
DI 10.1016/j.isprsjprs.2021.10.001
PG 15
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA WK6CD
UT WOS:000709811500004
DA 2022-01-04
ER

PT J
AU Peng, DF
   Bruzzone, L
   Zhang, YJ
   Guan, HY
   He, PF
AF Peng, Daifeng
   Bruzzone, Lorenzo
   Zhang, Yongjun
   Guan, Haiyan
   He, Pengfei
TI SCDNET: A novel convolutional network for semantic change detection in
   high resolution optical remote sensing imagery
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Semantic change detection; Remote sensing; Siamese UNet; Multi-scale
   atrous convolution; Attention mechanism; Deep supervision
ID FUSION; FRAMEWORK
AB With the continuing improvement of remote-sensing (RS) sensors, it is crucial to monitor Earth surface changes at fine scale and in great detail. Thus, semantic change detection (SCD), which is capable of locating and identifying "from-to" change information simultaneously, is gaining growing attention in RS community. However, due to the limitation of large-scale SCD datasets, most existing SCD methods are focused on scene-level changes, where semantic change maps are generated with only coarse boundary or scarce category information. To address this issue, we propose a novel convolutional network for large-scale SCD (SCDNet). It is based on a Siamese UNet architecture, which consists of two encoders and two decoders with shared weights. First, multi-temporal images are given as input to the encoders to extract multi-scale deep representations. A multi-scale atrous convolution (MAC) unit is inserted at the end of the encoders to enlarge the receptive field as well as capturing multi-scale information. Then, difference feature maps are generated for each scale, which are combined with feature maps from the encoders to serve as inputs for the decoders. Attention mechanism and deep supervision strategy are further introduced to improve network performance. Finally, we utilize softmax layer to produce a semantic change map for each time image. Extensive experiments are carried out on two large-scale high-resolution SCD datasets, which demonstrates the effectiveness and superiority of the proposed method.
C1 [Peng, Daifeng; Guan, Haiyan; He, Pengfei] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Peng, Daifeng; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
   [Zhang, Yongjun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
RP Peng, DF (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
EM daifeng@nuist.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801386, 41671454]; Natural Science
   Foundation of Jiangsu ProvinceNatural Science Foundation of Jiangsu
   Province [BK20180797, BK20190785]; Startup Project for Introducing
   Talent of Nanjing University of Information Science and Technology
   (NUIST) [2018r029]; China Scholarship CouncilChina Scholarship Council
   [201908320183]
FX This work was supported the National Natural Science Foundation of China
   (41801386, 41671454), the Natural Science Foundation of Jiangsu Province
   (BK20180797, BK20190785), the Startup Project for Introducing Talent of
   Nanjing University of Information Science and Technology (NUIST)
   (2018r029), and the China Scholarship Council (201908320183).
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bruzzone L, 2000, INT J REMOTE SENS, V21, P817, DOI 10.1080/014311600210614
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Chen H., 2021, IEEE T GEOSCI ELECT
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng W., 2020, ARXIV PREPRINT ARXIV
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Doxani G, 2012, INT J APPL EARTH OBS, V15, P38, DOI 10.1016/j.jag.2011.07.002
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao J, 2010, INT J APPL EARTH OBS, V12, P9, DOI 10.1016/j.jag.2009.08.003
   Ghiasi G., 2018, ADV NEURAL INFORM PR
   Guo E., 2018, ARXIV181009111
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hutter, 2017, ARXIV171105101
   Kataoka H., 2016, ARXIV PREPRINT ARXIV
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lei YJ, 2021, IEEE T IMAGE PROCESS, V30, P55, DOI 10.1109/TIP.2020.3031173
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li YQ, 2018, IMMS 2019: 2019 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND MANAGEMENT SCIENCES, P123, DOI [10.1016/j.jag.2018.05.023, 10.1145/3357292.3357320]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Peng D., 2020, IEEE T GEOSCI ELECT
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pitts DAD, 2017, INT J APPL EARTH OBS, V57, P49, DOI 10.1016/j.jag.2016.12.004
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Ru L., 2019, P 10 INT WORKSH AN M, P1
   Ru L., 2020, ARXIV PREPRINT ARXIV
   Sakurada K, 2020, IEEE INT CONF ROBOT, P6861, DOI 10.1109/ICRA40945.2020.9196985
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Tian S., 2020, ARXIV PREPRINT ARXIV
   Varghese A., 2018, P EUR C COMP VIS ECC
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Y, 2019, INT GEOSCI REMOTE SE, P198, DOI 10.1109/IGARSS.2019.8898211
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Yang K., 2020, ARXIV PREPRINT ARXIV
NR 40
TC 0
Z9 0
U1 17
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC 1
PY 2021
VL 103
AR 102465
DI 10.1016/j.jag.2021.102465
PG 16
WC Remote Sensing
SC Remote Sensing
GA UR7GZ
UT WOS:000696914400004
OA gold
DA 2022-01-04
ER

PT J
AU Chen, PH
   Guo, L
   Zhang, XR
   Qin, K
   Ma, WT
   Jiao, LC
AF Chen, Puhua
   Guo, Lei
   Zhang, Xiangrong
   Qin, Kai
   Ma, Wentao
   Jiao, Licheng
TI Attention-Guided Siamese Fusion Network for Change Detection of Remote
   Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE change detection; Siamese network; remote sensing image; attention
   mechanism
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS; LAND-COVER; MODEL
AB Change detection for remote sensing images is an indispensable procedure for many remote sensing applications, such as geological disaster assessment, environmental monitoring, and urban development monitoring. Through this technique, the difference in certain areas after some emergencies can be determined to estimate their influence. Additionally, by analyzing the sequential difference maps, the change tendency can be found to help to predict future changes, such as urban development and environmental pollution. The complex variety of changes and interferential changes caused by imaging processing, such as season, weather and sensors, are critical factors that affect the effectiveness of change detection methods. Recently, there have been many research achievements surrounding this topic, but a perfect solution to all the problems in change detection has not yet been achieved. In this paper, we mainly focus on reducing the influence of imaging processing through the deep neural network technique with limited labeled samples. The attention-guided Siamese fusion network is constructed based on one basic Siamese network for change detection. In contrast to common processing, besides high-level feature fusion, feature fusion is operated during the whole feature extraction process by using an attention information fusion module. This module can not only realize the information fusion of two feature extraction network branches, but also guide the feature learning network to focus on feature channels with high importance. Finally, extensive experiments were performed on three public datasets, which could verify the significance of information fusion and the guidance of the attention mechanism during feature learning in comparison with related methods.
C1 [Chen, Puhua; Zhang, Xiangrong; Ma, Wentao; Jiao, Licheng] Xidian Univ, Sch Artificial Intelligence, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Guo, Lei] Xian Elect Engn Res Inst, Gen Design Dept 5, Xian 710071, Peoples R China.
   [Qin, Kai] Natl Nucl Corp Beijing Res Inst Uranium Geol, Natl Key Lab Sci & Technol Remote Sensing Informa, Beijing 100029, Peoples R China.
RP Chen, PH (corresponding author), Xidian Univ, Sch Artificial Intelligence, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM phchen@xidian.edu.cn; 21173110636@stu.xidian.edu.cn;
   xrzhang@mail.xidian.edu.cn; qinkai@briug.cn; wtma_0@stu.xidian.edu.cn;
   lchjiao@mail.xidian.edu.cn
OI Zhang, Xiangrong/0000-0003-0379-2042
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61902298, 61806156]; Key Scientific Research
   Program of Education Department in Shaanxi Province of China [20JY023];
   China Postdoctoral Science FoundationChina Postdoctoral Science
   Foundation [2017M613081]; Postdoctoral Foundation of Shaanxi Province
   [2018BSHEDZZ46]; Fundamental Research Funds for the Central University
   [XJS201901]
FX This research was funded by the National Natural Science Foundation of
   China under Grant (no. 61902298 and 61806156), the Key Scientific
   Research Program of Education Department in Shaanxi Province of China
   (no. 20JY023), the China Postdoctoral Science Foundation Funded Project
   (no. 2017M613081), the 2018 Postdoctoral Foundation of Shaanxi Province
   (no. 2018BSHEDZZ46) and Fundamental Research Funds for the Central
   University (no. XJS201901).
CR Addink EA, 2012, INT J APPL EARTH OBS, V15, P1, DOI 10.1016/j.jag.2011.12.001
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Bontemps S, 2008, REMOTE SENS ENVIRON, V112, P3181, DOI 10.1016/j.rse.2008.03.013
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chehata N, 2014, INT J REMOTE SENS, V35, P4758, DOI 10.1080/01431161.2014.930199
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Dou Fangzheng, 2018, Computer Engineering, V44, P294, DOI 10.3969/j.issn.1000-3428.2018.04.047
   Fan JC, 2019, IEEE J-STARS, V12, P685, DOI 10.1109/JSTARS.2019.2892951
   Foo P. H., 2013, J ADV INFORM FUSION, V8, P33
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2017, REMOTE SENS ENVIRON, V196, P56, DOI 10.1016/j.rse.2017.05.001
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Liu G., 2021, IEEE T GEOSCI ELECT, DOI [10.1109/TGRS.2020.3026099, DOI 10.1109/TGRS.2020.3026099]
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Luppino L. T., 2020, ARXIV200407011
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Malila W.A., CHANGE VECTOR ANAL A
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Niemeyer I., 2008, OBJECT BASED IMAGE A, P185
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Ruder, 2016, ARXIV160904747
   Schwartz C, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12121916
   Song A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152345
   Stow D., 2010, HDB APPL SPATIAL STA, VVolume 4, P565
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Viana CM, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, P621, DOI 10.1016/B978-0-12-815226-3.00029-6
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang DD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300831
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xu L, 2019, IEEE ACCESS, V7, P78909, DOI 10.1109/ACCESS.2019.2922839
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang DJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081308
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhao Y, 2018, INT GEOSCI REMOTE SE, P4950, DOI 10.1109/IGARSS.2018.8518915
   Zhong J, 2006, INT J REMOTE SENS, V27, P2055, DOI 10.1080/01431160500444756
NR 64
TC 0
Z9 0
U1 7
U2 7
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2021
VL 13
IS 22
AR 4597
DI 10.3390/rs13224597
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA XH9VR
UT WOS:000725773600001
OA gold
DA 2022-01-04
ER

PT J
AU Yang, X
   Hu, L
   Zhang, YM
   Li, YQ
AF Yang, Xin
   Hu, Lei
   Zhang, Yongmei
   Li, Yunqing
TI MRA-SNet: Siamese Networks of Multiscale Residual and Attention for
   Change Detection in High-Resolution Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE high-resolution remote sensing images; change detection; Multi-Res
   block; Attention Gates; Siamese network
ID CLASSIFICATION; MAD
AB Remote sensing image change detection (CD) is an important task in remote sensing image analysis and is essential for an accurate understanding of changes in the Earth's surface. The technology of deep learning (DL) is becoming increasingly popular in solving CD tasks for remote sensing images. Most existing CD methods based on DL tend to use ordinary convolutional blocks to extract and compare remote sensing image features, which cannot fully extract the rich features of high-resolution (HR) remote sensing images. In addition, most of the existing methods lack robustness to pseudochange information processing. To overcome the above problems, in this article, we propose a new method, namely MRA-SNet, for CD in remote sensing images. Utilizing the UNet network as the basic network, the method uses the Siamese network to extract the features of bitemporal images in the encoder separately and perform the difference connection to better generate difference maps. Meanwhile, we replace the ordinary convolution blocks with Multi-Res blocks to extract spatial and spectral features of different scales in remote sensing images. Residual connections are used to extract additional detailed features. To better highlight the change region features and suppress the irrelevant region features, we introduced the Attention Gates module before the skip connection between the encoder and the decoder. Experimental results on a public dataset of remote sensing image CD show that our proposed method outperforms other state-of-the-art (SOTA) CD methods in terms of evaluation metrics and performance.
C1 [Yang, Xin; Hu, Lei; Li, Yunqing] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
   [Zhang, Yongmei] North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
RP Yang, X (corresponding author), Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
EM xinyang@jxnu.edu.cn; hulei@jxnu.edu.cn; zhangym@ncut.edu.cn;
   lyq@jxnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61662033]
FX This research was funded by the National Natural Science Foundation of
   China, grant number 61662033 and 61371143.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Fang S., SNUNET CD DENSELY CO, DOI [10.1109/LGRS.2021.3056416, DOI 10.1109/LGRS.2021.3056416]
   Fichera CR, 2012, EUR J REMOTE SENS, V45, P1, DOI 10.5721/EuJRS20124501
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoberg T, 2015, IEEE T GEOSCI REMOTE, V53, P659, DOI 10.1109/TGRS.2014.2326886
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Li XH, 2021, ISPRS J PHOTOGRAMM, V179, P14, DOI 10.1016/j.isprsjprs.2021.07.007
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Mnih V., 2014, P ADV NEURAL INF PRO, P2204, DOI DOI 10.1017/S037346330300239X
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pereira F. C. N., 2001, P 18 INT C MACH LEAR, P282
   Polosukhin I., 2017, ADV NEURAL INFORM PR, P5998, DOI DOI 10.5555/3295222.3295349
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang CS, 2018, IEEE J-STARS, V11, P2440, DOI 10.1109/JSTARS.2018.2817121
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou LC, 2016, IEEE J-STARS, V9, P3478, DOI 10.1109/JSTARS.2016.2514610
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 57
TC 0
Z9 0
U1 6
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2021
VL 13
IS 22
AR 4528
DI 10.3390/rs13224528
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA XG8EQ
UT WOS:000724981400001
OA gold
DA 2022-01-04
ER

PT J
AU Rui, X
   Cao, Y
   Yuan, X
   Kang, Y
   Song, WG
AF Rui, Xue
   Cao, Yang
   Yuan, Xin
   Kang, Yu
   Song, Weiguo
TI DisasterGAN: Generative Adversarial Networks for Remote Sensing Disaster
   Image Generation
SO REMOTE SENSING
LA English
DT Article
DE GAN; image generation; data augmentation; remote sensing disaster image
AB Rapid progress on disaster detection and assessment has been achieved with the development of deep-learning techniques and the wide applications of remote sensing images. However, it is still a great challenge to train an accurate and robust disaster detection network due to the class imbalance of existing data sets and the lack of training data. This paper aims at synthesizing disaster remote sensing images with multiple disaster types and different building damage with generative adversarial networks (GANs), making up for the shortcomings of the existing data sets. However, existing models are inefficient in multi-disaster image translation due to the diversity of disaster and inevitably change building-irrelevant regions caused by directly operating on the whole image. Thus, we propose two models: disaster translation GAN can generate disaster images for multiple disaster types using only a single model, which uses an attribute to represent disaster types and a reconstruction process to further ensure the effect of the generator; damaged building generation GAN is a mask-guided image generation model, which can only alter the attribute-specific region while keeping the attribute-irrelevant region unchanged. Qualitative and quantitative experiments demonstrate the validity of the proposed methods. Further experimental results on the damaged building assessment model show the effectiveness of the proposed models and the superiority compared with other data augmentation methods.
C1 [Rui, Xue; Yuan, Xin; Kang, Yu; Song, Weiguo] Univ Sci & Technol China, State Key Lab Fire Sci, Hefei 230026, Peoples R China.
   [Cao, Yang; Kang, Yu] Univ Sci & Technol China, Dept Automat, Hefei 230026, Peoples R China.
   [Kang, Yu] Univ Sci & Technol China, Inst Adv Technol, Hefei 230088, Peoples R China.
RP Song, WG (corresponding author), Univ Sci & Technol China, State Key Lab Fire Sci, Hefei 230026, Peoples R China.
EM ruixue27@mail.ustc.edu.cn; forrest@ustc.edu.cn;
   yx98314@mail.ustc.edu.cn; kangduyu@ustc.edu.cn; wgsong@ustc.edu.cn
FU National Key Research and Development Program of China
FX This research was funded by The National Key Research and Development
   Program of China,"Study on all-weather multi-mode forest fire danger
   monitoring, prediction and early-stage accurate fire detection ".
CR Arjovsky Martin, 2017, ARXIV170107875
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111369
   Benson V., 2020, HUMANITARIAN ASSISTA
   Boin J.B., 2020, P NEUR INF P SYST WO
   Bosch M, 2020, PROC SPIE, V11534, DOI 10.1117/12.2574639
   Chen P., 2020, ARXIV2020200104086
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Federal Emergency Management Agency, 2016, DAMAGE ASSESSMENT OP
   Federal Emergency Management Agency, 2018, TECHNICAL REPORT
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gulrajani I., 2017, ADV NEURAL INFORM PR, P5767, DOI DOI 10.5555/3295222.3295327
   Gupta R., 2019, P IEEE C COMP VIS PA, P10
   Hao H., 2020, ARXIV200406643
   Hensel M, 2017, ADV NEUR IN, V30
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Iqbal J, 2020, ISPRS J PHOTOGRAMM, V167, P263, DOI 10.1016/j.isprsjprs.2020.07.001
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   King DB, 2015, ACS SYM SER, V1214, P1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XH, 2021, ISPRS J PHOTOGRAMM, V179, P14, DOI 10.1016/j.isprsjprs.2021.07.007
   Li Z., 2020, ARXIV200808930
   Li Z., 2020, ARXIV200809041
   Lin, 2018, P EUR C COMP VIS ECC, P718
   Mounsaveng S., 2019, ARXIV2019190909801
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   Shen Y., 2020, P NEUR INF PROC SYST
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao RT, 2019, IEEE ACCESS, V7, P132594, DOI 10.1109/ACCESS.2019.2941272
   Taylor G.W., 2017, ARXIV170804552
   Wu SL, 2019, IET IMAGE PROCESS, V13, P2744, DOI 10.1049/iet-ipr.2018.6588
   Yu-Hui Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P243, DOI 10.1007/978-3-030-58526-6_15
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang G, 2018, LECT NOTES COMPUT SC, V11210, P422, DOI 10.1007/978-3-030-01231-1_26
   Zhang H., 2018, BT 6 INT C LEARN REP
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 40
TC 0
Z9 0
U1 4
U2 4
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2021
VL 13
IS 21
AR 4284
DI 10.3390/rs13214284
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA XE1UB
UT WOS:000723179700001
OA gold
DA 2022-01-04
ER

PT J
AU Karim, Z
   van Zyl, TL
AF Karim, Zainoolabadien
   van Zyl, Terence L.
TI Deep/Transfer Learning with Feature Space Ensemble Networks
   (FeatSpaceEnsNets) and Average Ensemble Networks (AvgEnsNets) for Change
   Detection Using DInSAR Sentinel-1 and Optical Sentinel-2 Satellite Data
   Fusion
SO REMOTE SENSING
LA English
DT Article
DE machine learning; deep learning; transfer learning; artificial
   intelligence; remote sensing; earth observation; DInSAR; change
   detection; space data science
ID DEEP; CLASSIFICATION
AB Differential interferometric synthetic aperture radar (DInSAR), coherence, phase, and displacement are derived from processing SAR images to monitor geological phenomena and urban change. Previously, Sentinel-1 SAR data combined with Sentinel-2 optical imagery has improved classification accuracy in various domains. However, the fusing of Sentinel-1 DInSAR processed imagery with Sentinel-2 optical imagery has not been thoroughly investigated. Thus, we explored this fusion in urban change detection by creating a verified balanced binary classification dataset comprising 1440 blobs. Machine learning models using feature descriptors and non-deep learning classifiers, including a two-layer convolutional neural network (ConvNet2), were used as baselines. Transfer learning by feature extraction (TLFE) using various pre-trained models, deep learning from random initialization, and transfer learning by fine-tuning (TLFT) were all evaluated. We introduce a feature space ensemble family (FeatSpaceEnsNet), an average ensemble family (AvgEnsNet), and a hybrid ensemble family (HybridEnsNet) of TLFE neural networks. The FeatSpaceEnsNets combine TLFE features directly in the feature space using logistic regression. AvgEnsNets combine TLFEs at the decision level by aggregation. HybridEnsNets are a combination of FeatSpaceEnsNets and AvgEnsNets. Several FeatSpaceEnsNets, AvgEnsNets, and HybridEnsNets, comprising a heterogeneous mixture of different depth and architecture models, are defined and evaluated. We show that, in general, TLFE outperforms both TLFT and classic deep learning for the small dataset used and that larger ensembles of TLFE models do not always improve accuracy. The best performing ensemble is an AvgEnsNet (84.862%) comprised of a ResNet50, ResNeXt50, and EfficientNet B4. This was matched by a similarly composed FeatSpaceEnsNet with an F1 score of 0.001 and variance of 0.266 less. The best performing HybridEnsNet had an accuracy of 84.775%. All of the ensembles evaluated outperform the best performing single model, ResNet50 with TLFE (83.751%), except for AvgEnsNet 3, AvgEnsNet 6, and FeatSpaceEnsNet 5. Five of the seven similarly composed FeatSpaceEnsNets outperform the corresponding AvgEnsNet.
C1 [Karim, Zainoolabadien] Univ Witwatersrand, Sch Comp Sci & Appl Math, ZA-2000 Johannesburg, South Africa.
   [van Zyl, Terence L.] Univ Johannesburg, Inst Intelligent Syst, ZA-2000 Johannesburg, South Africa.
RP Karim, Z (corresponding author), Univ Witwatersrand, Sch Comp Sci & Appl Math, ZA-2000 Johannesburg, South Africa.
EM Zainoolabadien.Karim@students.wits.ac.za; tvanzyl@uj.ac.za
RI van Zyl, Terence L/B-9841-2008
OI van Zyl, Terence L/0000-0003-4281-630X; Karim,
   Zainoolabadien/0000-0002-5850-8822
CR Anantrasirichai N, 2018, J GEOPHYS RES-SOL EA, V123, P6592, DOI 10.1029/2018JB015911
   Anantrasirichai N, 2021, IEEE T GEOSCI REMOTE, V59, P2940, DOI 10.1109/TGRS.2020.3018315
   [Anonymous], 2013, SENT 1 US HDB
   Bishop C.M., 2006, PATTERN RECOGN
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Brengman CMJ, 2021, GEOCHEM GEOPHY GEOSY, V22, DOI 10.1029/2020GC009204
   Chollet F., 2017, DEEP LEARNING PYTHON
   Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34
   CLEMEN RT, 1989, INT J FORECASTING, V5, P559, DOI 10.1016/0169-2070(89)90012-5
   Corradino C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161916
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Drzewiecki W, 2017, GEOD CARTOGR, V66, P171, DOI 10.1515/geocart-2017-0012
   European Space Agency, COP OP ACC HUB
   European Space Agency, SEN2COR
   Ferretti A., 2007, SAR PRINCIPLES GUIDE
   Flach P., 2015, ADV NEURAL INFORM PR, P838, DOI DOI 10.5555/2969239.2969333
   Gargiulo M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102969
   Gasparovic M, 2021, FORESTS, V12, DOI 10.3390/f12050553
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google, GOOGL EARTH
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helber P., 2017, ARXIV170900029, V9
   Ienco D, 2019, ISPRS J PHOTOGRAMM, V158, P11, DOI 10.1016/j.isprsjprs.2019.09.016
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1
   Karim Z., 2020, RES REPORT IND CHANG
   Karim Z, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P579
   Khalil RZ, 2018, EGYPT J REMOTE SENS, V21, pS23, DOI 10.1016/j.ejrs.2017.08.005
   Kornblith S., 2018, ARXIV180508974
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin M., 2014, P INT C LEARN REPR, P1, DOI DOI 10.1109/ASRU.2015.7404828
   Maclin, 1999, J ARTIF INTELL RES, V11, P169, DOI [DOI 10.1613/jair.614, 10.1613/jair.614]
   Mitchell T. M, 1997, MACH LEARN
   Oni O.O., 2020, P 2020 IEEE AS PAC C, P1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Price S., 2012, COMPUTER VISION MODE
   Python Software and Foundation, **NON-TRADITIONAL**
   Qiu C., 2019, P 2019 JOINT URB REM, P1, DOI [10.1109/JURSE.2019.8809009, DOI 10.1109/JURSE.2019.8809009]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Saha S., 2019, P 10 INT WORKSH AN M, P1
   Scikit-Image Development Team, HISTOGRAM ORIENTED G
   Scikit-Image Development Team, BLOB DETECTION
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stanford Radar Interferometry Research Group, SNAPHU STAT COST NET
   Sun J, 2020, J GEOPHYS RES-SOL EA, V125, DOI 10.1029/2020JB019840
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2016, ARXIV190511946
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Van Tricht K, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101642
   Van Zyl T.L., 2014, BIG DATA TECHNIQUES, P133
   van Zyl TL, 2021, IEEE J-STARS, V14, P7349, DOI 10.1109/JSTARS.2021.3097446
   Veci L., 2015, SENTINEL 1 TOOLBOX T
   Wang C, 2018, INT GEOSCI REMOTE SE, P1776
   Wu C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P1, DOI 10.1109/CIT.2017.11
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
NR 61
TC 0
Z9 0
U1 3
U2 3
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2021
VL 13
IS 21
AR 4394
DI 10.3390/rs13214394
PG 34
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA WZ1SX
UT WOS:000719754200001
OA gold
DA 2022-01-04
ER

PT J
AU Zheng, Z
   Zhong, YF
   Wang, JJ
   Ma, AL
   Zhang, LP
AF Zheng, Zhuo
   Zhong, Yanfei
   Wang, Junjue
   Ma, Ailong
   Zhang, Liangpei
TI Building damage assessment for rapid disaster response with a deep
   object-based semantic change detection framework: From natural disasters
   to man-made disasters
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Building damage assessment; Change detection; Disaster response; Deep
   learning; Remote sensing; OBIA
AB Sudden-onset natural and man-made disasters represent a threat to the safety of human life and property. Rapid and accurate building damage assessment using bitemporal high spatial resolution (HSR) remote sensing images can quickly and safely provide us with spatial distribution information and statistics of the damage degree to assist with humanitarian assistance and disaster response. For building damage assessment, strong feature representation and semantic consistency are the keys to obtaining a high accuracy. However, the conventional object-based image analysis (OBIA) framework using a patch-based convolutional neural network (CNN) can guarantee semantic consistency, but with weak feature representation, while the Siamese fully convolutional network approach has strong feature representation capabilities but is semantically inconsistent. In this paper, we propose a deep object-based semantic change detection framework, called ChangeOS, for building damage assessment. To seamlessly integrate OBIA and deep learning, we adopt a deep object localization network to generate accurate building objects, in place of the superpixel segmentation commonly used in the conventional OBIA framework. Furthermore, the deep object localization network and deep damage classification network are integrated into a unified semantic change detection network for end-to-end building damage assessment. This also provides deep object features that can supply an object prior to the deep damage classification network for more consistent semantic feature representation. Object-based post-processing is adopted to further guarantee the semantic consistency of each object. The experimental results obtained on a global scale dataset including 19 natural disaster events and two local scale datasets including the Beirut port explosion event and the Bata military barracks explosion event show that ChangeOS is superior to the currently published methods in speed and accuracy, and has a superior generalization ability for man-made disasters.
C1 [Zheng, Zhuo; Zhong, Yanfei; Wang, Junjue; Ma, Ailong; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430074, Peoples R China.
   [Zhong, Yanfei; Zhang, Liangpei] Wuhan Univ, Hubei Prov Engn Res Ctr Nat Resources Remote Sens, Wuhan 430079, Peoples R China.
RP Zhong, YF (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430074, Peoples R China.
EM zhengzhuo@whu.edu.cn; zhongyanfei@whu.edu.cn
OI Zheng, Zhuo/0000-0003-1811-6725; Wang, Junjue/0000-0002-9500-3399
FU National Key Research and Development Program of China [2017YFB0504202];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41771385, 41801267]; China Postdoctoral
   Science FoundationChina Postdoctoral Science Foundation [2017M622522]
FX The authors would like to thank the xView2 team for sharing xView2
   dataset and Maxar Technologies for sharing satellite images of two local
   study sites in this study. This work was supported in part by the
   National Key Research and Development Program of China under grant no.
   2017YFB0504202, in part by the National Natural Science Foundation of
   China under grant nos. 41771385 and 41801267, and in part by the China
   Postdoctoral Science Foundation under grant no. 2017M622522.
CR Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dong LG, 2013, ISPRS J PHOTOGRAMM, V84, P85, DOI 10.1016/j.isprsjprs.2013.06.011
   Durnov V, 2020, XVIEW2 1 PLACE SOLUT
   Ge PL, 2020, REMOTE SENS ENVIRON, V240, DOI 10.1016/j.rse.2020.111693
   Grunthal G., 1998, EUROPEAN MACROSEISMI, V13, P1
   Gupta R., 2019, P IEEE C COMP VIS PA, P10
   Gupta R., 2019, ARXIV2019191109296
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Huang B, 2018, REMOTE SENS ENVIRON, V214, P73, DOI 10.1016/j.rse.2018.04.050
   Kelman I, 2003, THESIS U CAMBRIDGE
   Koshimura S, 2020, GEOSCIENCES, V10, DOI 10.3390/geosciences10050177
   Lee J., 2020, ARXIV201114004
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu T, 2021, REMOTE SENS ENVIRON, V256, DOI 10.1016/j.rse.2021.112308
   Liu YY, 2021, IEEE T GEOSCI REMOTE, V59, P6106, DOI 10.1109/TGRS.2020.3022410
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Plank S, 2014, REMOTE SENS-BASEL, V6, P4870, DOI 10.3390/rs6064870
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tong XH, 2012, ISPRS J PHOTOGRAMM, V68, P13, DOI 10.1016/j.isprsjprs.2011.12.004
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   Valentijn T, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172839
   Vickery P., 2006, NAT HAZARDS REV, V7, P94
   Wu KS, 2005, PROC SPIE, V5747, P1965, DOI 10.1117/12.596105
   Yamazaki F, 2007, J EARTHQ TSUNAMI, V1, P193, DOI 10.1142/S1793431107000122
   Yusuf Y., 2001, J INDIAN SOC REMOTE, V29, P17, DOI 10.1007/BF02989909
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111593
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang Q, 2021, ISPRS J PHOTOGRAMM, V177, P161, DOI 10.1016/j.isprsjprs.2021.04.021
   Zheng Z, 2021, ISPRS J PHOTOGRAMM, V174, P254, DOI 10.1016/j.isprsjprs.2020.12.009
   Zheng Z, 2020, PROC CVPR IEEE, P4095, DOI 10.1109/CVPR42600.2020.00415
   Zheng Z, 2020, IEEE T GEOSCI REMOTE, V58, P5612, DOI 10.1109/TGRS.2020.2967821
   Zheng Z, 2020, ISPRS J PHOTOGRAMM, V166, P1, DOI 10.1016/j.isprsjprs.2020.04.019
   Zhong YF, 2018, ISPRS J PHOTOGRAMM, V138, P281, DOI 10.1016/j.isprsjprs.2018.02.014
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 41
TC 0
Z9 0
U1 19
U2 19
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD NOV
PY 2021
VL 265
AR 112636
DI 10.1016/j.rse.2021.112636
PG 17
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA UR8XH
UT WOS:000697024400003
DA 2022-01-04
ER

PT J
AU Vega, PJS
   da Costa, GAOP
   Feitosa, RQ
   Adarme, MXO
   de Almeida, CA
   Heipke, C
   Rottensteiner, F
AF Soto Vega, Pedro Juan
   Ostwald Pedro da Costa, Gilson Alexandre
   Feitosa, Raul Queiroz
   Ortega Adarme, Mabel Ximena
   de Almeida, Claudio Aparecido
   Heipke, Christian
   Rottensteiner, Franz
TI An unsupervised domain adaptation approach for change detection and its
   application to deforestation mapping in tropical biomes
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Deforestation detection; Change detection; Domain adaptation; CycleGAN;
   Deep learning; Remote sensing
ID SLOW FEATURE ANALYSIS; CLASSIFICATION; MULTISENSOR; NETWORKS; IMAGES
AB Changes in environmental conditions, geographical variability and different sensor properties typically make it almost impossible to employ previously trained classifiers for new data without a significant drop in classification accuracy. Domain adaptation (DA) techniques been proven useful to alleviate that problem. In particular, appearance adaptation techniques may be used to adapt images from a specific dataset in such a way that the generated images have a style that is similar to the images from another dataset. Such techniques are, however, prone to creating artifacts that hinder proper classification of the adapted images. In this work we propose an unsupervised DA approach for change detection tasks, which is based on a particular appearance adaptation method: the Cycle-Consistent Generative Adversarial Network (CycleGAN). Specifically, we extend that method by introducing additional constraints in the training phase of the model components, which make it preserve the semantic structure and class transitions in the adapted images. We evaluate the proposed approach on a deforestation detection application, considering different sites in the Amazon rain-forest and in the Brazilian Cerrado (savanna) using Landsat-8 images. In the experiments, each site corresponds to a domain, and the accuracy of a classifier trained with images and references from one (source) domain is measured in the classification of another (target) domain. The results show that the proposed approach is successful in producing artifact-free adapted images, which can be satisfactory classified by the pre-trained source classifiers. On average, the accuracies achieved in the classification of the adapted images outperformed the baselines (when no adaptation was made) by 7.1% in terms of mean average precision, and 9.1% in terms of F1-Score. To the best of our knowledge, the proposed method is the first unsupervised domain adaptation approach devised for change detection.
C1 [Soto Vega, Pedro Juan; Feitosa, Raul Queiroz; Ortega Adarme, Mabel Ximena] Pontifical Catholic Univ Rio de Janeiro PUC Rio, Comp Vis Lab, Rio De Janeiro, Brazil.
   [Ostwald Pedro da Costa, Gilson Alexandre] State Univ Rio de Janeiro UERJ, Inst Math & Stat, Rio De Janeiro, Brazil.
   [de Almeida, Claudio Aparecido] Natl Inst Space Res INPE, Amazon Program Coordinat, Sao Jose Dos Campos, Brazil.
   [Heipke, Christian; Rottensteiner, Franz] Leibniz Univ Hannover LUH, Inst Photogrammetry & GeoInformat, Hannover, Germany.
RP Vega, PJS (corresponding author), Pontifical Catholic Univ Rio de Janeiro PUC Rio, Comp Vis Lab, Rio De Janeiro, Brazil.
EM psoto@ele.puc-rio.br; gilson.costa@ime.uerj.br; raul@ele.puc-rio.br;
   mortega@ele.puc-rio.br; claudio.almeida@inpe.br;
   heipke@ipi.uni-hannover.de; rottensteiner@ipi.uni-hannover.de
RI Vega, Pedro Juan Soto/ABE-1800-2020; Feitosa, Raul/D-6570-2017
OI Vega, Pedro Juan Soto/0000-0001-5396-8531; Feitosa,
   Raul/0000-0001-8344-5096
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ); Deutsche Akademische Austauschdienst (DAAD)Deutscher
   Akademischer Austausch Dienst (DAAD); Fundacao de Amparo a Pesquisa do
   Estado do Rio de Janeiro (FAPERJ)Fundacao Carlos Chagas Filho de Amparo
   a Pesquisa do Estado do Rio De Janeiro (FAPERJ); NVIDIA Corporation
FX This work was supported by Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES), Conselho Nacional de Desenvolvimento Cientifico
   e Tecnologico (CNPq), Deutsche Akademische Austauschdienst (DAAD),
   Fundacao de Amparo a Pesquisa do Estado do Rio de Janeiro (FAPERJ), and
   NVIDIA Corporation.
CR Adarme MO, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060910
   Afify HA, 2011, ALEX ENG J, V50, P187, DOI 10.1016/j.aej.2011.06.001
   Alexakis E.B., 2020, ISPRS INT ARCH, V43, P1507
   Almeida C.A., 2021, METHODOLOGY FOREST M
   Andrade R., 2020, INT ARCH PHOTOGRAMM, V43, P1497
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Benjdira B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111369
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Calinski T., 1974, COMMUN STAT THEORY M, V3, P1, DOI DOI 10.1080/03610927408827101
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Chen Hui., 2020, ARXIV200616234 CS ST
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chu Y., 2016, 2016 2 INT C ART INT
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   De Sy V, 2015, ENVIRON RES LETT, V10, DOI 10.1088/1748-9326/10/12/124004
   Deng XQ, 2019, INT GEOSCI REMOTE SE, P4955, DOI 10.1109/IGARSS.2019.8900277
   Dhillon IS, 2007, SIAM J MATRIX ANAL A, V29, P1120, DOI 10.1137/060649021
   Elshamli A, 2017, IEEE J-STARS, V10, P4198, DOI 10.1109/JSTARS.2017.2711360
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gholami B, 2020, IEEE T IMAGE PROCESS, V29, P3993, DOI 10.1109/TIP.2019.2963389
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Goodman RC, 2019, FOREST ECOL MANAG, V439, P18, DOI 10.1016/j.foreco.2019.02.037
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Han T, 2007, IEEE GEOSCI REMOTE S, V4, P147, DOI 10.1109/LGRS.2006.887066
   Hinton GE, 2009, SCHOLARPEDIA, V4, P5947, DOI [DOI 10.4249/SCHOLARPEDIA.5947, DOI 10.4249/scholarpedia.5947]
   Hoffman J., 2017, ARXIV171103213
   Hsu TMH, 2015, IEEE I CONF COMP VIS, P4121, DOI 10.1109/ICCV.2015.469
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   IBGE, 2012, MAN TECN VEG BRAS, V2nd
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kauth R.J., 1976, LARS S, P41
   King DB, 2015, ACS SYM SER, V1214, P1
   Koller D., 2009, PROBABILISTIC GRAPHI
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li, 2009, MARKOV RANDOM FIELD
   Li L, 2019, INT GEOSCI REMOTE SE, P1498, DOI 10.1109/IGARSS.2019.8898146
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Malila W.A, 1980, P LARS S, P385
   Malingreau JP, 2012, AMBIO, V41, P309, DOI 10.1007/s13280-011-0196-7
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mateo-Garcia G, 2019, INT GEOSCI REMOTE SE, P712, DOI 10.1109/IGARSS.2019.8899193
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Nogueron R., 2006, HUMAN PRESSURE BRAZI
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parente L, 2021, REMOTE SENS APPL, V21, DOI 10.1016/j.rsase.2020.100444
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pereira F. C. N., 2001, P 18 INT C MACH LEAR, P282
   Pinheiro Maurano L.E., 2019, CIENCIA FLORESTAL, V29
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadeghi V, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2301-x
   Saha S., 2020, IEEE GEOSCI REMOTE S
   Saha S, 2019, INT GEOSCI REMOTE SE, P5033, DOI 10.1109/IGARSS.2019.8900173
   Schenkel F, 2019, INT GEOSCI REMOTE SE, P728, DOI 10.1109/IGARSS.2019.8899796
   Song SY, 2019, IEEE GEOSCI REMOTE S, V16, P1324, DOI 10.1109/LGRS.2019.2896411
   Soto P. J., 2020, INT ARCH PHOTOGRAMM, V43, P1635
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tasar O., 2020, IEEE T GEOSCI ELECT
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E., 2014, ARXIV14123474
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wiskott L, 1999, NEUROCOMPUTING, V26-7, P925, DOI 10.1016/S0925-2312(99)00011-9
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wittich D., ISPRS J PHOTOGRAMM, V180, P82
   Wittich D., 2019, ISPRS ANN PHOTOGRAMM, V4
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yosinski J, 2014, ADV NEUR IN, V27
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang XH, 2013, IEEE GEOSCI REMOTE S, V10, P14, DOI 10.1109/LGRS.2012.2189867
   Zhou LC, 2016, IEEE J-STARS, V9, P3478, DOI 10.1109/JSTARS.2016.2514610
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 76
TC 0
Z9 0
U1 15
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD NOV
PY 2021
VL 181
BP 113
EP 128
DI 10.1016/j.isprsjprs.2021.08.026
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA US1AE
UT WOS:000697168200008
DA 2022-01-04
ER

PT J
AU Khoshboresh-Masouleh, M
   Shah-Hosseini, R
AF Khoshboresh-Masouleh, Mehdi
   Shah-Hosseini, Reza
TI Building panoptic change segmentation with the use of uncertainty
   estimation in squeeze-and-attention CNN and remote sensing observations
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID IMAGERY
AB In conventional frameworks, the building change prediction of the deep model can be just blindly assumed accurate, but sometimes the truth is not. In this study, a new deep convolutional neural network (CNN) is proposed for building panoptic change segmentation using uncertainty estimation in squeeze-and-attention CNN and remote sensing observations. The setup is based on a large-scale dataset, called the LEVIR building change detection dataset (also known as LEVIR-CD), including bi-temporal red-green-blue (RGB) images labelled for building change segmentation with a period of 5 to 14 years have significant land-use changes from 20 various areas that sit in Texas of the United States. The quantitative assessments of the LEVIR-CD dataset show that the panoptic quality (PQ), recognition quality (RQ), segmentation quality (SQ), and mean intersection over union (mIoU) for building panoptic change segmentation are about 91.8, 94.7, 96.9, and 97.3, respectively. Compared with the deep learning networks with different backbones and loss functions, the proposed method demonstrates better performance and good generalization ability for building panoptic change segmentation.
C1 [Khoshboresh-Masouleh, Mehdi; Shah-Hosseini, Reza] Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran 456311155, Iran.
   [Khoshboresh-Masouleh, Mehdi] Int Assoc Engineers, Comp Sci Div, Hong Kong, Peoples R China.
RP Shah-Hosseini, R (corresponding author), Univ Tehran, Coll Engn, Sch Surveying & Geospatial Engn, Tehran 456311155, Iran.
EM rshahosseini@ut.ac.ir
RI Khoshboresh-Masouleh, Mehdi/ABC-5371-2020
OI Khoshboresh-Masouleh, Mehdi/0000-0002-9565-3615
CR Arnab A, 2018, PROC CVPR IEEE, P888, DOI 10.1109/CVPR.2018.00099
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Champion N, 2010, PATTERN RECOGN LETT, V31, P1138, DOI 10.1016/j.patrec.2009.10.012
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen LC, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3525560
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Gstaiger V, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122054
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hu S, 2019, LECT NOTES COMPUT SC, V11765, P137, DOI 10.1007/978-3-030-32245-8_16
   Huang PY, 2018, LECT NOTES COMPUT SC, V11205, P536, DOI 10.1007/978-3-030-01246-5_32
   Javadi S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091404
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Kendall A., 2016, ARXIV151102680
   Khoshboresh Masouleh M., 2019, ISPRS INT ARCH PHOTO, DOI [10.5194/isprs-archives-XLII-4-W18-615-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W18-615-2019]
   Khoshboresh-Masouleh M., 2019, DEPLOYING SUPERPIXEL, V1
   Khoshboresh-Masouleh M, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.034503
   King DB, 2015, ACS SYM SER, V1214, P1
   Kirillov A, 2019, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR.2019.00963
   Kwon Y, 2020, COMPUT STAT DATA AN, V142, DOI 10.1016/j.csda.2019.106816
   Li QZ, 2018, LECT NOTES COMPUT SC, V11219, P106, DOI 10.1007/978-3-030-01267-0_7
   Li YW, 2019, PROC CVPR IEEE, P7019, DOI 10.1109/CVPR.2019.00719
   Li YA, 2020, INT J COMPUT VISION, V128, P2763, DOI 10.1007/s11263-020-01309-y
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu HY, 2019, PROC CVPR IEEE, P6165, DOI 10.1109/CVPR.2019.00633
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Maggiori E, 2017, INT GEOSCI REMOTE SE, P3226, DOI 10.1109/IGARSS.2017.8127684
   Makuti S.F., 2018 ISPRS TC 2 MIDT, DOI [10.5194/isprs-archives-XLII-2-651-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-651-2018]
   Masouleh MK, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024508
   Masouleh MK, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.046018
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mouat D.A., 1993, GEOCARTO INT, V8, P39, DOI [10.1080/10106049309354407, DOI 10.1080/10106049309354407]
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Paszke A., 2019, ADV NEURAL INFORM PR, V32, P8026
   Paul A, 2017, GEOCARTO INT, V32, P640, DOI 10.1080/10106049.2016.1167966
   Rika V., 2020, ARXIV200811201
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tan M., 2020, ARXIV190511946CSSTAT
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Wang X., 2020, ARXIV200310152, P17721
   Xinlong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P649, DOI 10.1007/978-3-030-58523-5_38
   Xiong YW, 2019, PROC CVPR IEEE, P8810, DOI 10.1109/CVPR.2019.00902
   Xu S, 2015, CLASSIFICATION CHANG, DOI [10.3990/1.97836538350, DOI 10.3990/1.97836538350]
   Yang T.-J., 2019, ARXIV190205093
   Zakeri F, 2020, GEOCARTO INT, DOI 10.1080/10106049.2020.1768595
   Zilong Zhong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13062, DOI 10.1109/CVPR42600.2020.01308
   Zong K., 2013, GEOINFORMATICS RESOU, V398, P522, DOI [10.1007/978-3-642-45025-9_51, DOI 10.1007/978-3-642-45025-9_51]
NR 58
TC 0
Z9 0
U1 5
U2 5
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD OCT 18
PY 2021
VL 42
IS 20
BP 7798
EP 7820
DI 10.1080/01431161.2021.1966853
PG 23
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA US3QA
UT WOS:000697346800001
DA 2022-01-04
ER

PT J
AU Wu, L
   Qi, WW
   Guo, ZW
   Zhao, JH
   Yang, HJ
   Li, N
AF Wu, Lin
   Qi, Wenwen
   Guo, Zhengwei
   Zhao, Jianhui
   Yang, Huijin
   Li, Ning
TI Winter wheat planting area extraction using SAR change detection
SO REMOTE SENSING LETTERS
LA English
DT Article
AB With its all-day and all-weather imaging capability, Synthetic Aperture Radar (SAR) has shown great potential in crop identification. This letter puts forward a novel method of extracting winter wheat planting area by means of SAR change detection. Based on the phenological differences between winter wheat and other crops, the Difference Image (DI) is generated firstly by the different temporal SAR images. Then, Object Markov Random Field (OMRF) model is used to DI pre-classification. Finally, Convolutional Neural Network (CNN) is utilized to obtain the better area extraction result of winter wheat. The area extraction accuracy is proved by the field survey data, with an accuracy of 90.53%. This research can provide a new idea and method for agricultural remote sensing monitoring.
C1 [Wu, Lin; Qi, Wenwen; Guo, Zhengwei; Zhao, Jianhui; Yang, Huijin; Li, Ning] Henan Univ, Coll Comp & Informat Engn, Kaifeng, Peoples R China.
   [Wu, Lin] Henan Univ, Coll Environm & Planning, Kaifeng, Peoples R China.
   [Wu, Lin; Qi, Wenwen; Guo, Zhengwei; Zhao, Jianhui; Yang, Huijin; Li, Ning] Henan Univ, Henan Engn Res Ctr Intelligent Technol & Applicat, Kaifeng, Peoples R China.
   [Qi, Wenwen; Guo, Zhengwei; Zhao, Jianhui; Yang, Huijin; Li, Ning] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng, Peoples R China.
RP Guo, ZW (corresponding author), Henan Univ, Coll Comp & Informat Engn, Kaifeng, Peoples R China.
EM gzw@henu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61871175]; College Key Research Project of
   Henan Province [19A420005, 21A520004]; Plan of Science and Technology of
   Henan Province [202102210175, 212102210093, 212102210101]; Key
   Laboratory of Land Satellite Remote Sensing Application, Ministry of
   Natural Resources of the People's Republic of China [KLSMNR-202102]
FX This work was supported by the National Natural Science Foundation of
   China [61871175], the College Key Research Project of Henan Province
   [19A420005, 21A520004], the Plan of Science and Technology of Henan
   Province [202102210175, 212102210093, 212102210101] and Key Laboratory
   of Land Satellite Remote Sensing Application, Ministry of Natural
   Resources of the People's Republic of China [KLSMNR-202102].
CR Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Qu Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152493
   Tian HaiFeng, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P154
   Wang D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020332
   [赵红伟 Zhao Hongwei], 2020, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V36, P169
   Zheng C, 2015, IEEE J-STARS, V8, P1924, DOI 10.1109/JSTARS.2014.2361756
   [周涛 Zhou Tao], 2017, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V33, P215
NR 8
TC 0
Z9 0
U1 17
U2 17
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PD OCT 3
PY 2021
VL 12
IS 10
BP 951
EP 960
DI 10.1080/2150704X.2021.1951873
PG 10
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA TK9LE
UT WOS:000674475600001
DA 2022-01-04
ER

PT J
AU Di Pilato, A
   Taggio, N
   Pompili, A
   Iacobellis, M
   Di Florio, A
   Passarelli, D
   Samarelli, S
AF Di Pilato, Antonio
   Taggio, Nicolo
   Pompili, Alexis
   Iacobellis, Michele
   Di Florio, Adriano
   Passarelli, Davide
   Samarelli, Sergio
TI Deep Learning Approaches to Earth Observation Change Detection
SO REMOTE SENSING
LA English
DT Article
DE change detection; convolutional neural network; earth observation; deep
   learning; Sentinel-2
ID NEURAL-NETWORKS
AB The interest in change detection in the field of remote sensing has increased in the last few years. Searching for changes in satellite images has many useful applications, ranging from land cover and land use analysis to anomaly detection. In particular, urban change detection provides an efficient tool to study urban spread and growth through several years of observation. At the same time, change detection is often a computationally challenging and time-consuming task; therefore, a standard approach with manual detection of the elements of interest by experts in the domain of Earth Observation needs to be replaced by innovative methods that can guarantee optimal results with unquestionable value and within reasonable time. In this paper, we present two different approaches to change detection (semantic segmentation and classification) that both exploit convolutional neural networks to address these particular needs, which can be further refined and used in post-processing workflows for a large variety of applications.</p>
C1 [Di Pilato, Antonio; Pompili, Alexis] Univ Bari Aldo Moro, Dipartimento Interateneo Fis, I-70126 Bari, Italy.
   [Taggio, Nicolo; Iacobellis, Michele; Passarelli, Davide; Samarelli, Sergio] Planetek Italia Srl, I-70132 Bari, Italy.
   [Di Florio, Adriano] Politecn Bari, Dipartimento Interateneo Fis, I-70126 Bari, Italy.
   [Di Pilato, Antonio] Ctr Adv Syst Understanding CASUS, D-02826 Gorlitz, Germany.
RP Di Pilato, A (corresponding author), Univ Bari Aldo Moro, Dipartimento Interateneo Fis, I-70126 Bari, Italy.; Di Pilato, A (corresponding author), Ctr Adv Syst Understanding CASUS, D-02826 Gorlitz, Germany.
EM antonio.dipilato@uniba.it; taggio@planetek.it; alexis.pompili@uniba.it;
   iacobellis@planetek.it; adriano.diflorio@poliba.it;
   passarelli@planetek.it; samarelli@planetek.it
RI Pompili, Alexis/ABG-3556-2021
OI DI PILATO, Antonio/0000-0002-9233-3632
CR Afaq Y, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101310
   Ayhan B, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P316, DOI 10.1109/UEMCON47517.2019.8992937
   Cazaubiel V., 2017, Proceedings of the SPIE, V10566, DOI 10.1117/12.2308278
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kou R, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223815
   Panuju DR, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111781
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salah HS, 2019, INT J REMOTE SENS, V40, P6635, DOI 10.1080/01431161.2019.1583394
   Simonyan Karen, 2015, VERY DEEP CONVOLUTIO
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Wang MC, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12121933
NR 17
TC 1
Z9 1
U1 10
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD OCT
PY 2021
VL 13
IS 20
AR 4083
DI 10.3390/rs13204083
PG 15
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA WS9TT
UT WOS:000715518900001
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Xue, JK
   Xu, H
   Yang, H
   Wang, B
   Wu, PH
   Choi, J
   Cai, LX
   Wu, YL
AF Xue, Junkang
   Xu, Hao
   Yang, Hui
   Wang, Biao
   Wu, Penghai
   Choi, Jaewan
   Cai, Lixiao
   Wu, Yanlan
TI Multi-Feature Enhanced Building Change Detection Based on Semantic
   Information Guidance
SO REMOTE SENSING
LA English
DT Article
DE remote sensing; building change detection; deep learning; multi-branch;
   semantic information
ID IMAGES; NETWORK
AB Building change detection has always been an important research focus in production and urbanization. In recent years, deep learning methods have demonstrated a powerful ability in the field of detecting remote sensing changes. However, due to the heterogeneity of remote sensing and the characteristics of buildings, the current methods do not present an effective means to perceive building changes or the ability to fuse multi-temporal remote sensing features, which leads to fragmented and incomplete results. In this article, we propose a multi-branched network structure to fuse the semantic information of the building changes at different levels. In this model, two accessory branches were used to guide the buildings' semantic information under different time sequences, and the main branches can merge the change information. In addition, we also designed a feature enhancement layer to further strengthen the integration of the main and accessory branch information. For ablation experiments, we designed experiments on the above optimization process. For MDEFNET, we designed experiments which compare with typical deep learning model and recent deep learning change detection methods. Experimentation with the WHU Building Change Detection Dataset showed that the method in this paper obtained accuracies of 0.8526, 0.9418, and 0.9204 in Intersection over Union (IoU), Recall, and F1 Score, respectively, which could assess building change areas with complete boundaries and accurate results.</p>
C1 [Xue, Junkang; Yang, Hui; Wang, Biao; Wu, Penghai; Wu, Yanlan] Anhui Univ, Sch Resources & Environm Engn, Hefei 230601, Peoples R China.
   [Xu, Hao] Inst Spacecraft Syst Engn, Beijing 100094, Peoples R China.
   [Yang, Hui; Wang, Biao; Wu, Penghai; Wu, Yanlan] Informat Mat & Intelligent Sensing Lab Anhui Prov, Hefei 230601, Peoples R China.
   [Yang, Hui] Anhui Univ, Inst Phys Sci, Hefei 230601, Peoples R China.
   [Yang, Hui] Anhui Univ, Inst Informat Technol, Hefei 230601, Peoples R China.
   [Choi, Jaewan] Chungbuk Natl Univ, Sch Civil Engn, Chungju 28644, South Korea.
   [Cai, Lixiao] Shandong Jianzhu Univ, Sch Design Grp, Jinan 250101, Peoples R China.
RP Wu, YL (corresponding author), Anhui Univ, Sch Resources & Environm Engn, Hefei 230601, Peoples R China.; Wu, YL (corresponding author), Informat Mat & Intelligent Sensing Lab Anhui Prov, Hefei 230601, Peoples R China.
EM x19301089@stu.ahu.edu.cn; haibeihms@163.com; yanghui@ahu.edu.cn;
   wangbiao-rs@ahu.edu.cn; wuph@ahu.edu.cn; jaewanchoi@chungbuk.ac.kr;
   13681@sdjzu.edu.cn; wuyanlan@ahu.edu.cn
OI Wu, Penghai/0000-0002-1983-5978
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41971311, 42101381, 41901282]; National
   Natural Science Foundation of Anhui [2008085QD188]
FX FundingThis research was funded by the National Natural Science
   Foundation of China (grant numbers 41971311, 42101381 and 41901282) and
   the National Natural Science Foundation of Anhui (grant number
   2008085QD188).
CR Afaq Y, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101310
   Afify HM, 2021, INT J IMAG SYST TECH, V31, P1741, DOI 10.1002/ima.22568
   Ahmed S., 2021, J APPL REMOTE SENS, V15, DOI [10.1117/IIRS.15.028505, DOI 10.1117/IIRS.15.028505]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baraldi A, 2012, REMOTE SENS-BASEL, V4, P2694, DOI 10.3390/rs4092694
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen J, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7060213
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   de Moel H, 2015, MITIG ADAPT STRAT GL, V20, P865, DOI 10.1007/s11027-015-9654-z
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Eid ANM, 2020, REMOTE SENS APPL, V19, DOI 10.1016/j.rsase.2020.100347
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   [方海泉 Fang Haiquan], 2019, [北京大学学报. 自然科学版, Acta Scientiarum Naturalium Universitatis Pekinensis], V55, P692
   Ferraris V, 2018, IEEE T GEOSCI REMOTE, V56, P1566, DOI 10.1109/TGRS.2017.2765348
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong ML, 2004, PATTERN RECOGN, V37, P1723, DOI 10.1016/j.patcog.2004.02.004
   Hou X, 2021, ISPRS J PHOTOGRAMM, V177, P103, DOI 10.1016/j.isprsjprs.2021.05.001
   Huang GL, 2017, IEEE ICC
   Huang LJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091441
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Li Q, 2021, REMOTE SENS ENVIRON, V262, DOI 10.1016/j.rse.2021.112508
   Niemeyer I., 2008, OBJECT BASED IMAGE A, P185
   Papadomanolaki M, 2021, IEEE T GEOSCI REMOTE, V59, P7651, DOI 10.1109/TGRS.2021.3055584
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qian JH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172669
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Wang B, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080804
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang Z, 2021, COMPUT IND, V132, DOI 10.1016/j.compind.2021.103506
   Xiao YQ, 2019, IEEE ACCESS, V7, P174495, DOI 10.1109/ACCESS.2019.2957518
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhaopeng Zhang, 2018, International Journal of Coal Science & Technology, V5, P105, DOI 10.1007/s40789-018-0195-4
   Zhong QY, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111374
NR 40
TC 0
Z9 0
U1 9
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD OCT
PY 2021
VL 13
IS 20
AR 4171
DI 10.3390/rs13204171
PG 16
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA WT6YQ
UT WOS:000716009400001
OA gold
DA 2022-01-04
ER

PT J
AU Zhang, M
   Shi, WZ
   Chen, SX
   Zhan, Z
   Shi, ZC
AF Zhang, Min
   Shi, Wenzhong
   Chen, Shanxiong
   Zhan, Zhao
   Shi, Zhicheng
TI Deep Multiple Instance Learning for Landslide Mapping
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Terrain factors; Feature extraction; Logic gates; Task analysis; Neural
   networks; Remote sensing; Training; Change detection; convolutional
   neural network (CNN); landslide; multiple-instance learning (MIL);
   remote sensing
ID IMAGERY
AB In this letter, a novel neural network (CDMI-Net) that combines change detection and multiple instance learning (MIL) is proposed for landslide mapping. After obtaining a score map of landslides provided by the network, the final binary map is generated by fast postprocessing. The benefits of the proposed method are threefold. First, using the MIL framework, the network is trained only by the scene-level samples and it reduces the need for pixel-level samples. Second, a change-detection network architecture using a two-stream U-Net with shared weights is designed to learn the deep features of the landslide from the two-period aerial images, reducing the false-positive results. Third, integrating a gated attention-based pooling layer and a fast level-set evolution algorithm can finally produce the pixel-level results. Experimental results show that the proposed CDMI-Net achieves comparable and even better performance on the testing image pairs than all other methods and has great potential for the landslide mapping application.
C1 [Zhang, Min; Chen, Shanxiong; Zhan, Zhao] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Shi, Wenzhong; Shi, Zhicheng] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
RP Shi, WZ (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
EM lswzshi@polyu.edu.hk
RI ; ZHANG, Min/G-4525-2019
OI ZHAN, ZHAO/0000-0002-5092-715X; Chen, Shanxiong/0000-0002-9235-6340;
   ZHANG, Min/0000-0003-1643-5271
FU Ministry of Science and Technology of the People's Republic of
   ChinaMinistry of Science and Technology, China [2017YFB0503604]
FX This work was supported in part by the Ministry of Science and
   Technology of the People's Republic of China under Project
   2017YFB0503604.
CR Chen WT, 2014, REMOTE SENS ENVIRON, V152, P291, DOI 10.1016/j.rse.2014.07.004
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Feng J, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1884
   Ilse M, 2018, PR MACH LEARN RES, V80
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Li ZB, 2015, IEEE T GEOSCI REMOTE, V53, P883, DOI 10.1109/TGRS.2014.2330341
   Mahrooghy M, 2015, IEEE J-STARS, V8, P3791, DOI 10.1109/JSTARS.2015.2427337
   Martha TR, 2010, GEOMORPHOLOGY, V116, P24, DOI 10.1016/j.geomorph.2009.10.004
   Martha TR, 2011, IEEE T GEOSCI REMOTE, V49, P4928, DOI 10.1109/TGRS.2011.2151866
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Rau JY, 2014, IEEE T GEOSCI REMOTE, V52, P1336, DOI 10.1109/TGRS.2013.2250293
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Zare A, 2018, IEEE T PATTERN ANAL, V40, P2342, DOI 10.1109/TPAMI.2017.2756632
   Zhao CY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020279
NR 19
TC 1
Z9 1
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2021
VL 18
IS 10
BP 1711
EP 1715
DI 10.1109/LGRS.2020.3007183
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA UY0WT
UT WOS:000701254500011
DA 2022-01-04
ER

PT J
AU Yang, KP
   Xia, GS
   Liu, ZC
   Du, B
   Yang, W
   Pelillo, M
   Zhang, LP
AF Yang, Kunping
   Xia, Gui-Song
   Liu, Zicheng
   Du, Bo
   Yang, Wen
   Pelillo, Marcello
   Zhang, Liangpei
TI Asymmetric Siamese Networks for Semantic Change Detection in Aerial
   Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Semantics; Adaptation models; Measurement; Feature extraction;
   Convolution; Task analysis; Benchmark testing; Aerial images; asymmetric
   Siamese network (ASN); benchmark dataset; semantic change detection
   (SCD); separated kappa (SeK)
ID UNSUPERVISED CHANGE DETECTION; REGISTRATION; FRAMEWORK
AB Given two multitemporal aerial images, semantic change detection (SCD) aims to locate the land-cover variations and identify their change types with pixelwise boundaries. This problem is vital in many earth vision-related tasks, such as precise urban planning and natural resource management. Existing state-of-the-art algorithms mainly identify the changed pixels by applying homogeneous operations on each input image and comparing the extracted features. However, in changed regions, totally different land-cover distributions often require heterogeneous feature extraction procedures for images acquired at different times. In this article, we present an asymmetric Siamese network (ASN) to locate and identify semantic changes through feature pairs obtained from modules of widely different structures, which involves areas of various sizes and applies different quantities of parameters to factor in the discrepancy across land-cover distributions during different times. To better train and evaluate our model, we create a large-scale well-annotated SEmantic Change detectiON Dataset (SECOND), while an adaptive threshold learning (ATL) module and a separated kappa (SeK) coefficient are proposed to alleviate the influences of label imbalance in model training and evaluation. The experimental results demonstrate that the proposed model can stably outperform the state-of-the-art algorithms with different encoder backbones.
C1 [Yang, Kunping; Xia, Gui-Song; Liu, Zicheng; Du, Bo; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
   [Xia, Gui-Song; Du, Bo] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Inst Artificial Intelligence, Wuhan 430072, Peoples R China.
   [Yang, Wen] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Pelillo, Marcello] Ca Foscari Univ Venice, Dept Environm Sci Informat & Stat DAIS, I-30172 Venice, Italy.
RP Xia, GS (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Inst Artificial Intelligence, Wuhan 430072, Peoples R China.
EM kunpingyang@whu.edu.cn; guisong.xia@whu.edu.cn; zicheng.liu@whu.edu.cn;
   dubo@whu.edu.cn; yangwen@whu.edu.cn; pelillo@unive.it; zlp62@whu.edu.cn
OI Pokethitiyook, Prayad/0000-0002-9017-2900; Yang, Kwang
   Mo/0000-0002-4550-4961
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61922065, 61771350, 61771351,
   41820104006]; Major Projects of Technological Innovation in Hubei
   Province [2019AEA170]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant 61922065, Grant 61771350, Grant
   61771351, and Grant 41820104006; in part by the Major Projects of
   Technological Innovation in Hubei Province under Grant 2019AEA170; and
   in part by all numerical computations for the Supercomputing Center,
   Wuhan University.
CR ALLISON GB, 1983, NATURE, V301, P143, DOI 10.1038/301143a0
   Arneth A, 2015, NATURE, V524, P44, DOI 10.1038/524044a
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Carlotto MJ, 1997, IEEE T IMAGE PROCESS, V6, P189, DOI 10.1109/83.552106
   Chatelain F, 2007, IEEE T IMAGE PROCESS, V16, P1796, DOI 10.1109/TIP.2007.896651
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5
   Chen Y, 2018, IEEE IMAGE PROC, P4008, DOI 10.1109/ICIP.2018.8451392
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Ding Jian, 2021, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2021.3117983
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang, 2020, IEEE T GEOSCI REMOTE, V59, P1
   Huertas A, 2000, IMAGE VISION COMPUT, V18, P583, DOI 10.1016/S0262-8856(99)00063-3
   KOLOS M, 2019, P INT S NEUR NEUR NE, P371
   Lanza A, 2011, IEEE T PATTERN ANAL, V33, P1894, DOI 10.1109/TPAMI.2011.42
   Li, 2017, 2017 IEEE 7 ANN, P1, DOI [DOI 10.1109/CCWC.2017.7868369, 10.1109/CCWC.2017.7868369]
   Lingg AJ, 2014, IEEE T IMAGE PROCESS, V23, P2405, DOI 10.1109/TIP.2014.2309432
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 1998, IEEE T IMAGE PROCESS, V7, P1258, DOI 10.1109/83.709658
   Long Y ., 2020, ARXIV200612485
   Long Y, 2021, IEEE J-STARS, V14, P4205, DOI 10.1109/JSTARS.2021.3070368
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   McCallum A., 2004, P 21 INT C MACH LEAR, P282
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Pollock K, 2016, NATURE, V531, pS64, DOI 10.1038/531S64a
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rengarajan V, 2017, IEEE T PATTERN ANAL, V39, P1959, DOI 10.1109/TPAMI.2016.2630687
   Robin A, 2010, IEEE T PATTERN ANAL, V32, P1977, DOI 10.1109/TPAMI.2010.37
   Saha S, 2018, INT GEOSCI REMOTE SE, P1902, DOI 10.1109/IGARSS.2018.8519440
   Sakurada K., 2015, P BRIT MACH VIS C, V61, P1, DOI DOI 10.5244/C.29.61
   Schindler K, 2020, P ECMLPKDD WORKSH MA, P1
   Song XP, 2018, NATURE, V560, P639, DOI 10.1038/s41586-018-0411-9
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tong XY, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111322
   Vakalopoulou Maria, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P61, DOI 10.1109/CVPRW.2015.7301384
   Varghese A, 2019, LECT NOTES COMPUT SC, V11130, P129, DOI 10.1007/978-3-030-11012-3_10
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10988, DOI 10.1109/CVPR42600.2020.01100
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 59
TC 3
Z9 3
U1 11
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3113912
EA SEP 2021
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS4LJ
UT WOS:000732882400001
PM 34378998
DA 2022-01-04
ER

PT J
AU Andresini, G
   Appice, A
   Iaia, D
   Malerba, D
   Taggio, N
   Aiello, A
AF Andresini, Giuseppina
   Appice, Annalisa
   Iaia, Daniele
   Malerba, Donato
   Taggio, Nicolo
   Aiello, Antonello
TI Leveraging autoencoders in change vector analysis of optical satellite
   images
SO JOURNAL OF INTELLIGENT INFORMATION SYSTEMS
LA English
DT Article; Early Access
DE Autoencoder; Change vector analysis; Change detection; Remote sensing;
   Satellite image analysis
ID CLASSIFICATION; FRAMEWORK
AB Various applications in remote sensing demand automatic detection of changes in optical satellite images of the same scene acquired over time. This paper investigates how to leverage autoencoders in change vector analysis, in order to better delineate possible changes in a couple of co-registered, optical satellite images. Let us consider both a primary image and a secondary image acquired over time in the same scene. First an autoencoder artificial neural network is trained on the primary image. Then the reconstruction of both images is restored via the trained autoencoder so that the spectral angle distance can be computed pixelwise on the reconstructed data vectors. Finally, a threshold algorithm is used to automatically separate the foreground changed pixels from the unchanged background. The assessment of the proposed method is performed in three couples of benchmark hyperspectral images using different criteria, such as overall accuracy, missed alarms and false alarms. In addition, the method supplies promising results in the analysis of a couple of multispectral images of the burned area in the Majella National Park (Italy).
C1 [Andresini, Giuseppina; Appice, Annalisa; Iaia, Daniele; Malerba, Donato] Univ Bari Aldo Moro, Dept Informat, Via Orabona 4, I-70125 Bari, Italy.
   [Appice, Annalisa; Malerba, Donato] Consorzio Interuniv Nazl Informat CIN, Bari, Italy.
   [Taggio, Nicolo; Aiello, Antonello] Planetek Italia Srl, Via Massaua 12, I-70132 Bari, Italy.
RP Andresini, G (corresponding author), Univ Bari Aldo Moro, Dept Informat, Via Orabona 4, I-70125 Bari, Italy.
EM giuseppina.andresini@uniba.it; annalisa.appice@uniba.it;
   d.iaia@studenti.uniba.it; donato.malerba@uniba.it; taggio@planetek.it;
   aiello@planetek.it
FU Italian Ministry for Universities and Research (MIUR)Ministry of
   Education, Universities and Research (MIUR) [ARS01_00141]
FX This work fulfills the research objectives of the PON "Ricerca e
   Innovazione" 20142020 project "CLOSE - Close to the Earth" (ARS01
   00141), funded by the Italian Ministry for Universities and Research
   (MIUR).
CR Alberti M, 2003, BIOSCIENCE, V53, P1169, DOI 10.1641/0006-3568(2003)053[1169:IHIEOA]2.0.CO;2
   An J., 2015, SPECIAL LECT IE, V2, P1
   Andresini G, 2020, IEEE ACCESS, V8, P53346, DOI 10.1109/ACCESS.2020.2980937
   Andresini G, 2019, 2019 4TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW), P281, DOI 10.1109/EuroSPW.2019.00038
   Appice A., 2019, P CEUR WORKSH, V2466, P1
   Appice A, 2020, APPL INTELL, V50, P3179, DOI 10.1007/s10489-020-01701-8
   Appice A, 2019, ISPRS J PHOTOGRAMM, V147, P215, DOI 10.1016/j.isprsjprs.2018.11.023
   Appice A, 2017, PATTERN RECOGN, V63, P229, DOI 10.1016/j.patcog.2016.10.010
   Appice A, 2016, MACH LEARN, V103, P343, DOI 10.1007/s10994-016-5559-7
   Appice A, 2015, DATA MIN KNOWL DISC, V29, P84, DOI 10.1007/s10618-013-0337-7
   Tran BN, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111680
   Barbieri V., 2019, 12 EARSEL FOR FIR SI, P62
   Bergstra J., 2013, INT C MACH LEARN, V28
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Choi Seung-Seok, 2010, J SYST CYBERN INF, P43
   Clifton C, 2003, APPL INTELL, V18, P215, DOI 10.1023/A:1021942526896
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du Z, 2012, APPL INTELL, V36, P542, DOI 10.1007/s10489-010-0274-8
   Epting J, 2005, REMOTE SENS ENVIRON, V96, P328, DOI 10.1016/j.rse.2005.03.002
   Falini A., 2020, LECT NOTES COMPUTER
   Ferreira D.C., 2019, INT JOINT C NEUR NET, P1
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Glorot X., 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1.1.208.6449
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guccione P, 2015, IEEE T GEOSCI REMOTE, V53, P3615, DOI 10.1109/TGRS.2014.2380475
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Helmy A. K., 2010, American Journal of Engineering and Applied Sciences, V3, P604, DOI 10.3844/ajeassp.2010.604.610
   Hoye G., 2013, 2013 5 WORKSH HYP IM, P1, DOI [10.1109/WHISPERS.2013.8080703, DOI 10.1109/WHISPERS.2013.8080703]
   Hu CJ, 2014, 2014 IEEE 11TH INTL CONF ON UBIQUITOUS INTELLIGENCE AND COMPUTING AND 2014 IEEE 11TH INTL CONF ON AUTONOMIC AND TRUSTED COMPUTING AND 2014 IEEE 14TH INTL CONF ON SCALABLE COMPUTING AND COMMUNICATIONS AND ITS ASSOCIATED WORKSHOPS, P855, DOI 10.1109/UIC-ATC-ScalCom.2014.50
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ilsever M., 2012, 2 DIMENSIONAL CHANGE, DOI [10.1007/978-1-4471-4255-3, DOI 10.1007/978-1-4471-4255-3]
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Irsoy O, 2017, NEUROCOMPUTING, V258, P63, DOI 10.1016/j.neucom.2017.02.075
   Islam T., 2017, REMOTE SENSING HYDRO
   Kalinicheva E, 2019, LECT NOTES COMPUT SC, V11729, P637, DOI 10.1007/978-3-030-30508-6_50
   Kalinicheva E, 2018, IEEE I C ELECT CIRC, P641, DOI 10.1109/ICECS.2018.8617850
   Kerner HR, 2019, IEEE J-STARS, V12, P3900, DOI 10.1109/JSTARS.2019.2936771
   Key C.H., 2006, RMRSGTR164CD USDA, P1, DOI [10.1002/app.1994.070541203, DOI 10.1002/APP.1994.070541203]
   Khanday W., 2016, ASIAN J TECHNOLOGY M, V6, P39
   Kwan C, 2019, INFORMATION, V10, DOI 10.3390/info10110353
   Larabi ME, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.046512
   Lentile LB, 2009, INT J WILDLAND FIRE, V18, P594, DOI 10.1071/WF07091
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Lopez-Fandino J, 2017, PROCEEDINGS OF THE 2017 9TH IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA ACQUISITION AND ADVANCED COMPUTING SYSTEMS: TECHNOLOGY AND APPLICATIONS (IDAACS), VOL 1, P404, DOI 10.1109/IDAACS.2017.8095113
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Mao M. Z., 2011, P INT C NEUR INF PRO, P1
   Michel U., 2012, REMOTE SENSING SPATI, VI-4, P107
   Mouroulis P, 2000, APPL OPTICS, V39, P2210, DOI 10.1364/AO.39.002210
   Najafi A, 2017, INT ARCH PHOTOGRAMM, V42-4, P195, DOI 10.5194/isprs-archives-XLII-4-W4-195-2017
   Oh DY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051308
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Penglin Z., 2012, ISPRS INT ARCH PHOTO, VI-7, P263
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sarafijanovic-Djukic Natasa, 2019, Discovery Science. 22nd International Conference, DS 2019. Proceedings. Lecture Notes in Artificial Intelligence (LNAI 11828), P493, DOI 10.1007/978-3-030-33778-0_37
   Seydi ST, 2017, EUR J REMOTE SENS, V50, P517, DOI 10.1080/22797254.2017.1367963
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Shone N, 2018, IEEE TETCI, V2, P41, DOI 10.1109/TETCI.2017.2772792
   Uzair M., 2020, 2020 IEEE 23 INT MUL, P1, DOI 10.1109/INMIC50486.2020.9318195
   Wang JF, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P1172, DOI 10.1109/ICInfA.2015.7279464
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   Wang Y., 2015, P 7 INT C INT MULT C, P1
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030284
   Yang Z., 2007, ASPRS 2007 ANN C, V2, P767
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zheng J, 2018, IEEE SENS J, V18, P5464, DOI 10.1109/JSEN.2018.2836337
NR 69
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0925-9902
EI 1573-7675
J9 J INTELL INF SYST
JI J. Intell. Inf. Syst.
PY 2021
DI 10.1007/s10844-021-00670-9
EA SEP 2021
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
SC Computer Science
GA UW5MN
UT WOS:000700199900001
OA hybrid
DA 2022-01-04
ER

PT J
AU Ji, HW
   Luo, XQ
AF Ji, Haowei
   Luo, Xianqi
TI Implementation of Ensemble Deep Learning Coupled with Remote Sensing for
   the Quantitative Analysis of Changes in Arable Land Use in a Mining Area
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Ensemble learning; Convolutional neural network; Feature pyramid; Change
   detection; Deep learning; Classification; Land use
ID LAKE
AB The high-intensity exploitation of mineral resources in mining cities in China has created new environmental challenges and serious environmental situations in recent years. The land use patterns in mining areas change rapidly for natural and anthropogenic reasons. Land-use/land-cover (LU/LC) change is extremely important in the sustainable development of mining cities. Large-scale opencast coal mining results in the destruction of built-up land, industrial land and mining land as well as arable land resources. Therefore, the analysis of changes in mineral resources and arable land use has attracted increasing attention. With the development of remote sensing (RS) and deep learning (DL) technology, many forms of data for detecting land-use changes are available. The goal of this paper is to promote coordinated land-use development. In this study, an ensemble feature pyramid convolutional neural network model (EFPCNNM) approach, which combines the theory of convolutional neural network (CNN), feature pyramid (FP) and ensemble learning (EL), was used to analyze land-use change in the Longmen Mountain opencast coal mine area in Anqing City, Huaining County, Anhui Province, China. Unlike the CNN, and ensemble convolutional neural network model (ECNNM), which only used the high-level features to predict the ground objects, and the feature information of other layers was not fully considered, EFPCNNM enhanced the small target information in high-level features and improved the detection performance of significant ground object. EFPCNNM was highly portable and could be embedded in many models to further boost performance. Comparative experiments on support vector machine (SVM), extreme learning machine (ELM), artificial neural network (ANN), CNN and ECNNM methods demonstrated that the EFPCNNM could exceed the other models in terms of detection accuracy and inference speed, e.g., the overall accuracy was 93.5036%, kappa coefficient was 0.9423, and time was 2.7569 s. Multitemporal RS images from eight periods starting in 2005 and ending in 2019 were used as the land-use data. With a typical classification system and RS quantitative analysis, this paper also evaluated the temporal and spatial changes in arable land use in the mining area. Of all the land-use types, the area of arable land decreased the most over the study period, and the area of mining land and construction land increased the most. In addition, changes in the seepage area associated with collapse sites in the study area were analyzed. The results of this change detection process could provide decision support for the coordinated development of land use and mineral resources in mining areas.
C1 [Ji, Haowei; Luo, Xianqi] Shanghai Jiao Tong Univ, Sch Naval Architecture Ocean & Civil Engn, Shanghai 200240, Peoples R China.
RP Ji, HW (corresponding author), Shanghai Jiao Tong Univ, Sch Naval Architecture Ocean & Civil Engn, Shanghai 200240, Peoples R China.
EM jihaowei@sjtu.edu.cn
FU National Key R&D Program of China [2016YFC0401908]
FX This work was supported in part by the National Key R&D Program of China
   (Grant No. 2016YFC0401908). The author would like to thank the anonymous
   reviewers for their constructive comments.
CR Agarwal R, 2017, J INDIAN SOC REMOTE, V45, P569, DOI 10.1007/s12524-016-0619-9
   Araya-Lopez RA, 2018, ISPRS J PHOTOGRAMM, V145, P213, DOI 10.1016/j.isprsjprs.2018.04.001
   Bai XY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111332
   Chen THK, 2020, REMOTE SENS ENVIRON, V251, DOI 10.1016/j.rse.2020.112096
   Delgado-Martin J, 2013, ENVIRON SCI POLLUT R, V20, P7520, DOI 10.1007/s11356-013-1618-9
   Fagiewicz K, 2019, QUAEST GEOGR, V38, P151, DOI 10.2478/quageo-2019-0046
   Fawcett TJ, 2020, J NEUROSCI METH, V344, DOI 10.1016/j.jneumeth.2020.108853
   Hashim AM, 2020, ENVIRON SCI POLLUT R, DOI 10.1007/s11356-020-10208-1
   Hou XY, 2015, J INDIAN SOC REMOTE, V43, P287, DOI 10.1007/s12524-014-0400-x
   Jiang Z, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3337798
   Joshi K, 2018, AMBIENT SCI, V5, P9, DOI 10.21276/ambi.2018.05.2.ra01
   Khurana M, 2020, IEEE GEOSCI REMOTE S, V17, P794, DOI 10.1109/LGRS.2019.2933906
   Kwinta A, 2020, INT J ROCK MECH MIN, V128, DOI 10.1016/j.ijrmms.2020.104263
   Li JT, 2018, J MT SCI-ENGL, V15, P394, DOI 10.1007/s11629-017-4542-5
   Lin CH, 2020, J SUPERCOMPUT, V76, P2503, DOI 10.1007/s11227-019-03012-3
   Losfeld G, 2015, ENVIRON SCI POLLUT R, V22, P5592, DOI 10.1007/s11356-014-3358-x
   MohanRajan SN, 2021, J INDIAN SOC REMOTE, V49, P913, DOI 10.1007/s12524-020-01258-6
   Mu L, 2019, IEEE J-STARS, V12, P5233, DOI 10.1109/JSTARS.2019.2956318
   Munyati C, 2011, AREA, V43, P189, DOI 10.1111/j.1475-4762.2010.00979.x
   Nath B, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10124631
   Nurzhanova A, 2019, ENVIRON SCI POLLUT R, V26, P13320, DOI 10.1007/s11356-019-04707-z
   Panigrahi S, 2019, SOFT COMPUT, V23, P7699, DOI 10.1007/s00500-018-3395-3
   Park JH, 2016, ENVIRON SCI POLLUT R, V23, P11814, DOI 10.1007/s11356-016-6335-8
   Pasha SV, 2016, J INDIAN SOC REMOTE, V44, P905, DOI 10.1007/s12524-016-0562-9
   Radhakrishnan N, 2017, J INDIAN SOC REMOTE, V45, P815, DOI 10.1007/s12524-016-0616-z
   Seydi ST, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122010
   Song X, 2020, ENVIRON RES LETT, V15, DOI 10.1088/1748-9326/ab94e8
   Sun HS, 2016, J INDIAN SOC REMOTE, V44, P11, DOI 10.1007/s12524-015-0471-3
   Yin NN, 2016, ENVIRON SCI POLLUT R, V23, P17840, DOI 10.1007/s11356-016-6941-5
   Zhang H, 2017, ENVIRON SCI POLLUT R, V24, P2890, DOI 10.1007/s11356-016-7988-z
   Zhang XK, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232787
   Zhang YH, 2017, J INDIAN SOC REMOTE, V45, P887, DOI 10.1007/s12524-016-0617-y
   Zhao HQ, 2019, SPECTROSC SPECT ANAL, V39, P1858, DOI 10.3964/j.issn.1000-0593(2019)06-1858-06
   Zhao YL, 2013, DISASTER ADV, V6, P125
   Zhu DY, 2020, ENVIRON SCI POLLUT R, V27, P15716, DOI 10.1007/s11356-020-08054-2
NR 35
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD NOV
PY 2021
VL 49
IS 11
BP 2875
EP 2890
DI 10.1007/s12524-021-01430-6
EA SEP 2021
PG 16
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA WR3GQ
UT WOS:000698095200001
DA 2022-01-04
ER

PT J
AU Saha, S
   Ebel, P
   Zhu, XX
AF Saha, Sudipan
   Ebel, Patrick
   Zhu, Xiao Xiang
TI Self-Supervised Multisensor Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Optical sensors; Optical imaging; Training; Earth; Synthetic aperture
   radar; Deep learning; Spatial resolution; Change detection (CD); deep
   learning; multisensor analysis; self-supervised learning
ID MULTIPLE-CHANGE DETECTION; CHANGE VECTOR ANALYSIS; DATA FUSION; IMAGES
AB Most change detection (CD) methods assume that prechange and postchange images are acquired by the same sensor. However, in many real-life scenarios, e.g., natural disasters, it is more practical to use the latest available images before and after the occurrence of incidence, which may be acquired using different sensors. In particular, we are interested in the combination of the images acquired by optical and synthetic aperture radar (SAR) sensors. SAR images appear vastly different from the optical images even when capturing the same scene. Adding to this, CD methods are often constrained to use only target image-pair, no labeled data, and no additional unlabeled data. Such constraints limit the scope of traditional supervised machine learning and unsupervised generative approaches for multisensor CD. The recent rapid development of self-supervised learning methods has shown that some of them can even work with only few images. Motivated by this, in this work, we propose a method for multisensor CD using only the unlabeled target bitemporal images that are used for training a network in a self-supervised fashion by using deep clustering and contrastive learning. The proposed method is evaluated on four multimodal bitemporal scenes showing change, and the benefits of our self-supervised approach are demonstrated. Code is available at https://gitlab.lrz.de/ai4eo/cd/-/tree/main/sarOpticalMultisensorTgrs2021.
C1 [Saha, Sudipan; Ebel, Patrick; Zhu, Xiao Xiang] Tech Univ Munich, Dept Aerosp & Geodesy, Data Sci Earth Observat, D-85521 Ottobrunn, Germany.
   [Zhu, Xiao Xiang] German Aerosp Ctr DLR, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
RP Zhu, XX (corresponding author), German Aerosp Ctr DLR, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
EM sudipan.saha@tum.de; patrick.ebel@tum.de; xiaoxiang.zhu@dlr.de
FU European Research Council (ERC) under the European UnionEuropean
   Research Council (ERC) [ERC-2016-StG714087]; Helmholtz Association
   through the Framework of Helmholtz Artificial Intelligence (AI)-Local
   Unit "Munich Unit at Aeronautics, Space and Transport (MASTr)"
   [ZT-I-PF-5-01]; Helmholtz Excellent Professorship "Data Science in Earth
   Observation-Big Data Fusion for Urban Research" [W2-W3-100]; German
   Federal Ministry of Education and Research (BMBF)Federal Ministry of
   Education & Research (BMBF) [01DD20001]
FX Manuscript received May 10, 2021; revised June 23, 2021 and July 21,
   2021; accepted July 25, 2021. This work was supported in part by the
   European Research Council (ERC) under the European Union's Horizon 2020
   Research and Innovation Programme (grant agreement No.
   [ERC-2016-StG714087], Project acronym: So2Sat), in part by the Helmholtz
   Association through the Framework of Helmholtz Artificial Intelligence
   (AI)-Local Unit "Munich Unit at Aeronautics, Space and Transport
   (MASTr)" under Grant ZT-I-PF-5-01, in part by the Helmholtz Excellent
   Professorship "Data Science in Earth Observation-Big Data Fusion for
   Urban Research" under Grant W2-W3-100, and in part by the German Federal
   Ministry of Education and Research (BMBF) in the framework of the
   international future AI Laboratory "AI4EO-Artificial Intelligence for
   Earth Observation: Reasoning, Uncertainties, Ethics and Beyond" under
   Grant 01DD20001. (Corresponding author: Xiao Xiang Zhu.)
CR Ahmed UI, 2020, PROC SPIE, V11535, DOI 10.1117/12.2579480
   Appice A., 2019, P CEUR WORKSH, V2466, P1
   Asano Y. M., ARXIV190413132
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bruzzone, 2020, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/ lgrs.2020.3043822, DOI 10.1109/LGRS.2020.3043822]
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Camps-Valls G., 2021, DEEP LEARNING EARTH
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen X., 2020, ARXIV PREPRINT ARXIV
   Chen X., 2020, ARXIV201110566
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Grill J.-B., 2020, ADV NEUR IN
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hirschmugl M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040727
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Keshk HM, 2020, INT J AERONAUT SPACE, V21, P549, DOI 10.1007/s42405-019-00222-0
   Komodakis N, 2018, INT C LEARN REPR
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Menapace W., 2020, ARXIV200804646
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Puhm M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193135
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Ruder, 2016, ARXIV160904747
   Saha S, 2020, IEEE T GEOSCI REMOTE, V58, P8780, DOI 10.1109/TGRS.2020.2990640
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P856, DOI 10.1109/LGRS.2020.2990284
   Saha S, 2019, LECT NOTES COMPUT SC, V11752, P499, DOI 10.1007/978-3-030-30645-8_46
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, INT GEOSCI REMOTE SE, P5033, DOI 10.1109/IGARSS.2019.8900173
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Schmitt M, 2016, IEEE GEOSC REM SEN M, V4, P6, DOI 10.1109/MGRS.2016.2561021
   Seydi ST, 2017, EUR J REMOTE SENS, V50, P517, DOI 10.1080/22797254.2017.1367963
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Simonyan K, 2014, ArXiv:1409.1556
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   TIAN Yonglong, 2020, 34 C NEUR INF PROC S
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Xu Y, 2013, PROC SPIE, V8919, DOI 10.1117/12.2031104
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhou N, 2021, IEEE J-STARS, V14, P1326, DOI 10.1109/JSTARS.2020.3038169
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 51
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3109957
EA SEP 2021
PG 10
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XT3AL
UT WOS:000733464700001
OA Green Accepted, Green Submitted, Bronze
DA 2022-01-04
ER

PT J
AU Zhang, X
   Su, X
   Yuan, QQ
   Wang, Q
AF Zhang, Xiao
   Su, Xin
   Yuan, Qiangqiang
   Wang, Qing
TI Spatial-Temporal Gray-Level Co-Occurrence Aware CNN for SAR Image Change
   Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Radar polarimetry; Feature extraction; Training; Speckle; Reliability;
   Synthetic aperture radar; Convolutional neural networks; 3-D gray-level
   co-occurrence matrix (3-D-GLCM); change detection; deep learning;
   synthetic aperture radar (SAR)
ID MATRIX; NETWORK
AB Deep learning-based synthetic aperture radar (SAR) image change detection has recently achieved remarkable success due to its great potential for extracting abstract features. However, the existing methods still have room for improvement in dealing with the speckle of SAR images. In this letter, a deep spatial-temporal gray-level co-occurrence aware convolutional neural network (STGCNet) is proposed, which can effectively mine the spatial-temporal information of the bitemporal images and obtain the speckle-robust results by introducing the 3-D gray-level co-occurrence matrix (3-D-GLCM) as auxiliary feature. Specifically, representative features are extracted from original image pairs and their corresponding 3-D-GLCM through two-stream network, followed by an adaptive fusion module to balance the contribution of each branch. Then, the final binary change detection results are obtained by a fully connected layer. The training process relies on reliable labels generated by unsupervised models rather than manually annotated data, and therefore, the proposed STGCNet is practical in reality. Experiments on synthesized and real SAR data sets demonstrate the robustness and competitiveness of the proposed method compared with the state-of-the-art algorithms.
C1 [Zhang, Xiao; Yuan, Qiangqiang] Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
   [Su, Xin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Yuan, Qiangqiang] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
   [Wang, Qing] Air Force Res Inst, Beijing 100085, Peoples R China.
RP Su, X (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM xiaozhang@whu.edu.cn; xinsu.rs@whu.edu.cn; qqyuan@sgg.whu.edu.cn;
   wangqing_rs@pku.edu.cn
FU Chang'an University, Xi'an, China, through the National Key Research and
   Development Program of China [2020YFC1512000]; Excellent Youth
   Foundation of Hubei Scientific Committee [2020CFA051]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61801332, 41901302]
FX This work was supported in part by Chang'an University, Xi'an, China,
   through the National Key Research and Development Program of China under
   Grant 2020YFC1512000, in part by the Excellent Youth Foundation of Hubei
   Scientific Committee under Grant 2020CFA051, and in part by the National
   Natural Science Foundation of China under Grant 61801332 and Grant
   41901302.
CR Aiazzi B, 2013, IEEE T GEOSCI REMOTE, V51, P2022, DOI 10.1109/TGRS.2013.2238946
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Luo B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232740
   Moya L, 2019, ISPRS J PHOTOGRAMM, V149, P14, DOI 10.1016/j.isprsjprs.2019.01.008
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Su X, 2015, ISPRS J PHOTOGRAMM, V101, P247, DOI 10.1016/j.isprsjprs.2014.12.012
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang XZ, 2021, ISPRS J PHOTOGRAMM, V173, P79, DOI 10.1016/j.isprsjprs.2021.01.004
NR 18
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3110302
EA SEP 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR6ZS
UT WOS:000732375100001
DA 2022-01-04
ER

PT J
AU Wang, SN
   Wang, YN
   Liu, Y
   Li, LL
AF Wang, Shaona
   Wang, Yanan
   Liu, Yang
   Li, Linlin
TI SAR image change detection based on sparse representation and a capsule
   network
SO REMOTE SENSING LETTERS
LA English
DT Article
AB Synthetic aperture radar (SAR) image change detection has good application prospects in the domain of remote sensing image processing. However, the accuracy of change detection is negatively affected by the inherent speckle noise in SAR images. To solve this problem, a method based on sparse representation (SR) and a capsule network is proposed. Firstly, sparse features of the difference image (DI) are extracted by the SR method. Secondly, a lightweight capsule network (L-CapsNet) is constructed, which is used to mine the spatial relationship between features. The network classifies the changed and unchanged pixels. Finally, the change map (CM) is generated. The proposed method can obtain more robust features while reducing the influence of speckle noise. Experiments are performed on four SAR data sets to compare the proposed method with related methods. The results confirm the superior performance of the proposed method.
C1 [Wang, Shaona; Wang, Yanan; Liu, Yang; Li, Linlin] Tiangong Univ, Tianjin Key Lab Optoelect Detect Technol & Syst, Sch Elect & Elect Engn, Tianjin, Peoples R China.
RP Wang, SN (corresponding author), Tiangong Univ, Sch Elect & Elect Engn, Tianjin, Peoples R China.
EM shaonaw@163.com
OI wang, shaona/0000-0003-1677-1048; Yanan, Wang/0000-0003-3379-7944
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61901297]; National Science Foundation in
   Tianjin Province of China [18JCQNJC70600]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant [61901297]; in part by the National
   Science Foundation in Tianjin Province of China under Grant
   [18JCQNJC70600].
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen JW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101619
   De Alban JDT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020306
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton Geoffrey E, 2011, INT C ART NEUR NETW
   Pati N, 2015, PROCEDIA COMPUT SCI, V48, P769, DOI 10.1016/j.procs.2015.04.213
   Quan SN, 2018, IEEE J-STARS, V11, P458, DOI 10.1109/JSTARS.2017.2787591
   Ren YF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12182866
   Sabour S., 2017, P ADV NEURAL INF PRO, P3859, DOI DOI 10.1371/JOURNAL.PONE.0035195
   Sumaiya MN, 2018, IET RADAR SONAR NAV, V12, P515, DOI 10.1049/iet-rsn.2017.0393
   Wang RF, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.036501
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wang SN, 2016, REMOTE SENS LETT, V7, P1043, DOI 10.1080/2150704X.2016.1212417
   Wang SN, 2016, IEEE J-STARS, V9, P3452, DOI 10.1109/JSTARS.2016.2547638
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zhou S, 2020, REMOTE SENS LETT, V11, P757, DOI 10.1080/2150704X.2020.1766722
NR 21
TC 1
Z9 1
U1 15
U2 15
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PD SEP 2
PY 2021
VL 12
IS 9
BP 890
EP 899
DI 10.1080/2150704X.2021.1946199
PG 10
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA TE0KB
UT WOS:000669705600001
DA 2022-01-04
ER

PT J
AU Jiang, XF
   Xiang, S
   Wang, M
   Tang, P
AF Jiang, Xiaofan
   Xiang, Shao
   Wang, Mi
   Tang, Peng
TI Dual-Pathway Change Detection Network Based on the Adaptive Fusion
   Module
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Decoding; Training; Encoding; Indexes; Fuses; Remote
   sensing; Adaptive fusion; auxiliary supervision; change detection (CD);
   deep learning; dual-pathway feature difference networks (FDNs)
AB In recent years, with the development of high-resolution remote sensing (RS) images and deep learning technology, high-quality source data and state-of-the-art methods have become increasingly available, and great progress has been made in change detection (CD) in RS fields. However, existing methods still suffer from weak network feature representation and poor CD performance. To address these problems, we propose a novel CD network, called dual-pathway CD network (DP-CD-Net), which can help enhance feature representation and achieve a more accurate difference map. The proposed method contains a dual-pathway feature difference network (FDN), an adaptive fusion module (AFM), and an auxiliary supervision strategy. Dual-pathway FDNs can effectively enhance feature representation by supplementing the detailed information from the encoding layers. Then, we use the AFM method to fuse the difference maps. To solve the problem of training difficulty, we use the auxiliary supervision strategy to improve the performance of DP-CD-Net. We conduct extensive experiments to validate the performance of the proposed method on the LEVIR-CD dataset. The results demonstrate that the proposed method performs better than existing methods.
C1 [Jiang, Xiaofan; Xiang, Shao; Wang, Mi] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
   [Tang, Peng] Tech Univ Munich, Dept Informat, D-80333 Munich, Germany.
RP Wang, M (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
EM jiangxiaofan2014@163.com; xiangshao@whu.edu.cn; wangmi@whu.edu.cn;
   tangp@in.tum.de
RI ; Xiang, Shao/V-3790-2018
OI TANG, Peng/0000-0003-4099-6677; Xiang, Shao/0000-0002-2797-1937
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61825103, 91838303, 91738302]
FX This work was supported by the National Natural Science Foundation of
   China under Project 61825103, Project 91838303, and Project 91738302.
CR Bao TF, 2020, IEEE GEOSCI REMOTE S, V17, P1797, DOI 10.1109/LGRS.2019.2955309
   Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen H, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3095166
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Sun S., 2020, IEEE GEOSCI REMOTE S, DOI [10.1109/LGRS.2020.3041530, DOI 10.1109/LGRS.2020.3041530]
   Yang SY, 2019, IEEE ACCESS, V7, P116413, DOI 10.1109/ACCESS.2019.2934983
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhu B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P55, DOI 10.1109/ICIVC.2018.8492747
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3103991
EA SEP 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR2ZZ
UT WOS:000732105200001
DA 2022-01-04
ER

PT J
AU Peng, XL
   Zhong, RF
   Li, Z
   Li, QY
AF Peng, Xueli
   Zhong, Ruofei
   Li, Zhen
   Li, Qingyang
TI Optical Remote Sensing Image Change Detection Based on Attention
   Mechanism and Image Difference
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Optical design; Optical computing; Network architecture; Feature
   extraction; Optical imaging; Optical network units; Data models;
   Attention mechanism; change detection; fully convolutional network;
   image difference; optical remote sensing image
ID RECURRENT NEURAL-NETWORKS; SLOW FEATURE ANALYSIS; CLASSIFICATION;
   ALGORITHMS
AB This study presents a new end-to-end change detection network, called difference-enhancement dense-attention convolutional neural network (DDCNN), that is designed for detection of changes in the bitemporal optical remote sensing images. To model the internal correlation between high-level and low-level features, a dense attention method consisting of several up-sampling attention units is proposed. Both the up-sampling spatial and up-sampling channel attention are adopted by the unit. The unit, which can use high-level features with rich category information to guide the selection of low-level features, can use the spatial context information to capture the changed features of ground objects. Furthermore, DDCNN also pays attention to the differentiating features of the bitemporal images. By introducing a DE unit, each pixel is weighted and the features are selectively aggregated. The combination of dense attention and the DE unit improves the effectiveness of the network and its accuracy in extracting the change features. The effectiveness of the proposed approach is demonstrated via five challenge data sets. The experimental results show that DDCNN achieves new state-of-the-art change detection performance on these five challenging data sets. For the seasonal change detection data set in particular, compared with the best existing change detection model, the proposed method increases the F1 score and IoU by 2.96% and 5.17%, respectively; compared with the baseline method, our method improved 3.75% and 6.50% on the F1 score and IoU, respectively.
C1 [Peng, Xueli; Zhong, Ruofei; Li, Zhen; Li, Qingyang] Capital Normal Univ, Acad Multidisciplinary Studies, Beijing Adv Innovat Ctr Imaging Technol, Minist Educ,Key Lab 3D Informat Acquisit & Applic, Beijing 100048, Peoples R China.
RP Zhong, RF (corresponding author), Capital Normal Univ, Acad Multidisciplinary Studies, Beijing Adv Innovat Ctr Imaging Technol, Minist Educ,Key Lab 3D Informat Acquisit & Applic, Beijing 100048, Peoples R China.
EM xuelipeng@cnu.edu.cn; zrf@cnu.edu.cn; sdlz123@126.com; 779477922@qq.com
OI Li, Zhen/0000-0002-0704-7499; Peng, Xueli/0000-0002-0613-7230; li,
   qingyang/0000-0003-2602-9250; ruofei, Zhong/0000-0002-6064-4479
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42071444]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 42071444.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J., 2020, DASNET DUAL ATTENTIV, DOI DOI 10.1109/JSTARS.2020.3037893
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du PJ, 2020, ISPRS J PHOTOGRAMM, V161, P278, DOI 10.1016/j.isprsjprs.2020.01.026
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo E., 2018, ARXIV181009111
   Huang LC, 2010, INT ASIA CONF INFORM, P258, DOI 10.1109/CAR.2010.5456680
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Kesikoglu MH, 2013, INT ARCH PHOTOGRAMM, V40-7-W2, P129, DOI 10.5194/isprsarchives-XL-7-W2-129-2013
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lefebvre A., 2008, P IEEE INT GEOSC REM, VVolume 4, pIV, DOI [10.1109/IGARSS.2008.4779809, DOI 10.1109/IGARSS.2008.4779809]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Lu P, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.111235
   MARCHESI S, 2009, P IEEE INT GEOSC REM, V2, P890
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Robertson LD, 2011, INT J REMOTE SENS, V32, P1505, DOI 10.1080/01431160903571791
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L., 2018, ARXIV180510180
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Zhan, 2016, J COMPUT THEOR NANOS, V13, P3757, DOI DOI 10.1166/jctn.2016.5208
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 51
TC 4
Z9 4
U1 12
U2 12
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2021
VL 59
IS 9
BP 7296
EP 7307
DI 10.1109/TGRS.2020.3033009
PG 12
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA UJ0EQ
UT WOS:000690968800017
DA 2022-01-04
ER

PT J
AU Shao, RZ
   Du, C
   Chen, H
   Li, J
AF Shao, Ruizhe
   Du, Chun
   Chen, Hao
   Li, Jun
TI SUNet: Change Detection for Heterogeneous Remote Sensing Images from
   Satellite and UAV Using a Dual-Channel Fully Convolution Network
SO REMOTE SENSING
LA English
DT Article
DE change detection; remote sensing; heterogeneous images; deep learning;
   fully convolution network
AB Change Detection in heterogeneous remote sensing images plays an increasingly essential role in many real-world applications, e.g., urban growth tracking, land use monitoring, disaster evaluation and damage assessment. The objective of change detection is to identify changes of geo-graphical entities or phenomena through two or more bitemporal images. Researchers have invested a lot in the homologous change detection and yielded fruitful results. However, change detection between heterogenous remote sensing images is still a great challenge, especially for change detection of heterogenous remote sensing images obtained from satellites and Unmanned Aerial Vehicles (UAV). The main challenges in satellite-UAV change detection tasks lie in the intensive difference of color for the same ground objects, various resolutions, the parallax effect and image distortion caused by different shooting angles and platform altitudes. To address these issues, we propose a novel method based on dual-channel fully convolution network. First, in order to alleviate the influence of differences between heterogeneous images, we employ two different channels to map heterogeneous remote sensing images from satellite and UAV, respectively, to a mutual high dimension latent space for the downstream change detection task. Second, we adopt Hough method to extract the edge of ground objects as auxiliary information to help the change detection model to pay more attention to shapes and contours, instead of colors. Then, IoU-WCE loss is designed to deal with the problem of imbalanced samples in change detection task. Finally, we conduct extensive experiments to verify the proposed method using a new Satellite-UAV heterogeneous image data set, named HTCD, which is annotated by us and has been open to public. The experimental results show that our method significantly outperforms the state-of-the-art change detection methods.
C1 [Shao, Ruizhe; Du, Chun; Chen, Hao; Li, Jun] Natl Univ Def Technol, Coll Elect Sci & Technol, Dept Cognit Commun, Changsha 410000, Peoples R China.
RP Chen, H (corresponding author), Natl Univ Def Technol, Coll Elect Sci & Technol, Dept Cognit Commun, Changsha 410000, Peoples R China.
EM shaoruizhe@nudt.edu.cn; duchun@nudt.edu.cn; hchen@nudt.edu.cn;
   junli@nudt.edu.cn
OI Chen, Hao/0000-0002-7880-3394
FU Chinese National Natural Science Foundation of [Grant number Chinese
   National Natural Science Foundation] [61806211, 41971362]; Natural
   Science Foundation of Hunan Province ChinaNatural Science Foundation of
   Hunan Province [2020JJ4103]
FX The work is supported by the Chinese National Natural Science Foundation
   of [Grant number Chinese National Natural Science Foundation, Grant
   number 61806211, Grant number 41971362] and Natural Science Foundation
   of Hunan Province China (Grant 2020JJ4103).
CR Ansari RA, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100418
   Ayhan B., P IEEE UB COMP EL MO, P10
   Boyle R., 2014, IMAGE PROCESSING ANA
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Caliva F., 2020, ARXIV2020190803679
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Chen H., 2021, IEEE WINT CONF APPL, P1, DOI [10.1109/TGRS.2021.3066802, DOI 10.1049/rpg2.12114, DOI 10.1109/WACV48630.2021.00005]
   Chen H., 2020, ARXIV2020210300208
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Jiang X, 2020, IEEE J-STARS, V13, P1551, DOI 10.1109/JSTARS.2020.2983993
   Kwan C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202377
   Li C., P IOP C SER EARTH EN, P012166
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu T, 2018, REMOTE SENS ENVIRON, V216, P328, DOI 10.1016/j.rse.2018.06.031
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Lu M, 2016, REMOTE SENS ENVIRON, V184, P374, DOI 10.1016/j.rse.2016.07.028
   Ma J., 2020, ARXIV2020200513449
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Pang SY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040966
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Radhika K, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1484587
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Reigber A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111710
   Sefrin O, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010078
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun YT, 2021, INT REV IMMUNOL, DOI 10.1080/08830185.2021.1897124
   Taghanaki SA, 2019, COMPUT MED IMAG GRAP, V75, P24, DOI 10.1016/j.compmedimag.2019.04.005
   Thonfeld F, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071057
   Tian S., 2020, ARXIV2020201103247
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Wang L, 2020, IEEE ACCESS, V8, P167939, DOI 10.1109/ACCESS.2020.3020475
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Weber E., 2020, ARXIV2020200405525
   Wolniewicz W., 2004, INT ARCH PHOTOGRAMM, V35, P19
   Wong KCL, 2018, LECT NOTES COMPUT SC, V11072, P612, DOI 10.1007/978-3-030-00931-1_70
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu J., 2020, ARXIV2020210208041
   Yan Z., P IGARSS 2020 2020 I, P2906
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zongjian L., 2008, INT ARCH PHOTOGRAMME, V37, P1183
NR 51
TC 0
Z9 0
U1 32
U2 32
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2021
VL 13
IS 18
AR 3750
DI 10.3390/rs13183750
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UY3RV
UT WOS:000701445800001
OA gold
DA 2022-01-04
ER

PT J
AU Diakogiannis, FI
   Waldner, F
   Caccetta, P
AF Diakogiannis, Foivos I.
   Waldner, Francois
   Caccetta, Peter
TI Looking for Change? Roll the Dice and Demand Attention
SO REMOTE SENSING
LA English
DT Article
DE semantic segmentation; change detection; deep learning; attention;
   convolutional neural networks; dice similarity
ID SEGMENTATION
AB Change detection, i.e., the identification per pixel of changes for some classes of interest from a set of bi-temporal co-registered images, is a fundamental task in the field of remote sensing. It remains challenging due to unrelated forms of change that appear at different times in input images. Here, we propose a deep learning framework for the task of semantic change detection in very high-resolution aerial images. Our framework consists of a new loss function, a new attention module, new feature extraction building blocks, and a new backbone architecture that is tailored for the task of semantic change detection. Specifically, we define a new form of set similarity that is based on an iterative evaluation of a variant of the Dice coefficient. We use this similarity metric to define a new loss function as well as a new, memory efficient, spatial and channel convolution Attention layer: the FracTAL. We introduce two new efficient self-contained feature extraction convolution units: the CEECNet and FracTALResNet units. Further, we propose a new encoder/decoder scheme, a network macro-topology, that is tailored for the task of change detection. The key insight in our approach is to facilitate the use of relative attention between two convolution layers in order to fuse them. We validate our approach by showing excellent performance and achieving state-of-the-art scores (F1 and Intersection over Union-hereafter IoU) on two building change detection datasets, namely, the LEVIRCD (F1: 0.918, IoU: 0.848) and the WHU (F1: 0.938, IoU: 0.882) datasets.
C1 [Diakogiannis, Foivos I.] Univ Western Australia, Int Ctr Radioastron Res, Perth, WA 6021, Australia.
   [Diakogiannis, Foivos I.; Caccetta, Peter] CSIRO, Data61, Kensington, WA 6151, Australia.
   [Waldner, Francois] CSIRO Agr & Food, St Lucia, Qld 4067, Australia.
   [Diakogiannis, Foivos I.] 3 Ken & Julie Michael Bldg,7 Fairway, Perth, WA 6009, Australia.
RP Diakogiannis, FI (corresponding author), Univ Western Australia, Int Ctr Radioastron Res, Perth, WA 6021, Australia.; Diakogiannis, FI (corresponding author), CSIRO, Data61, Kensington, WA 6151, Australia.
EM foivos.diakogiannis@uwa.edu.au; Franz.WALDNER@ec.europa.eu;
   peter.caccetta@data61.csiro.au
RI Diakogiannis, Foivos/D-6267-2019
OI Diakogiannis, Foivos/0000-0002-8788-8174; Caccetta,
   Peter/0000-0002-9693-7927; Waldner, Francois/0000-0002-5599-7456
FU CSIROCommonwealth Scientific & Industrial Research Organisation (CSIRO)
FX The project was funded by CSIRO.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Bengio, 2014, ARXIV14091259, P103, DOI 10.3115/v1/w14-4012
   Bengio Y., 2014, ARXIV PREPRINT ARXIV, DOI DOI 10.1146/ANNUREV.NEURO.26.041002.131047
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Del Balso, 2018, ARXIV180205799
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Dosovitskiy A., 2020, ARXIV201011929
   Emmerich MTM, 2018, NAT COMPUT, V17, P585, DOI 10.1007/s11047-018-9685-y
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Guo E., 2018, ARXIV181009111
   Haghighi S., 2018, J OPEN SOURCE SOFTW, V3, P729, DOI [10.21105/joss.00729, DOI 10.21105/JOSS.00729]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hinton, 2009, TECHNICAL REPORT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Katharopoulos A, 2020, PR MACH LEARN RES, V119
   Kim YJ, 2017, ARXIV170200887
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Li R., 2020, ARXIV201114302
   Lindeberg T, 1994, SCALE SPACE THEORY C
   Liu JY, 2020, INT J REMOTE SENS, V41, P5573, DOI 10.1080/01431161.2020.1734251
   Liu Y., 2019, ARXIV190907726
   Low F, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020159
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lucic M., 2018, ARXIV181205069
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Morton DC, 2005, EARTH INTERACT, V9
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakurada K, 2015, P BMVC, P61
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Smola AJ, 2020, DIVE DEEP LEARNING
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Varghese A., 2018, P EUR C COMP VIS ECC
   Vaswani A, 2017, ADV NEUR IN, V30
   Waldner F, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13112197
   Waldner F, 2020, REMOTE SENS ENVIRON, V245, DOI 10.1016/j.rse.2020.111741
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI [10.1109/TPAMI.2020.2982166, 10.1109/LGRS.2020.3027363]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Zhang H., 2018, ARXIV180508318, DOI DOI 10.5194/ACP-2018-720
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhaobin Cao, 2020, IOP Conference Series: Earth and Environmental Science, V502, DOI 10.1088/1755-1315/502/1/012017
NR 61
TC 1
Z9 1
U1 5
U2 5
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2021
VL 13
IS 18
AR 3707
DI 10.3390/rs13183707
PG 40
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UW5DC
UT WOS:000700175300001
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Li, LL
   Ma, HB
   Jia, ZH
AF Li, Liangliang
   Ma, Hongbing
   Jia, Zhenhong
TI Change Detection from SAR Images Based on Convolutional Neural Networks
   Guided by Saliency Enhancement
SO REMOTE SENSING
LA English
DT Article
DE synthetic aperture radar image; change detection; saliency detection;
   convolutional-wavelet neural networks; hierarchical fuzzy c-means
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION; SPECKLE
   REDUCTION; WAVELET TRANSFORM; NONLOCAL MEANS; FUSION; PCANET; MODEL
AB Change detection is an important task in identifying land cover change in different periods. In synthetic aperture radar (SAR) images, the inherent speckle noise leads to false changed points, and this affects the performance of change detection. To improve the accuracy of change detection, a novel automatic SAR image change detection algorithm based on saliency detection and convolutional-wavelet neural networks is proposed. The log-ratio operator is adopted to generate the difference image, and the speckle reducing anisotropic diffusion is used to enhance the original multitemporal SAR images and the difference image. To reduce the influence of speckle noise, the salient area that probably belongs to the changed object is obtained from the difference image. The saliency analysis step can remove small noise regions by thresholding the saliency map, and interest regions can be preserved. Then an enhanced difference image is generated by combing the binarized saliency map and two input images. A hierarchical fuzzy c-means model is applied to the enhanced difference image to classify pixels into the changed, unchanged, and intermediate regions. The convolutional-wavelet neural networks are used to generate the final change map. Experimental results on five SAR data sets indicated the proposed approach provided good performance in change detection compared to state-of-the-art relative techniques, and the values of the metrics computed by the proposed method caused significant improvement.
C1 [Li, Liangliang; Ma, Hongbing] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
RP Ma, HB (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM leeliangliang@tsinghua.edu.cn; hbma@tsinghua.edu.cn; jzhh@xju.edu.cn
OI Ma, Hongbing/0000-0002-1785-4024
FU Shanghai Aerospace Science and Technology Innovation Fund [SAST2019-048]
FX This work was supported by the Shanghai Aerospace Science and Technology
   Innovation Fund under Grant No. SAST2019-048.
CR Argenti F, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2277512
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen H, 2021, INT J REMOTE SENS, V42, P2686, DOI 10.1080/01431161.2020.1862437
   Chen PY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061295
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Devapal D, 2017, J INDIAN SOC REMOTE, V45, P443, DOI 10.1007/s12524-016-0607-0
   Dong H., 2021, IEEE T IND INFORM, P1, DOI [10.1109/tgrs.2021.3073562, DOI 10.1109/TII.2021.3090036]
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Farhadiani R, 2019, IEEE J-STARS, V12, P1489, DOI 10.1109/JSTARS.2019.2907655
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gao YH, 2018, INT GEOSCI REMOTE SE, P7320, DOI 10.1109/IGARSS.2018.8519461
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Hao M, 2016, INT J REMOTE SENS, V37, P4276, DOI 10.1080/01431161.2016.1210838
   He YX, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13152969
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hu T, 2021, IEEE T GEOSCI REMOTE, V59, P1516, DOI 10.1109/TGRS.2020.2999634
   Huo JY, 2021, J APPL REMOTE SENS, V15, DOI 10.1117/1.JRS.15.016506
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Jung J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020265
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li LL, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050591
   Li LL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051756
   Li LL, 2021, MULTIMED TOOLS APPL, V80, P12389, DOI 10.1007/s11042-020-10462-y
   Li LL, 2020, MULTIMED TOOLS APPL, V79, P24303, DOI 10.1007/s11042-020-09154-4
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li ST, 2012, IEEE GEOSCI REMOTE S, V9, P836, DOI 10.1109/LGRS.2011.2182632
   Li Z, 2020, ISPRS J PHOTOGRAMM, V163, P137, DOI 10.1016/j.isprsjprs.2020.03.002
   Liu LY, 2019, IEEE ACCESS, V7, P43970, DOI 10.1109/ACCESS.2019.2908282
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Liu YF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020551
   Lou XM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051179
   Ma JJ, 2012, IEEE GEOSCI REMOTE S, V9, P1122, DOI 10.1109/LGRS.2012.2191387
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Majidi M, 2020, INT J REMOTE SENS, V41, P9606, DOI 10.1080/01431161.2020.1826066
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Shang RH, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046017
   Shao P, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163171
   Sharma A, 2018, SMART INNOV SYST TEC, V84, P412, DOI 10.1007/978-3-319-63645-0_47
   Shen FY, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.016517
   Su LZ, 2014, INT J REMOTE SENS, V35, P7673, DOI 10.1080/01431161.2014.975378
   Sumaiya MN, 2016, IEEE GEOSCI REMOTE S, V13, P1726, DOI 10.1109/LGRS.2016.2606119
   Wang C, 2021, INT J REMOTE SENS, V42, P2246, DOI 10.1080/2150704X.2020.1805134
   Wang X, 2018, PROC SPIE, V10615, DOI 10.1117/12.2305510
   Wang XG, 2017, REMOTE SENS LETT, V8, P214, DOI 10.1080/2150704X.2016.1258125
   Wu TJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010174
   Wu TJ, 2018, IEEE GEOSCI REMOTE S, V15, P63, DOI 10.1109/LGRS.2017.2773118
   Yang G, 2019, IEEE T GEOSCI REMOTE, V57, P8890, DOI 10.1109/TGRS.2019.2923643
   Yang L, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13173394
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI [10.1109/TIP.2002.804276, 10.1109/TIP.2002.804279]
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030548
   Zhang Y, 2018, IEEE J-STARS, V11, P4701, DOI 10.1109/JSTARS.2018.2866540
   Zhang Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244182
   Zhao JX, 2021, IEEE ACCESS, V9, P4673, DOI 10.1109/ACCESS.2020.3047915
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
   Zhou WY, 2018, EUR J REMOTE SENS, V51, P785, DOI 10.1080/22797254.2018.1491804
   Zhou YY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212462
NR 66
TC 0
Z9 0
U1 14
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2021
VL 13
IS 18
AR 3697
DI 10.3390/rs13183697
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UW4AQ
UT WOS:000700101300001
OA gold
DA 2022-01-04
ER

PT J
AU Ke, QT
   Zhang, P
AF Ke, Qingtian
   Zhang, Peng
TI MCCRNet: A Multi-Level Change Contextual Refinement Network for Remote
   Sensing Image Change Detection
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE image change detection; attention mechanism; multi-level feature fusing;
   pixel contextual representation
ID CONVOLUTIONAL NEURAL-NETWORK
AB Change detection based on bi-temporal remote sensing images has made significant progress in recent years, aiming to identify the changed and unchanged pixels between a registered pair of images. However, most learning-based change detection methods only utilize fused high-level features from the feature encoder and thus miss the detailed representations that low-level feature pairs contain. Here we propose a multi-level change contextual refinement network (MCCRNet) to strengthen the multi-level change representations of feature pairs. To effectively capture the dependencies of feature pairs while avoiding fusing them, our atrous spatial pyramid cross attention (ASPCA) module introduces a crossed spatial attention module and a crossed channel attention module to emphasize the position importance and channel importance of each feature while simultaneously keeping the scale of input and output the same. This module can be plugged into any feature extraction layer of a Siamese change detection network. Furthermore, we propose a change contextual representations (CCR) module from the perspective of the relationship between the change pixels and the contextual representation, named change region contextual representations. The CCR module aims to correct changed pixels mistakenly predicted as unchanged by a class attention mechanism. Finally, we introduce an effective sample number adaptively weighted loss to solve the class-imbalanced problem of change detection datasets. On the whole, compared with other attention modules that only use fused features from the highest feature pairs, our method can capture the multi-level spatial, channel, and class context of change discrimination information. The experiments are performed with four public change detection datasets of various image resolutions. Compared to state-of-the-art methods, our MCCRNet achieved superior performance on all datasets (i.e., LEVIR, Season-Varying Change Detection Dataset, Google Data GZ, and DSIFN) with improvements of 0.47%, 0.11%, 2.62%, and 3.99%, respectively.
C1 [Ke, Qingtian; Zhang, Peng] Sun Yat Sen Univ, Sch Elect & Commun Engn, Shenzhen 518107, Peoples R China.
RP Zhang, P (corresponding author), Sun Yat Sen Univ, Sch Elect & Commun Engn, Shenzhen 518107, Peoples R China.
EM keqt3@mail2.sysu.edu.cn; zhangpeng5@mail.sysu.edu.cn
FU Shenzhen Science and Technology Program [KQTD20190929172704911]
FX This research was supported by the Shenzhen Science and Technology
   Program, grant number KQTD20190929172704911.
CR Bao TF, 2020, IEEE GEOSCI REMOTE S, V17, P1797, DOI 10.1109/LGRS.2019.2955309
   Carranza-Garcia M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Darrell T., P IEEE C COMP VIS PA
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   [范大昭 Fan Dazhao], 2018, [测绘学报, Acta Geodetica et Cartographica Sinica], V47, P844
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Fang S, 2021, IEEE GEOSCI REMOTE S, DOI 10.1109/LGRS.2021.3056416
   Fernandez A., 2018, LEARNING IMBALANCED, P63
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gang S., P IEEE C COMP VIS PA
   Han ZM, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9080478
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuo CL, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10060377
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Liu WS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020559
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Lu EHC, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9020074
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Pelillo, 2020, ARXIV201005687
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ren Y, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050813
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saeed, 2018, J APPL EMERG SCI, V8, P32
   Shao JY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101670
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Simonyan K, 2014, ArXiv:1409.1556
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Wu CY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13050905
   Ye Z, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040696
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang XW, 2021, IEEE GEOSCI REMOTE S, DOI [10.1109/LGRS.2021.3049370, 10.1002/er.6410]
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 54
TC 0
Z9 0
U1 12
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. J. Geo-Inf.
PD SEP
PY 2021
VL 10
IS 9
AR 591
DI 10.3390/ijgi10090591
PG 24
WC Computer Science, Information Systems; Geography, Physical; Remote
   Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA UV5LU
UT WOS:000699520500001
OA gold
DA 2022-01-04
ER

PT J
AU Yang, L
   Chen, YM
   Song, SJ
   Li, F
   Huang, G
AF Yang, Le
   Chen, Yiming
   Song, Shiji
   Li, Fan
   Huang, Gao
TI Deep Siamese Networks Based Change Detection with Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE change detection; remote sensing; semantic segmentation; deep neural
   network
ID UNSUPERVISED CHANGE DETECTION; SAR IMAGES; FUSION; MODEL
AB Although considerable success has been achieved in change detection on optical remote sensing images, accurate detection of specific changes is still challenging. Due to the diversity and complexity of the ground surface changes and the increasing demand for detecting changes that require high-level semantics, we have to resort to deep learning techniques to extract the intrinsic representations of changed areas. However, one key problem for developing deep learning metho for detecting specific change areas is the limitation of annotated data. In this paper, we collect a change detection dataset with 862 labeled image pairs, where the urban construction-related changes are labeled. Further, we propose a supervised change detection method based on a deep siamese semantic segmentation network to handle the proposed data effectively. The novelty of the method is that the proposed siamese network treats the change detection problem as a binary semantic segmentation task and learns to extract features from the image pairs directly. The siamese architecture as well as the elaborately designed semantic segmentation networks significantly improve the performance on change detection tasks. Experimental results demonstrate the promising performance of the proposed network compared to existing approaches.
C1 [Yang, Le; Li, Fan] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
   [Chen, Yiming; Song, Shiji; Huang, Gao] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
RP Yang, L (corresponding author), Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China.
EM yangle15@xjtu.edu.cn; chenyimi15@mails.tsinghua.edu.cn;
   shijis@mail.tsinghua.edu.cn; lifan@mail.xjtu.edu.cn;
   gaohuang@tsinghua.edu.cn
OI Huang, Gao/0000-0002-7251-0988; Li, Fan/0000-0002-7566-1634; Yang,
   Le/0000-0001-8379-4915
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1903213, 41427806]; Key Projects of
   Ministry of Science and Technology of China [2016YFB1200203]
FX This research was supported by National Natural Science Foundation of
   China: U1903213, National Natural Science Foundation of China: 41427806
   and Key Projects of Ministry of Science and Technology of China:
   2016YFB1200203.
CR Arguello F, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142687
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bock Michael, 2005, Journal for Nature Conservation (Jena), V13, P75, DOI 10.1016/j.jnc.2004.12.002
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2018, GISCI REMOTE SENS, V55, P159, DOI 10.1080/15481603.2018.1426092
   Chen G, 2014, ISPRS J PHOTOGRAMM, V87, P19, DOI 10.1016/j.isprsjprs.2013.10.007
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen K., 2008, P IGARSS 2008 2008 I, VVolume 3, pIII
   Chen L., 2014, COMPUT ENCE, P357
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Darrell, 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Silveira EMD, 2018, INT J REMOTE SENS, V39, P2597, DOI 10.1080/01431161.2018.1430397
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hinton G.E., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lei T, 2019, INT CONF ACOUST SPEE, P3027, DOI 10.1109/ICASSP.2019.8682802
   Li X., 2021, IEEE T GEOSCI ELECT, DOI [10.1109/TGRS.2021.3051383, DOI 10.1109/TGRS.2021.3051383]
   Li XY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142740
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Ma JJ, 2012, IEEE GEOSCI REMOTE S, V9, P1122, DOI 10.1109/LGRS.2012.2191387
   Miron A, 2015, INT CONF SYST SIGNAL, P273, DOI 10.1109/IWSSIP.2015.7314229
   Moser G, 2012, INT GEOSCI REMOTE SE, P1984, DOI 10.1109/IGARSS.2012.6351112
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ponce J, 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tison C, 2004, IEEE T GEOSCI REMOTE, V42, P2046, DOI 10.1109/TGRS.2004.834630
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xu QF, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142646
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 53
TC 1
Z9 1
U1 40
U2 40
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2021
VL 13
IS 17
AR 3394
DI 10.3390/rs13173394
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UO2IJ
UT WOS:000694523100001
OA gold
DA 2022-01-04
ER

PT J
AU Papadomanolaki, M
   Vakalopoulou, M
   Karantzalos, K
AF Papadomanolaki, Maria
   Vakalopoulou, Maria
   Karantzalos, Konstantinos
TI A Deep Multitask Learning Framework Coupling Semantic Segmentation and
   Fully Convolutional LSTM Networks for Urban Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; deep learning; long short-term memory networks
   (LSTMs); multitemporal; remote sensing; satellite; urban
ID REMOTE-SENSING IMAGES; NEURAL-NETWORKS; CLASSIFICATION; DYNAMICS
AB In this article, we present a deep multitask learning framework able to couple semantic segmentation and change detection using fully convolutional long short-term memory (LSTM) networks. In particular, we present a UNet-like architecture (L-UNet) that models the temporal relationship of spatial feature representations using integrated fully convolutional LSTM blocks on top of every encoding level. In this way, the network is able to capture the temporal relationship of spatial feature vectors in all encoding levels without the need to downsample or flatten them, forming an end-to-end trainable framework. Moreover, we further enrich the L-UNet architecture with an additional decoding branch that performs semantic segmentation on the available semantic categories that are presented in the different input dates, forming a multitask framework. Different loss quantities are also defined and combined together in a circular way to boost the overall performance. The developed methodology has been evaluated on three different data sets, i.e., the challenging bitemporal high-resolution Office National d'Etudes et de Recherches Aerospatiales (ONERA) Satellite Change Detection (OSCD) Sentinel-2 data set, the very high-resolution (VHR) multitemporal data set of the East Prefecture of Attica, Greece, and finally, the multitemporal VHR SpaceNet7 data set. Promising quantitative and qualitative results demonstrated that the synergy among the tasks can boost up the achieved performances. In particular, the proposed multitask framework contributed to a significant decrease in false-positive detections, with the F1 rate outperforming other state-of-the-art methods by at least 2.1% and 4.9% in the Attica VHR and SpaceNet7 data set cases, respectively. Our models and code can be found at https://github.com/mpapadomanolaki/multi-task-L-UNet.
C1 [Papadomanolaki, Maria; Karantzalos, Konstantinos] Natl Tech Univ Athens, Remote Sensing Lab, Zografos 15780, Greece.
   [Papadomanolaki, Maria; Vakalopoulou, Maria] Univ Paris Saclay, MICS Lab, Cent Supelec, F-91190 Gif Sur Yvette, France.
   [Vakalopoulou, Maria] Inria Saclay, F-91120 Gif Sur Yvette, France.
RP Papadomanolaki, M (corresponding author), Natl Tech Univ Athens, Remote Sensing Lab, Zografos 15780, Greece.; Papadomanolaki, M (corresponding author), Univ Paris Saclay, MICS Lab, Cent Supelec, F-91190 Gif Sur Yvette, France.
EM mar.papadomanolaki@gmail.com
RI Karantzalos, Konstantinos/ABF-4614-2021; Karantzalos,
   Konstantinos/AAL-3858-2021
OI Karantzalos, Konstantinos/0000-0001-8730-6245; Papadomanolaki,
   Maria/0000-0003-2125-9524
FU Research Committee of the National Technical University of Athens
   through Scholarship Grant
FX This work was supported by the Research Committee of the National
   Technical University of Athens through Scholarship Grant.
CR Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Benedek C, 2015, ISPRS J PHOTOGRAMM, V107, P22, DOI 10.1016/j.isprsjprs.2015.02.006
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977
   Chehata N., 2019, ARXIV191107757
   Chen J., 2016, ADV NEURAL INF PROCE, P3036
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Ebrahimzadeh Z., 2019, ARXIV190506913
   Ehsani K, 2018, PROC CVPR IEEE, P4051, DOI 10.1109/CVPR.2018.00426
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Gomez-Chova L, 2015, P IEEE, V103, P1560, DOI 10.1109/JPROC.2015.2449668
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Huang BH, 2018, INT GEOSCI REMOTE SE, P6947, DOI 10.1109/IGARSS.2018.8518525
   Huang X, 2020, REMOTE SENS ENVIRON, V244, DOI 10.1016/j.rse.2020.111802
   Karantzalos K, 2015, GEOTECH ENVIRON, V13, P237, DOI 10.1007/978-3-319-11469-9_10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JY, 2019, NATL SCI REV, V6, P1082, DOI 10.1093/nsr/nwz058
   Li X, 1998, INT J REMOTE SENS, V19, P1501, DOI 10.1080/014311698215315
   Li XC, 2018, REMOTE SENS ENVIRON, V216, P674, DOI 10.1016/j.rse.2018.07.030
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu Y., 2019, ARXIV190907726
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Marmanis D, 2016, ISPRS ANN PHOTO REM, V3, P473, DOI 10.5194/isprsannals-III-3-473-2016
   Milan A, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4225
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P7557, DOI 10.1109/TGRS.2020.2979552
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Ng JYH, 2018, IEEE WINT CONF APPL, P1606, DOI 10.1109/WACV.2018.00179
   Pacifici F, 2010, IEEE GEOSCI REMOTE S, V7, P58, DOI 10.1109/LGRS.2009.2021780
   Papadomanolaki M, 2016, ISPRS ANN PHOTO REM, V3, P83, DOI 10.5194/isprsannals-III-7-83-2016
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P1069, DOI 10.1109/IGARSS.2019.8898133
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060684
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Pratola C, 2013, IEEE T GEOSCI REMOTE, V51, P2055, DOI 10.1109/TGRS.2012.2236846
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Radoi A, 2019, IEEE J-STARS, V12, P2121, DOI 10.1109/JSTARS.2019.2916838
   Ru&beta;wurm M., 2019, ARXIV191010536
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Russwurm M., 2018, ARXIV181102471
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7040129
   Saha S., 2020, IEEE GEOSCI REMOTE S
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh B, 2016, PROC CVPR IEEE, P1961, DOI 10.1109/CVPR.2016.216
   Singh P, 2014, INT C PATT RECOG, P924, DOI 10.1109/ICPR.2014.169
   Song XP, 2016, REMOTE SENS ENVIRON, V175, P1, DOI 10.1016/j.rse.2015.12.027
   Stent S., 2015, BRIT MACH VIS C SWAN, P127
   Tan CW, 2018, I S BIOMED IMAGING, P1221, DOI 10.1109/ISBI.2018.8363791
   Taneja A, 2013, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2013.22
   Teimouri N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080990
   Vakalopoulou M, 2018, LECT NOTES COMPUT SC, V11073, P658, DOI 10.1007/978-3-030-00937-3_75
   Vakalopoulou M, 2016, INT GEOSCI REMOTE SE, P1827, DOI 10.1109/IGARSS.2016.7729469
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Vakalopoulou Maria, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P61, DOI 10.1109/CVPRW.2015.7301384
   Volpi M, 2012, IEEE GEOSCI REMOTE S, V9, P1026, DOI 10.1109/LGRS.2012.2189092
   Xingjian S., 2015, P 28 INT C NEUR INF, V1, P802, DOI DOI 10.1007/978-3-319-21233-3_6
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P475, DOI 10.1109/TPAMI.2018.2881114
NR 70
TC 2
Z9 2
U1 24
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2021
VL 59
IS 9
BP 7651
EP 7668
DI 10.1109/TGRS.2021.3055584
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA UJ0EQ
UT WOS:000690968800042
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Li, XH
   Du, ZS
   Huang, YY
   Tan, ZY
AF Li, Xinghua
   Du, Zhengshun
   Huang, Yanyuan
   Tan, Zhenyu
TI A deep translation (GAN) based change detection network for optical and
   SAR remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Deep translation; Depthwise separable convolution;
   GAN; Multi-scale loss; Optical and SAR images
ID CLASSIFICATION; SHANGHAI
AB With the development of space-based imaging technology, a larger and larger number of images with different modalities and resolutions are available. The optical images reflect the abundant spectral information and geometric shape of ground objects, whose qualities are degraded easily in poor atmospheric conditions. Although synthetic aperture radar (SAR) images cannot provide the spectral features of the region of interest (ROI), they can capture all-weather and all-time polarization information. In nature, optical and SAR images encapsulate lots of complementary information, which is of great significance for change detection (CD) in poor weather situations. However, due to the difference in imaging mechanisms of optical and SAR images, it is difficult to conduct their CD directly using the traditional difference or ratio algorithms. Most recent CD methods bring image translation to reduce their difference, but the results are obtained by ordinary algebraic methods and threshold segmentation with limited accuracy. Towards this end, this work proposes a d eep translation based change detection network (DTCDN) for optical and SAR images. The deep translation firstly maps images from one domain (e.g., optical) to another domain (e.g., SAR) through a cyclic structure into the same feature space. With the similar characteristics after deep translation, they become comparable. Different from most previous researches, the translation results are imported to a supervised CD network that utilizes deep context features to separate the unchanged pixels and changed pixels. In the experiments, the proposed DTCDN was tested on four representative data sets from Gloucester, California, and Shuguang village. Compared with state-of-the-art methods, the effectiveness and robustness of the proposed method were confirmed.
C1 [Li, Xinghua; Du, Zhengshun; Huang, Yanyuan] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Tan, Zhenyu] Northwest Univ, Coll Urban & Environm Sci, Xian 710127, Peoples R China.
RP Tan, ZY (corresponding author), Northwest Univ, Coll Urban & Environm Sci, Xian 710127, Peoples R China.
EM tanzhenyu@nwu.edu.cn
RI Li, Xinghua/F-6679-2014
OI Li, Xinghua/0000-0002-2094-6480
FU National Key R&D Program of China [2019YFB2102904]; National Natural
   Science Foundation of China (NSFC)National Natural Science Foundation of
   China (NSFC) [41701394]; NASA's Land Processes Distributed Active
   Archive Center; ESA's Copernicus
FX The work was supported by the National Key R&D Program of China under
   Grant No. 2019YFB2102904, and the National Natural Science Foundation of
   China (NSFC) under Grant No. 41701394. The authors are very grateful to
   Prof. Max Migonotte from Montreal University for sharing the optical and
   SAR datasets of Gloucester I and Shuguang village. The images of the
   California dataset are supported by NASA's Land Processes Distributed
   Active Archive Center and ESA's Copernicus. The authors also would like
   to thank Luigi T. Luppino from UiT. The Arctic University of Norway for
   providing the ground truth of California datasets and the codes of
   comparison methods.
CR Alberga V, 2009, REMOTE SENS-BASEL, V1, P122, DOI 10.3390/rs1030122
   Ao DY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101597
   Ayhan B, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P192, DOI 10.1109/UEMCON47517.2019.8993038
   Bi <prime>nkowski M., 2018, INT C LEARN REPR
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Fang B., 2020, P IEEE CVF C COMP VI, P8165, DOI [10.1109/CVPR42600.2020.00819, DOI 10.1109/CVPR42600.2020.00819]
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Guo HN, 2021, IEEE T GEOSCI REMOTE, V59, P4287, DOI 10.1109/TGRS.2020.3014312
   Guo QD, 2014, IEEE J-STARS, V7, P2351, DOI 10.1109/JSTARS.2014.2302446
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Heusel Martin, 2017, P 31 INT C NEUR INF, P6629
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121444
   Ji M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101202
   Jin L., 2017, C NEUR INF PROC SYST, P823, DOI [10.5555/3294771.3294850, DOI 10.5555/3294771.3294850]
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kwan C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202377
   Lazarow J, 2017, IEEE I CONF COMP VIS, P2793, DOI 10.1109/ICCV.2017.302
   Lee K, 2018, PROC CVPR IEEE, P3702, DOI 10.1109/CVPR.2018.00390
   Lei L., 2020, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/LGRS.2020.3037930, DOI 10.1109/LGRS.2020.3037930]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI [10.1109/TCYB.2020.2971638, 10.1109/TGRS.2020.3018879]
   Liu T, 2021, REMOTE SENS ENVIRON, V256, DOI 10.1016/j.rse.2021.112308
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Luppino L. T., 2020, ARXIV200104271
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Luppino LT, 2017, LECT NOTES COMPUT SC, V10270, P181, DOI 10.1007/978-3-319-59129-2_16
   Lyu HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030471
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Mignotte M, 2020, IEEE T GEOSCI REMOTE, V58, P8046, DOI 10.1109/TGRS.2020.2986239
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Reyes MF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11172067
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2018, PROC SPIE, V10789, DOI 10.1117/12.2325149
   Shang RH, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105542
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Sun YL, 2021, IEEE T GEOSCI REMOTE, V59, P4841, DOI 10.1109/TGRS.2020.3013673
   Sun YL, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107598
   Sun YT, 2021, INT REV IMMUNOL, DOI 10.1080/08830185.2021.1897124
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Tong XH, 2010, INT J REMOTE SENS, V31, P1485, DOI 10.1080/01431160903475290
   Touati R., 2020, J REMOTE SENSING GIS, V9, P1
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Touati R, 2018, IEEE IMAGE PROC, P3998, DOI 10.1109/ICIP.2018.8451184
   Touati R, 2017, INT CONF IMAG PROC
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Nguyen TL, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062482
   Turnes J.N., 2020, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/lgrs.2020.3031199, DOI 10.1109/LGRS.2020.3031199]
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Zhou J, 2016, IEEE T GEOSCI REMOTE, V54, P6497, DOI 10.1109/TGRS.2016.2585495
   Zhou WQ, 2008, SENSORS-BASEL, V8, P1613, DOI 10.3390/s8031613
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 73
TC 5
Z9 5
U1 23
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD SEP
PY 2021
VL 179
BP 14
EP 34
DI 10.1016/j.isprsjprs.2021.07.007
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA UC2UJ
UT WOS:000686386900002
DA 2022-01-04
ER

PT J
AU Wang, DC
   Chen, XN
   Jiang, MY
   Du, SH
   Xu, BJ
   Wang, JD
AF Wang, Decheng
   Chen, Xiangning
   Jiang, Mingyong
   Du, Shuhan
   Xu, Bijie
   Wang, Junda
TI ADS-Net:An Attention-Based deeply supervised network for remote sensing
   image change detection
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Change detection; Attention mechanism; Deep supervision network;
   Difference feature
ID FUSION NETWORK
AB Change detection technology is an important key to analyze remote sensing data and is of great significance for accurate comprehension of the earth's surface changes. With the continuous development and progress of deep learning technology, fully convolutional neural networks are applied gradually in remote sensing change detection tasks. The present methods mainly encounter the problems of simple network structure, poor detection of small change areas, and poor robustness since they cannot completely obtain the relationships and differences between the features of bi-temporal images. To solve such problems, we propose an attention mechanism-based deep supervision network (ADS-Net) for the change detection of bi-temporal remote sensing images. First, an encoding-decoding full convolutional network is designed with a dual-stream structure. Various level features of bi-temporal images are extracted in the encoding stage, then in the decoding stage, feature maps of different levels are inserted into a deep supervision network with different branches to reconstruct the change map. Ultimately, to obtain the final change detection map, the prediction results of each branch in the deep supervision network are fused with various weights. To highlight the characteristics of change, we propose an adaptive attention mechanism combining spatial and channel features to capture the relationship of different scale changes and achieve more accurate change detection. ADS-Net has been tested on the LEVIR-CD and SVCD datasets of challenging remote sensing image change detection. The results of quantitative analysis and qualitative comparison indicate that the ADS-Net method comprises better effectiveness and robustness compared to the other state-of-the-art change detection methods.
C1 [Wang, Decheng; Chen, Xiangning; Jiang, Mingyong; Du, Shuhan; Xu, Bijie] Space Engn Univ, Space Informat Acad, Beijing 101416, Peoples R China.
   [Wang, Junda] Beijing Satellite Nav Ctr, Beijing 100094, Peoples R China.
RP Chen, XN (corresponding author), Space Engn Univ, Space Informat Acad, Beijing 101416, Peoples R China.
EM wangdecheng@tom.com; xn_chen_edu@163.com; jiangmingyong2010@163.com;
   poisonous_mushroom@163.com; bijie_xu@163.com; 929116565@qq.com
OI wang, wang de cheng/0000-0003-4424-1589
FU Preliminary Research of Equipment Program of China [305020506];
   Experimental Technology Research of China [421414323]; Military
   Commission Science and Technology Committee Leading Fund
   [18-163-00-TS-004-080-01]
FX This study is supported by the Preliminary Research of Equipment Program
   of China (305020506), Experimental Technology Research of China
   (421414323) and Military Commission Science and Technology Committee
   Leading Fund (18-163-00-TS-004-080-01).
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Han Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060983
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lihui W, 2016, REMOTE SENSING LAND, DOI [10.6046/gtzyyg.2016.01.04, DOI 10.6046/GTZYYG.2016.01.04]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu RN, 2020, IEEE T IND INFORM, V16, P87, DOI 10.1109/TII.2019.2915536
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qiao HJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185076
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Singh, 1986, REMOTE SENSING TROPI, V44, P273
   Singh S, 2015, MAUSAM, V66, P77
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wang B, 2015, REMOTE SENS LETT, V6, P578, DOI 10.1080/2150704X.2015.1062155
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wickware G.M., 2007, INT J REMOTE SENS, V2, P277, DOI [10.1080/01431168108948362, DOI 10.1080/01431168108948362IM]
   Wiratama W, 2020, IEEE ACCESS, V8, P12279, DOI 10.1109/ACCESS.2020.2964798
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu YQ, 2016, CHINESE J GEOPHYS-CH, V59, P1284, DOI 10.6038/cjg20160411
   Ye S, 2021, REMOTE SENS ENVIRON, V252, DOI 10.1016/j.rse.2020.112167
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang HM, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030440
   Zhang LB, 2020, IEEE J-STARS, V13, P2778, DOI 10.1109/JSTARS.2020.2995703
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhao, 2011, GEOSCIENCE REMOTE SE, DOI [10.1109/IGARSS.2011.6048960, DOI 10.1109/IGARSS.2011.6048960]
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 43
TC 5
Z9 5
U1 42
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 1569-8432
EI 1872-826X
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD SEP
PY 2021
VL 101
AR 102348
DI 10.1016/j.jag.2021.102348
PG 17
WC Remote Sensing
SC Remote Sensing
GA SO3TH
UT WOS:000658898600001
OA gold
DA 2022-01-04
ER

PT J
AU Tang, X
   Zhang, HY
   Mou, LC
   Liu, F
   Zhang, XR
   Zhu, XX
   Jiao, LC
AF Tang, Xu
   Zhang, Huayu
   Mou, Lichao
   Liu, Fang
   Zhang, Xiangrong
   Zhu, Xiao Xiang
   Jiao, Licheng
TI An Unsupervised Remote Sensing Change Detection Method Based on
   Multiscale Graph Convolutional Network and Metric Learning
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Feature extraction; Task analysis; Measurement; Semantics; Remote
   sensing; Image segmentation; Training; Change detection (CD); graph
   convolution network (GCN); high resolution remote sensing (RS) images;
   metric learning; unsupervised
ID MULTIPLE-CHANGE DETECTION; URBAN CHANGE DETECTION; SLOW FEATURE
   ANALYSIS; IMAGES
AB As a fundamental application, change detection (CD) is widespread in the remote sensing (RS) community. With the increase in the spatial resolution of RS images, high-resolution remote sensing (HRRS) image CD tasks receive growing attention. The change information hidden in multitemporal HRRS images could help discover our planet comprehensively. In the current deep learning era, convolutional neural networks (CNNs) have become one of the most powerful tools for a wide range of RS tasks including HRRS image CD, due to their superb feature learning capacity. However, most of them need a large amount of labeled data to accomplish the CD process, which is challenging or even impractical in many RS applications. Also, given the limited valid receptive field, CNNs can only capture short-range context within HRRS images, which is probably not enough to fully explore change information from the images. To overcome these limitations, in this article, we propose an unsupervised CD method, termed GMCD, based on graph convolutional network (GCN) and metric learning. GMCD consists of a Siamese fully convolution network (FCN), a multiscale dynamic GCN (Mlt-GCN), and a pseudolabel generation mechanism based on metric learning. The Siamese FCN contains a Siamese encoder and a pyramid-shaped decoder, aiming to extract multiscale features and integrate them to generate reliable difference images (DIs). Mlt-GCN focuses on capturing the short- and long-range contextual patterns at feature map level to extract changed and unchanged areas completely. The pseudolabel generation mechanism aims to produce reliable pseudolabels (changed, unchanged, and uncertain) to help accomplish the model training in an unsupervised way. Experiments on four HRRS image CD datasets demonstrate that GMCD outperforms the existing state-of-the-art methods.
C1 [Tang, Xu; Zhang, Huayu; Zhang, Xiangrong; Jiao, Licheng] Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
   [Mou, Lichao; Zhu, Xiao Xiang] German Aerosp Ctr, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
   [Mou, Lichao; Zhu, Xiao Xiang] Tech Univ Munich, Data Sci Earth Observat SiPEO, D-80333 Munich, Germany.
   [Liu, Fang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Peoples R China.
RP Tang, X (corresponding author), Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM tangxu128@gmail.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61801351, 62171332, 61802190, 61772400]; Key
   Research and Development Program of Shaanxi [2021GY-035]; Key Laboratory
   of National Defense Science and Technology Foundation Project
   [6142A010301]; China Postdoctoral Science FoundationChina Postdoctoral
   Science Foundation [2017M620441]; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [30919011281, JSGP202101]; Xidian University Artificial
   Intelligence School Innovation Fund Project [YJS2115]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61801351, Grant 62171332, Grant
   61802190, and Grant 61772400; in part by the Key Research and
   Development Program of Shaanxi under Grant 2021GY-035; in part by the
   Key Laboratory of National Defense Science and Technology Foundation
   Project under Grant 6142A010301; in part by the China Postdoctoral
   Science Foundation Funded Project under Grant 2017M620441; in part by
   the Fundamental Research Funds for the Central Universities under Grant
   30919011281 and Grant JSGP202101; and in part by the Xidian University
   Artificial Intelligence School Innovation Fund Project under Grant
   YJS2115. (Corresponding author: Xu Tang.)
CR Abraham N, 2019, I S BIOMED IMAGING, P683, DOI 10.1109/ISBI.2019.8759329
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2011, INT GEOSCI REMOTE SE, P233, DOI 10.1109/IGARSS.2011.6048935
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruna J., 2013, P 2 INT C LEARN REPR
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Chen H., 2019, ARXIV190611479
   Chen Y, 2013, SIGNAL PROCESS, V93, P163, DOI 10.1016/j.sigpro.2012.07.013
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   de Jong K. L., 2019, P INT JOINT C NEUR N, P1
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Khan N, 2019, NEUROCOMPUTING, V357, P36, DOI 10.1016/j.neucom.2019.05.024
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li YY, 2017, INT GEOSCI REMOTE SE, P3090, DOI 10.1109/IGARSS.2017.8127652
   Liang JL, 2020, IEEE J-STARS, V13, P4325, DOI 10.1109/JSTARS.2020.3011333
   Lin PW, 2020, PROC CVPR IEEE, P4202, DOI 10.1109/CVPR42600.2020.00426
   Lin WY, 2020, PROC CVPR IEEE, P4173, DOI 10.1109/CVPR42600.2020.00423
   Liu F, 2021, IEEE T GEOSCI REMOTE, V59, P363, DOI 10.1109/TGRS.2020.2992032
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu H., 2020, P IEEE CVF C COMP VI
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Ma JJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152350
   Meddens AJH, 2013, REMOTE SENS ENVIRON, V132, P49, DOI 10.1016/j.rse.2013.01.002
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Paszke A, 2019, ADV NEUR IN, V32
   Ren SQ, 2015, ADV NEUR IN, V28
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Solano-Correa YT, 2019, IEEE GEOSCI REMOTE S, V16, P1334, DOI 10.1109/LGRS.2019.2896385
   Song, 2016, ADV NEURAL INFORM PR, P2110
   Varghese A, 2019, LECT NOTES COMPUT SC, V11130, P129, DOI 10.1007/978-3-030-11012-3_10
   Wan S, 2021, IEEE T GEOSCI REMOTE, V59, P597, DOI 10.1109/TGRS.2020.2994205
   Wang Feng, 2016, ARXIV160106823
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   Yuan ZH, 2018, INT GEOSCI REMOTE SE, P4931, DOI 10.1109/IGARSS.2018.8518196
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhan T, 2020, IEEE T GEOSCI REMOTE, V58, P5653, DOI 10.1109/TGRS.2020.2968098
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhou J, 2018, ARTIF CELL NANOMED B, V46, pS1016, DOI 10.1080/21691401.2018.1442841
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI 10.1007/978-3-030-01219-9_
NR 69
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3106381
EA AUG 2021
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2TT
UT WOS:000732768300001
DA 2022-01-04
ER

PT J
AU Bai, BF
   Fu, W
   Lu, T
   Li, ST
AF Bai, Beifang
   Fu, Wei
   Lu, Ting
   Li, Shutao
TI Edge-Guided Recurrent Convolutional Neural Network for Multitemporal
   Remote Sensing Image Building Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Feature extraction; Image edge detection; Buildings; Logic gates;
   Convolutional neural networks; Task analysis; Dams; Building change
   detection; edge structure prior; multitemporal images; recurrent
   convolutional neural network (CNN)
ID SLOW FEATURE ANALYSIS; FUSION; MAD
AB Building change detection is a very important application in the field of remote sensing. Recently, deep learning (DL) has been introduced to solve the change detection task and achieved good performance, mainly due to the capability of automatically learning deep features. However, the lack of using prior knowledge (e.g., edge structure information) leads to inaccurate detection results, especially in the areas of building boundaries. To solve this problem, an end-to-end DL method for building change detection, named by edge-guided recurrent convolutional neural network (EGRCNN), is proposed in this article. The main idea is to incorporate both discriminative information and edge structure prior in one framework to improve change detection results, especially to generate more accurate building boundaries. First, a siamese convolutional neural network is trained to simultaneously extract primary multilevel features from multitemporal images. Then, a difference analysis module (DAM) is introduced to further produce discriminative features, which is constructed based on the basic long short-term memory module. Finally, both the discriminative features and the estimated edge structure information are jointly exploited to predict building change map. On one hand, the proposed DAM helps to enhance the discrimination between the changed and unchanged regions. On the other hand, the prior edge information is used to push the predicted changed buildings to preserve the original structure, which can further improve the accuracy of building change detection. Experimental results demonstrate that the performance of the proposed method outperforms several state-of-the-art approaches, in terms of objective metrics and visual comparison results.
C1 [Bai, Beifang; Lu, Ting; Li, Shutao] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Bai, Beifang; Lu, Ting; Li, Shutao] Hunan Univ, Key Lab Visual Percept & Artificial Intelligence, Changsha 410082, Hunan, Peoples R China.
   [Fu, Wei] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
RP Lu, T (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.; Fu, W (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM fuwei@hnu.edu.cn; ting_lu@hnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61801179, 62001160]; Hunan Provincial
   Natural Science Foundation of ChinaNatural Science Foundation of Hunan
   Province [2019JJ50079]; Research and Development Plan of Key Fields in
   Guangdong Province [2018B010107001]; Fundamental Research Fund for the
   Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61801179 and Grant 62001160, in part by
   Hunan Provincial Natural Science Foundation of China under Grant
   2019JJ50079, in part by the Research and Development Plan of Key Fields
   in Guangdong Province under Grant 2018B010107001, and in part by the
   Fundamental Research Fund for the Central Universities.
CR Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI 10.1109/ICIP.2019.8803050
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Duan PH, 2019, IEEE T GEOSCI REMOTE, V57, P10336, DOI 10.1109/TGRS.2019.2933588
   Erturk A, 2016, IEEE J-STARS, V9, P708, DOI 10.1109/JSTARS.2015.2477431
   He QQ, 2021, INT ENTREP MANAG J, DOI [10.1007/s11365-020-00721-7, 10.1109/TGRS.2020.3045474]
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE GEOSC REM SEN M, V9, P52, DOI 10.1109/MGRS.2021.3064051
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Li XX, 2019, INT J PHOTOENERGY, V2019, DOI 10.1155/2019/3725364
   Li Y, 2020, IEEE T GEOSCI REMOTE, V58, P4976, DOI 10.1109/TGRS.2020.2971081
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Varghese A., 2018, P EUR C COMP VIS ECC, P1
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xu YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010144
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3106697
EA AUG 2021
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XT2UV
UT WOS:000733450100001
DA 2022-01-04
ER

PT J
AU Yu, B
   Chen, F
   Xu, C
   Wang, L
   Wang, N
AF Yu, Bo
   Chen, Fang
   Xu, Chong
   Wang, Lei
   Wang, Ning
TI Matrix SegNet: A Practical Deep Learning Framework for Landslide Mapping
   from Images of Different Areas with Different Spatial Resolutions
SO REMOTE SENSING
LA English
DT Article
DE landslide detection; Matrix nets; different spatial resolutions
ID SEMANTIC SEGMENTATION; INVENTORY
AB Practical landslide inventory maps covering large-scale areas are essential in emergency response and geohazard analysis. Recently proposed techniques in landslide detection generally focused on landslides in pure vegetation backgrounds and image radiometric correction. There are still challenges in regard to robust methods that automatically detect landslides from images with multiple platforms and without radiometric correction. It is a significant issue in practical application. In order to detect landslides from images over different large-scale areas with different spatial resolutions, this paper proposes a two-branch Matrix SegNet to semantically segment input images by change detection. The Matrix SegNet learns landslide features in multiple scales and aspect ratios. The pre- and post- event images are captured directly from Google Earth, without radiometric correction. To evaluate the proposed framework, we conducted landslide detection in four study areas with two different spatial resolutions. Moreover, two other widely used frameworks: U-Net and SegNet, were adapted to detect landslides via the same data by change detection. The experiments show that our model improves the performance largely in terms of recall, precision, F1-score, and IOU. It is a good starting point to develop a practical, deep learning landslide detection framework for large scale application, using images from different areas, with different spatial resolutions.
C1 [Yu, Bo; Chen, Fang; Wang, Ning] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Chen, Fang; Wang, Ning] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Chen, Fang] Chinese Acad Sci, Aerosp Informat Res Inst, Hainan Key Lab Earth Observat, Sanya 572029, Peoples R China.
   [Chen, Fang; Wang, Lei] Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100094, Peoples R China.
   [Xu, Chong] Natl Inst Nat Hazards, Minist Emergency Management China, Beijing 100085, Peoples R China.
RP Chen, F (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.; Chen, F (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Chen, F (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Hainan Key Lab Earth Observat, Sanya 572029, Peoples R China.; Chen, F (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, State Key Lab Remote Sensing Sci, Beijing 100094, Peoples R China.
EM boyu@radi.ac.cn; chenfang_group@radi.ac.cn; chongxu@ninhm.ac.cn;
   wanglei@radi.ac.cn; wangning@radi.ac.cn
RI Chen, Fang/AAU-7638-2020; WANG, Lei/B-4845-2012; Xu, Chong/B-6460-2012
OI Xu, Chong/0000-0002-3956-4925; wang, lei/0000-0002-7163-3644
FU National Key R&D Program of China [2019YFD1100803]
FX This research was funded by the National Key R&D Program of China, grant
   number 2019YFD1100803.
CR Aimaiti Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202351
   Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen F, 2018, LANDSLIDES, V15, P453, DOI 10.1007/s10346-017-0884-x
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng Y.S, P EGU GEN ASS C ABST
   Deijns AAJ, 2020, INT J APPL EARTH OBS, V84, DOI 10.1016/j.jag.2019.101943
   Deng YB, 2015, INT J APPL EARTH OBS, V39, P40, DOI 10.1016/j.jag.2015.02.010
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Gariano SL, 2016, EARTH-SCI REV, V162, P227, DOI 10.1016/j.earscirev.2016.08.011
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Haque U, 2019, SCI TOTAL ENVIRON, V682, P673, DOI 10.1016/j.scitotenv.2019.03.415
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI 10.1109/TPAMI.2018.2844175
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kargel JS, 2016, SCIENCE, V351, DOI 10.1126/science.aac8353
   Kingma D., 2014, 14126980 ARXIV
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Lin CW, 2011, ENG GEOL, V123, P3, DOI 10.1016/j.enggeo.2011.06.007
   Lin T.Y., P IEEE INT C COMP VI P IEEE INT C COMP VI, P2980
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lina L, 2014, J ENG GEOL, V22, P11
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Lu P, 2019, ISPRS J PHOTOGRAMM, V156, P147, DOI 10.1016/j.isprsjprs.2019.08.004
   Lu P, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.111235
   Melekhov I, 2019, IEEE WINT CONF APPL, P1034, DOI 10.1109/WACV.2019.00115
   Mondini AC, 2013, GEOMORPHOLOGY, V201, P135, DOI 10.1016/j.geomorph.2013.06.015
   Moosavi V, 2014, GEOMORPHOLOGY, V204, P646, DOI 10.1016/j.geomorph.2013.09.012
   Mustafa M, 2018, REMOTE SENS-BASEL, V10, P1029
   Pradhan B, 2016, IEEE T GEOSCI REMOTE, V54, P1610, DOI 10.1109/TGRS.2015.2484325
   Prakash N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030346
   Rashwan A, P 2019 IEEE CVF INT, P2025
   Ronneberger O., 2015, PROC INT C MED IMAG, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Tian YY, 2019, J EARTH SCI-CHINA, V30, P206, DOI 10.1007/s12583-018-0869-2
   Tran CJ, 2019, GEOSCIENCES, V9, DOI 10.3390/geosciences9050221
   Wang N, 2020, ISPRS J PHOTOGRAMM, V162, P137, DOI 10.1016/j.isprsjprs.2020.02.012
   Wolf D, 2016, IEEE ROBOT AUTOM LET, V1, P49, DOI 10.1109/LRA.2015.2506118
   Wood JL, 2020, GEOMORPHOLOGY, V355, DOI 10.1016/j.geomorph.2020.107061
   Xie Enze, 2019, ARXIV190913226, P12193
   Ye CM, 2019, IEEE J-STARS, V12, P5047, DOI 10.1109/JSTARS.2019.2951725
   Youssef AM, 2016, LANDSLIDES, V13, P839, DOI 10.1007/s10346-015-0614-1
   Yu B, 2020, COMPUT GEOSCI-UK, V135, DOI 10.1016/j.cageo.2019.104388
   Yu B, 2018, IEEE J-STARS, V11, P3252, DOI 10.1109/JSTARS.2018.2860989
   Yu B, 2017, PHOTOGRAMM ENG REM S, V83, P351, DOI [10.14358/pers.83.5.351, 10.14358/PERS.83.5.351]
   Yu B, 2017, COMPUT GEOSCI-UK, V100, P115, DOI 10.1016/j.cageo.2016.12.007
   Yu H, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P40, DOI 10.1109/ICMA.2017.8015785
   Zaytseva V ., 2019, P C NEUR INF PROC SY
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183859
NR 52
TC 0
Z9 0
U1 12
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2021
VL 13
IS 16
AR 3158
DI 10.3390/rs13163158
PG 16
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UH5BO
UT WOS:000689946400001
OA gold
DA 2022-01-04
ER

PT J
AU Xiang, S
   Wang, M
   Jiang, XF
   Xie, GQ
   Zhang, ZQ
   Tang, P
AF Xiang, Shao
   Wang, Mi
   Jiang, Xiaofan
   Xie, Guangqi
   Zhang, Zhiqi
   Tang, Peng
TI Dual-Task Semantic Change Detection for Remote Sensing Images Using the
   Generative Change Field Module
SO REMOTE SENSING
LA English
DT Article
DE very-high-resolution remote sensing images; semantic change detection;
   generative change field; separable loss
ID BUILDING CHANGE DETECTION; NETWORKS; MIXTURE; MODEL
AB With the advent of very-high-resolution remote sensing images, semantic change detection (SCD) based on deep learning has become a research hotspot in recent years. SCD aims to observe the change in the Earth's land surface and plays a vital role in monitoring the ecological environment, land use and land cover. Existing research mainly focus on single-task semantic change detection; the problem they face is that existing methods are incapable of identifying which change type has occurred in each multi-temporal image. In addition, few methods use the binary change region to help train a deep SCD-based network. Hence, we propose a dual-task semantic change detection network (GCF-SCD-Net) by using the generative change field (GCF) module to locate and segment the change region; what is more, the proposed network is end-to-end trainable. In the meantime, because of the influence of the imbalance label, we propose a separable loss function to alleviate the over-fitting problem. Extensive experiments are conducted in this work to validate the performance of our method. Finally, our work achieves a 69.9% mIoU and 17.9 Sek on the SECOND dataset. Compared with traditional networks, GCF-SCD-Net achieves the best results and promising performances.
C1 [Xiang, Shao; Wang, Mi; Jiang, Xiaofan; Xie, Guangqi; Zhang, Zhiqi] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Tang, Peng] Tech Univ Munich, Dept Informat, D-80333 Munich, Germany.
RP Wang, M (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM xiangshao@whu.edu.cn; wangmi@whu.edu.cn; 2014106190034@whu.edu.cn;
   xiegqrs@whu.edu.cn; zzq540@whu.edu.cn; tangp@in.tum.de
RI Xiang, Shao/V-3790-2018
OI Xiang, Shao/0000-0002-2797-1937; Xie, Guangqi/0000-0002-0292-1626; TANG,
   Peng/0000-0003-4099-6677
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61825103, 91838303, 91738302]
FX The study was supported by a grant from the National Natural Science
   Foundation of China under project 61825103, 91838303, and 91738302.
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Chatelain F, 2007, IEEE T IMAGE PROCESS, V16, P1796, DOI 10.1109/TIP.2007.896651
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   CHEN Q, 2016, REMOTE SENS-BASEL, V8, P549, DOI DOI 10.3390/rs8070549
   Danihelka, 2014, ARXIV14105401
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lanza A, 2011, IEEE T PATTERN ANAL, V33, P1894, DOI 10.1109/TPAMI.2011.42
   Li AJ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3050885
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lingg AJ, 2014, IEEE T IMAGE PROCESS, V23, P2405, DOI 10.1109/TIP.2014.2309432
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 1998, IEEE T IMAGE PROCESS, V7, P1258, DOI 10.1109/83.709658
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Pelillo, 2020, ARXIV201005687
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Robbins H., 1985, H ROBBINS SELECTED P, P102
   Robin A, 2010, IEEE T PATTERN ANAL, V32, P1977, DOI 10.1109/TPAMI.2010.37
   Ronneberger O., 2015, PROC INT C MED IMAG, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2018, INT GEOSCI REMOTE SE, P1902, DOI 10.1109/IGARSS.2018.8519440
   Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897
   Sun Y., 2020, IEEE GEOSCI REMOTE S, P1, DOI [10.1109/LGRS.2020.3018858, DOI 10.1109/LGRS.2020.3018858]
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Yao J, 2018, NEUROCOMPUTING, V278, P4, DOI 10.1016/j.neucom.2017.05.102
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 38
TC 0
Z9 0
U1 23
U2 23
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2021
VL 13
IS 16
AR 3336
DI 10.3390/rs13163336
PG 15
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA UH2YR
UT WOS:000689803700001
OA gold
DA 2022-01-04
ER

PT J
AU Xu, JL
   Luo, CB
   Chen, XY
   Wei, SC
   Luo, Y
AF Xu, Jialang
   Luo, Chunbo
   Chen, Xinyue
   Wei, Shicai
   Luo, Yang
TI Remote Sensing Change Detection Based on Multidirectional Adaptive
   Feature Fusion and Perceptual Similarity
SO REMOTE SENSING
LA English
DT Article
DE remote sensing change detection; feature fusion; attention mechanism;
   very-high-resolution image pairs; perceptual loss
ID NEURAL-NETWORKS; URBAN; FRAMEWORK; IMAGES
AB Remote sensing change detection (RSCD) is an important yet challenging task in Earth observation. The booming development of convolutional neural networks (CNNs) in computer vision raises new possibilities for RSCD, and many recent RSCD methods have introduced CNNs to achieve promising improvements in performance. In this paper we propose a novel multidirectional fusion and perception network for change detection in bi-temporal very-high-resolution remote sensing images. First, we propose an elaborate feature fusion module consisting of a multidirectional fusion pathway (MFP) and an adaptive weighted fusion (AWF) strategy for RSCD to boost the way that information propagates in the network. The MFP enhances the flexibility and diversity of information paths by creating extra top-down and shortcut-connection paths. The AWF strategy conducts weight recalibration for every fusion node to highlight salient feature maps and overcome semantic gaps between different features. Second, a novel perceptual similarity module is designed to introduce perceptual loss into the RSCD task, which adds perceptual information, such as structure and semantic information, for high-quality change map generation. Extensive experiments on four challenging benchmark datasets demonstrate the superiority of the proposed network compared with eight state-of-the-art methods in terms of F1, Kappa, and visual qualities.
C1 [Xu, Jialang; Luo, Chunbo; Wei, Shicai; Luo, Yang] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.
   [Luo, Chunbo; Luo, Yang] Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, Huzhou 313001, Peoples R China.
   [Luo, Chunbo] Univ Exeter, Dept Comp Sci, Exeter EX4 4RN, Devon, England.
   [Chen, Xinyue] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Peoples R China.
RP Luo, CB (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu 611731, Peoples R China.; Luo, CB (corresponding author), Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, Huzhou 313001, Peoples R China.; Luo, CB (corresponding author), Univ Exeter, Dept Comp Sci, Exeter EX4 4RN, Devon, England.
EM xujialang@std.uestc.edu.cn; c.luo@uestc.edu.cn;
   chenxinyue@stu.scu.edu.cn; 201921010232@std.uestc.edu.cn;
   luoyang@uestc.edu.cn
RI Xu, Jialang/ABE-9627-2020
OI Xu, Jialang/0000-0003-2324-7033; Wei, Shicai/0000-0001-5744-2035
FU National Key R&D Program of China [2018YFB2101300]
FX This research was funded by the National Key R&D Program of China (Grant
   No. 2018YFB2101300).
CR Awty-Carroll K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232779
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YF, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107557
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang BW, 2020, INT CONF COMP INFO, P1
   Fang S., SNUNET 400 DENSELY C
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Ghaderpour E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12234001
   Hadsell Raia, 2006, P 2006 IEEE COMP VIS, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060983
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Isaienkov K, 2021, IEEE J-STARS, V14, P364, DOI 10.1109/JSTARS.2020.3034186
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee H, 2021, IEEE J-STARS, V14, P4139, DOI 10.1109/JSTARS.2021.3069242
   Lefebvre A., 2008, P IEEE INT GEOSC REM, VVolume 4, pIV, DOI [10.1109/IGARSS.2008.4779809, DOI 10.1109/IGARSS.2008.4779809]
   Lei T, 2019, INT CONF ACOUST SPEE, P3027, DOI 10.1109/ICASSP.2019.8682802
   Lei T, 2017, INFORM SCIENCES, V387, P34, DOI 10.1016/j.ins.2017.01.003
   Lei YJ, 2021, IEEE T IMAGE PROCESS, V30, P55, DOI 10.1109/TIP.2020.3031173
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Loshchilov I, 2016, SGDR STOCHASTIC GRAD
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Marchesi S, 2009, INT GEOSCI REMOTE SE, P1231, DOI 10.1109/IGARSS.2009.5418265
   Miller O, 2005, PATTERN RECOGN, V38, P1976, DOI 10.1016/j.patcog.2004.07.010
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ouahabi A, 2021, PATTERN RECOGN LETT, V144, P27, DOI 10.1016/j.patrec.2021.01.010
   Papadomanolaki M., DEEP MULTITASK LEARN
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng X., OPTICAL REMOTE SENSI
   Rad MS, 2019, IEEE I CONF COMP VIS, P2710, DOI 10.1109/ICCV.2019.00280
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shi N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12183057
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Simonyan K, 2014, ArXiv:1409.1556
   Singh A., 1986, REMOTE SENSING TROPI, V44, P273, DOI DOI 10.1080/10106048809354188
   Srinivas S., 2019, ADV NEURAL INFORM PR, P4124
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan M., 2020, P IEEE CVF C COMP VI, P10781
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Wang RF, 2020, IEEE GEOSCI REMOTE S, V17, P77, DOI 10.1109/LGRS.2019.2915251
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan T, 2020, IEEE T GEOSCI REMOTE, V58, P5653, DOI 10.1109/TGRS.2020.2968098
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 71
TC 0
Z9 0
U1 21
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2021
VL 13
IS 15
AR 3053
DI 10.3390/rs13153053
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA TW3IC
UT WOS:000682297300001
OA gold
DA 2022-01-04
ER

PT J
AU Zitzlsberger, G
   Podhoranyi, M
   Svaton, V
   Lazecky, M
   Martinovic, J
AF Zitzlsberger, Georg
   Podhoranyi, Michal
   Svaton, Vaclav
   Lazecky, Milan
   Martinovic, Jan
TI Neural Network-Based Urban Change Monitoring with Deep-Temporal
   Multispectral and SAR Remote Sensing Data
SO REMOTE SENSING
LA English
DT Article
DE urban change detection; continuous urban monitoring; neural network;
   SAR; optical multispectral; deep-temporal; ERS-1; ERS-2; Landsat 5 TM;
   Sentinel 1; Sentinel 2
ID BUILT-UP INDEXES; IMPERVIOUS SURFACE; EXTRACTION; LAND; CLASSIFICATION;
   FRAMEWORK; SPACE; PIXEL; AREA
AB Remote-sensing-driven urban change detection has been studied in many ways for decades for a wide field of applications, such as understanding socio-economic impacts, identifying new settlements, or analyzing trends of urban sprawl. Such kinds of analyses are usually carried out manually by selecting high-quality samples that binds them to small-scale scenarios, either temporarily limited or with low spatial or temporal resolution. We propose a fully automated method that uses a large amount of available remote sensing observations for a selected period without the need to manually select samples. This enables continuous urban monitoring in a fully automated process. Furthermore, we combine multispectral optical and synthetic aperture radar (SAR) data from two eras as two mission pairs with synthetic labeling to train a neural network for detecting urban changes and activities. As pairs, we consider European Remote Sensing (ERS-1/2) and Landsat 5 Thematic Mapper (TM) for 1991-2011 and Sentinel 1 and 2 for 2017-2021. For every era, we use three different urban sites-Limassol, Rotterdam, and Liege-with at least 500 km(2) each, and deep observation time series with hundreds and up to over a thousand of samples. These sites were selected to represent different challenges in training a common neural network due to atmospheric effects, different geographies, and observation coverage. We train one model for each of the two eras using synthetic but noisy labels, which are created automatically by combining state-of-the-art methods, without the availability of existing ground truth data. To combine the benefit of both remote sensing types, the network models are ensembles of optical- and SAR-specialized sub-networks. We study the sensitivity of urban and impervious changes and the contribution of optical and SAR data to the overall solution. Our implementation and trained models are available publicly to enable others to utilize fully automated continuous urban monitoring.
C1 [Zitzlsberger, Georg; Podhoranyi, Michal; Svaton, Vaclav; Lazecky, Milan; Martinovic, Jan] VSB Tech Univ Ostrava, IT4Innovat, Ostrava 70800, Czech Republic.
   [Lazecky, Milan] Univ Leeds, Sch Earth & Environm, Leeds LS2 9JT, W Yorkshire, England.
RP Zitzlsberger, G (corresponding author), VSB Tech Univ Ostrava, IT4Innovat, Ostrava 70800, Czech Republic.
EM georg.zitzlsberger@vsb.cz
OI Lazecky, Milan/0000-0001-8179-5949; Zitzlsberger,
   Georg/0000-0001-7467-8218
FU ESA via the Blockchain ENabled DEep Learning for Space Data (BLENDED)
   project [4000129481/19/I-IT4I]; Ministry of Education, Youth and Sports
   from the National Programme of Sustainability (NPS II) project
   "IT4Innovations excellence in science" [LQ1602]; Ministry of Education,
   Youth and Sports of the Czech RepublicMinistry of Education, Youth &
   Sports - Czech Republic [90140, OPEN-21-31]
FX This research was funded by ESA via the Blockchain ENabled DEep Learning
   for Space Data (BLENDED) project (SpaceApps Subcontract No.
   4000129481/19/I-IT4I) and by the Ministry of Education, Youth and Sports
   from the National Programme of Sustainability (NPS II) project
   "IT4Innovations excellence in science -LQ1602" and by the IT4Innovations
   Infrastructure, which is supported by the Ministry of Education, Youth
   and Sports of the Czech Republic through the e-INFRA CZ (ID:90140) via
   the Open Access Grant Competition (OPEN-21-31).
CR Ansari RA, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100418
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedetti A, 2018, INT GEOSCI REMOTE SE, P1962, DOI 10.1109/IGARSS.2018.8517586
   Canty MJ, 2008, REMOTE SENS ENVIRON, V112, P1025, DOI 10.1016/j.rse.2007.07.013
   Chen J., 2016, P WORKSH TRACK INT C
   Chen JY, 2020, EUR J REMOTE SENS, V53, P274, DOI 10.1080/22797254.2020.1820383
   Chen JY, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.016502
   Chen THK, 2020, REMOTE SENS ENVIRON, V251, DOI 10.1016/j.rse.2020.112096
   Conradsen K, 2016, IEEE T GEOSCI REMOTE, V54, P3007, DOI 10.1109/TGRS.2015.2510160
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Del Balso, 2018, ARXIV180205799
   Demir I, 2018, IEEE COMPUT SOC CONF, P172, DOI 10.1109/CVPRW.2018.00031
   Deng CB, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2018.10.011
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Esch T, 2020, INT J DIGIT EARTH, V13, P136, DOI 10.1080/17538947.2018.1548655
   Esch T, 2017, ISPRS J PHOTOGRAMM, V134, P30, DOI 10.1016/j.isprsjprs.2017.10.012
   Estoque RC, 2015, ECOL INDIC, V56, P205, DOI 10.1016/j.ecolind.2015.03.037
   Faridatul MI, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7120453
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Gal Yarin, 2016, ADV NEURAL INFORM PR, V2016, P1019, DOI DOI 10.5555/3157096.3157211
   Glorot X., 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1.1.208.6449
   Gomez-Chova L, 2006, PATTERN RECOGN LETT, V27, P234, DOI 10.1016/j.patrec.2005.08.004
   Guha S, 2021, QUATERN INT, V575, P249, DOI 10.1016/j.quaint.2020.06.041
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang B., 2019, ARXIV180512219
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Jafari M, 2016, EUR J REMOTE SENS, V49, P513, DOI 10.5721/EuJRS20164927
   Jiang M, 2020, ISPRS J PHOTOGRAMM, V169, P93, DOI 10.1016/j.isprsjprs.2020.08.023
   Jing CB, 2021, REMOTE SENS ENVIRON, V255, DOI 10.1016/j.rse.2021.112293
   Ju C, 2018, J APPL STAT, V45, P2800, DOI 10.1080/02664763.2018.1441383
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   King MD, 2013, IEEE T GEOSCI REMOTE, V51, P3826, DOI 10.1109/TGRS.2012.2227333
   Kundu K, 2020, J INDIAN SOC REMOTE, V48, P1535, DOI 10.1007/s12524-020-01177-6
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lehner A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020173
   Lin, 2019, J AMB INTEL HUM COMP, P1, DOI [10.1007/s12652-019-01276-4, DOI 10.1007/S12652-019-01276-4]
   Lu DS, 2011, ISPRS J PHOTOGRAMM, V66, P298, DOI 10.1016/j.isprsjprs.2010.10.010
   Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035
   Malof, 2018, ARXIV180512219
   Manzoni M, 2021, REMOTE SENS ENVIRON, V253, DOI 10.1016/j.rse.2020.112152
   Marconcini M, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00580-5
   Mitra D, 2018, APPL GEOGR, V97, P109, DOI 10.1016/j.apgeog.2018.04.012
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   Muro J, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100795
   Nguyen T., 2020, P INT C LEARN REPR I
   Nielsen AA, 2017, INT GEOSCI REMOTE SE, P3901, DOI 10.1109/IGARSS.2017.8127854
   Pandey D, 2020, ADV SPACE RES, V66, P1829, DOI 10.1016/j.asr.2020.06.038
   Patra S, 2007, LECT NOTES COMPUT SC, V4815, P161
   Qin YW, 2017, ISPRS J PHOTOGRAMM, V124, P89, DOI 10.1016/j.isprsjprs.2016.12.011
   Reina GA, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00065
   Roth HR, 2018, COMPUT MED IMAG GRAP, V66, P90, DOI 10.1016/j.compmedimag.2018.03.001
   Roy M, 2014, IEEE GEOSCI REMOTE S, V11, P49, DOI 10.1109/LGRS.2013.2245855
   Shahroudnejad A., 2021, ARXIV2021210201792
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sinha S, 2020, ADV SPACE RES, V66, P1372, DOI 10.1016/j.asr.2020.05.040
   Smola, 2010, ADV NEURAL INFORM PR, P2595
   Song H., 2020, ARXIV200708199
   Susaki J, 2014, REMOTE SENS ENVIRON, V155, P334, DOI 10.1016/j.rse.2014.09.006
   Valentin B., 2021, P 2021 C BIG DAT SPA, P97, DOI [10.2760/125905, DOI 10.2760/125905]
   Wania A, 2014, APPL GEOGR, V46, P35, DOI 10.1016/j.apgeog.2013.10.005
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xingjian S., 2015, P 28 INT C NEUR INF, V1, P802, DOI DOI 10.1007/978-3-319-21233-3_6
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Xu HQ, 2010, PHOTOGRAMM ENG REM S, V76, P557, DOI 10.14358/PERS.76.5.557
   Yoo C, 2019, ISPRS J PHOTOGRAMM, V157, P155, DOI 10.1016/j.isprsjprs.2019.09.009
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Zhang HS, 2016, LANDSCAPE URBAN PLAN, V151, P55, DOI 10.1016/j.landurbplan.2016.03.009
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang SH, 2018, IEEE ACCESS, V6, P41224, DOI 10.1109/ACCESS.2018.2857405
   Zhong JL, 2020, J CLEAN PROD, V259, DOI 10.1016/j.jclepro.2020.120754
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 75
TC 0
Z9 0
U1 13
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2021
VL 13
IS 15
AR 3000
DI 10.3390/rs13153000
PG 31
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA TW3JO
UT WOS:000682301100001
OA gold
DA 2022-01-04
ER

PT J
AU Hou, X
   Bai, YP
   Li, Y
   Shang, CJ
   Shen, Q
AF Hou, Xuan
   Bai, Yunpeng
   Li, Ying
   Shang, Changjing
   Shen, Qiang
TI High-resolution triplet network with dynamic multiscale feature for
   change detection on satellite images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Triplet network; High-resolution images; Dynamic
   convolution; Remote sensing
ID REMOTE-SENSING IMAGES; CLASSIFICATION; SET
AB Change detection in remote sensing images aims to accurately determine any significant land surface changes based on acquired multi-temporal image data, being a pivotal task of remote sensing image processing. Over the past few years, owing to its powerful learning and expression ability, deep learning has been widely applied in the general field of image processing and has demonstrated remarkable potentials in performing change detection in images. However, a majority of the existing deep learning-based change detection mechanisms are modified from single-image semantic segmentation algorithms, without considering the temporal information contained within the images, thereby not always appropriate for real-world change detection. This paper proposes a High-Resolution Triplet Network (HRTNet) framework, including a dynamic inception module, to tackle such shortcomings in change detection. First, a novel triplet input network is introduced, which is capable of learning bi-temporal image features, extracting the temporal information reflecting the difference between images over time. Then, a network is employed to extract high-resolution image features, ensuring the learned features preserving high-resolution characteristics with minimal reduction of information. The paper also proposes a novel dynamic inception module, which helps improve the feature expression ability of HRTNet, enriching the multi-scale information of the features extracted. Finally, the distances between feature pairs are measured to generate a high-precision change map. The effectiveness and robustness of HRTNet are verified on three popular high-resolution remote sensing image datasets. Systematic experimental results show that the proposed approach outperforms state-of-the-art change detection methods.
C1 [Hou, Xuan; Li, Ying] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710129, Peoples R China.
   [Bai, Yunpeng; Shang, Changjing; Shen, Qiang] Aberystwyth Univ, Fac Business & Phys Sci, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
RP Li, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated AeroSp Ground Ocean Big, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710129, Peoples R China.
EM lybyp@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61871460]; Shaanxi Provincial Key RD Program
   [2020KW-003, 2021KWZ-03]; Strategic Partner Acceleration Award under Ser
   Cymru II program, U.K [80761-AU201]
FX This research was supported by the National Natural Science Foundation
   of China (61871460), the Shaanxi Provincial Key R&D Program (2020KW-003,
   2021KWZ-03) and in part by the Strategic Partner Acceleration Award
   under Grant 80761-AU201, funded under the Ser Cymru II program, U.K. The
   authors are very grateful to the Editor and anonymous reviewers for
   their constructive comments that have helped improve this work
   significantly.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jaderberg M, 2015, ADV NEUR IN, V28
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Khelifi L., 2020, ARXIV PREPRINT ARXIV
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei YJ, 2021, IEEE T IMAGE PROCESS, V30, P55, DOI 10.1109/TIP.2020.3031173
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu YM, 2021, INFECT CONT HOSP EP, V42, P906, DOI 10.1017/ice.2020.366
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Mnih V., 2014, P ADV NEURAL INF PRO, P2204, DOI DOI 10.1017/S037346330300239X
   Mundia CN, 2005, INT J REMOTE SENS, V26, P2831, DOI 10.1080/01431160500117865
   Negri R.G., 2020, IEEE T GEOSCI ELECT
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qilong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11531, DOI 10.1109/CVPR42600.2020.01155
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   SenseTime, 2020, ARTIFICIAL INTELLIGE
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xu Q., 2020, IEEE GEOSCI REMOTE S
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang HK, 2019, IEEE T GEOSCI REMOTE, V57, P5813, DOI 10.1109/TGRS.2019.2902568
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 53
TC 2
Z9 2
U1 35
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG
PY 2021
VL 177
BP 103
EP 115
DI 10.1016/j.isprsjprs.2021.05.001
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA SR3ZD
UT WOS:000660980400007
DA 2022-01-04
ER

PT J
AU Zhang, L
   Hu, XY
   Zhang, M
   Shu, Z
   Zhou, H
AF Zhang, Lin
   Hu, Xiangyun
   Zhang, Mi
   Shu, Zhen
   Zhou, Hao
TI Object-level change detection with a dual correlation attention-guided
   detector
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Object level; Attention; Dual learning; Data
   augmentation
ID NETWORK; FUSION
AB Automatic change detection from remotely sensed imagery is extremely important for many applications, including land use mapping. In recent years, a growing number of researchers have applied capable deep-learning methods to the research on change detection. The majority of deep learning-based change detection methods currently perform pixel-by-pixel classification at the original image scale, but they can hardly avoid the false changes caused by strong parallax effects and projected shadows, without considering the totality of changed objects/regions. In this study, we propose an object-level change detection framework to detect changed geographic entities (such as newly built buildings or changed artificial structures) by paying more attention to the overall characteristics and context association of changed object instances. The detected changed objects are represented as bounding boxes, which are simple, regular, and convenient to use in object feature extraction. In terms of data handling, a special data augmentation method for change detection called Alternative-Mosaic is proposed to effectively accelerate model training and improve model performance. For the model, we propose a one-stage change detection network called dual correlation attention-guided detector (DCA-Det) to detect the changed objects. In particular, we feed the dual-temporal images into a weight-shared backbone network to extract the change features of different scales. The change features on the same scale are further refined, and then the features between different scales are fused by the correlation attention-guided feature fusion neck. Finally, the change detection heads output the prediction results of the changed objects/regions of different scales. Experiments were conducted on public LEVIR building change detection and aerial imagery change detection (AICD) datasets. The quantitative evaluation and visualization results proved the superiority and robustness of our framework. Our DCA-Det can obtain state-of-the-art performance on object-level metrics (99.50% AP(IoU=. 50) and 79.72% AP(IoU=. 50:.05:.95)) on the AICD-2012 dataset.
C1 [Zhang, Lin; Hu, Xiangyun; Zhang, Mi; Shu, Zhen; Zhou, Hao] Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Xiangyun] Wuhan Univ, Inst Artificial Intelligence Geomat, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
RP Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM amu0106@whu.edu.cn; huxy@whu.edu.cn; mizhang@whu.edu.cn;
   zhenshu1994@whu.edu.cn; lokezhou@whu.edu.cn
FU Chinese National Natural Science FoundationNational Natural Science
   Foundation of China (NSFC) [92038301, 41771363, 41901265]; Wuhan
   University - Huawei GeoInformatics Innovation Laboratory
FX We appreciate the reviewers and editors for their constructive comments
   which helped us improve the quality of the paper. This work has been
   supported by the Chinese National Natural Science Foundation Projects
   (Grant Nos. 92038301, 41771363 and 41901265), and was supported in part
   by the fundings of Wuhan University - Huawei GeoInformatics Innovation
   Laboratory.
CR Azulay A, 2019, J MACH LEARN RES, V20
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chien-Yao Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Diakogiannis F.I., 2020, ARXIV200902062
   Du F, 2020, PROC CVPR IEEE, P6835, DOI 10.1109/CVPR42600.2020.00687
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Farhadi, 2018, ARXIV180402767
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Han PC, 2019, NEUROCOMPUTING, V349, P190, DOI 10.1016/j.neucom.2019.04.029
   Haofan Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P111, DOI 10.1109/CVPRW50498.2020.00020
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kingma D., 2014, 14126980 ARXIV
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Larochelle H., 2010, ADV NEURAL INFORM PR, V23
   Lefebvre A, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P1697, DOI 10.1109/ICIP.2009.5413679
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Loshchilov I, 2017, P ICLR, P1
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Meng Y, 2021, APPL INTELL, V51, P3202, DOI 10.1007/s10489-020-01992-x
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI 10.1109/IWSSIP48289.2020.9145130
   QUARMBY NA, 1989, INT J REMOTE SENS, V10, P953, DOI 10.1080/01431168908903937
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   RICHARDS JA, 1984, REMOTE SENS ENVIRON, V16, P35, DOI 10.1016/0034-4257(84)90025-7
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Shifeng Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9756, DOI 10.1109/CVPR42600.2020.00978
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang S., 2020, NEUROCOMPUTING
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang R., 2019, 36 INT C MACH LEARN, P12712
   Zhang XL, 2017, REMOTE SENS ENVIRON, V201, P243, DOI 10.1016/j.rse.2017.09.022
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou H, 2021, REMOTE SENS LETT, V12, P387, DOI 10.1080/2150704X.2021.1892851
NR 52
TC 1
Z9 1
U1 29
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG
PY 2021
VL 177
BP 147
EP 160
DI 10.1016/j.isprsjprs.2021.05.002
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA SR3ZD
UT WOS:000660980400010
DA 2022-01-04
ER

PT J
AU Zhang, PZ
   Ban, YF
   Nascetti, A
AF Zhang, Puzhao
   Ban, Yifang
   Nascetti, Andrea
TI Learning U-Net without forgetting for near real-time wildfire monitoring
   by the fusion of SAR and optical time series
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Wildfire; Burned area; Change detection; Deep learning; U-Net; SAR;
   Sentinel-1; Sentinel-2
ID NORMALIZED BURN RATIO; FIRE SEVERITY; LANDSAT; CLASSIFICATION;
   CALIBRATION; INTEGRATION; IMAGES; RDNBR; SCARS; INDEX
AB Wildfires are increasing in intensity and frequency across the globe due to climate change and rising global temperature. Development of novel approach to Monitor wildfire progressions in near real-time is therefore of critical importance for emergency responses. The objective of this research is to investigate continuous learning with U-Net by exploiting both Sentinel-1 SAR and Sentinel-2 MSI time series for increasing the frequency and accuracy of wildfire progression mapping. In this study, optical-based burned areas prior to each SAR acquisition (when available) were accumulated into SAR-based pseudo progression masks to train a deep residual U-Net model. Unlike multi-temporal fusion of SAR and optical data, the temporal fusion of progression masks allows us to track as many wildfire progressions as possible. Specifically, two approaches were investigated to train the deep residual U-Net model for continuous learning: 1) Continuous joint training (CJT) with all historical data (including both SAR and optical data); 2) Learning without forgetting (LwF) based on newly incoming data alone (SAR or optical). For LwF, a mean squared loss was integrated to keep the capabilities learned before and prevent it from overfitting to newly incoming data only. By fusing optical-based burned areas, SAR-based progression pseudo masks improve significantly, which benefits both data sampling and model training, considering the challenges in SAR-based change extraction attributed to the variability in SAR backscatter of the surrounding environments. Pre-trained ResNet was frozen as the encoder of the U-Net model, and the decoder part was trained to further refine the derived burned area maps in a progression-wise manner. The experimental results demonstrated that LwF has the potential to match CJT in terms of the agreement between SAR-based results and optical-based ground truth, achieving a F1 score of 0.8423 on the Sydney Fire (2019-2020) and 0.7807 on the Chuckegg Creek Fire (2019). We also observed that the SAR cross-polarization ratio (VH/VV) shows good capability in suppressing multiplicative noise and detecting burned areas when VH and VV have diverse temporal behaviors.
C1 [Zhang, Puzhao; Ban, Yifang; Nascetti, Andrea] KTH Royal Inst Technol, Div Geoinformat, Teknikringen 10A, S-11428 Stockholm, Sweden.
RP Ban, YF (corresponding author), KTH Royal Inst Technol, Div Geoinformat, Teknikringen 10A, S-11428 Stockholm, Sweden.
EM yifang@kth.se
FU European Space Agency's EO Science for Society Program; KTH Digital
   Futures
FX This research is part of two projects, 'SAR4Wildfire' funded by the
   European Space Agency's EO Science for Society Program, and
   "EO-AI4GlobalChange" funded by KTH Digital Futures. We thank the Editor
   and Reviewers for their constructive comments and suggestions made to
   improve this manuscript.
CR Tanase MA, 2010, IEEE T GEOSCI REMOTE, V48, P917, DOI 10.1109/TGRS.2009.2025943
   Taghanaki SA, 2021, ARTIF INTELL REV, V54, P137, DOI 10.1007/s10462-020-09854-1
   Ban YF, 2003, CAN J REMOTE SENS, V29, P518, DOI 10.5589/m03-014
   Ban YF, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56967-x
   Ban YF, 2016, REMOTE SENS DIGIT IM, V20, P19, DOI 10.1007/978-3-319-47037-5_2
   Ban YF, 2013, IEEE T GEOSCI REMOTE, V51, P1998, DOI 10.1109/TGRS.2012.2236560
   Ban YF, 2010, INT J REMOTE SENS, V31, P1391, DOI 10.1080/01431160903475415
   Belenguer-Plomer MA, 2019, PROC SPIE, V11154, DOI 10.1117/12.2532832
   Belenguer-Plomer MA, 2019, REMOTE SENS ENVIRON, V233, DOI 10.1016/j.rse.2019.111345
   Bourgeau-Chavez LL, 2007, INT J REMOTE SENS, V28, P2133, DOI 10.1080/01431160600976061
   Bourgeau-Chavez LL, 2002, INT J REMOTE SENS, V23, P4211, DOI 10.1080/01431160110109589
   BourgeauChavez LL, 1997, INT J REMOTE SENS, V18, P355, DOI 10.1080/014311697219114
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Cai YT, 2020, INT J APPL EARTH OBS, V92, DOI 10.1016/j.jag.2020.102164
   Cardil A, 2019, J ENVIRON MANAGE, V235, P342, DOI 10.1016/j.jenvman.2019.01.077
   Chuvieco E, 2020, CURR FOR REP, V6, P81, DOI 10.1007/s40725-020-00116-5
   Crowley MA, 2019, REMOTE SENS ENVIRON, V232, DOI 10.1016/j.rse.2019.111295
   Dean, 2015, ARXIV150302531
   dos Reis J.B.C., 2019, BIODIV BRASIL, V1, P236
   Engelbrecht J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080764
   Escuin S, 2008, INT J REMOTE SENS, V29, P1053, DOI 10.1080/01431160701281072
   He K, 2016, CVPR, P770, DOI DOI 10.1109/CVPR.2016.90
   Huang MM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132073
   Jenkins LK, 2014, REMOTE SENS-BASEL, V6, P6347, DOI 10.3390/rs6076347
   Jiang X, 2020, IEEE J-STARS, V13, P1551, DOI 10.1109/JSTARS.2020.2983993
   KASISCHKE ES, 1992, INT J REMOTE SENS, V13, P3495, DOI 10.1080/01431169208904137
   Kim Y, 2012, IEEE GEOSCI REMOTE S, V9, P564, DOI 10.1109/LGRS.2011.2174772
   Kingma D. P., 2015, P INT C LEARN REPR I, P1
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lin T.-Y., 2017, FOCAL LOSS DENSE OBJ
   Littell JS, 2018, EARTHS FUTURE, V6, P1097, DOI 10.1029/2018EF000878
   Liu SJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060690
   Liu XZ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101654
   Lozano OM, 2017, RISK ANAL, V37, P1898, DOI 10.1111/risa.12739
   Miller JD, 2007, REMOTE SENS ENVIRON, V109, P66, DOI 10.1016/j.rse.2006.12.006
   Miller JD, 2009, REMOTE SENS ENVIRON, V113, P645, DOI 10.1016/j.rse.2008.11.009
   Mitchard E.T., 2012, BIOGEOSCIENCES, V9, P179, DOI [10.5194/bg-9-179-2012, DOI 10.5194/bg-9-179-2012]
   Orynbaikyzy A, 2019, INT J REMOTE SENS, V40, P6553, DOI 10.1080/01431161.2019.1569791
   Reiche J, 2015, REMOTE SENS ENVIRON, V156, P276, DOI 10.1016/j.rse.2014.10.001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Siegert F, 2000, REMOTE SENS ENVIRON, V72, P64, DOI 10.1016/S0034-4257(99)00092-9
   Stroppiana D, 2015, REMOTE SENS-BASEL, V7, P1320, DOI 10.3390/rs70201320
   Tanase MA, 2014, IEEE J-STARS, V7, P267, DOI 10.1109/JSTARS.2013.2261053
   Tanase MA, 2010, REMOTE SENS ENVIRON, V114, P2182, DOI 10.1016/j.rse.2010.04.021
   Veraverbeke S, 2011, INT J REMOTE SENS, V32, P3521, DOI 10.1080/01431161003752430
   Verbyla DL, 2008, INT J WILDLAND FIRE, V17, P527, DOI 10.1071/WF08038
   Vila-Vilardell L, 2020, FOREST ECOL MANAG, V461, DOI 10.1016/j.foreco.2020.117927
   Vreugdenhil M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091396
   Ye S, 2021, REMOTE SENS ENVIRON, V252, DOI 10.1016/j.rse.2020.112167
   Zhang PZ, 2019, ISPRS J PHOTOGRAMM, V158, P50, DOI 10.1016/j.isprsjprs.2019.09.013
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 51
TC 0
Z9 0
U1 16
U2 16
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD AUG
PY 2021
VL 261
AR 112467
DI 10.1016/j.rse.2021.112467
PG 12
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA SU9LG
UT WOS:000663450900004
OA hybrid
DA 2022-01-04
ER

PT J
AU Li, XH
   He, MZ
   Li, HF
   Shen, HF
AF Li, Xinghua
   He, Meizhen
   Li, Huifang
   Shen, Huanfeng
TI A Combined Loss-Based Multiscale Fully Convolutional Network for
   High-Resolution Remote Sensing Image Change Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Remote sensing; Convolution; Feature extraction; Training; Task
   analysis; Loss measurement; Convolutional neural networks; Change
   detection (CD); combined loss function; high-resolution remote sensing
   images (HRSIs); multiscale fully convolutional neural network (MFCN)
ID MODEL
AB In the task of change detection (CD), high-resolution remote sensing images (HRSIs) can provide rich ground object information. However, the interference from noise and complex background information can also bring some challenges to CD. In recent years, deep learning methods represented by convolutional neural networks (CNNs) have achieved good CD results. However, the existing methods have difficulty in detecting the detailed change information of the ground objects effectively. The imbalance of positive and negative samples can also seriously affect the CD results. In this letter, to solve the above problems, we propose a method based on a multiscale fully convolutional neural network (MFCN), which uses multiscale convolution kernels to extract the detailed features of the ground object features. A loss function combining weighted binary cross-entropy (WBCE) loss and dice coefficient loss is also proposed, so that the model can be trained from unbalanced samples. The proposed method was compared with six state-of-the-art CD methods on the DigitalGlobe dataset. The experiments showed that the proposed method can achieve a higher F1-score, and the detection effect of the detailed changes was better than that of the other methods.
C1 [Li, Xinghua] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [He, Meizhen; Li, Huifang; Shen, Huanfeng] Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430079, Peoples R China.
RP Shen, HF (corresponding author), Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430079, Peoples R China.
EM lixinghua5540@whu.edu.cn; hmz_whu@163.com; huifangli@whu.edu.cn;
   shenhf@whu.edu.cn
RI Li, Xinghua/F-6679-2014
OI Li, Xinghua/0000-0002-2094-6480
FU National Key Research and Development Program of China [2019YFB2102904];
   National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [41701394]
FX The work was supported in part by the National Key Research and
   Development Program of China under Grant 2019YFB2102904 and in part by
   the National Natural Science Foundation of China (NSFC) under Grant
   41701394.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Ferraris V, 2018, IEEE T GEOSCI REMOTE, V56, P1566, DOI 10.1109/TGRS.2017.2765348
   Guibin Xu, 2020, IOP Conference Series: Materials Science and Engineering, V768, DOI 10.1088/1757-899X/768/7/072073
   Ke L, 2018, IEEE ACCESS, V6, P27442, DOI 10.1109/ACCESS.2018.2807380
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Meola J, 2011, IEEE T GEOSCI REMOTE, V49, P2647, DOI 10.1109/TGRS.2011.2109726
   Sadeghi V, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2301-x
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thakkar AK, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2267-8
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yan L, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060841
   Zeng Y, 2008, REMOTE SENS ENVIRON, V112, P4261, DOI 10.1016/j.rse.2008.07.007
NR 15
TC 1
Z9 1
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3098774
EA JUL 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR4GF
UT WOS:000732189000001
DA 2022-01-04
ER

PT J
AU Liu, ZG
   Zhang, ZW
   Pan, Q
   Ning, LB
AF Liu, Zhun-Ga
   Zhang, Zuo-Wei
   Pan, Quan
   Ning, Liang-Bo
TI Unsupervised Change Detection From Heterogeneous Data Based on Image
   Translation
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Optical sensors; Optical imaging; Feature extraction; Synthetic aperture
   radar; Remote sensing; Laser radar; Radar polarimetry; Classification;
   clustering; heterogeneous images; image translation; unsupervised change
   detection (USCD)
ID URBAN CHANGE DETECTION; LAND-COVER; CLASSIFICATION; SIMILARITY
AB It is quite an important and challenging problem for change detection (CD) from heterogeneous remote sensing images. The images obtained from different sensors (i.e., synthetic aperture radar (SAR) & optical camera) characterize the distinct properties of objects. Thus, it is impossible to detect changes by direct comparison of heterogeneous images. In this article, a new unsupervised change detection (USCD) method is proposed based on image translation. The cycle-consistent adversarial networks (CycleGANs) are employed to learn the subimage to subimage mapping relation using the given pair (i.e., before and after the event) of heterogeneous images from which the changes will be detected. Then, we can translate one image (e.g., SAR) from its original feature space (e.g., SAR) to another space (e.g., optical). By doing this, the pair of images can be represented in a common feature space (e.g., optical). The pixels with close pattern values in the before-event image may have quite different values in the after-event image if the change happens on some ones. Thus, we can generate the difference map between the translated before-event image and the original after-event image. Then, the difference map is divided into changed and unchanged parts. However, these detection results are not very reliable. We will select some significantly changed and unchanged pixel pairs from the two parts with the clustering technique (i.e., K-means). These selected pixel pairs are used to learn a binary classifier, and the other pixel pairs will be classified by this classifier to obtain the final CD results. Experimental results on different real datasets demonstrate the effectiveness of the proposed USCD method compared with several other related methods.
C1 [Liu, Zhun-Ga; Zhang, Zuo-Wei; Pan, Quan; Ning, Liang-Bo] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
RP Liu, ZG (corresponding author), Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
EM liuzhunga@nwpu.edu.cn; zuowei_zhang@mail.nwpu.edu.cn;
   quanpan@nwpu.edu.cn; ninglb@mail.nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61790554, U20B2067, 61790552]; Innovation
   Foundation for Doctor Dissertation of Northwestern Polytechnical
   University [CX201953]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61790554, Grant U20B2067, and Grant
   61790552; and in part by the Innovation Foundation for Doctor
   Dissertation of Northwestern Polytechnical University under Grant
   CX201953.
CR Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Chaturvedi I, 2015, SIGNAL PROCESS, V110, P250, DOI 10.1016/j.sigpro.2014.09.009
   Chen J, 2011, IEEE GEOSCI REMOTE S, V8, P317, DOI 10.1109/LGRS.2010.2068537
   Chintala S, 2015, ARXIV151106434, P248, DOI DOI 10.1051/0004-6361/201527329
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Goncalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Green O, 2018, IEEE T IMAGE PROCESS, V27, P2217, DOI 10.1109/TIP.2017.2781375
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Hastie T, 1996, IEEE T PATTERN ANAL, V18, P607, DOI 10.1109/34.506411
   He D., 2016, ADV NEURAL INFORM PR, DOI DOI 10.5555/3157096.3157188
   Huang X, 2018, IEEE IND APPLIC SOC, DOI 10.1007/978-3-030-01219-9_11
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li MJ, 2018, LECT NOTES COMPUT SC, V11213, P186, DOI 10.1007/978-3-030-01240-3_12
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Liu DS, 2008, REMOTE SENS ENVIRON, V112, P2222, DOI 10.1016/j.rse.2007.10.002
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu MY, 2017, ADV NEUR IN, V30
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Natekin A, 2013, FRONT NEUROROBOTICS, V7, DOI 10.3389/fnbot.2013.00021
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ontivero-Ortega M, 2017, NEUROIMAGE, V163, P471, DOI 10.1016/j.neuroimage.2017.09.001
   Paglieroni DW, 2015, IEEE T GEOSCI REMOTE, V53, P2426, DOI 10.1109/TGRS.2014.2360097
   Quin G, 2014, IEEE T GEOSCI REMOTE, V52, P5349, DOI 10.1109/TGRS.2013.2288271
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Touati R, 2020, IEEE J-STARS, V13, P588, DOI 10.1109/JSTARS.2020.2964409
   Touati R, 2019, IEEE J-STARS, V12, P3588, DOI 10.1109/JSTARS.2019.2934602
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI [10.1109/TPAMI.2020.2982166, 10.1109/LGRS.2020.3027363]
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Ye S, 2015, PHOTOGRAMM ENG REM S, V81, P637, DOI 10.14358/PERS.81.8.637
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhang QL, 2015, IEEE T GEOSCI REMOTE, V53, P219, DOI 10.1109/TGRS.2014.2321145
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
NR 57
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3097717
EA JUL 2021
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2ZI
UT WOS:000732782800001
DA 2022-01-04
ER

PT J
AU Zhao, CH
   Cheng, H
   Feng, S
AF Zhao, Chunhui
   Cheng, Hao
   Feng, Shou
TI A Spectral-Spatial Change Detection Method Based on Simplified 3-D
   Convolutional Autoencoder for Multitemporal Hyperspectral Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Convolution; Kernel; Data mining; Training;
   Hyperspectral imaging; Decoding; 3-D convolutional autoencoder (3DCAE);
   change detection; hyperspectral images (HSIs); spatial-spectral
   information
AB Change detection for multitemporal hyperspectral images (HSIs) has always been a research hotspot of remote sensing. However, most current detection methods only use spectral information or spatial information separately, and there are many false detection areas in the detection results. Besides, the feature extraction method based on neural networks needs a huge amount of training samples, but collecting labeled training samples for change detection tasks is difficult. Therefore, this letter proposes a hyperspectral change detection method based on a simplified 3-D convolutional autoencoder (S3DCAECD). First, the framework is based on deep unsupervised autoencoder (AE), which can extract deep spectral-spatial features from bitemporal images without the need for prior information. Second, by adding a 3-D convolution kernel and eliminating the pooling layer, the structure of 3-D convolutional AE is simplified, which can reduce spectral redundancy and improve data processing speed. Finally, a softmax classifier with a 2-D convolutional layer added is used to obtain the detection result, and only a few label samples are needed to train the classifier. Three HSIs' experimental results indicate that the accuracy of the S3DCAECD is more than 95% on three experimental datasets and it has better detection results than several commonly used methods.
C1 [Zhao, Chunhui; Cheng, Hao; Feng, Shou] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
   [Zhao, Chunhui; Cheng, Hao; Feng, Shou] Harbin Engn Univ, Key Lab Adv Marine Commun & Informat Technol, Minist Ind & Informat Technol, Harbin 150001, Peoples R China.
RP Feng, S (corresponding author), Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
EM zhaochunhui1965@163.com; chenghaowise@qq.com; fengshou@hrbeu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62002083, 61971153, 62071136, 61801142];
   Heilongjiang Postdoctoral Foundation [LBH-Z20051]; Heilongjiang
   Postdoctoral Funds for Scientific Research Initiation [LBH-Q20085];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [3072021CFT0801,
   3072021CF0814, 3072021CF0807, 3072021CF0808]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62002083, Grant 61971153, Grant
   62071136, and Grant 61801142; in part by the Heilongjiang Postdoctoral
   Foundation under Grant LBH-Z20051; in part by the Heilongjiang
   Postdoctoral Funds for Scientific Research Initiation under Grant
   LBH-Q20085; and in part by the Fundamental Research Funds for the
   Central Universities under Grant 3072021CFT0801, Grant 3072021CF0814,
   Grant 3072021CF0807, and Grant 3072021CF0808.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P143, DOI 10.1109/ICIP.1999.821583
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Lin Y, 2020, IEEE GEOSCI REMOTE S, V17, P1757, DOI 10.1109/LGRS.2019.2953754
   Liu G., 2021, IEEE T GEOSCI ELECT, DOI [10.1109/TGRS.2020.3026099, DOI 10.1109/TGRS.2020.3026099]
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Yu CY, 2020, IEEE J-STARS, V13, P2485, DOI 10.1109/JSTARS.2020.2983224
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3096526
EA JUL 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR2RI
UT WOS:000732082700001
DA 2022-01-04
ER

PT J
AU Wang, LF
   Wang, LG
   Wang, QM
   Atkinson, PM
AF Wang, Lifeng
   Wang, Liguo
   Wang, Qunming
   Atkinson, Peter M.
TI SSA-SiamNet: Spectral-Spatial-Wise Attention-Based Siamese Network for
   Hyperspectral Image Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Feature extraction; Task analysis; Tensors; Hyperspectral imaging;
   Training; Redundancy; Convolution; Attention mechanism; change detection
   (CD); convolutional block attention module (CBAM); hyperspectral images
   (HSIs); Siamese network (SiamNet)
ID ARCHITECTURE
AB Deep learning methods, especially convolutional neural network (CNN)-based methods, have shown promising performance for hyperspectral image (HSI) change detection (CD). It is acknowledged widely that different spectral channels and spatial locations in input image patches may contribute differently to CD. However, they are treated equally in existing CNN-based approaches. To increase the accuracy of HSI CD, we propose an end-to-end Siamese CNN (SiamNet) with a spectral-spatial-wise attention (SSA-SiamNet) mechanism. The proposed SSA-SiamNet method can emphasize informative channels and locations and suppress less informative ones to refine the spectral-spatial features adaptively. Moreover, in the network training phase, the weighted contrastive loss function is used for more reliable separation of changed and unchanged pixels and to accelerate the convergence of the network. SSA-SiamNet was validated using four groups of bitemporal HSIs. The accuracy of CD using the SSA-SiamNet was found to be consistently greater than for ten benchmark methods.
C1 [Wang, Lifeng; Wang, Liguo] Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150000, Peoples R China.
   [Wang, Liguo] Dalian Minzu Univ, Sch Informat & Commun Engn, Dalian 116600, Peoples R China.
   [Wang, Qunming] Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
   [Atkinson, Peter M.] Univ Lancaster, Fac Sci & Technol, Lancaster LA1 4YR, England.
   [Atkinson, Peter M.] Univ Southampton, Dept Geog & Environm, Southampton SO17 1BJ, Hants, England.
RP Wang, QM (corresponding author), Tongji Univ, Coll Surveying & Geoinformat, Shanghai 200092, Peoples R China.
EM wanglifeng_2016@163.com; wqm11111@126.com
OI Atkinson, Peter/0000-0002-5489-6880
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41971297, 62071084]; Tongji University
   [02502350047]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41971297 and Grant 62071084 and in part
   by Tongji University under Grant 02502350047.
CR Adao T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111110
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bullock EL, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2019.04.018
   Cai YM, 2020, IEEE T GEOSCI REMOTE, V58, P1969, DOI 10.1109/TGRS.2019.2951433
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chang CI, 2021, IEEE T GEOSCI REMOTE, V59, P5131, DOI 10.1109/TGRS.2020.3021671
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hadsell Raia, 2006, P IEEE COMP SOC C CO, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hang R., 2020, IEEE T GEOSCI ELECT, V59, P1
   Hao SY, 2018, IEEE T GEOSCI REMOTE, V56, P4650, DOI 10.1109/TGRS.2018.2832228
   Hao SY, 2018, IEEE T GEOSCI REMOTE, V56, P2349, DOI 10.1109/TGRS.2017.2778343
   Haut JM, 2019, IEEE T GEOSCI REMOTE, V57, P8065, DOI 10.1109/TGRS.2019.2918080
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Huang X, 2017, REMOTE SENS ENVIRON, V196, P56, DOI 10.1016/j.rse.2017.05.001
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia S, 2020, IEEE T NEUR NET LEAR, V31, P1638, DOI 10.1109/TNNLS.2019.2921564
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Kweon IS., 2018, ARXIV180706514
   Li JJ, 2020, IEEE T GEOSCI REMOTE, V58, P4304, DOI 10.1109/TGRS.2019.2962713
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040331
   Lin Z, 2019, IEEE GEOSCI REMOTE S, V16, P751, DOI 10.1109/LGRS.2018.2882551
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2017, IEEE GEOSCI REMOTE S, V14, P324, DOI 10.1109/LGRS.2016.2639540
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111307
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Mou LC, 2020, IEEE T GEOSCI REMOTE, V58, P110, DOI 10.1109/TGRS.2019.2933609
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Rasti B, 2020, IEEE GEOSC REM SEN M, V8, P60, DOI 10.1109/MGRS.2020.2979764
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Song MP, 2020, IEEE T GEOSCI REMOTE, V58, P8093, DOI 10.1109/TGRS.2020.2987137
   Sun H, 2020, IEEE T GEOSCI REMOTE, V58, P3232, DOI 10.1109/TGRS.2019.2951160
   Sun ZH, 2019, INT J REMOTE SENS, V40, P593, DOI 10.1080/01431161.2018.1516313
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang QM, 2021, REMOTE SENS ENVIRON, V259, DOI 10.1016/j.rse.2021.112407
   Wang QM, 2020, REMOTE SENS ENVIRON, V249, DOI 10.1016/j.rse.2020.112009
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wen DW, 2016, IEEE T GEOSCI REMOTE, V54, P609, DOI 10.1109/TGRS.2015.2463075
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu HY, 2020, IEEE T GEOSCI REMOTE, V58, P3043, DOI 10.1109/TGRS.2019.2947032
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhu MH, 2021, IEEE T GEOSCI REMOTE, V59, P449, DOI 10.1109/TGRS.2020.2994057
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 56
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3095899
EA JUL 2021
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS4MJ
UT WOS:000732885000001
OA Green Accepted
DA 2022-01-04
ER

PT J
AU Chen, H
   Qi, ZP
   Shi, ZW
AF Chen, Hao
   Qi, Zipeng
   Shi, Zhenwei
TI Remote Sensing Image Change Detection With Transformers
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Semantics; Context modeling; Feature extraction; Computational modeling;
   Task analysis; Buildings; Radio frequency; Attention mechanism; change
   detection (CD); convolutional neural networks (CNNs); high-resolution
   (HR) optical remote sensing (RS) image; transformers
ID NETWORK
AB Modern change detection (CD) has achieved remarkable success by the powerful discriminative ability of deep convolutions. However, high-resolution remote sensing CD remains challenging due to the complexity of objects in the scene. Objects with the same semantic concept may show distinct spectral characteristics at different times and spatial locations. Most recent CD pipelines using pure convolutions are still struggling to relate long-range concepts in space-time. Nonlocal self-attention approaches show promising performance via modeling dense relationships among pixels, yet are computationally inefficient. Here, we propose a bitemporal image transformer (BIT) to efficiently and effectively model contexts within the spatial-temporal domain. Our intuition is that the high-level concepts of the change of interest can be represented by a few visual words, that is, semantic tokens. To achieve this, we express the bitemporal image into a few tokens and use a transformer encoder to model contexts in the compact token-based space-time. The learned context-rich tokens are then fed back to the pixel-space for refining the original features via a transformer decoder. We incorporate BIT in a deep feature differencing-based CD framework. Extensive experiments on three CD datasets demonstrate the effectiveness and efficiency of the proposed method. Notably, our BIT-based model significantly outperforms the purely convolutional baseline using only three times lower computational costs and model parameters. Based on a naive backbone (ResNet18) without sophisticated structures (e.g., feature pyramid network (FPN) and UNet), our model surpasses several state-of-the-art CD methods, including better than four recent attention-based methods in terms of efficiency and accuracy. Our code is available at https://github.com/justchenhao/BIT_CD.
C1 [Chen, Hao; Qi, Zipeng; Shi, Zhenwei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
   [Chen, Hao; Qi, Zipeng; Shi, Zhenwei] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Chen, Hao; Qi, Zipeng; Shi, Zhenwei] Beihang Univ, Sch Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
RP Shi, ZW (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
EM shizhenwei@buaa.edu.cn
FU National Key Research and Development Program of China [2019YFC1510905];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61671037]; Beijing Natural Science
   FoundationBeijing Natural Science Foundation [4192034]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2019YFC1510905, in part by the
   National Natural Science Foundation of China under Grant 61671037, and
   in part by the Beijing Natural Science Foundation under Grant 4192034.
CR Bao TF, 2020, IEEE GEOSCI REMOTE S, V17, P1797, DOI 10.1109/LGRS.2019.2955309
   Bazi Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13030516
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen H ., 2020, P IEEE CVF C COMP VI, P12299
   Chen H, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3095166
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen M, 2020, PR MACH LEARN RES, V119
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060901
   Devlin J., 2018, P ANN C N AM CHAPT A
   Diakogiannis F. I., 2020, ARXIV200902062
   Dong Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P323, DOI 10.1007/978-3-030-58604-1_20
   Dosovitskiy A ., ARXIV201011929
   Esser P., P IEEE CVF C COMP VI, P12873
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Fang S, 2021, IEEE GEOSCI REMOTE S, DOI 10.1109/LGRS.2021.3056416
   Gimpel K., 2020, ARXIV160608415
   He J, 2020, IEEE T GEOSCI REMOTE, V58, P165, DOI 10.1109/TGRS.2019.2934760
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Jegou H., 2020, ARXIV201212877, P10347
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Li Z., IEEE J SEL TOPICS AP, V13, P847
   Liu RY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232844
   Liu W., ARXIV210110804, V2021
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Nguyen Toan Q, 2019, P WORKSH SPOK LANG T
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Shen XQ, 2020, MULTIMED TOOLS APPL, V79, P26661, DOI 10.1007/s11042-020-09294-7
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Su W., P INT C LEARN REPR, V2021, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P5028, DOI 10.1109/TGRS.2020.3011002
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu, 2020, ARXIV200603677
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yuan Y, 2021, IEEE J-STARS, V14, P474, DOI 10.1109/JSTARS.2020.3036602
   Zaytseva V ., 2019, P C NEUR INF PROC SY
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhao W., IEEE GEOSCI REMOTE S, P2021, DOI [10.1109/LGRS.2020.3035780, DOI 10.1109/LGRS.2020.3035780]
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zheng S, P IEEE CVF C COMP VI, P6881
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 56
TC 5
Z9 5
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3095166
EA JUL 2021
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2SF
UT WOS:000732764300001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Wu, C
   Chen, HRX
   Du, B
   Zhang, LP
AF Wu, Chen
   Chen, Hongruixuan
   Du, Bo
   Zhang, Liangpei
TI Unsupervised Change Detection in Multitemporal VHR Images Based on Deep
   Kernel PCA Convolutional Mapping Network
SO IEEE TRANSACTIONS ON CYBERNETICS
LA English
DT Article; Early Access
DE Feature extraction; Principal component analysis; Kernel; Convolution;
   Remote sensing; Training; Task analysis; Change detection (CD); deep
   siamese KPCA convolutional mapping network (KPCA-MNet); kernel principal
   component analysis (KPCA); unsupervised multiclass change detection;
   very-high-resolution (VHR) images
ID CHANGE VECTOR ANALYSIS; SLOW FEATURE ANALYSIS; CLASSIFICATION;
   MULTISENSOR; ALGORITHM; FOREST; MAD
AB With the development of Earth observation technology, a very-high-resolution (VHR) image has become an important data source of change detection (CD). These days, deep learning (DL) methods have achieved conspicuous performance in the CD of VHR images. Nonetheless, most of the existing CD models based on DL require annotated training samples. In this article, a novel unsupervised model, called kernel principal component analysis (KPCA) convolution, is proposed for extracting representative features from multitemporal VHR images. Based on the KPCA convolution, an unsupervised deep siamese KPCA convolutional mapping network (KPCA-MNet) is designed for binary and multiclass CD. In the KPCA-MNet, the high-level spatial-spectral feature maps are extracted by a deep siamese network consisting of weight-shared KPCA convolutional layers. Then, the change information in the feature difference map is mapped into a 2-D polar domain. Finally, the CD results are generated by threshold segmentation and clustering algorithms. All procedures of KPCA-MNet do not require labeled data. The theoretical analysis and experimental results in two binary CD datasets and one multiclass CD datasets demonstrate the validity, robustness, and potential of the proposed method.
C1 [Wu, Chen; Chen, Hongruixuan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Sch Comp Sci, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
   [Zhang, Liangpei] Wuhan Univ, Remote Sensing Grp, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
RP Zhang, LP (corresponding author), Wuhan Univ, Remote Sensing Grp, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM chen.wu@whu.edu.cn; qschrx@whu.edu.cn; gunspace@163.com;
   zlp62@whu.edu.cn
OI Chen, Hongruixuan/0000-0003-0100-4786
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971317, 61822113, 41801285]; Natural
   Science Foundation of Hubei ProvinceNatural Science Foundation of Hubei
   Province [2020CFB594, 2018CFA050]; National Key Research and Development
   Program of China [2018YFA0605500]; Science and Technology Major Project
   of Hubei Province (Next-Generation AI Technologies) [2019AEA170]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61971317, Grant 61822113, and Grant
   41801285; in part by the Natural Science Foundation of Hubei Province
   under Grant 2020CFB594 and Grant 2018CFA050; in part by the National Key
   Research and Development Program of China under Grant 2018YFA0605500;
   and in part by the Science and Technology Major Project of Hubei
   Province (Next-Generation AI Technologies) under Grant 2019AEA170. This
   article was recommended by Associate Editor H. Wang.
CR Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Doroodgar B, 2014, IEEE T CYBERNETICS, V44, P2719, DOI 10.1109/TCYB.2014.2314294
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gu YF, 2008, IEEE GEOSCI REMOTE S, V5, P43, DOI 10.1109/LGRS.2007.907304
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hoberg T, 2015, IEEE T GEOSCI REMOTE, V53, P659, DOI 10.1109/TGRS.2014.2326886
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei Z, 2014, IEEE T GEOSCI REMOTE, V52, P1227, DOI 10.1109/TGRS.2013.2248738
   Li H, 2014, IEEE T CYBERNETICS, V44, P1544, DOI 10.1109/TCYB.2013.2289331
   Li XQ, 2019, IEEE T CYBERNETICS, V49, P380, DOI 10.1109/TCYB.2017.2772289
   Li ZR, 2010, IEEE IMAGE PROC, P2701, DOI 10.1109/ICIP.2010.5652028
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen A, 2008, P SPIE INT SOC OPT E, V7109
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xia JS, 2017, IEEE J-STARS, V10, P1601, DOI 10.1109/JSTARS.2016.2636877
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang L., 2019, P 10 INT WORKSH AN M, P1
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 62
TC 2
Z9 2
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2168-2267
EI 2168-2275
J9 IEEE T CYBERNETICS
JI IEEE T. Cybern.
PY 2021
DI 10.1109/TCYB.2021.3086884
EA JUL 2021
PG 15
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Computer Science, Cybernetics
SC Automation & Control Systems; Computer Science
GA XR3LD
UT WOS:000732134200001
PM 34236977
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Tang, C
   Zhang, ZM
   He, GJ
   Long, TF
   Wang, GZ
   Wei, MY
   She, WQ
AF Tang, Chao
   Zhang, Zhaoming
   He, Guojin
   Long, Tengfei
   Wang, Guizhou
   Wei, Mingyue
   She, Wenqing
TI An improved fully convolution network model for change detection in
   mining areas using sentinel-2 images
SO REMOTE SENSING LETTERS
LA English
DT Article
AB High-resolution satellite images have recently been widely used for change detection of mineral resources and mining area environments. However, with their increasing resolution and number of feature sub-categories, traditional machine learning methods have become sensitive to pseudo-changes and intra-class changes, which are prone to producing misclassifications. To address these problems, a novel fully convolutional network, the Hybrid Dilated Convolutional Siamese Network (HDC-Siam) was proposed. This model combines the modular dilated convolution network with the fully convolutional Siamese networks structure, in order to reduce the commission rate. In this paper, pairs of Sentinel-2 images with an interval of about two years was used as the experimental data. The HDC-Siam model was used to detect changes, where we evaluated the accuracy in the Dongsheng coalfield in Ordos, China and the Kuznetsk coalfield in Kemerovo, Russia. We obtained F (1)-scores of 85% and 75% for these respective locations. In addition, we conducted comparative experiments using two other methods - Fully Convolutional Siamese - Difference (FC-Siam-diff) and Fully Convolutional Early Fusion (FC-EF) - in order to verify that the HDC-Siam works.
C1 [Tang, Chao; Zhang, Zhaoming; He, Guojin; Long, Tengfei; Wang, Guizhou; Wei, Mingyue; She, Wenqing] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
   [Tang, Chao; Wei, Mingyue] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China.
   [She, Wenqing] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Zhang, ZM (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing, Peoples R China.
EM zhangzm@radi.ac.cn
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [61731022]; Strategic Priority
   Research Program of the Chinese Academy of SciencesChinese Academy of
   Sciences [XDA19090300]; National Key Research and Development Program of
   China [2016YFA0600302,2016YFB0501502]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) [61731022]; the Strategic Priority Research Program of the
   Chinese Academy of Sciences [XDA19090300]; National Key Research and
   Development Program of China [2016YFA0600302,2016YFB0501502].
CR Buslaev A, 2018, IEEE COMPUT SOC CONF, P197, DOI 10.1109/CVPRW.2018.00035
   Chasmer L, 2018, SCI TOTAL ENVIRON, V642, P436, DOI 10.1016/j.scitotenv.2018.06.039
   Chen L.-C., 2018, COMP VIS ECCV 2018
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng B, 2020, INT J REMOTE SENS, V41, P3575, DOI 10.1080/01431161.2019.1706009
   Daudt R.C, 2018, IGARSS 2018 2018 IEE
   Daudt R.C, 2018, 2018 25 IEEE INT C I
   [杜培军 Du Peijun], 2012, [中国矿业大学学报. 自然科学版, Journal of China University of Mining & Technology], V41, P262
   El Amin A. M., 2016, P SPIE
   El Amin A.M., 2017 2 INT C IM VIS
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, P257, DOI 10.1109/CVPRW.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Xu YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010144
   Yu F., 2016, ARXIV151107122CS
   Zhang M., 2017, INT ARCH PHOTOGRAMME, V42, P1017
   Zhang ZM, 2015, PHOTOGRAMM ENG REM S, V81, P745
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
NR 19
TC 1
Z9 1
U1 10
U2 19
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PD JUL 3
PY 2021
VL 12
IS 7
BP 684
EP 694
DI 10.1080/2150704X.2021.1925372
PG 11
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA SB4EW
UT WOS:000649950700001
DA 2022-01-04
ER

PT J
AU Zhang, HY
   Lin, MH
   Yang, GY
   Zhang, LP
AF Zhang, Hongyan
   Lin, Manhui
   Yang, Guangyi
   Zhang, Liangpei
TI ESCNet: An End-to-End Superpixel-Enhanced Change Detection Network for
   Very-High-Resolution Remote Sensing Images
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Feature extraction; Image segmentation; Remote sensing; Image color
   analysis; Task analysis; Semantics; Neural networks; Change detection
   (CD); neural network; remote sensing imagery; superpixel segmentation
ID COVER CHANGE DETECTION; LAND-USE; MAD
AB Change detection (CD), as one of the central problems in Earth observation, has attracted a lot of research interest over recent decades. Due to the rapid development of satellite sensors in recent years, we have witnessed an enrichment of the CD source data with the availability of very-high-resolution (VHR) multispectral imagery, which provides abundant change clues. However, precisely locating real changed areas still remains a challenge. In this article, we propose an end-to-end superpixel-enhanced CD network (ESCNet) for VHR images, which combines differentiable superpixel segmentation and a deep convolutional neural network (DCNN). Two weight-sharing superpixel sampling networks (SSNs) are tailored for the feature extraction and superpixel segmentation of bitemporal image pairs. A UNet-based Siamese neural network is then employed to mine the different information. The superpixels are then leveraged to reduce the latent noise in the pixel-level feature maps while preserving the edges, where a novel superpixelation module is used to serve this purpose. Furthermore, to compensate for the dependence on the number of superpixels, we propose an innovative adaptive superpixel merging (ASM) module, which has a concise form and is fully differentiable. A pixel-level refinement module making use of the multilevel decoded features is also appended to the end of the framework. Experiments on two public datasets confirmed the superiority of ESCNet compared to the traditional and state-of-the-art (SOTA) deep learning-based CD (DLCD) methods.
C1 [Zhang, Hongyan; Lin, Manhui; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
   [Yang, Guangyi] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
RP Yang, GY (corresponding author), Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
EM zhanghongyan@whu.edu.cn; ygy@whu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42071322, 61871298]; Natural Science
   Foundation of Qinghai Province [2020-ZJ-927]; Wuhan Application
   Foundation Frontier Project [2020010601012184]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 42071322 and Grant 61871298, in part by
   the Natural Science Foundation of Qinghai Province under Grant
   2020-ZJ-927, and in part by the Wuhan Application Foundation Frontier
   Project under Grant 2020010601012184.
CR Abd El-Kawy OR, 2011, APPL GEOGR, V31, P483, DOI 10.1016/j.apgeog.2010.10.012
   Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Ball G.H., 1965, ISODATA NOVEL METHOD
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bontemps S, 2008, REMOTE SENS ENVIRON, V112, P3181, DOI 10.1016/j.rse.2008.03.013
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Bruzzone L, 2002, IEEE T GEOSCI REMOTE, V40, P1984, DOI 10.1109/TGRS.2002.803794
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Erener A, 2009, RIV ITAL TELERILEVAM, V41, P47
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   FRICK A, 2019, J GEOVISUALIZATION S, V3, P1
   Gehler P. V, 2015, ARXIV151106739
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jabari S, 2019, ISPRS J PHOTOGRAMM, V147, P163, DOI 10.1016/j.isprsjprs.2018.11.014
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Kim DH, 2014, REMOTE SENS ENVIRON, V155, P178, DOI 10.1016/j.rse.2014.08.017
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lefevre S, 2016, GEOBIA, P1
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lein K. J, 2011, ENV SENSING ANAL TEC
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu P, 2011, IEEE GEOSCI REMOTE S, V8, P701, DOI 10.1109/LGRS.2010.2101045
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Lv PY, 2016, IEEE GEOSCI REMOTE S, V13, P1965, DOI 10.1109/LGRS.2016.2619163
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Pang SY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060729
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K., 2015, P BRIT MACH VIS C, V61, P1, DOI DOI 10.5244/C.29.61
   Szegedy, 2015, ARXIV 1502 03167
   Tu WC, 2018, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2018.00066
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xu G, 2020, IEEE GEOSCI REMOTE S, DOI [10. 1109/LGRS.2020.3022512, DOI 10.1109/LGRS.2020.3022512]
   Zhai H, 2021, IEEE GEOSC REM SEN M, DOI 10.1109/MGRS.2020.3032575
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang Hongyan, 2020, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2020.3041646
   Zhang JX, 2007, ISPRS J PHOTOGRAMM, V62, P461, DOI 10.1016/j.isprsjprs.2007.07.002
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030548
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 59
TC 1
Z9 1
U1 9
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PY 2021
DI 10.1109/TNNLS.2021.3089332
EA JUL 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
SC Computer Science; Engineering
GA XS9UI
UT WOS:000733244200001
PM 34224358
DA 2022-01-04
ER

PT J
AU Liu, MX
   Shi, Q
   Marinoni, A
   He, D
   Liu, XP
   Zhang, LP
AF Liu, Mengxi
   Shi, Qian
   Marinoni, Andrea
   He, Da
   Liu, Xiaoping
   Zhang, Liangpei
TI Super-Resolution-Based Change Detection Network With Stacked Attention
   Module for Images With Different Resolutions
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Feature extraction; Remote sensing; Superresolution; Spatial resolution;
   Measurement; Semantics; Data mining; Change detection (CD); fully
   convolutional networks (FCNs); metric learning; remote sensing images;
   super-resolution
ID LAND-COVER CHANGE; CLASSIFICATION; SCALE
AB Change detection (CD) aims to distinguish surface changes based on bitemporal images. Since high-resolution (HR) images cannot be typically acquired continuously over time, bitemporal images with different resolutions are often adopted for CD in practical applications. Traditional subpixel-based methods for CD using images with different resolutions may lead to substantial error accumulation when the HR images are employed, which is because of intraclass heterogeneity and interclass similarity. Therefore, it is necessary to develop a novel method for CD using images with different resolutions that are more suitable for the HR images. To this end, we propose a super-resolution-based change detection network (SRCDNet) with a stacked attention module (SAM). The SRCDNet employs a super-resolution (SR) module containing a generator and a discriminator to directly learn the SR images through adversarial learning and overcome the resolution difference between the bitemporal images. To enhance the useful information in multiscale features, a SAM consisting of five convolutional block attention modules (CBAMs) is integrated to the feature extractor. The final change map is obtained through a metric learning-based change decision module, wherein a distance map between bitemporal features is calculated. Ablation study and comparative experiments on two large datasets, building change detection dataset (BCDD) and season-varying change detection dataset (CDD), and a real-image experiment on the Google dataset fully demonstrate the superiority of the proposed method. The source code of SRCDNet is available at https://github.com/liumency/SRCDNet.
C1 [Liu, Mengxi; Shi, Qian; He, Da; Liu, Xiaoping] Sun Yat Sen Univ, Sch Geog & Planning, Guangdong Prov Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.
   [Marinoni, Andrea] UiT Arctic Univ Norway, Dept Phys & Technol, N-9019 Tromso, Norway.
   [Marinoni, Andrea] Univ Cambridge, Dept Engn, Cambridge CB2 1TN, England.
   [Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
RP Shi, Q (corresponding author), Sun Yat Sen Univ, Sch Geog & Planning, Guangdong Prov Key Lab Urbanizat & Geosimulat, Guangzhou 510275, Peoples R China.
EM liumx23@mail2.sysu.edu.cn; shixi5@mail.sysu.edu.cn;
   andrea.marinoni@uit.no; heda@mail.sysu.edu.cn; liuxp3@mail.sysu.edu.cn;
   zlp62@whu.edu.cn
FU Program for Guangdong Introducing Innovative and Entrepreneurial Teams
   [2017ZT07X355]; Guangdong Natural Science FoundationNational Natural
   Science Foundation of Guangdong Province [2019A1515011057]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61976234]; Open research fund of National Key
   Laboratory of Surveying, Mapping and Remote Sensing Information
   Engineering, Wuhan University; Guangzhou Applied Basic Research Project;
   Center for Integrated Remote Sensing and Forecasting for Arctic
   Operations (CIRFA); Research Council of Norway (RCN)Research Council of
   Norway [237906]
FX This work was supported in part by the Program for Guangdong Introducing
   Innovative and Entrepreneurial Teams under Grant 2017ZT07X355, in part
   by the Guangdong Natural Science Foundation under Grant 2019A1515011057,
   in part by the National Natural Science Foundation of China under Grant
   61976234, in part by the Open research fund of National Key Laboratory
   of Surveying, Mapping and Remote Sensing Information Engineering, Wuhan
   University, in part by the Guangzhou Applied Basic Research Project, in
   part by the Center for Integrated Remote Sensing and Forecasting for
   Arctic Operations (CIRFA), and in part by the Research Council of Norway
   (RCN) under Grant 237906. (Corresponding author: Qian Shi.)
CR Aplin P, 2001, INT J REMOTE SENS, V22, P2853, DOI 10.1080/01431160110053176
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   BYRNE GF, 1980, REMOTE SENS ENVIRON, V10, P175, DOI 10.1016/0034-4257(80)90021-8
   Chen CF, 2013, REMOTE SENS-BASEL, V5, P6408, DOI 10.3390/rs5126408
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Dayanik S, 2008, ANN APPL PROBAB, V18, P552, DOI 10.1214/07-AAP463
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   FOODY GM, 1994, INT J REMOTE SENS, V15, P619, DOI 10.1080/01431169408954100
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kim J, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761209
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XD, 2016, IEEE T GEOSCI REMOTE, V54, P3822, DOI 10.1109/TGRS.2016.2528583
   Ling F, 2011, IEEE GEOSCI REMOTE S, V8, P182, DOI 10.1109/LGRS.2010.2055034
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Petit CC, 2001, INT J GEOGR INF SCI, V15, P785, DOI 10.1080/13658810110074483
   Sak H, 2014, INTERSPEECH, P338
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Simonyan K, 2014, ArXiv:1409.1556
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Tu JH, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6050131
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang QM, 2015, IEEE J-STARS, V8, P1339, DOI 10.1109/JSTARS.2014.2355832
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030284
   Yuan F, 2007, REMOTE SENS ENVIRON, V106, P375, DOI 10.1016/j.rse.2006.09.003
   Zaremba W., 2014, ARXIV14092329
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
NR 49
TC 1
Z9 1
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3091758
EA JUL 2021
PG 18
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2XY
UT WOS:000732779200001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Xu, QF
   Chen, KM
   Zhou, GY
   Sun, X
AF Xu, Quanfu
   Chen, Keming
   Zhou, Guangyao
   Sun, Xian
TI Change Capsule Network for Optical Remote Sensing Image Change Detection
SO REMOTE SENSING
LA English
DT Article
DE change detection; capsule network; similarity measure; change vector
   analysis; deep learning
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS
AB Change detection based on deep learning has made great progress recently, but there are still some challenges, such as the small data size in open-labeled datasets, the different viewpoints in image pairs, and the poor similarity measures in feature pairs. To alleviate these problems, this paper presents a novel change capsule network by taking advantage of a capsule network that can better deal with the different viewpoints and can achieve satisfactory performance with small training data for optical remote sensing image change detection. First, two identical non-shared weight capsule networks are designed to extract the vector-based features of image pairs. Second, the unchanged region reconstruction module is adopted to keep the feature space of the unchanged region more consistent. Third, vector cosine and vector difference are utilized to compare the vector-based features in a capsule network efficiently, which can enlarge the separability between the changed pixels and the unchanged pixels. Finally, a binary change map can be produced by analyzing both the vector cosine and vector difference. From the unchanged region reconstruction module and the vector cosine and vector difference module, the extracted feature pairs in a change capsule network are more comparable and separable. Moreover, to test the effectiveness of the proposed change capsule network in dealing with the different viewpoints in multi-temporal images, we collect a new change detection dataset from a taken-over Al Udeid Air Basee (AUAB) using Google Earth. The results of the experiments carried out on the AUAB dataset show that a change capsule network can better deal with the different viewpoints and can improve the comparability and separability of feature pairs. Furthermore, a comparison of the experimental results carried out on the AUAB dataset and SZTAKI AirChange Benchmark Set demonstrates the effectiveness and superiority of the proposed method.
C1 [Xu, Quanfu; Chen, Keming; Zhou, Guangyao; Sun, Xian] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100190, Peoples R China.
   [Xu, Quanfu; Chen, Keming; Sun, Xian] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100190, Peoples R China.
   [Xu, Quanfu; Chen, Keming; Zhou, Guangyao; Sun, Xian] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol NIST, Beijing 100190, Peoples R China.
   [Xu, Quanfu; Chen, Keming; Sun, Xian] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
RP Chen, KM (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100190, Peoples R China.; Chen, KM (corresponding author), Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100190, Peoples R China.; Chen, KM (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol NIST, Beijing 100190, Peoples R China.; Chen, KM (corresponding author), Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
EM xuquanfu18@mails.ucas.ac.cn; kmchen.ie@gmail.com;
   zhouguangyao@aircas.ac.cn; sunxian@aircas.ac.cn
OI xu, quanfu/0000-0003-0636-0827
CR Awrangjeb M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101512
   Awrangjeb M, 2015, REMOTE SENS-BASEL, V7, P14119, DOI 10.3390/rs71014119
   Bass C., 2019, INT C MED IM DEEP LE P INT C MED IM DEEP, P39
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedek C, 2008, INT C PATT RECOG, P1686
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Caye Daudt R., 2019, COMP VIS PATT REC WO
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen GZ, 2018, IEEE J-STARS, V11, P1633, DOI 10.1109/JSTARS.2018.2810320
   COPPIN PR, 1994, IEEE T GEOSCI REMOTE, V32, P918, DOI 10.1109/36.298020
   Das S., 2021, GEOJOURNAL, V656, P1
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng F, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093153
   Duarte K., 2018, ARXIV180508162
   Duarte K., 2018, ARXIV181200303
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Ketkar Nikhil, 2017, INTRO KERAS DEEP LEA, P97, DOI DOI 10.1007/978-1-4842-2766-4
   Kingma D., 2014, 14126980 ARXIV
   LaLonde R, 2018, ARXIV180404241
   Li SD, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111177
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Malila W.A, 1980, P LARS S, P385
   Mas JF, 2017, EUR J REMOTE SENS, V50, P626, DOI 10.1080/22797254.2017.1387505
   Mehrotra A, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P408, DOI 10.1109/IndiaCom.2014.6828169
   Michel U., 2012, ISPRS ANN PHOTOGRAMM, V1, DOI [10.5194/isprsannals-I-4-107-2012, DOI 10.5194/ISPRSANNALS-I-4-107-2012]
   Mishra PK, 2020, EGYPT J REMOTE SENS, V23, P133, DOI 10.1016/j.ejrs.2019.02.001
   Neill JO, 2018, ARXIV180507242
   Palazzolo E, 2018, IEEE INT CONF ROBOT, P6308
   Park DH, 2019, IEEE I CONF COMP VIS, P4623, DOI 10.1109/ICCV.2019.00472
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qiu Y, 2020, IEEE ROBOT AUTOM LET, V5, P4743, DOI 10.1109/LRA.2020.3003290
   Rottensteiner F, 2014, ISPRS J PHOTOGRAMM, V93, P256, DOI 10.1016/j.isprsjprs.2013.10.004
   Sabour Sara, 2017, PROC NEURIPS, P3856
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K., 2017, ARXIV171202941 ARXIV171202941
   Sakurada K, 2020, IEEE INT CONF ROBOT, P6861, DOI 10.1109/ICRA40945.2020.9196985
   Shi N, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12183057
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh M, 2019, IEEE I CONF COMP VIS, P340, DOI 10.1109/ICCV.2019.00043
   Smits PC, 2000, IEEE T GEOSCI REMOTE, V38, P1484, DOI 10.1109/36.843048
   Sohl TL, 1999, PHOTOGRAMM ENG REM S, V65, P475
   Upadhyay Y., 2018, GENERATIVE ADVERSARI ARXIV180603796
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Xu Q, 2021, IETE TECH REV, V38, P563, DOI 10.1080/02564602.2020.1800526
   Yuhaniz SS, 2009, INT J REMOTE SENS, V30, P6121, DOI 10.1080/01431160902810638
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
NR 59
TC 1
Z9 1
U1 18
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL
PY 2021
VL 13
IS 14
AR 2646
DI 10.3390/rs13142646
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA TO7OE
UT WOS:000677095100001
OA gold
DA 2022-01-04
ER

PT J
AU de Gelis, I
   Lefevre, S
   Corpetti, T
AF de Gelis, Iris
   Lefevre, Sebastien
   Corpetti, Thomas
TI Change Detection in Urban Point Clouds: An Experimental Comparison with
   Simulated 3D Datasets
SO REMOTE SENSING
LA English
DT Article
DE 3D change detection; urban monitoring; bi-temporal point clouds dataset;
   airborne LiDAR simulator
ID BUILDING CHANGE DETECTION; LIDAR DATA; CLASSIFICATION; EXTRACTION;
   IMAGES
AB In the context of rapid urbanization, monitoring the evolution of cities is crucial. To do so, 3D change detection and characterization is of capital importance since, unlike 2D images, 3D data contain vertical information of utmost importance to monitoring city evolution (that occurs along both horizontal and vertical axes). Urban 3D change detection has thus received growing attention, and various methods have been published on the topic. Nevertheless, no quantitative comparison on a public dataset has been reported yet. This study presents an experimental comparison of six methods: three traditional (difference of DSMs, C2C and M3C2), one machine learning with hand-crafted features (a random forest model with a stability feature) and two deep learning (feed-forward and Siamese architectures). In order to compare these methods, we prepared five sub-datasets containing simulated pairs of 3D annotated point clouds with different characteristics: from high to low resolution, with various levels of noise. The methods have been tested on each sub-dataset for binary and multi-class segmentation. For supervised methods, we also assessed the transfer learning capacity and the influence of the training set size. The methods we used provide various kinds of results (2D pixels, 2D patches or 3D points), and each of them is impacted by the resolution of the PCs. However, while the performances of deep learning methods highly depend on the size of the training set, they seem to be less impacted by training on datasets with different characteristics. Oppositely, conventional machine learning methods exhibit stable results, even with smaller training sets, but embed low transfer learning capacities. While the main changes in our datasets were usually identified, there were still numerous instances of false detection, especially in dense urban areas, thereby calling for further development in this field. To assist such developments, we provide a public dataset composed of pairs of point clouds with different qualities together with their change-related annotations. This dataset was built with an original simulation tool which allows one to generate bi-temporal urban point clouds under various conditions.
C1 [de Gelis, Iris] Magellium, F-31000 Toulouse, France.
   [Lefevre, Sebastien] Univ Bretagne Sud, IRISA, UMR 6074, F-56000 Vannes, France.
   [Corpetti, Thomas] CNRS, LETG, UMR 6554, F-35000 Rennes, France.
RP de Gelis, I (corresponding author), Magellium, F-31000 Toulouse, France.
EM iris.de-gelis@irisa.fr; sebastien.lefevre@irisa.fr;
   thomas.corpetti@univ-rennes2.fr
RI ; Lefevre, Sebastien/S-9444-2017
OI de Gelis, Iris/0000-0003-3030-1907; Lefevre,
   Sebastien/0000-0002-2384-8202
FU Magellium, Toulouse; CNES, Toulouse
FX This research was funded by Magellium, Toulouse and the CNES, Toulouse.
CR Amini Amirkolaee H., 2019, INT ARCH PHOTOGRAMM, P89, DOI [10.5194/isprs-archives-XLII-4-W18-89-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W18-89-2019]
   Awrangjeb M, 2015, ISPRS ANN PHOTO REM, VII-3, P393, DOI 10.5194/isprsannals-II-3-W5-393-2015
   Champion N, 2010, PATTERN RECOGN LETT, V31, P1138, DOI 10.1016/j.patrec.2009.10.012
   Czerniawski T, 2021, AUTOMAT CONSTR, V124, DOI 10.1016/j.autcon.2021.103568
   Dai CG, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101680
   de Gelis I., 2021, P IEEE INT GEOSC REM
   Dini GR, 2012, INT ARCH PHOTOGRAMM, V39, P299
   Erdogan M, 2019, INT J REMOTE SENS, V40, P3772, DOI 10.1080/01431161.2018.1552816
   Gharibbafghi Z., 2019, P IEEE CVF C COMP VI
   Girardeau-Montaut D, 2016, CLOUDCOMPARE
   Girardeau-Montaut D., 2005, INT ARCH PHOTOGRAMM, V36, P30
   Guerin C, 2014, IEEE J-STARS, V7, P4020, DOI 10.1109/JSTARS.2014.2300509
   He HQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020355
   Jang YeongJae, 2019, [JOURNAL OF THE KOREAN SOCIETY OF SURVEY,GEODESY,PHOTOGRAMMETRY, AND CARTOGRAPHY, 한국측량학회지], V37, P389, DOI 10.7848/ksgpc.2019.37.5.389
   Kalantar B, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12213529
   Kim S., 2009, LASERSCANNING09, V18, P259
   Lague D, 2013, ISPRS J PHOTOGRAMM, V82, P10, DOI 10.1016/j.isprsjprs.2013.04.009
   Lefevre S, 2017, P IEEE, V105, P1884, DOI 10.1109/JPROC.2017.2684300
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lyu XZ, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9110678
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mou L., 2017, P 2017 JOINT URB REM, P1
   Murakami H, 1999, ISPRS J PHOTOGRAMM, V54, P148, DOI 10.1016/S0924-2716(99)00006-4
   Nuth C, 2011, CRYOSPHERE, V5, P271, DOI 10.5194/tc-5-271-2011
   Okyay U, 2019, EARTH-SCI REV, V198, DOI 10.1016/j.earscirev.2019.102929
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pang SY, 2014, REMOTE SENS-BASEL, V6, P10733, DOI 10.3390/rs61110733
   Peng DF, 2016, INT ARCH PHOTOGRAMM, V41, P669, DOI 10.5194/isprsarchives-XLI-B3-669-2016
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   Rahman MT, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5020015
   Reynolds R, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010071
   Rottensteiner F., 2008, INT ARCH PHOTOGRAMME, V37, P265
   Roynard X, 2016, INT ARCH PHOTOGRAMM, V41, P693, DOI 10.5194/isprsarchives-XLI-B3-693-2016
   Salah HS, 2019, INT J REMOTE SENS, V40, P6635, DOI 10.1080/01431161.2019.1583394
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Shirowzhan S, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102841
   Siddiqui F.U., 2017, P 2017 INT C DIG IM, P1
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Stal C, 2013, INT J REMOTE SENS, V34, P1087, DOI 10.1080/01431161.2012.717183
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Tran THG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020448
   Touati R., 2020, J REMOTE SENS GIS, V9, DOI [10.35248/2469-4134.20.9.272, DOI 10.35248/2469-4134.20.9.272]
   Vetrivel A, 2018, ISPRS J PHOTOGRAMM, V140, P45, DOI 10.1016/j.isprsjprs.2017.03.001
   Vu TT, 2004, INT GEOSCI REMOTE SE, P3413
   Wang X, 2020, ISPRS J PHOTOGRAMM, V159, P322, DOI 10.1016/j.isprsjprs.2019.11.028
   Warth G, 2019, EUR J REMOTE SENS, V52, P322, DOI 10.1080/22797254.2019.1604083
   Waser L., 2007, INT ARCH PHOTOGRAMM, V36, P313
   Xu H, 2015, REMOTE SENS-BASEL, V7, P9682, DOI 10.3390/rs70809682
   Xu S, 2015, REMOTE SENS-BASEL, V7, P17051, DOI 10.3390/rs71215867
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang Z., 2018, ARXIV180709562
   Zhang ZC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202417
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 53
TC 0
Z9 0
U1 11
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL
PY 2021
VL 13
IS 13
AR 2629
DI 10.3390/rs13132629
PG 29
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA TG0BH
UT WOS:000671077900001
OA gold, Green Published
DA 2022-01-04
ER

PT J
AU Peng, DF
   Bruzzone, L
   Zhang, YJ
   Guan, HY
   Ding, HY
   Huang, X
AF Peng, Daifeng
   Bruzzone, Lorenzo
   Zhang, Yongjun
   Guan, Haiyan
   Ding, Haiyong
   Huang, Xu
TI SemiCDNet: A Semisupervised Convolutional Neural Network for Change
   Detection in High Resolution Remote-Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Image segmentation; Remote sensing; Data models; Machine learning;
   Buildings; Feature extraction; Task analysis; Change detection (CD);
   deep learning (DL); feature distribution; generative adversarial network
   (GAN); remote sensing (RS); semisupervised convolutional network
ID BUILDING CHANGE DETECTION; LAND-COVER; FRAMEWORK; INFORMATION; LABELS
AB Change detection (CD) is one of the main applications of remote sensing. With the increasing popularity of deep learning, most recent developments of CD methods have introduced the use of deep learning techniques to increase the accuracy and automation level over traditional methods. However, when using supervised CD methods, a large amount of labeled data is needed to train deep convolutional networks with millions of parameters. These labeled data are difficult to acquire for CD tasks. To address this limitation, a novel semisupervised convolutional network for CD (SemiCDNet) is proposed based on a generative adversarial network (GAN). First, both the labeled data and unlabeled data are input into the segmentation network to produce initial predictions and entropy maps. Then, to exploit the potential of unlabeled data, two discriminators are adopted to enforce the feature distribution consistency of segmentation maps and entropy maps between the labeled and unlabeled data. During the competitive training, the generator is continuously regularized by utilizing the unlabeled information, thus improving its generalization capability. The effectiveness and reliability of our proposed method are verified on two high-resolution remote sensing data sets. Extensive experimental results demonstrate the superiority of the proposed method against other state-of-the-art approaches.
C1 [Peng, Daifeng; Guan, Haiyan; Ding, Haiyong] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Peng, Daifeng; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
   [Zhang, Yongjun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Huang, Xu] Wuhan Engn Sci & Technol Inst, Wuhan 430019, Peoples R China.
RP Peng, DF (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
EM daifeng@nuist.edu.cn; lorenzo.bruzzone@ing.unitn.it; zhangyj@whu.edu.cn;
   guanhy.nj@nuist.edu.cn; hyongd@163.com; huangxurs@whu.edu.cn
RI Bruzzone, Lorenzo/A-2076-2012
OI Bruzzone, Lorenzo/0000-0002-6036-459X; zhang, yong
   jun/0000-0001-9845-4251; Huang, Xu/0000-0003-3797-6042
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801386, 41701540, 41671454, 41571350];
   Natural Science Foundation of Jiangsu ProvinceNatural Science Foundation
   of Jiangsu Province [BK20180797]; Startup Project for Introducing Talent
   of Nanjing University of Information Science and Technology (NUIST)
   [2018r029]; China Scholarship CouncilChina Scholarship Council
   [201908320183]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41801386, Grant 41701540, Grant
   41671454, Grant 41571350; in part by the Natural Science Foundation of
   Jiangsu Province under Grant BK20180797; in part by the Startup Project
   for Introducing Talent of Nanjing University of Information Science and
   Technology (NUIST) under Grant 2018r029; and in part by the China
   Scholarship Council under Grant 201908320183.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2011, REMOTE SENS ENVIRON, V115, P1532, DOI 10.1016/j.rse.2011.02.012
   Chen KM, 2013, IEEE GEOSCI REMOTE S, V10, P236, DOI 10.1109/LGRS.2012.2199279
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen S, 2019, LECT NOTES COMPUT SC, V11766, P457, DOI 10.1007/978-3-030-32248-9_51
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V158, P35, DOI 10.1016/j.isprsjprs.2019.09.008
   Hong DF, 2019, ISPRS J PHOTOGRAMM, V147, P193, DOI 10.1016/j.isprsjprs.2018.10.006
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Huang ZH, 2019, INT J REMOTE SENS, V40, P5737, DOI 10.1080/01431161.2019.1580821
   Hung W.C., 2018, ARXIV180207934
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Janalipour M, 2017, INT J REMOTE SENS, V38, P82, DOI 10.1080/01431161.2016.1259673
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Khan S. H, 2016, ARXIV160602009
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Liu JF, 2019, INT GEOSCI REMOTE SE, P74, DOI 10.1109/IGARSS.2019.8898913
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Marpu PR, 2011, IEEE GEOSCI REMOTE S, V8, P799, DOI 10.1109/LGRS.2011.2109697
   Mittal S, 2021, IEEE T PATTERN ANAL, V43, P1369, DOI 10.1109/TPAMI.2019.2960224
   Mondal AK., 2019, ARXIV190811569
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   Peng C, 2019, IEEE J-STARS, V12, P2612, DOI 10.1109/JSTARS.2019.2906387
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Tao C, 2019, ISPRS J PHOTOGRAMM, V158, P155, DOI 10.1016/j.isprsjprs.2019.10.001
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Wen DW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070763
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang J., 2018, ARXIV181200352
   Zhang WZ, 2018, IEEE T GEOSCI REMOTE, V56, P3587, DOI 10.1109/TGRS.2018.2802785
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 65
TC 11
Z9 11
U1 47
U2 47
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUL
PY 2021
VL 59
IS 7
BP 5891
EP 5906
DI 10.1109/TGRS.2020.3011913
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA SX4HH
UT WOS:000665167500036
DA 2022-01-04
ER

PT J
AU Shi, J
   Liu, XD
   Lei, Y
AF Shi, Jiao
   Liu, Xiaodong
   Lei, Yu
TI SAR Images Change Detection Based on Self-Adaptive Network Architecture
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Synthetic aperture radar; Biological neural networks; Training; Network
   architecture; Neurons; Remote sensing; Encoding; Change detection;
   evolutionary algorithm; network architecture search (NAS); neural
   network; SAR images
ID SYNTHETIC-APERTURE RADAR
AB In the last few years, neural networks were introduced to change detection for a better understanding of remote sensing images. However, the designs of these neural networks were time-consuming processes of trial and error, which failed to account for their validity. Thus, a simple and efficient change detection method based on network architecture search in terms of the evolutionary algorithm is proposed to deal with SAR images change detection problems. In the proposed method, an efficient gene encoding is applied to represent the unpredictable optimal depth and the number of neurons in each hidden layer. Besides, a combinatorial evaluation strategy and a self-adaptive network solution selection are designed for effective and reasonable network architectures. What is more, a hidden layer random alignment crossover operator and a drawing lots mutation operator are designed for the enhancement of diversity of network architectures. Experimental results on a few SAR image data sets demonstrate that the proposed method can generate appropriate networks to solving SAR images change detection.
C1 [Shi, Jiao; Liu, Xiaodong; Lei, Yu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
RP Shi, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Peoples R China.
EM jiaoshi@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61603299, 61602385]; National Natural
   Science Foundation of Shaanxi Province [2018JQ6003, 2018JQ6030];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61603299 and Grant 61602385, in part by
   the National Natural Science Foundation of Shaanxi Province under Grant
   2018JQ6003 and Grant 2018JQ6030, and in part by the Fundamental Research
   Funds for the Central Universities.
CR Benassai G, 2018, IEEE J OCEANIC ENG, V43, P586, DOI 10.1109/JOE.2017.2782560
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Huang Y, 2018, DIGIT SIGNAL PROCESS, V78, P121, DOI 10.1016/j.dsp.2018.03.003
   Jia M, 2018, INT J REMOTE SENS, V39, P1068, DOI 10.1080/01431161.2017.1395966
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Rikka S, 2018, INT J REMOTE SENS, V39, P1256, DOI 10.1080/01431161.2017.1399475
   Shang R., 2017, P INT C BIOINSP COMP, P533
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhuang HF, 2017, INT J REMOTE SENS, V38, P4914, DOI 10.1080/01431161.2017.1331475
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 18
TC 1
Z9 1
U1 15
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD JUL
PY 2021
VL 18
IS 7
BP 1204
EP 1208
DI 10.1109/LGRS.2020.2994163
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA SX2IR
UT WOS:000665034700017
DA 2022-01-04
ER

PT J
AU Chen, YX
   Bruzzone, L
AF Chen, Yuxing
   Bruzzone, Lorenzo
TI Self-Supervised Change Detection in Multiview Remote Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Change detection; multiview; remote sensing; self-supervised learning;
   sentinel-1/-2
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS; SLOW FEATURE
   ANALYSIS; FRAMEWORK
AB The large amount of unlabeled remote sensing acquired from different sources and at different times (defined as multiple views in this article) presents both an opportunity and a challenge for change detection. Recently, many generative model-based methods have been proposed for remote sensing image change detection on such unlabeled data. However, the high diversities in the learned features weaken the discrimination of the relevant change indicators in unsupervised change detection tasks. Moreover, these methods lack research on massive archived images. In this work, a self-supervised change detection approach based on an unlabeled multiview setting is proposed to overcome this limitation. This is achieved by the use of a multiview contrastive loss in the feature alignment between multiview images. In this approach, a pseudo-Siamese network is trained to regress the output between its two branches pretrained in a contrastive way on a large dataset of single-sensor or cross-sensor image pairs. Finally, the feature distance between the outputs of the two branches is used to define a change measure, which can be analyzed by thresholding to get the final binary change map. Experiments are carried out on two single-sensor and three crass-sensor datasets. The proposed approach is compared with other supervised and unsupervised state-of-the-art change detection methods. Results demonstrate both improvements over state-of-the-art unsupervised methods and the proposed approach narrows the gap between unsupervised and supervised change detection.
C1 [Chen, Yuxing; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.
RP Bruzzone, L (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.
EM chenyuxing16@mails.ucas.ac.cn; lorenzo.bruzzone@unitn.it
FU China Scholarship CouncilChina Scholarship Council
FX This work was supported in part by the China Scholarship Council.
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 1997, INT J REMOTE SENS, V18, P3883, DOI 10.1080/014311697216702
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Dong HH, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111868
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gutmann Michael, 2010, P MACHINE LEARNING R, V9, P297
   He K., 2020, ARXIV191105722, P9729, DOI DOI 10.1109/CVPR42600.2020.00975
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang MM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132073
   Leenstra M., PATTERN RECOGN, V2021, P578
   Liu X., 2020, ARXIV200608218, V2006
   Luppino L. T., 2020, ARXIV200407011
   Luppino LT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3056196
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Ren CJ, 2021, IEEE T GEOSCI REMOTE, V59, P10047, DOI 10.1109/TGRS.2020.3043766
   Robinson J., 2020, ADV NEURAL INFORM PR, V33, P21798
   Rosin PL, 2005, INT J REMOTE SENS, V26, P1075, DOI 10.1080/01431160512331330481
   Roy DP, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.111254
   Saha S., 2019, P 10 INT WORKSH AN M, P1
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Sun YL, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107598
   Tarvainen A., 2017, MEAN TEACHERS ARE BE, P1195
   Tian Y., 2020, COMPUTER VISION ECCV, P776, DOI [10.1007/978-3-030-58621-8_45, DOI 10.1007/978-3-030-58621-845]
   van den Oord Aaron, 2018, ARXIV PREPRINT ARXIV
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
NR 48
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3089453
EA JUN 2021
PG 12
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS3IV
UT WOS:000732807800001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Pang, SY
   Zhang, AR
   Hao, JJ
   Liu, FZ
   Chen, J
AF Pang, Shiyan
   Zhang, Anran
   Hao, Jingjing
   Liu, Fengzhu
   Chen, Jia
TI SCA-CDNet: a robust siamese correlation-and-attention-based change
   detection network for bitemporal VHR images
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article; Early Access
AB Change detection is a key step in various geographic information applications such as land cover change monitoring, agricultural assessment, natural disaster evaluation, and illegal building investigation. In practice, discovering, or outlining these changes is labour intensive and time-consuming. To address this problem, a novel end-to-end Siamese correlation-and-attention-based change detection network (SCA-CDNet) is proposed for bitemporal very-high-resolution images in this paper. In this method, five strategies are adopted to improve the final change detection results. First, data augmentation is used to reduce the overfitting effectively and improve the generalization ability of the training model. Second, in encoding, classic networks (e.g. ResNet) are introduced to extract the multiscale features of the image and make full use of the existing pretraining weights of the network to reduce the difficulty of subsequent model training. Third, a new correlation module is designed to stack the above bitemporal features correspondingly and extract change features with smaller dimensions. Fourth, an attention model is introduced between the correlation module and the decoder module to make the network pay more attention to areas or channels with a greater effect on change analysis. Fifth, a new weighted cross-entropy loss function is designed, which enables training to focus on error detection and improve the final accuracy of the training model. Finally, extensive experimental results on three public data sets including the evaluation of data augmentation, ablation study, and comparison with the state of the art demonstrate the effectiveness and superiority of our proposed method, achieving an intersection of union (IoU) of 84.15%, 83.50%, and 77.29% on the three data sets, respectively.
C1 [Pang, Shiyan; Zhang, Anran; Hao, Jingjing; Chen, Jia] Cent China Normal Univ, Fac Artificial Intelligence Educ, Wuhan, Peoples R China.
   [Liu, Fengzhu] Beijing Inst Surveying & Mapping, Beijing, Peoples R China.
   [Liu, Fengzhu] Beijing Key Lab Urban Spatial Informat Engn, Beijing, Peoples R China.
RP Chen, J (corresponding author), Cent China Normal Univ, Fac Artificial Intelligence Educ, Wuhan, Peoples R China.
EM jc@mail.ccnu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41701389, 61605054]; self-determined
   research funds of CCNU from the colleges'-basic research and operation
   of MOE [CCNU20XJ007]; Beijing Key Laboratory of Urban Spatial
   Information Engineering [2019208]
FX This research was supported in part by the National Natural Science
   Foundation of China under Grant 41701389 and Grant 61605054;
   self-determined research funds of CCNU from the colleges'-basic research
   and operation of MOE under Grant CCNU20XJ007 and Beijing Key Laboratory
   of Urban Spatial Information Engineering under Grant 2019208.
CR Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Dalal N., 2005, P IEEE C COMP VIS PA, P886, DOI DOI 10.1109/CVPR.2005.177
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Jongchan P., 2018, P BRIT MACH VIS C NE, P734
   Kaku A., 2019, ARXIV PREPRINT ARXIV
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu Y., 2020, ARXIV200810937
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng D., 2020, IEEE T GEOENCE REMOT, V59, P5891
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K., 2015, P BRIT MACH VIS C, V61, P1, DOI DOI 10.5244/C.29.61
   Sakurada K., 2018, WEAKLY SUPERVISED SI, DOI [10.1078/abs.1811.11985, DOI 10.1078/ABS.1811.11985]
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 35
TC 0
Z9 0
U1 12
U2 12
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PY 2021
DI 10.1080/01431161.2021.1941390
EA JUN 2021
PG 22
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA TB5XX
UT WOS:000668021500001
DA 2022-01-04
ER

PT J
AU Shi, Q
   Liu, MX
   Li, SC
   Liu, XP
   Wang, F
   Zhang, LP
AF Shi, Qian
   Liu, Mengxi
   Li, Shengchen
   Liu, Xiaoping
   Wang, Fei
   Zhang, Liangpei
TI A Deeply Supervised Attention Metric-Based Network and an Open Aerial
   Image Dataset for Remote Sensing Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Feature extraction; Data mining; Measurement; Semantics; Hyperspectral
   imaging; Convolutional neural networks; Benchmark testing; Change
   detection dataset (CDD); convolutional block attention module (CBAM);
   deeply supervised (DS) layers; metric learning; remote sensing change
   detection (CD)
ID LAND-COVER CHANGE; CLASSIFICATION; MAD
AB Change detection (CD) aims to identify surface changes from bitemporal images. In recent years, deep learning (DL)-based methods have made substantial breakthroughs in the field of CD. However, CD results can be easily affected by external factors, including illumination, noise, and scale, which leads to pseudo-changes and noise in the detection map. To deal with these problems and achieve more accurate results, a deeply supervised (DS) attention metric-based network (DSAMNet) is proposed in this article. A metric module is employed in DSAMNet to learn change maps by means of deep metric learning, in which convolutional block attention modules (CBAM) are integrated to provide more discriminative features. As an auxiliary, a DS module is introduced to enhance the feature extractor's learning ability and generate more useful features. Moreover, another challenge encountered by data-driven DL algorithms is posed by the limitations in change detection datasets (CDDs). Therefore, we create a CD dataset, Sun Yat-Sen University (SYSU)-CD, for bitemporal image CD, which contains a total of 20,000 aerial image pairs of size 256 x 256. Experiments are conducted on both the CDD and the SYSU-CD dataset. Compared to other state-of-the-art methods, our network achieves the highest accuracy on both datasets, with an F1 of 93.69% on the CDD dataset and 78.18% on the SYSU-CD dataset.
C1 [Shi, Qian; Liu, Mengxi; Li, Shengchen; Liu, Xiaoping] Sun Yat Sen Univ, Guangdong Prov Key Lab Urbanizat & Geosimulat, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
   [Wang, Fei] Xinjiang Univ, Coll Resource & Environm Sci, Xinjiang Common Univ Key Lab Smart City & Environ, Urumqi 830046, Peoples R China.
   [Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
RP Liu, MX (corresponding author), Sun Yat Sen Univ, Guangdong Prov Key Lab Urbanizat & Geosimulat, Sch Geog & Planning, Guangzhou 510275, Peoples R China.
EM shixi5@mail.sysu.edu.cn; liumx23@mail2.sysu.edu.cn;
   lishch8@mail2.sysu.edu.cn; liuxp3@mail.sysu.edu.cn;
   wangfei1986@xju.edu.cn; zlp62@whu.edu.cn
FU Guangdong Natural Science FoundationNational Natural Science Foundation
   of Guangdong Province [2019A1515011057]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [61976234]; Open Research Fund of the National Key Laboratory of
   Surveying, Mapping and Remote Sensing Information Engineering, Wuhan
   University, Guangzhou Applied Basic Research Project; Program for
   Guangdong Introducing Innovative and Entrepreneurial Teams
   [2017ZT07X355]
FX This work was supported in part by the Guangdong Natural Science
   Foundation under Grant 2019A1515011057, in part by the National Natural
   Science Foundation of China under Grant 61976234, in part by the Open
   Research Fund of the National Key Laboratory of Surveying, Mapping and
   Remote Sensing Information Engineering, Wuhan University, Guangzhou
   Applied Basic Research Project, and in part by the Program for Guangdong
   Introducing Innovative and Entrepreneurial Teams under Grant
   2017ZT07X355. (Corresponding author: Mengxi Liu.)
CR Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   BYRNE GF, 1980, REMOTE SENS ENVIRON, V10, P175, DOI 10.1016/0034-4257(80)90021-8
   Chen CF, 2013, REMOTE SENS-BASEL, V5, P6408, DOI 10.3390/rs5126408
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   CRIST EP, 1985, REMOTE SENS ENVIRON, V17, P301, DOI 10.1016/0034-4257(85)90102-6
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hadsell Raia, 2006, P IEEE COMP SOC C CO, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   JACKSON RD, 1983, REMOTE SENS ENVIRON, V13, P409, DOI 10.1016/0034-4257(83)90010-X
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kux H., 2008, OBJECT BASED IMAGE A, P531, DOI DOI 10.1007/978-3-540-77058-9_29
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Liu PH, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070830
   Long, ARXIV200612485
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Shi Q, 2018, IEEE ACCESS, V6, P25486, DOI 10.1109/ACCESS.2017.2773142
   Simonyan K, 2014, ArXiv:1409.1556
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Szegedy, 2015, ARXIV 1502 03167
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Z., 2015, GOOD PRACTICES VERY
   Wessels KJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8110888
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhu QK, 2017, IEEE IJCNN, P178, DOI 10.1109/IJCNN.2017.7965852
NR 55
TC 11
Z9 11
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3085870
EA JUN 2021
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2OP
UT WOS:000732754900001
DA 2022-01-04
ER

PT J
AU Stephenson, OL
   Kohne, T
   Zhan, E
   Cahill, BE
   Yun, SH
   Ross, ZE
   Simons, M
AF Stephenson, Oliver L.
   Kohne, Tobias
   Zhan, Eric
   Cahill, Brent E.
   Yun, Sang-Ho
   Ross, Zachary E.
   Simons, Mark
TI Deep Learning-Based Damage Mapping With InSAR Coherence Time Series
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Synthetic aperture radar; Coherence; Satellites; Earth; Spaceborne
   radar; Deep learning; Radar imaging; Damage mapping; interferometric
   synthetic aperture radar (InSAR); machine learning; natural hazards
ID EARTHQUAKE; INTERFEROMETRY; DECORRELATION; MODEL
AB Satellite remote sensing is playing an increasing role in the rapid mapping of damage after natural disasters. In particular, synthetic aperture radar (SAR) can image the Earth's surface and map damage in all weather conditions, day and night. However, current SAR damage mapping methods struggle to separate damage from other changes in the Earth's surface. In this study, we propose a novel approach to damage mapping, combining deep learning with the full time history of SAR observations of an impacted region in order to detect anomalous variations in the Earth's surface properties due to a natural disaster. We quantify Earth surface change using time series of interferometric SAR coherence, then use a recurrent neural network (RNN) as a probabilistic anomaly detector on these coherence time series. The RNN is first trained on pre-event coherence time series, and then forecasts a probability distribution of the coherence between pre- and post-event SAR images. The difference between the forecast and observed co-event coherence provides a measure of confidence in the identification of damage. The method allows the user to choose a damage detection threshold that is customized for each location, based on the local behavior of coherence through time before the event. We apply this method to calculate estimates of damage for three earthquakes using multiyear time series of Sentinel-1 SAR acquisitions. Our approach shows good agreement with observed damage and quantitative improvement compared to using pre- to co-event coherence loss as a damage proxy.
C1 [Stephenson, Oliver L.; Kohne, Tobias; Ross, Zachary E.; Simons, Mark] CALTECH, Seismol Lab, Div Geol & Planetary Sci, Pasadena, CA 91125 USA.
   [Zhan, Eric] CALTECH, Dept Comp & Math Sci, Div Engn & Appl Sci, Pasadena, CA 91125 USA.
   [Cahill, Brent E.] REMY Biosci, Irvine, CA 92614 USA.
   [Yun, Sang-Ho] CALTECH, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.
RP Stephenson, OL (corresponding author), CALTECH, Seismol Lab, Div Geol & Planetary Sci, Pasadena, CA 91125 USA.
EM olstephe@caltech.edu
FU National Aeronautics and Space Administration (NASA) Applied Sciences
   Disasters Program
FX This work was supported by the National Aeronautics and Space
   Administration (NASA) Applied Sciences Disasters Program and performed
   at the Jet Propulsion Laboratory, California Institute of Technology.
   (Corresponding author: Oliver L. Stephenson.)
CR 3Blue1Brown, 2017, WHAT IS NEUR NETW DE
   Anantrasirichai N, 2019, REMOTE SENS ENVIRON, V230, DOI 10.1016/j.rse.2019.04.032
   Antiga L., 2019, ADV NEURAL INFORM PR, P8024, DOI DOI 10.1038/S41591-021-01287-9
   Bamler R, 1998, INVERSE PROBL, V14, pR1, DOI 10.1088/0266-5611/14/4/001
   Bengio, 2014, ARXIV14091259, P103, DOI 10.3115/v1/w14-4012
   Berrar D, 2012, BRIEF BIOINFORM, V13, P83, DOI 10.1093/bib/bbr008
   Bouaraba A, 2012, PROG ELECTROMA RES M, V22, P219, DOI 10.2528/PIERM11110707
   Brandenberg S. J., 2019, GEOTECH EXTREME EVEN, P1, DOI [10.18118/G6H66K, DOI 10.18118/G6H66K]
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Copernicus Emergency Management Service, 2016, EMSR177 EARTHQ CTR I
   Davis J., 2006, P 23 INT C MACH LEAR, P233, DOI [10.1145/1143844.1143874, DOI 10.1145/1143844.1143874]
   DZIEWONSKI AM, 1981, J GEOPHYS RES, V86, P2825, DOI 10.1029/JB086iB04p02825
   Ekstrom G, 2012, PHYS EARTH PLANET IN, V200, P1, DOI 10.1016/j.pepi.2012.04.002
   Endo Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122059
   European Space Agency, SINGL LOOK COMPL SEN
   Ferretti A, 2011, IEEE T GEOSCI REMOTE, V49, P3460, DOI 10.1109/TGRS.2011.2124465
   Fielding EJ, 2005, J GEOPHYS RES-SOL EA, V110, DOI 10.1029/2004JB003299
   Geudtner D, 1996, INT GEOSCI REMOTE SE, P966, DOI 10.1109/IGARSS.1996.516536
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hough SE, 2020, B SEISMOL SOC AM, V110, P1506, DOI 10.1785/0120200045
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jordan TE, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111544
   Jung J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020265
   Jung J, 2018, IEEE T GEOSCI REMOTE, V56, P1520, DOI 10.1109/TGRS.2017.2764748
   Jung J, 2016, IEEE T GEOSCI REMOTE, V54, P5765, DOI 10.1109/TGRS.2016.2572166
   Karimzadeh S, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081255
   Kaufman, 2011, P 17 ACM SIGKDD INT, P556, DOI DOI 10.1145/2020408.2020496
   Kendrick K., 2019, P SO CAL EARTHQ CTR, V9779, P7
   King DB, 2015, ACS SYM SER, V1214, P1
   Kong YL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030452
   Le Q. V., 2014, ADV NEURAL INFORM PR, DOI DOI 10.1007/S10107-014-0839-0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Y, 2019, ISPRS J PHOTOGRAMM, V152, P178, DOI 10.1016/j.isprsjprs.2019.04.014
   Lipton Z., 2015, COMPUT SCI, DOI DOI 10.1145/2647868.2654889
   Long, 2015, MICROWAVE RADAR RADI
   Loos S, 2020, EARTHQ SPECTRA, V36, P1695, DOI 10.1177/8755293020926190
   Malhotra P., 2015, PROC, V89, P89
   Met Office, 2010, CART CART PYTH LIB M
   Monti-Guarnieri AV, 2018, IEEE T GEOSCI REMOTE, V56, P6811, DOI 10.1109/TGRS.2018.2843560
   Motohka T, 2019, INT GEOSCI REMOTE SE, P5271, DOI 10.1109/IGARSS.2019.8898169
   Mura MD, 2008, IEEE GEOSCI REMOTE S, V5, P433, DOI 10.1109/LGRS.2008.917726
   Ndikumana E, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081217
   Olah, 2015, UNDERSTANDING LSTM N
   Olen S, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081272
   Pesaresi M, 2007, INT J REMOTE SENS, V28, P3013, DOI 10.1080/01431160601094492
   Ponti DJ, 2020, SEISMOL RES LETT, V91, P2942, DOI 10.1785/0220190322
   Rosen P. A., 2012, P 9 EUR C SYNTH AP R, P730
   Rosen PA, 2000, P IEEE, V88, P333, DOI 10.1109/5.838084
   Ross ZE, 2019, SCIENCE, V366, P346, DOI 10.1126/science.aaz0109
   Ross ZE, 2019, J GEOPHYS RES-SOL EA, V124, P856, DOI 10.1029/2018JB016674
   Sharma P, 2019, AEROSP CONF PROC
   Simons M, 2002, B SEISMOL SOC AM, V92, P1390, DOI 10.1785/0120000933
   Simons M., 2015, TREATISE GEOPHYS, V2nd, P339, DOI [10. 1016/B978-0-444-53802-4. 00061-0, DOI 10.1016/B978-0-444-53802-4.00061-0]
   United Nations Institute for Training and Research, 2017, DAM STRUCT REL DENS
   United States Geological Survey, 2016, M 6 2 10 KM SE NORC
   United States Geological Survey, 2017, M 7 3 29 KM S HAL IR
   Voigt S, 2016, SCIENCE, V353, P247, DOI 10.1126/science.aad8728
   Washaya P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071026
   Wessel Paul, 2013, Eos, Transactions American Geophysical Union, V94, P409, DOI 10.1002/2013EO450001
   Wieland M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100792
   Xingjian S., 2015, P 28 INT C NEUR INF, V1, P802, DOI DOI 10.1007/978-3-319-21233-3_6
   Yun SH, 2015, SEISMOL RES LETT, V86, P1549, DOI 10.1785/0220150152
   ZEBKER HA, 1992, IEEE T GEOSCI REMOTE, V30, P950, DOI 10.1109/36.175330
   Zimmaro P, 2020, B SEISMOL SOC AM, V110, P1549, DOI 10.1785/0120200025
NR 64
TC 1
Z9 1
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3084209
EA JUN 2021
PG 17
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2UH
UT WOS:000732769700001
OA Green Submitted, Green Accepted
DA 2022-01-04
ER

PT J
AU Alexakis, EB
   Armenakis, C
AF Bousias Alexakis, Evangelos
   Armenakis, Costas
TI Performance Improvement of Encoder/Decoder-Based CNN Architectures for
   Change Detection from Very High-Resolution Satellite Imagery
SO CANADIAN JOURNAL OF REMOTE SENSING
LA English
DT Article
ID NETWORK
AB Over the past few years, Convolutional Neural Networks (CNN) have grown in popularity with the remote sensing community due to their relatively easy training process, excellent generalization capacity and state-of-the-art performance. CNN models following an encoder-decoder architecture to perform end-to-end semantic segmentation have been applied to Change Detection (CD) applications with remarkable results. In this paper, we aim to further improve the performance of such models. First, we experiment with the introduction of additional boundary information into an encoder-decoder architecture that performs semantic segmentation for CD. We use the Dense Extreme Inception Network (DexiNeD) to produce the semantically informed edges. Second, we propose a training process that implicitly teaches the model to become more robust to misregistration errors. We evaluate our proposed approaches on a CD dataset, which consists of very high resolution RGB satellite image pairs, using two encoder-decoder models, UNet and UNet++, as our backbone architecture. The evaluation results suggest that both enhancements improve the performance of the CD network, with the average improvement on precision, recall, F1score and IoU ranging between 1% and 2% when incorporating boundary features into our architectures, and up to 2.5% when modeling the misregistration errors in the training process.
C1 [Bousias Alexakis, Evangelos; Armenakis, Costas] York Univ, Lassonde Sch Engn, Dept Earth & Space Sci & Engn, Geomat Engn, Toronto, ON, Canada.
RP Armenakis, C (corresponding author), York Univ, Lassonde Sch Engn, Dept Earth & Space Sci & Engn, Geomat Engn, Toronto, ON, Canada.
EM armenc@yorku.ca
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC); York University
FX This work is financially supported by the Natural Sciences and
   Engineering Research Council of Canada (NSERC Discovery and CREATE
   grants) and York University.
CR Alexakis E.B., 2020, ISPRS INT ARCH, V43, P1507
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Boulch A, 2018, IEEE INT C IM PROC I
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao C, 2019, ENVIRONMENTS, V6, DOI 10.3390/environments6020025
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Foody GM, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5110199
   Fuse T., 2020, ISPRS ANN PHOTOGRAMM, V2, P565, DOI [10.5194/isprs-annals-V-2-2020-565-2020, DOI 10.5194/ISPRS-ANNALS-V-2-2020-565-2020]
   He JZ, 2022, IEEE T PATTERN ANAL, V44, P100, DOI 10.1109/TPAMI.2020.3007074
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karantzalos K., 2020, ISPRS ANN PHOTOGRAMM, VV-2-2020, P541, DOI [10.5194/isprs-annals-V-2-2020-541-2020, DOI 10.5194/ISPRS-ANNALS-V-2-2020-541-2020]
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, P257, DOI 10.1109/CVPRW.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sappa A.D., 2020, ARXIV190901955CS
   Seydi ST, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122010
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tu Z., 2015, ARXIV150406375CS
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 40
TC 1
Z9 1
U1 12
U2 12
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0703-8992
EI 1712-7971
J9 CAN J REMOTE SENS
JI Can. J. Remote Sens.
PD MAR 4
PY 2021
VL 47
IS 2
SI SI
BP 309
EP 336
DI 10.1080/07038992.2021.1922880
EA JUN 2021
PG 28
WC Remote Sensing
SC Remote Sensing
GA TI7ZG
UT WOS:000667116900001
DA 2022-01-04
ER

PT J
AU Tang, PQ
   Li, JJ
   Ding, FF
   Chen, WK
   Li, XF
AF Tang, Peiqi
   Li, Jianjun
   Ding, Feifei
   Chen, Weikun
   Li, Xinfu
TI PSNet: change detection with prototype similarity
SO VISUAL COMPUTER
LA English
DT Article; Early Access
DE Remote sensing image; Change detection; End-to-end method; Metric
   learning
ID NEURAL-NETWORKS; IMAGES
AB Change detection is a fundamental problem in remote sensing image processing. Due to the great advantages in learning the knowledge representations and the complex relationship from large-scale datasets, deep learning has made great progress in change detection tasks in remote sensing community. However, most of the existing methods based on deep learning for change detection are implemented by learning differences of image pairs directly without paying considerations in influences of unstructured and temporal changes, or called nature changes, such as light and seasonal changes. In this paper, an end-to-end deep learning network for remote sensing image change detection is proposed, aiming to accurately detect the change of regions from a high-resolution image pair by learning prototype similarity, in which the metric learning is used and it is one of the meta-learning methods to learn change prototypes from support image pairs. The similarity between the query image pairs and the change prototypes can be measured by a learnable CNN metric. The experimental results based on the two public change detection datasets of high-resolution satellite images, CDD and BCDD, show that our proposed method performs better than other state-of-the-art change detection methods with an improvement of 3.5% and 0.4%, respectively.
C1 [Tang, Peiqi; Li, Jianjun; Ding, Feifei; Chen, Weikun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
   [Li, Xinfu] China Elect Technol Grp, Inst 36, Jiaxing 100048, Zhejiang, Peoples R China.
RP Li, JJ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
EM 791035236@qq.com; lijjcan@gmail.com; dingfeifei7@gmail.com;
   chenweikun@gmail.com; lixinfu@gmail.com
OI li, jianjun/0000-0001-6658-9709
FU National Science Fund of ChinaNational Natural Science Foundation of
   China (NSFC) [61871170]; Key Research and Development Plan of Zhejiang
   [2021C03131, KY2017210A001]; Key Laboratory of Brain Machine
   Collaborative Intelligence of Zhejiang Province
FX This work was supported in part by National Science Fund of China: No.
   61871170; Key Research and Development Plan of Zhejiang: No. 2021C03131;
   The Basic Research Program of KY2017210A001; Key Laboratory of Brain
   Machine Collaborative Intelligence of Zhejiang Province.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen J., 2020, ARXIV COMPUTER VISIO
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Darrell, 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rakelly K, 2018, INT C LEARN REPR
   Ronneberger O., 2015, PROC INT C MED IMAG, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xing EP, 2018, BMVC, V3
   Yosinski J, 2015, ARXIV COMPUTER VISIO
   Zemel, 2017, ADV NEURAL INFORM PR, P4077, DOI DOI 10.5555/3294996.3295163
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
NR 33
TC 0
Z9 0
U1 16
U2 16
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0178-2789
EI 1432-2315
J9 VISUAL COMPUT
JI Visual Comput.
PY 2021
DI 10.1007/s00371-021-02177-4
EA JUN 2021
PG 10
WC Computer Science, Software Engineering
SC Computer Science
GA SU6BX
UT WOS:000663221500001
DA 2022-01-04
ER

PT J
AU Moustafa, MS
   Mohamed, SA
   Ahmed, S
   Nasr, AH
AF Moustafa, Marwa S.
   Mohamed, Sayed A.
   Ahmed, Sayed
   Nasr, Ayman H.
TI Hyperspectral change detection based on modification of UNet neural
   networks
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE hyperspectral imagery; semantic segmentation; change detection; deep
   learning
ID IMAGES
AB The Earth's surface changes continuously due to several natural and humanmade factors. Efficient change detection (CD) is useful in monitoring and managing different situations. The recent rise in launched hyperspectral platforms provides a diversity of spectrum in addition to the spatial resolution required to meet recent civil applications requirements. Traditional multispectral CD algorithms hardly cope with the complex nature of hyperspectral images and their high dimensionality. To overcome these limitations, a CD deep convolutional neural network (CNN) semantic segmentation-based workflow was proposed. The proposed workflow is composed of four main stages, namely preprocessing, training, testing, and evaluation. Initially, preprocessing is performed to overcome hyperspectral image noise and the high dimensionality problem. Random oversampling (ROS), deep learning, and bagging ensemble were incorporated to handle imbalanced dataset. Also, we evaluated the generality and performance of the original UNet model and four variants of UNet, namely residual UNet, residual recurrent UNet, attention UNet, and attention residual recurrent UNet. Three hyperspectral CD datasets were employed in performance assessment for binary and multiclass change cases; all datasets suffer from class imbalance and small region of interest size. Recurrent residual UNet presented the best performance in both accuracy and inference time. Overall, the obtained results imply that deep CNN segmentation models can be utilized to implement efficient CD for hyperspectral imageries. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.
C1 [Moustafa, Marwa S.; Mohamed, Sayed A.; Ahmed, Sayed; Nasr, Ayman H.] Natl Author Remote Sensing & Space Sci, Cairo, Egypt.
RP Moustafa, MS (corresponding author), Natl Author Remote Sensing & Space Sci, Cairo, Egypt.
EM marwa.gis@gmail.com
RI Moustafa, Marwa/AAW-3476-2021
OI Moustafa, Marwa/0000-0003-3805-9668
CR Alom MZ, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.1.014006
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Destefanis G, 2000, MEAT SCI, V56, P255, DOI 10.1016/S0309-1740(00)00050-4
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Elkholy MM, 2020, INT J REMOTE SENS, V41, P4797, DOI 10.1080/01431161.2020.1724346
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamed A.A., 2020, INT J INTELLIGENT EN, V13, P539, DOI [10.22266/ijies2020.1031.47, DOI 10.22266/IJIES2020.1031.47]
   Henry C, 2018, IEEE GEOSCI REMOTE S, V15, P1867, DOI 10.1109/LGRS.2018.2864342
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Ignatiev V, 2019, PROC SPIE, V11041, DOI 10.1117/12.2523141
   Jafarzadeh H, 2019, IEEE J-STARS, V12, P4888, DOI 10.1109/JSTARS.2019.2939133
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Kingma D., 2014, 14126980 ARXIV
   Krauss T, 2020, SPRING REMOTE SENS P, P47, DOI 10.1007/978-3-030-10979-0_4
   Li LL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0131160
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma J, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102035
   Mahmoud A., 2020, INT J INTELL ENG SYS, V13, P65, DOI DOI 10.22266/IJIES2020.0229.07
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oktay, 2018, ATTENTION U NET LEAR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Talukdar S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071135
   Thabtah F, 2020, INFORM SCIENCES, V513, P429, DOI 10.1016/j.ins.2019.11.004
   Venugopal N, 2020, NEURAL PROCESS LETT, V51, P2355, DOI 10.1007/s11063-019-10174-x
   Wang B, 2015, REMOTE SENS LETT, V6, P578, DOI 10.1080/2150704X.2015.1062155
   Yeung M., ARXIV210204525
   Yu MZ, 2020, INT J DIGIT EARTH, V13, P1339, DOI 10.1080/17538947.2020.1738569
   Zefrehi HG, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.113005
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030548
   Zhang Y., 2015, ARXIV PREPRINT ARXIV
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
NR 40
TC 0
Z9 0
U1 0
U2 0
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
EI 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD JUN 17
PY 2021
VL 15
IS 2
AR 028505
DI 10.1117/IIRS.15.028505
PG 15
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA TB0NN
UT WOS:000667640000001
DA 2022-01-04
ER

PT J
AU Shi, J
   Zhang, ZP
   Tan, CH
   Liu, XD
   Lei, Y
AF Shi, Jiao
   Zhang, Zeping
   Tan, Chunhui
   Liu, Xiaodong
   Lei, Yu
TI Unsupervised Multiple Change Detection in Remote Sensing Images via
   Generative Representation Learning Network
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Remote sensing; Training; Learning systems; Iron;
   Generators; Reliability; Adversarial learning; deep neural network
   (DNN); multiple change detection (CD); multispectral images; remote
   sensing
ID CHANGE VECTOR ANALYSIS
AB With abundant temporal, spectral, and spatial information, multispectral images are proficient for acquiring a superior comprehension of the Earth's condition and its changes, which enables the achievement of multiple change detection (CD) tasks. However, high temporal, spatial, and spectral information of data brings obstacles to perform multiple change analysis due to the lack of effective feature extraction operation. In addition, the traditional multiple CD methods rely too much on manual participation. Here, a generative representation learning network (GRN) and a cyclic clustering technique are combined into a unified model, which is driven to learn spatial-temporal-spectral features for unsupervised multiple CD. GRN aims to efficiently extract and merge robust difference information with a recurrent learning mechanism for self-adaptive classification refinement, in which different types of changes can be identified and highlighted. Furthermore, a cyclic training strategy is designed to refine the clustering-friendly features, in which similar change types are gradually merged into the same classes. Meanwhile, the number of change types will be optimized through a self-adaptive way and eventually converge to its stable state, which is close to the real distribution. Experimental results on real multispectral datasets demonstrate the effectiveness and superiority of the proposed model on multiple CD.
C1 [Shi, Jiao; Zhang, Zeping; Tan, Chunhui; Liu, Xiaodong; Lei, Yu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
RP Lei, Y (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM jiaoshi@nwpu.edu.cn; zhangzeping@mail.nwpu.edu.cn; 1007627512@qq.com;
   1643585722@qq.com; leiy@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62076204]; National Natural Science
   Foundation of Shaanxi Province [2018JQ6003, 2018JQ6030]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2017M613204, 2017M623246]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62076204, in part by the National
   Natural Science Foundation of Shaanxi Province under Grant 2018JQ6003
   and Grant 2018JQ6030, and in part by the China Postdoctoral Science
   Foundation under Grant 2017M613204 and Grant 2017M623246.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Saha S, 2019, INT GEOSCI REMOTE SE, P5033, DOI 10.1109/IGARSS.2019.8900173
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu K, 2017, IEEE GEOSCI REMOTE S, V14, P1750, DOI 10.1109/LGRS.2017.2733558
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
NR 13
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3085022
EA JUN 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR2MY
UT WOS:000732071300001
DA 2022-01-04
ER

PT J
AU Daudt, RC
   Le Saux, B
   Boulch, A
   Gousseau, Y
AF Daudt, Rodrigo Caye
   Le Saux, Bertrand
   Boulch, Alexandre
   Gousseau, Yann
TI Weakly supervised change detection using guided anisotropic diffusion
SO MACHINE LEARNING
LA English
DT Article; Early Access
DE Remote sensing; Change detection; Weak supervision; Neural networks;
   Anisotropic diffusion
ID CLASSIFICATION; IMAGES
AB Large scale datasets created from crowdsourced labels or openly available data have become crucial to provide training data for large scale learning algorithms. While these datasets are easier to acquire, the data are frequently noisy and unreliable, which is motivating research on weakly supervised learning techniques. In this paper we propose original ideas that help us to leverage such datasets in the context of change detection. First, we propose the guided anisotropic diffusion (GAD) algorithm, which improves semantic segmentation results using the input images as guides to perform edge preserving filtering. We then show its potential in two weakly-supervised learning strategies tailored for change detection. The first strategy is an iterative learning method that combines model optimisation and data cleansing using GAD to extract the useful information from a large scale change detection dataset generated from open vector data. The second one incorporates GAD within a novel spatial attention layer that increases the accuracy of weakly supervised networks trained to perform pixel-level predictions from image-level labels. Improvements with respect to state-of-the-art are demonstrated on 4 different public datasets.
C1 [Daudt, Rodrigo Caye] Swiss Fed Inst Technol, Photogrammetry & Remote Sensing, Zurich, Switzerland.
   [Le Saux, Bertrand] European Space Agcy, ESRIN Lab, I-00044 Rome, Italy.
   [Boulch, Alexandre] Valeoai, F-75008 Paris, France.
   [Daudt, Rodrigo Caye; Gousseau, Yann] Inst Polytech Paris, Telecom Paris, Paris, France.
   [Daudt, Rodrigo Caye] Univ Paris Saclay, DTIS, ONERA, F-91123 Palaiseau, France.
RP Daudt, RC (corresponding author), Swiss Fed Inst Technol, Photogrammetry & Remote Sensing, Zurich, Switzerland.; Daudt, RC (corresponding author), Inst Polytech Paris, Telecom Paris, Paris, France.; Daudt, RC (corresponding author), Univ Paris Saclay, DTIS, ONERA, F-91123 Palaiseau, France.
EM rodrigo.cayedaudt@geod.baug.ethz.ch
OI Le Saux, Bertrand/0000-0001-7162-6746; Caye Daudt,
   Rodrigo/0000-0002-4952-9736
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Alvarez J. L. H., 2020, S2 CGAN SELF SUPERVI
   Aubert G., 2006, MATH PROBLEMS IMAGE, V147
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen Y, 2018, IEEE IMAGE PROC, P4008, DOI 10.1109/ICIP.2018.8451392
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Darrell, 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   Daudt R. C., IEEE C COMP VIS PATT
   Daudt RC, 2019, INT GEOSCI REMOTE SE, P5602, DOI 10.1109/IGARSS.2019.8898563
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Frenay B., 2014, EUR S ART NEUR NETW
   Frenay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Guo E., 2018, ARXIV181009111 CORR
   Guyon I., 1996, DISCOVERING INFORMAT
   He K, 2016, CVPR, P770, DOI DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ioffe S., 2015, ARXIV150203167, P448
   Jeatrakul P, 2010, J ADV COMPUT INTELL, V14, P297, DOI 10.20965/jaciii.2010.p0297
   John G. H., 1995, KDD-95 Proceedings. First International Conference on Knowledge Discovery and Data Mining, P174
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kingma D., 2014, 14126980 ARXIV
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Koltun V., 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172
   Luppino L. T., 2020, CODE ALIGNED AUTOENC
   Maggiori E, 2017, INT GEOSCI REMOTE SE, P3226, DOI 10.1109/IGARSS.2017.8127684
   MATIC N, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P330, DOI 10.1109/ICPR.1992.201784
   Natarajan N., 2013, ADV NEURAL INFORM PR, P1196
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Rolnick D., 2017, ARXIV170510694 CORR
   Ronneberger O., 2015, PROC INT C MED IMAG, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Saha Sangeeta, 2020, Int J Dyn Control, P1, DOI 10.1007/s40435-020-00721-z
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K, 2015, P BMVC, P61
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   SORENSEN T., 1948, BIOL SKR DAN VID SEL, V5, P1, DOI DOI 10.1007/978-3-319-20816-9_60
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 55
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 0885-6125
EI 1573-0565
J9 MACH LEARN
JI Mach. Learn.
PY 2021
DI 10.1007/s10994-021-06008-4
EA JUN 2021
PG 27
WC Computer Science, Artificial Intelligence
SC Computer Science
GA SP6PI
UT WOS:000659788700001
OA Bronze
DA 2022-01-04
ER

PT J
AU Du, HL
   Zhuang, Y
   Dong, S
   Li, C
   Chen, H
   Zhao, BY
   Chen, L
AF Du, Hailin
   Zhuang, Yin
   Dong, Shan
   Li, Can
   Chen, He
   Zhao, Boya
   Chen, Liang
TI Bilateral Semantic Fusion Siamese Network for Change Detection From
   Multitemporal Optical Remote Sensing Imagery
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Semantics; Feature extraction; Convolution; Remote sensing; Optical
   sensors; Optical imaging; Training; Bilateral semantic fusion;
   bitemporal images; change detection (CD); siamese network
AB Change detection (CD) is an essential task in optical remote sensing, and it can be used to extract the valid information from sequential multitemporal images. However, since the character of long-term revisiting and very high resolution (VHR) development, the great differences of illumination, season, and interior textures between bitemporal images bring considerable challenges for pixel-wise CD. In this letter, focusing on accurate pixel-wise CD, a bilateral semantic fusion Siamese network (BSFNet) is proposed. First, to better map bitemporal images into semantic feature domain for comparison, a novel BSFNet is designed to effectively integrate shallow and deep semantic features, which can provide pixel-wise CD results with complete regions and clear boundary locations. Then, in order to facilitate the reasonable convergence of the proposed BSFNet, a scale-invariant sample balance (SISB) loss is designed for metric learning to avoid the problems of sample imbalance and scale variance. Finally, extensive experiments are carried out on two published CDD and LEVIR CD datasets, and results indicate that the proposed BSFNet can provide superior performance than the other state-of-the-art methods. Our work is available at https://github.com/ClarissaDHL/BSFNet.
C1 [Du, Hailin; Zhuang, Yin; Li, Can; Chen, He; Chen, Liang] Beijing Key Lab Embedded Real Time Informat Proc, Beijing 100081, Peoples R China.
   [Dong, Shan] Commun Univ China, Engn Ctr Digital Audio & Video, Beijing 100024, Peoples R China.
   [Zhao, Boya] Chinese Acad Sci, Space Technol Res Inst Remote Sensing Technol, Beijing 100081, Peoples R China.
RP Zhuang, Y (corresponding author), Beijing Key Lab Embedded Real Time Informat Proc, Beijing 100081, Peoples R China.
EM zhuangyin640829@163.com
OI Du, Hailin/0000-0003-4130-2219; Dong, Shan/0000-0003-1894-7449
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91738302]; Civil Aviation Program [B0201];
   National Science Foundation for Young Scientists of China [62001455]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 91738302, in part by the Civil Aviation
   Program under Grant B0201, and in part by the National Science
   Foundation for Young Scientists of China under Grant 62001455.
CR Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   He QQ, 2021, INT ENTREP MANAG J, DOI [10.1007/s11365-020-00721-7, 10.1109/TGRS.2020.3045474]
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 14
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3082630
EA JUN 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR4UE
UT WOS:000732225300001
DA 2022-01-04
ER

PT J
AU Shi, WZ
   Zhang, M
   Ke, HF
   Fang, X
   Zhan, Z
   Chen, SX
AF Shi, Wenzhong
   Zhang, Min
   Ke, Hongfei
   Fang, Xin
   Zhan, Zhao
   Chen, Shanxiong
TI Landslide Recognition by Deep Convolutional Neural Network and Change
   Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Terrain factors; Feature extraction; Training; Data mining; Image
   recognition; Convolutional neural networks; Remote sensing; Change
   detection; convolutional neural network (CNN); landslide; remotely
   sensed (RS) images
ID TESSINA LANDSLIDE; HAZARD ASSESSMENT; IMAGERY; INVENTORY; FRAMEWORK
AB It is a technological challenge to recognize landslides from remotely sensed (RS) images automatically and at high speeds, which is fundamentally important for preventing and controlling natural landslide hazards. Many methods have been developed, but there remains room for improvement for stable, higher accuracy, and high-speed landslide recognition for large areas with complex land cover. In this article, a novel integrated approach combining a deep convolutional neural network (CNN) and change detection is proposed for landslide recognition from RS images. Logically, it comprises the following four parts. First, a CNN for landslide recognition is built based on training data sets from RS images with historical landslides. Second, the object-oriented change detection CNN (CDCNN) with a fully connected conditional random field (CRF) is implemented based on the trained CNN. Third, the preliminary CDCNN is optimized by the proposed postprocessing methods. Finally, the results are further enhanced by a set of information extraction methods, including trail extraction, source point extraction, and attribute extraction. Furthermore, in the implementation of the proposed approach, image block processing and parallel processing strategies are adopted. As a result, the speed has been improved significantly, which is extremely important for RS images covering large areas. The effectiveness of the proposed approach has been examined using two landslide-prone sites, Lantau Island and Sharp Peak, Hong Kong, with a total area of more than 70 km(2). Besides its high speed, the proposed approach has an accuracy exceeding 80%, and the experiments demonstrate its high practicability.
C1 [Shi, Wenzhong] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Peoples R China.
   [Zhang, Min; Ke, Hongfei; Fang, Xin; Zhan, Zhao; Chen, Shanxiong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
RP Zhang, M (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
EM lswzshi@polyu.edu.hk; 007zhangmin@whu.edu.cn; kehongfei@whu.edu.cn;
   fangxin94@whu.edu.cn; zhanzhao@whu.edu.cn; shanxiongchen@whu.edu.cn
RI ; ZHANG, Min/G-4525-2019
OI ZHAN, ZHAO/0000-0002-5092-715X; ZHANG, Min/0000-0003-1643-5271; Chen,
   Shanxiong/0000-0002-9235-6340
FU Ministry of Science and Technology of the People's Republic of
   ChinaMinistry of Science and Technology, China [2017YFB0503604]; Hong
   Kong Polytechnic University Projects through the Landslip Prevention and
   Mitigation Programme, 2017 [CE 49/2017 (GE)]
FX This work was supported in part by the Hong Kong Polytechnic University
   Projects through the Landslip Prevention and Mitigation Programme, 2017,
   under Agreement CE 49/2017 (GE), and in part by the Ministry of Science
   and Technology of the People's Republic of China under Project
   2017YFB0503604.
CR Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Behling R, 2016, REMOTE SENS ENVIRON, V186, P88, DOI 10.1016/j.rse.2016.07.017
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040333
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Dai FC, 2001, ENVIRON GEOL, V40, P381, DOI 10.1007/s002540000163
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Fiorucci F, 2019, LANDSLIDES, V16, P165, DOI 10.1007/s10346-018-1069-y
   Fiorucci F, 2018, NAT HAZARD EARTH SYS, V18, P405, DOI 10.5194/nhess-18-405-2018
   Gao L, 2018, LANDSLIDES, V15, P727, DOI 10.1007/s10346-017-0904-x
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Murillo-Garcia FG, 2015, LANDSLIDES, V12, P277, DOI 10.1007/s10346-014-0473-1
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guzzetti F, 2003, NAT HAZARD EARTH SYS, V3, P469, DOI 10.5194/nhess-3-469-2003
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hervas J, 2003, GEOMORPHOLOGY, V54, P63, DOI 10.1016/S0169-555X(03)00056-4
   Huang FM, 2018, ENVIRON EARTH SCI, V77, DOI 10.1007/s12665-018-7334-5
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Ko FWY, 2018, ENG GEOL, V242, P12, DOI 10.1016/j.enggeo.2018.05.001
   Krahenbuhl P., 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Lu P, 2011, IEEE GEOSCI REMOTE S, V8, P701, DOI 10.1109/LGRS.2010.2101045
   Martha TR, 2012, ISPRS J PHOTOGRAMM, V67, P105, DOI 10.1016/j.isprsjprs.2011.11.004
   Metternicht G, 2005, REMOTE SENS ENVIRON, V98, P284, DOI 10.1016/j.rse.2005.08.004
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Mondini AC, 2013, GEOMORPHOLOGY, V201, P135, DOI 10.1016/j.geomorph.2013.06.015
   Mondini AC, 2011, GEOMORPHOLOGY, V134, P440, DOI 10.1016/j.geomorph.2011.07.021
   Pardeshi SD, 2013, SPRINGERPLUS, V2, DOI 10.1186/2193-1801-2-523
   Pellicani R, 2015, B ENG GEOL ENVIRON, V74, P357, DOI 10.1007/s10064-014-0639-z
   Rau JY, 2014, IEEE T GEOSCI REMOTE, V52, P1336, DOI 10.1109/TGRS.2013.2250293
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sameen MI, 2019, IEEE ACCESS, V7, P114363, DOI 10.1109/ACCESS.2019.2935761
   Scaioni M, 2014, REMOTE SENS-BASEL, V6, P9600, DOI [10.3390/rs6109600, 10.3390/rs60x000x]
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Tsutsui K, 2007, IEEE T GEOSCI REMOTE, V45, P1681, DOI 10.1109/TGRS.2007.895209
   van Westen CJ, 2003, GEOMORPHOLOGY, V54, P77, DOI 10.1016/S0169-555X(03)00057-6
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Xu C, 2015, GEOMORPHOLOGY, V248, P77, DOI 10.1016/j.geomorph.2015.07.002
   Xu C, 2014, LANDSLIDES, V11, P441, DOI 10.1007/s10346-013-0404-6
   Yang XJ, 2010, INT J APPL EARTH OBS, V12, P487, DOI 10.1016/j.jag.2010.05.006
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
   Zhang W, 2017, PROCEEDINGS OF 2017 IEEE INTERNATIONAL CONFERENCE ON UNMANNED SYSTEMS (ICUS), P400, DOI 10.1109/ICUS.2017.8278377
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang WZ, 2018, IEEE T GEOSCI REMOTE, V56, P3587, DOI 10.1109/TGRS.2018.2802785
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhong YF, 2014, IEEE T GEOSCI REMOTE, V52, P7023, DOI 10.1109/TGRS.2014.2306692
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 53
TC 11
Z9 11
U1 65
U2 75
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUN
PY 2021
VL 59
IS 6
BP 4654
EP 4672
DI 10.1109/TGRS.2020.3015826
PG 19
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA SF5ZU
UT WOS:000652834200013
DA 2022-01-04
ER

PT J
AU Zulfiqar, A
   Ghaffar, MM
   Shahzad, M
   Weis, C
   Malik, MI
   Shafait, F
   Wehn, N
AF Zulfiqar, Annus
   Ghaffar, Muhammad M.
   Shahzad, Muhammad
   Weis, Christian
   Malik, Muhammad, I
   Shafait, Faisal
   Wehn, Norbert
TI AI-ForestWatch: semantic segmentation based end-to-end framework for
   forest estimation and change detection using multi-spectral remote
   sensing imagery
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE deep neural networks; semantic segmentation; multi-spectral remote
   sensing; multi-temporal forest change detection
ID COVER CHANGE; DEFORESTATION; DEGRADATION; PATTERNS; INDEXES; MODEL
AB Forest change detection is crucial for sustainable forest management. The changes in the forest area due to deforestation (such as wild fires or logging due to development activities) or afforestation alter the total forest area. Additionally, it impacts the available stock for commercial purposes, climate change due to carbon emissions, and biodiversity of the forest habitat estimations, which are essential for disaster management and policy making. In recent years, foresters have relied on hand-crafted features or bi-temporal change detection methods to detect change in the remote sensing imagery to estimate the forest area. Due to manual processing steps, these methods are fragile and prone to errors and can generate inaccurate (i.e., under or over) segmentation results. In contrast to traditional methods, we present AI-ForestWatch, an end to end framework for forest estimation and change analysis. The proposed approach uses deep convolution neural network-based semantic segmentation to process multi-spectral spaceborne images to quantitatively monitor the forest cover change patterns by automatically extracting features from the dataset. Our analysis is completely data driven and has been performed using extended (with vegetation indices) Landsat-8 multi-spectral imagery from 2014 to 2020. As a case study, we estimated the forest area in 15 districts of Pakistan and generated forest change maps from 2014 to 2020, where major afforestation activity is carried out during this period. Our critical analysis shows an improvement of forest cover in 14 out of 15 districts. The AI-ForestWatch framework along with the associated dataset will be made public upon publication so that it can be adapted by other countries or regions. (C) The Authors. Published by SPIE under a Creative Commons Attribution 4.0 Unported License.
C1 [Zulfiqar, Annus; Shahzad, Muhammad; Malik, Muhammad, I; Shafait, Faisal] Natl Univ Sci & Technol, Sch Elect Engn & Comp Sci, Islamabad, Pakistan.
   [Ghaffar, Muhammad M.; Weis, Christian; Wehn, Norbert] Tech Univ Kaiserslautern, Dept Elect & Comp Engn, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
   [Shahzad, Muhammad; Malik, Muhammad, I; Shafait, Faisal] Natl Ctr Artificial Intelligence, Deep Learning Lab, Islamabad, Pakistan.
RP Ghaffar, MM (corresponding author), Tech Univ Kaiserslautern, Dept Elect & Comp Engn, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
EM ghaffar@eit.uni-kl.de
FU German Academic Exchange Service (DAAD)Deutscher Akademischer Austausch
   Dienst (DAAD) [57402923]
FX The authors would like to thank Forest Department of Khyber Pakhtunkhwa
   for providing the Billion Tree Afforestation Project data. The authors
   would also like to thank Tasleem Khan for providing with useful insights
   into land cover classification problem and its application and
   difficulties working with KP forest cover data. Furthermore, we would
   like to thank the anonymous reviewers for their valuable feedback. Part
   of this research was supported by the German Academic Exchange Service
   (DAAD) under Grant No. 57402923. The authors have no conflicts of
   interest to declare.
CR Ali A, 2019, SIGNIFICANCE BILLION, V1, P157
   Barati S, 2011, EGYPT J REMOTE SENS, V14, P49, DOI 10.1016/j.ejrs.2011.06.001
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060901
   Google, GOOGL EARTH ENG
   Hansen MC, 2016, REMOTE SENS ENVIRON, V185, P221, DOI 10.1016/j.rse.2016.02.023
   Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1215904, 10.1126/science.1244693]
   Helber P, 2018, INT GEOSCI REMOTE SE, P204, DOI 10.1109/IGARSS.2018.8519248
   Huang CQ, 2010, REMOTE SENS ENVIRON, V114, P183, DOI 10.1016/j.rse.2009.08.017
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Jiang ZY, 2007, J APPL REMOTE SENS, V1, DOI 10.1117/1.2709702
   Khan M. I, 2017, 3 PARTY MONITORING B
   Khan N, 2019, FORESTS, V10, DOI 10.3390/f10080703
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kim DH, 2014, REMOTE SENS ENVIRON, V155, P178, DOI 10.1016/j.rse.2014.08.017
   Lehmann EA, 2013, INT J APPL EARTH OBS, V21, P453, DOI 10.1016/j.jag.2012.06.005
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu JZ, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.105012
   NASA, LANDS TIM
   Nazir N, 2019, J MT SCI-ENGL, V16, P2640, DOI 10.1007/s11629-018-5076-1
   Ni XL, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.022207
   Olmos-Trujillo E, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12051939
   Potapov PV, 2012, REMOTE SENS ENVIRON, V122, P106, DOI 10.1016/j.rse.2011.08.027
   Qamer FM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050385
   Rabinovich A., 2015, PROC CVPR IEEE, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sentinel-Hub, NDVI NORM DIFF VEG I
   Sentinel-Hub, EVI ENH VEG IND
   Shimada M, 2014, REMOTE SENS ENVIRON, V155, P13, DOI 10.1016/j.rse.2014.04.014
   Song DX, 2015, ISPRS J PHOTOGRAMM, V103, P81, DOI 10.1016/j.isprsjprs.2014.09.005
   Song H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020114
   Souza CM, 2013, REMOTE SENS-BASEL, V5, P5493, DOI 10.3390/rs5115493
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   The Bonn Challenge, CHALL GLOB EFF
   The Landscape Toolbox, SOIL ADJ VEG IND
   UN Sustainable Development Goals, SUST MAN FOR COMB DE
   USGS, LANDS SURF REFL DER
   Vesa L, 2019, FOREST INVENTORY DAT
   Voight C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070823
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xue JR, 2017, J SENSORS, V2017, DOI 10.1155/2017/1353691
   Zhang XM, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.022211
   Zhao QX, 2019, FOREST ECOL MANAG, V434, P224, DOI 10.1016/j.foreco.2018.12.019
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 47
TC 0
Z9 0
U1 10
U2 13
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
EI 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD MAY 31
PY 2021
VL 15
IS 2
AR 024518
DI 10.1117/1.JRS.15.024518
PG 21
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA SO5CT
UT WOS:000658990900001
OA hybrid
DA 2022-01-04
ER

PT J
AU Zheng, XT
   Chen, XM
   Lu, XQ
   Sun, BY
AF Zheng, Xiangtao
   Chen, Xiumei
   Lu, Xiaoqiang
   Sun, Bangyong
TI Unsupervised Change Detection by Cross-Resolution Difference Learning
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Image resolution; Feature extraction; Image segmentation; Remote
   sensing; Mutual information; Learning systems; Data mining; Coupled deep
   neural network (CDNN); cross-resolution difference; mutual information
   distance; unsupervised change detection (CD)
ID THRESHOLD SELECTION METHOD; MULTIPLE-CHANGE DETECTION; CHANGE VECTOR
   ANALYSIS; IMAGES; LANDSAT
AB Change detection (CD) aims to identify the differences between multitemporal images acquired over the same geographical area at different times. With the advantages of requiring no cumbersome labeled change information, unsupervised CD has attracted extensive attention of researchers. Multitemporal images tend to have different resolutions as they are usually captured at different times with different sensor properties. It is difficult to directly obtain one pixelwise change map for two images with different resolutions, so current methods usually resize multitemporal images to a unified size. However, resizing operations change the original information of pixels, which limits the final CD performance. This article aims to detect changes from multitemporal images in the originally different resolutions without resizing operations. To achieve this, a cross-resolution difference learning method is proposed. Specifically, two cross-resolution pixelwise difference maps are generated for the two different resolution images and fused to produce the final change map. First, the two input images are segmented into individual homogeneous regions separately due to different resolutions. Second, each pixelwise difference map is produced according to two measure distances, the mutual information distance and the deep feature distance, between image regions in which the pixel lies. Third, the final binary change map is generated by fusing and binarizing the two cross-resolution difference maps. Extensive experiments on four datasets demonstrate the effectiveness of the proposed method for detecting changes from different resolution images.
C1 [Zheng, Xiangtao; Chen, Xiumei; Lu, Xiaoqiang; Sun, Bangyong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Peoples R China.
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol CAS, Xian 710119, Peoples R China.
EM luxq666666@gmail.com
OI Lu, Xiaoqiang/0000-0002-7037-5188
FU National Science Fund for Distinguished Young ScholarsNational Natural
   Science Foundation of China (NSFC)National Science Fund for
   Distinguished Young Scholars [61925112]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [61806193, 61772510]; Innovation Capability Support Program of Shaanxi
   [2020KJXX-091, 2020TD-015]; Key Research and Development Program of
   Shaanxi [2020ZDLGY04-03]; Funds for International Cooperation and
   Exchange of the National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [62011530021]
FX This work was supported in part by the National Science Fund for
   Distinguished Young Scholars under Grant 61925112, in part by the
   National Natural Science Foundation of China under Grant 61806193 and
   Grant 61772510, in part by the Innovation Capability Support Program of
   Shaanxi under Grant 2020KJXX-091 and Grant 2020TD-015, in part by the
   Key Research and Development Program of Shaanxi under Grant
   2020ZDLGY04-03, and in part by the Funds for International Cooperation
   and Exchange of the National Natural Science Foundation of China under
   Grant 62011530021. (Corresponding author: Xiaoqiang Lu.)
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alphan H, 2009, ENVIRON MONIT ASSESS, V151, P327, DOI 10.1007/s10661-008-0274-x
   An L, 2015, IEEE GEOSCI REMOTE S, V12, P1863, DOI 10.1109/LGRS.2015.2432071
   Bao TF, 2020, IEEE GEOSCI REMOTE S, V17, P1797, DOI 10.1109/LGRS.2019.2955309
   Bergamasco L, 2019, PROC SPIE, V11155, DOI 10.1117/12.2533812
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2014, ISPRS J PHOTOGRAMM, V87, P19, DOI 10.1016/j.isprsjprs.2013.10.007
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gueguen L, 2011, IEEE T GEOSCI REMOTE, V49, P4503, DOI 10.1109/TGRS.2011.2141999
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kalinicheva E, 2019, LECT NOTES COMPUT SC, V11729, P637, DOI 10.1007/978-3-030-30508-6_50
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P2504, DOI 10.1109/TGRS.2019.2951779
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Lv ZY, 2020, IEEE T GEOSCI REMOTE, V58, P6524, DOI 10.1109/TGRS.2020.2977248
   Marinelli D, 2019, IEEE T GEOSCI REMOTE, V57, P4913, DOI 10.1109/TGRS.2019.2894339
   Meddens AJH, 2013, REMOTE SENS ENVIRON, V132, P49, DOI 10.1016/j.rse.2013.01.002
   Mercier G, 2006, INT GEOSCI REMOTE SE, P204, DOI 10.1109/IGARSS.2006.57
   Mignotte M, 2020, IEEE T GEOSCI REMOTE, V58, P8046, DOI 10.1109/TGRS.2020.2986239
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, INT GEOSCI REMOTE SE, P5033, DOI 10.1109/IGARSS.2019.8900173
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Theiler J., 2006, P ICML WORKSH MACH L, P7
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Volpi M, 2012, IEEE GEOSCI REMOTE S, V9, P1026, DOI 10.1109/LGRS.2012.2189092
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wang Q, 2007, IEEE T IMAGE PROCESS, V16, P889, DOI 10.1109/TIP.2007.891794
   Wu TJ, 2018, IEEE GEOSCI REMOTE S, V15, P63, DOI 10.1109/LGRS.2017.2773118
   Xiong BL, 2012, IEEE GEOSCI REMOTE S, V9, P287, DOI 10.1109/LGRS.2011.2166149
   Zhan T, 2020, IEEE T GEOSCI REMOTE, V58, P5653, DOI 10.1109/TGRS.2020.2968098
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P4799, DOI 10.1109/TGRS.2019.2893115
   Zheng XT, 2019, IEEE T GEOSCI REMOTE, V57, P2596, DOI 10.1109/TGRS.2018.2875304
NR 50
TC 1
Z9 1
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
DI 10.1109/TGRS.2021.3079907
PY 2021
EA MAY 2021
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2PD
UT WOS:000732756300001
DA 2022-01-04
ER

PT J
AU Abdi, G
   Jabari, S
AF Abdi, Ghasem
   Jabari, Shabnam
TI A Multi-Feature Fusion Using Deep Transfer Learning for Earthquake
   Building Damage Detection
SO CANADIAN JOURNAL OF REMOTE SENSING
LA English
DT Article
ID CONVOLUTIONAL NEURAL-NETWORKS; UNSUPERVISED CHANGE DETECTION;
   OF-THE-ART; IMAGERY; REPRESENTATION
AB With the recent tremendous improvements in the spatial, spectral, and temporal resolutions of remote sensing imaging systems, there has been a dramatic increase in their applications. Amongst different applications of very high-resolution remote sensing images, damage detection for rapid emergency response is one of the most challenging ones. Recently, deep learning frameworks have enhanced the performance of earthquake damage detection by automatic extraction of strong deep features. However, most of the existing studies in this area focus on using nadir satellite images or orthophotos which limits the available data sources. The objective of this study is to present a multi-modal integrated structure to combine orthophoto and off-nadir images for earthquake building damage detection. In this context, a multi-feature fusion method based on deep transfer learning is presented, which contains four different steps, namely pre-processing, deep feature extraction, deep feature fusion, and transfer learning. To validate the presented framework, two comparative experiments are conducted on the 2010 Haiti earthquake, using pre- and post-event off-nadir satellite images, which were collected by WorldView-2 (WV-2) satellite platform as well as a post-event airborne orthophoto. The results demonstrate considerable advantages in identifying damaged and non-damaged buildings with over 83% for the overall accuracy.
C1 [Abdi, Ghasem; Jabari, Shabnam] Univ New Brunswick, Dept Geodesy & Geomat Engn, Fredericton, NB, Canada.
RP Jabari, S (corresponding author), Univ New Brunswick, Dept Geodesy & Geomat Engn, Fredericton, NB, Canada.
EM sh.jabari@unb.ca
OI Jabari, Shabnam/0000-0002-8633-3847
FU Mitacs; 3D Planeta Inc.; Global Facility for Disaster Recovery and
   Recovery (GFDRR)
FX This research has been funded by Mitacs and 3D Planeta Inc. The pre- and
   post-event off-nadir satellite images were provided by the DigitalGlobe
   Foundation. LiDAR data were acquired by the Centre for Imaging Science
   at Rochester Institute of Technology (RIT) and Kucera International
   under sub-contract to ImageCat, Inc., and funded by the Global Facility
   for Disaster Recovery and Recovery (GFDRR) hosted at the World Bank. The
   authors acknowledge the contribution of the aforementioned organizations
   for their generous financial support or for providing the study
   datasets.
CR Abdi G, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.016038
   Abdi G, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042604
   Abdi G, 2017, EUR J REMOTE SENS, V50, P414, DOI 10.1080/22797254.2017.1348914
   Bu SH, 2020, NEUROCOMPUTING, V378, P166, DOI 10.1016/j.neucom.2019.10.022
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Chen YS, 2017, IEEE GEOSCI REMOTE S, V14, P1253, DOI 10.1109/LGRS.2017.2704625
   Cooner AJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100868
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Datta A., 2020, GEOSPATIAL WORLD
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Fathollahi F, 2020, INT J REMOTE SENS, V41, P3924, DOI 10.1080/01431161.2019.1711240
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   Ghouaiel N, 2016, GEO-SPAT INF SCI, V19, P222, DOI 10.1080/10095020.2016.1244998
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Han PC, 2019, NEUROCOMPUTING, V349, P190, DOI 10.1016/j.neucom.2019.04.029
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang FH, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102585
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Jabari S, 2016, PHOTOGRAMM ENG REM S, V82, P521, DOI 10.14358/PERS.82.7.521
   Jabari Shabnam, 2018, URBAN REMOTE SENSING, V2nd, P125, DOI [10.1201/9781138586642, DOI 10.1201/9781138586642]
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121444
   Ji M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111689
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Kerle N, 2019, INT ARCH PHOTOGRAMM, V42-3, P187, DOI 10.5194/isprs-archives-XLII-3-W8-187-2019
   Kerner HR, 2019, IEEE J-STARS, V12, P3900, DOI 10.1109/JSTARS.2019.2936771
   Keshk HM, 2020, INT J AERONAUT SPACE, V21, P549, DOI 10.1007/s42405-019-00222-0
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Larabi ME, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.046512
   Lavender A., 2018, MANY EARTH OBSERVATI
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Luo B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232740
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Menderes A, 2015, PROCED EARTH PLAN SC, V15, P257, DOI 10.1016/j.proeps.2015.08.063
   Naito S, 2020, EARTHQ SPECTRA, V36, P1166, DOI 10.1177/8755293019901309
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Nex F, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232765
   Novikov German, 2018, Business Information Systems. 21st International Conference, BIS 2018. Proceedings. Lecture Notes in Business Information Processing (LNBIP 320), P347, DOI 10.1007/978-3-319-93931-5_25
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Sadeghi V, 2018, MEASUREMENT, V127, P1, DOI 10.1016/j.measurement.2018.05.097
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Smith LN, 2019, PROC SPIE, V11006, DOI 10.1117/12.2520589
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Su LZ, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.035014
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Tran THG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020448
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Wu C. -S., 2019, ARXIV PREPRINT ARXIV
   Xu J., 2019, ARXIV191014142
   Xu JF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024506
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yeom J, 2017, INT J REMOTE SENS, V38, P985, DOI 10.1080/01431161.2016.1274445
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang ZC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202417
NR 84
TC 3
Z9 3
U1 9
U2 17
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0703-8992
EI 1712-7971
J9 CAN J REMOTE SENS
JI Can. J. Remote Sens.
PD MAR 4
PY 2021
VL 47
IS 2
SI SI
BP 337
EP 352
DI 10.1080/07038992.2021.1925530
EA MAY 2021
PG 16
WC Remote Sensing
SC Remote Sensing
GA TI7ZG
UT WOS:000654263800001
DA 2022-01-04
ER

PT J
AU Yang, MJ
   Jiao, LC
   Liu, F
   Hou, BA
   Yang, SY
   Jian, M
AF Yang, Meijuan
   Jiao, Licheng
   Liu, Fang
   Hou, Biao
   Yang, Shuyuan
   Jian, Meng
TI DPFL-Nets: Deep Pyramid Feature Learning Networks for Multiscale Change
   Detection
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Feature extraction; Remote sensing; Sensors; Radar polarimetry;
   Correlation; Task analysis; Semantics; Change detection; deep neural
   networks; feature transformation; heterogeneous images; local
   consistency; pyramid features; remote sensing
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION; SATELLITE
   IMAGES; SEGMENTATION
AB Due to the complementary properties of different types of sensors, change detection between heterogeneous images receives increasing attention from researchers. However, change detection cannot be handled by directly comparing two heterogeneous images since they demonstrate different image appearances and statistics. In this article, we propose a deep pyramid feature learning network (DPFL-Net) for change detection, especially between heterogeneous images. DPFL-Net can learn a series of hierarchical features in an unsupervised fashion, containing both spatial details and multiscale contextual information. The learned pyramid features from two input images make unchanged pixels matched exactly and changed ones dissimilar and after transformed into the same space for each scale successively. We further propose fusion blocks to aggregate multiscale difference images (DIs), generating an enhanced DI with strong separability. Based on the enhanced DI, unchanged areas are predicted and used to train DPFL-Net in the next iteration. In this article, pyramid features and unchanged areas are updated alternately, leading to an unsupervised change detection method. In the feature transformation process, local consistency is introduced to constrain the learned pyramid features, modeling the correlations between the neighboring pixels and reducing the false alarms. Experimental results demonstrate that the proposed approach achieves superior or at least comparable results to the existing state-of-the-art change detection methods in both homogeneous and heterogeneous cases.
C1 [Yang, Meijuan; Jiao, Licheng; Liu, Fang; Hou, Biao; Yang, Shuyuan] Xidian Univ, Sch Artificial Intelligence,Minist Educ,Int Res C, Joint Int Res Lab Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Jian, Meng] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
RP Jiao, LC (corresponding author), Xidian Univ, Sch Artificial Intelligence,Minist Educ,Int Res C, Joint Int Res Lab Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM mjuanyang@gmail.com; lchjiao@mail.xidian.edu.cn
OI Jian, Meng/0000-0001-5659-5128; Yang, Meijuan/0000-0002-9277-7751
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1701267]; State Key Program of National
   Natural Science of ChinaNational Natural Science Foundation of China
   (NSFC) [61836009]; Major Research Plan of the National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [91438201]; Foundation for Innovative Research Groups of the National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61621005]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1701267, in part by the State Key
   Program of National Natural Science of China under Grant 61836009, in
   part by the Major Research Plan of the National Natural Science
   Foundation of China under Grant 91438201, and in part by the Foundation
   for Innovative Research Groups of the National Natural Science
   Foundation of China under Grant 61621005.
CR Alberga V, 2009, REMOTE SENS-BASEL, V1, P122, DOI 10.3390/rs1030122
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P968, DOI 10.1109/TNNLS.2018.2852738
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Knyaz VA, 2017, IEEE INT CONF COMP V, P2155, DOI 10.1109/ICCVW.2017.252
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   Li GB, 2018, IEEE T NEUR NET LEAR, V29, P6038, DOI 10.1109/TNNLS.2018.2817540
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P2707, DOI 10.1109/TNNLS.2018.2885799
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu GC, 2015, PATTERN RECOGN, V48, P685, DOI 10.1016/j.patcog.2014.09.027
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Liu G, 2016, EUR SIGNAL PR CONF, P2435, DOI 10.1109/EUSIPCO.2016.7760686
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu ZG, 2012, IEEE T GEOSCI REMOTE, V50, P1955, DOI 10.1109/TGRS.2011.2169075
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Luo W, 2018, IEEE T NEUR NET LEAR, V29, P3289, DOI 10.1109/TNNLS.2017.2712793
   Luppino L. T., ARXIV200407011
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Luppino LT, 2017, LECT NOTES COMPUT SC, V10270, P181, DOI 10.1007/978-3-319-59129-2_16
   Marcos D, 2016, PROC CVPR IEEE, P5091, DOI 10.1109/CVPR.2016.550
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Mignotte M, 2020, IEEE T GEOSCI REMOTE, V58, P8046, DOI 10.1109/TGRS.2020.2986239
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Quan D, 2019, IEEE I CONF COMP VIS, P3017, DOI 10.1109/ICCV.2019.00311
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   Shao ZF, 2019, REMOTE SENS ENVIRON, V235, DOI 10.1016/j.rse.2019.111425
   Shao ZF, 2019, IEEE J-STARS, V12, P2663, DOI 10.1109/JSTARS.2019.2925456
   Shao ZF, 2018, IEEE J-STARS, V11, P1656, DOI 10.1109/JSTARS.2018.2805923
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Touati R, 2017, INT CONF IMAG PROC
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Xiong W, 2017, PATTERN RECOGN, V62, P225, DOI 10.1016/j.patcog.2016.08.006
   Xu J, 2016, IEEE T MED IMAGING, V35, P119, DOI 10.1109/TMI.2015.2458702
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang YM, 2012, PROC CVPR IEEE, P582, DOI 10.1109/CVPR.2012.6247724
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhu H, 2019, IEEE T NEUR NET LEAR, V30, P2853, DOI 10.1109/TNNLS.2018.2888757
NR 60
TC 1
Z9 1
U1 5
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PY 2021
DI 10.1109/TNNLS.2021.3079627
EA MAY 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
SC Computer Science; Engineering
GA XR4OK
UT WOS:000732210300001
PM 34029198
DA 2022-01-04
ER

PT J
AU Chen, C
   Ma, HX
   Yao, GR
   Lv, N
   Yang, H
   Li, C
   Wan, SH
AF Chen, Chen
   Ma, Hongxiang
   Yao, Guorun
   Lv, Ning
   Yang, Hua
   Li, Cong
   Wan, Shaohua
TI Remote Sensing Image Augmentation Based on Text Description for
   Waterside Change Detection
SO REMOTE SENSING
LA English
DT Article
DE data augmentation; deeply monitoring; GAN; remote sensing image; text
   description
AB Since remote sensing images are difficult to obtain and need to go through a complicated administrative procedure for use in China, it cannot meet the requirement of huge training samples for Waterside Change Detection based on deep learning. Recently, data augmentation has become an effective method to address the issue of an absence of training samples. Therefore, an improved Generative Adversarial Network (GAN), i.e., BTD-sGAN (Text-based Deeply-supervised GAN), is proposed to generate training samples for remote sensing images of Anhui Province, China. The principal structure of our model is based on Deeply-supervised GAN(D-sGAN), and D-sGAN is improved from the point of the diversity of the generated samples. First, the network takes Perlin Noise, image segmentation graph, and encoded text vector as input, in which the size of image segmentation graph is adjusted to 128 x 128 to facilitate fusion with the text vector. Then, to improve the diversity of the generated images, the text vector is used to modify the semantic loss of the downsampled text. Finally, to balance the time and quality of image generation, only a two-layer Unet++ structure is used to generate the image. Herein, "Inception Score", "Human Rank", and "Inference Time" are used to evaluate the performance of BTD-sGAN, StackGAN++, and GAN-INT-CLS. At the same time, to verify the diversity of the remote sensing images generated by BTD-sGAN, this paper compares the results when the generated images are sent to the remote sensing interpretation network and when the generated images are not added; the results show that the generated image can improve the precision of soil-moving detection by 5%, which proves the effectiveness of the proposed model.
C1 [Chen, Chen; Ma, Hongxiang; Yao, Guorun] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Lv, Ning] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Yang, Hua] Northwest Univ, Sch Econ & Management, Xian 710127, Peoples R China.
   [Li, Cong] State Grid JiLin Prov Elect Power Co Ltd Informat, Changchun 130000, Peoples R China.
   [Wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
RP Wan, SH (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Peoples R China.
EM cc2000@mail.xidian.edu.cn; mhongxiang@163.com; gr_yao@126.com;
   nlv@mail.xidian.edu.cn; yang.flower@163.com; congli8462@163.com;
   shaohua.wan@ieee.org
RI ; Wan, Shaohua/B-9243-2014
OI YAO, Guorun/0000-0003-1762-0794; ma, hongxiang/0000-0001-8975-5773; Wan,
   Shaohua/0000-0001-7013-9081
FU National Key Research and Development Program of China [2020YFB1807500];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62072360, 62001357, 61672131, 61901367]; key
   research and development plan of Shaanxi province [2021ZDLGY02-09,
   2020JQ-844]; fundamental research funds for the central
   universitiesFundamental Research Funds for the Central Universities
   [31412111303, 31512111310]; key laboratory of embedded system and
   service computing (Tongji University) (ESSC), Ministry of Education
   [KF201905]; Xi'an Science and Technology Plan [20RGZN0005]; Xi'an Key
   Laboratory of Mobile Edge Computing and Security [201805052-ZD3CG36]
FX This work was supported by the National Key Research and Development
   Program of China (2020YFB1807500), the National Natural Science
   Foundation of China (62072360, 62001357, 61672131, 61901367), the key
   research and development plan of Shaanxi province (2021ZDLGY02-09,
   2020JQ-844), the fundamental research funds for the central universities
   (31412111303, 31512111310), the key laboratory of embedded system and
   service computing (Tongji University) (ESSC KF201905), Ministry of
   Education, Xi'an Science and Technology Plan (20RGZN0005) and the Xi'an
   Key Laboratory of Mobile Edge Computing and Security
   (201805052-ZD3CG36).
CR Nguyen A, 2017, PROC CVPR IEEE, P3510, DOI 10.1109/CVPR.2017.374
   Nguyen A, 2016, ADV NEUR IN, V29
   Chen C, 2020, IEEE COMMUN SURV TUT, V22, P2378, DOI 10.1109/COMST.2020.3005361
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Fergus R, 2015, ADV NEURAL INFORM PR, P1486, DOI DOI 10.5555/
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Gauthier J., 2014, CLASS PROJECT STANFO, V2014, P2
   Ghaderpour E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12234001
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hong S, 2018, PROC CVPR IEEE, P7986, DOI 10.1109/CVPR.2018.00833
   Huang FR, 2021, IEEE T EVOLUT COMPUT, V25, P856, DOI 10.1109/TEVC.2021.3066285
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang JJ, 2018, IEEE T GEOSCI REMOTE, V56, P4581, DOI 10.1109/TGRS.2018.2828029
   Kingma D.P., 2014, P INT C LEARN REPR A, DOI DOI 10.1145/1830483.1830503
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lv N, 2020, IGARSS 2020 - 2020 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, P2511, DOI 10.1109/IGARSS39084.2020.9324263
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reed S. E., 2016, ADV NEURAL INFORM PR, P217
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T., 2016, ADV NEURAL INF PROCE, V29
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Shivani S, 2021, J REAL-TIME IMAGE PR, V18, P1493, DOI 10.1007/s11554-020-01005-7
   Sonderby C. K., 2016, ARXIV161004490
   Srivastava G, 2020, J INTELL FUZZY SYST, V38, P2561, DOI 10.3233/JIFS-179543
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan WR, 2017, IEEE IMAGE PROC, P3760, DOI 10.1109/ICIP.2017.8296985
   Tang B, 2018, IEEE ACCESS, V6, P15713, DOI 10.1109/ACCESS.2018.2815741
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yan YM, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8060276
   Yang JF, 2019, IEEE ACCESS, V7, P28894, DOI 10.1109/ACCESS.2019.2902121
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhu Z, 2015, REMOTE SENS ENVIRON, V162, P67, DOI 10.1016/j.rse.2015.02.009
NR 41
TC 0
Z9 0
U1 16
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2021
VL 13
IS 10
AR 1894
DI 10.3390/rs13101894
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA ST6NY
UT WOS:000662559500001
OA gold
DA 2022-01-04
ER

PT J
AU Gargees, RS
   Scott, GJ
AF Gargees, Rasha S.
   Scott, Grant J.
TI Large-Scale, Multiple Level-of-Detail Change Detection from Remote
   Sensing Imagery Using Deep Visual Feature Clustering
SO REMOTE SENSING
LA English
DT Article
DE change detection; big data; deep features; fuzzy clustering; transfer
   learning; land cover
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS; C-MEANS
   ALGORITHM; FUZZY; LAND; DIVERGENCE; CLASSIFICATION; INFORMATION;
   EXTRACTION; NETWORK
AB In the era of big data, where massive amounts of remotely sensed imagery can be obtained from various satellites accompanied by the rapid change in the surface of the Earth, new techniques for large-scale change detection are necessary to facilitate timely and effective human understanding of natural and human-made phenomena. In this research, we propose a chip-based change detection method that is enabled by using deep neural networks to extract visual features. These features are transformed into deep orthogonal visual features that are then clustered based on land cover characteristics. The resulting chip cluster memberships allow arbitrary level-of-detail change analysis that can also support irregular geospatial extent based agglomerations. The proposed methods naturally support cross-resolution temporal scenes without requiring normalization of the pixel resolution across scenes and without requiring pixel-level coregistration processes. This is achieved with configurable spatial locality comparisons between years, where the aperture of a unit of measure can be a single chip, a small neighborhood of chips, or a large irregular geospatial region. The performance of our proposed method has been validated using various quantitative and statistical metrics in addition to presenting the visual geo-maps and the percentage of the change. The results show that our proposed method efficiently detected the change from a large scale area.
C1 [Gargees, Rasha S.; Scott, Grant J.] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
RP Gargees, RS (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
EM rsgt3b@mail.missouri.edu; GrantScott@missouri.edu
OI Scott, Grant/0000-0001-5870-9387; Gargees, Rasha/0000-0003-3087-2910
CR Aguirre-Gutierrez J, 2012, APPL GEOGR, V34, P29, DOI 10.1016/j.apgeog.2011.10.010
   Ansari RA, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100418
   Bey A, 2020, REMOTE SENS ENVIRON, V239, DOI 10.1016/j.rse.2019.111611
   Bezdek J. C., 2017, PRIMER CLUSTER ANAL
   Buddhavarapu VG, 2020, PATTERN RECOGN LETT, V140, P1, DOI 10.1016/j.patrec.2020.09.020
   Cherfia TA, 2012, PROCEEDINGS OF THE 2012 IEEE SECOND INTERNATIONAL WORKSHOP ON ADVANCED INFORMATION SYSTEMS FOR ENTERPRISES (IWAISE 2012), P40, DOI 10.1109/IWAISE.2012.9
   De Vecchi D, 2015, INT GEOSCI REMOTE SE, P350, DOI 10.1109/IGARSS.2015.7325772
   Deng ZH, 2014, IEEE T CYBERNETICS, V44, P2585, DOI 10.1109/TCYB.2014.2311014
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Erturk S, 2018, INT GEOSCI REMOTE SE, P5045, DOI 10.1109/IGARSS.2018.8517721
   Gao ZJ, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103237
   Gargees RS, 2020, IEEE GEOSCI REMOTE S, V17, P1386, DOI 10.1109/LGRS.2019.2948799
   Geng J, 2020, ISPRS J PHOTOGRAMM, V167, P201, DOI 10.1016/j.isprsjprs.2020.07.007
   Gharieb RR, 2017, APPL SOFT COMPUT, V59, P143, DOI 10.1016/j.asoc.2017.05.055
   Hamouda K, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P245, DOI 10.1109/ICCES.2014.7030967
   Hamylton SM, 2020, INT J APPL EARTH OBS, V89, DOI 10.1016/j.jag.2020.102085
   Han W, 2018, ISPRS J PHOTOGRAMM, V145, P23, DOI 10.1016/j.isprsjprs.2017.11.004
   Haouas F, 2018, I C MECH MACH VIS PR, P120
   Hedayatnia B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2655, DOI 10.1109/BigData.2016.7840908
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Ilsever M, 2012, INT GEOSCI REMOTE SE, P6185, DOI 10.1109/IGARSS.2012.6352669
   Jain K., 2020, PROCEDIA COMPUT SCI, V171, P1184, DOI [10.1016/j.procs.2020.04.127, DOI 10.1016/J.PROCS.2020.04.127]
   Jin SM, 2017, REMOTE SENS ENVIRON, V195, P44, DOI 10.1016/j.rse.2017.04.021
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kearney SP, 2020, INT J APPL EARTH OBS, V87, DOI 10.1016/j.jag.2019.102031
   Kotkar SR, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P664, DOI 10.1109/INFOP.2015.7489466
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li, 2017, ARXIV170510450
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Li WJ, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111563
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Luo FL, 2019, IEEE T CYBERNETICS, V49, P2406, DOI 10.1109/TCYB.2018.2810806
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Lv PY, 2016, INT GEOSCI REMOTE SE, P1863, DOI 10.1109/IGARSS.2016.7729478
   Mahulkar HN, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P37, DOI 10.1109/ICCSP.2016.7754322
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Proulx-Bourque JS, 2018, INT GEOSCI REMOTE SE, P3441, DOI 10.1109/IGARSS.2018.8519171
   Rodriguez-Alvarez N, 2019, REMOTE SENS ENVIRON, V230, DOI 10.1016/j.rse.2019.05.021
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shedthi BS, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P105, DOI 10.1109/ICICCT.2017.7975168
   Suryana A, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON COMPUTING, ENGINEERING, AND DESIGN (ICCED 2018), P218, DOI 10.1109/ICCED.2018.00050
   Tamiminia H, 2017, INT J APPL EARTH OBS, V58, P201, DOI 10.1016/j.jag.2017.02.010
   Tan X., 2017, INT ARCH PHOTOGRAMM, V42, P143, DOI [10.5194/isprs-archives-XLII-2-W7-143-2017, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W7-143-2017]
   Tang ZP, 2015, INT GEOSCI REMOTE SE, P4840, DOI 10.1109/IGARSS.2015.7326914
   Tian DY, 2018, INFORM SCIENCES, V467, P415, DOI 10.1016/j.ins.2018.08.015
   Wang C, 2021, ENGINEERING-PRC, V7, P881, DOI 10.1016/j.eng.2020.03.016
   Wang J, 2020, ISPRS J PHOTOGRAMM, V164, P61, DOI 10.1016/j.isprsjprs.2020.04.007
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xing J, 2018, ISPRS J PHOTOGRAMM, V141, P252, DOI 10.1016/j.isprsjprs.2018.04.013
   Yang J, 2019, COMPUT GEOSCI-UK, V123, P10, DOI 10.1016/j.cageo.2018.11.003
   Yang W, 2014, IEEE J-STARS, V7, P3318, DOI 10.1109/JSTARS.2014.2347334
   Ye ZW, 2010, 2010 18TH INTERNATIONAL CONFERENCE ON GEOINFORMATICS
   Yu WJ, 2016, REMOTE SENS ENVIRON, V177, P37, DOI 10.1016/j.rse.2016.02.030
   Zhang AY, 2013, INT GEOSCI REMOTE SE, P2740, DOI 10.1109/IGARSS.2013.6723390
   Zhang C, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111593
   Zhang CX, 2020, INT J APPL EARTH OBS, V88, DOI 10.1016/j.jag.2020.102086
   Zhang L, 2015, IEEE J-STARS, V8, P4895, DOI 10.1109/JSTARS.2015.2467377
   Zhang MM, 2020, IEEE T CYBERNETICS, V50, P100, DOI 10.1109/TCYB.2018.2864670
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhang XL, 2019, INT J APPL EARTH OBS, V78, P215, DOI 10.1016/j.jag.2019.01.001
   Zhang XX, 2019, INT CONF ACOUST SPEE, P2742, DOI 10.1109/ICASSP.2019.8682206
   Zhang XW, 2019, INT J APPL EARTH OBS, V76, P26, DOI 10.1016/j.jag.2018.11.002
   Zhong LH, 2019, REMOTE SENS ENVIRON, V221, P430, DOI 10.1016/j.rse.2018.11.032
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zou Y, 2019, REMOTE SENS ENVIRON, V232, DOI 10.1016/j.rse.2019.111248
NR 67
TC 0
Z9 0
U1 8
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2021
VL 13
IS 9
AR 1661
DI 10.3390/rs13091661
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA SC5ZV
UT WOS:000650749700001
OA gold
DA 2022-01-04
ER

PT J
AU Liu, Y
   Pang, C
   Zhan, ZQ
   Zhang, XM
   Yang, X
AF Liu, Yi
   Pang, Chao
   Zhan, Zongqian
   Zhang, Xiaomeng
   Yang, Xue
TI Building Change Detection for Remote Sensing Images Using a Dual-Task
   Constrained Deep Siamese Convolutional Network Model
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Buildings; Semantics; Dams; Decoding; Task analysis;
   Image segmentation; Attention module; building change detection; deep
   learning; sample imbalance; semantic segmentation
AB In recent years, building change detection methods have made great progress by introducing deep learning, but they still suffer from the problem of the extracted features not being discriminative enough, resulting in incomplete regions and irregular boundaries. To tackle this problem, we propose a dual-task constrained deep Siamese convolutional network (DTCDSCN) model, which contains three subnetworks: a change detection network and two semantic segmentation networks. DTCDSCN can accomplish both change detection and semantic segmentation at the same time, which can help to learn more discriminative object-level features and obtain a complete change detection map. Furthermore, we introduce a dual attention module (DAM) to exploit the interdependencies between channels and spatial positions, which improves the feature representation. We also improve the focal loss function to suppress the sample imbalance problem. The experimental results obtained with the WHU building data set show that the proposed method is effective for building change detection and achieves state-of-the-art performance in terms of four metrics on the WHU building data set: precision, recall, F1-score, and intersection over union.
C1 [Liu, Yi; Pang, Chao; Zhan, Zongqian; Zhang, Xiaomeng; Yang, Xue] Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
RP Zhan, ZQ (corresponding author), Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430079, Peoples R China.
EM zqzhan@sgg.whu.edu.cn
FU National Key Research and Development Program of China [2016YFC0802500];
   Major Project of High Resolution Earth Observation Systems
   [11-Y20A03-9001-16/17]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [61871295]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFC0802500, in part by the
   Major Project of High Resolution Earth Observation Systems under Grant
   11-Y20A03-9001-16/17, and in part by the National Natural Science
   Foundation of China under Grant 61871295.
CR Adamko P, 2017, GLOBALIZATION AND ITS SOCIO-ECONOMIC CONSEQUENCES, PTS I - VI, P1
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Doshi J., 2018, NEURIPS WORKSH
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Kingma D., 2014, 14126980 ARXIV
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Maiya S. R, 2018, ARXIV181107896
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhou LC, 2018, IEEE COMPUT SOC CONF, P192, DOI 10.1109/CVPRW.2018.00034
   Zhu B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P55, DOI 10.1109/ICIVC.2018.8492747
NR 15
TC 10
Z9 10
U1 29
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAY
PY 2021
VL 18
IS 5
BP 811
EP 815
DI 10.1109/LGRS.2020.2988032
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA RQ9YJ
UT WOS:000642766600012
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Saha, S
   Solano-Correa, YT
   Bovolo, F
   Bruzzone, L
AF Saha, Sudipan
   Solano-Correa, Yady Tatiana
   Bovolo, Francesca
   Bruzzone, Lorenzo
TI Unsupervised Deep Transfer Learning-Based Change Detection for HR
   Multispectral Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Spatial resolution; Training; Gallium nitride;
   Generative adversarial networks; Generators; Change detection (CD); deep
   learning; generative adversarial network; high resolution; Sentinel-2
ID CHANGE VECTOR ANALYSIS
AB To overcome the limited capability of most state-of-the-art change detection (CD) methods in modeling spatial context of multispectral high spatial resolution (HR) images and exploiting all spectral bands jointly, this letter presents a novel unsupervised deep-learning-based CD method that can effectively model contextual information and handle the large number of bands in multispectral HR images. This is achieved by exploiting all spectral bands after grouping them into spectral-dedicated band groups. To eliminate the necessity of multitemporal training data, the proposed method exploits a data set targeted for image classification to train spectral-dedicated Auxiliary Classifier Generative Adversarial Networks (ACGANs). They are used to obtain pixelwise deep change hypervector from multitemporal images. Each feature in deep change hypervector is analyzed based on the magnitude to identify changed pixels. An ensemble decision fusion strategy is used to combine change information from different features. Experimental results on the urban, Alpine, and agricultural Sentinel-2 data sets confirm the effectiveness of the proposed method.
C1 [Saha, Sudipan; Solano-Correa, Yady Tatiana; Bovolo, Francesca] Fdn Bruno Kessler, I-38123 Trento, Italy.
   [Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
RP Bovolo, F (corresponding author), Fdn Bruno Kessler, I-38123 Trento, Italy.
EM saha@fbk.eu; solano@fbk.eu; bovolo@fbk.eu; lorenzo.bruzzone@unitn.it
RI ; Bruzzone, Lorenzo/A-2076-2012; Bovolo, Francesca/R-7491-2017
OI Solano-Correa, Yady Tatiana/0000-0002-4867-1837; Bruzzone,
   Lorenzo/0000-0002-6036-459X; Bovolo, Francesca/0000-0003-3104-7656;
   Saha, Sudipan/0000-0002-9440-0720
CR Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Ley A., 2018, P EUSAR 2018 12 EUR, P1
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Odena A, 2017, PR MACH LEARN RES, V70
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Tang X, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11172055
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
NR 12
TC 6
Z9 6
U1 15
U2 18
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAY
PY 2021
VL 18
IS 5
BP 856
EP 860
DI 10.1109/LGRS.2020.2990284
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA RQ9YJ
UT WOS:000642766600021
DA 2022-01-04
ER

PT J
AU Zheng, Z
   Wan, Y
   Zhang, YJ
   Xiang, SZ
   Peng, DF
   Zhang, B
AF Zheng, Zhi
   Wan, Yi
   Zhang, Yongjun
   Xiang, Sizhe
   Peng, Daifeng
   Zhang, Bin
TI CLNet: Cross-layer convolutional neural network for change detection in
   optical remote sensing imagery
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Optical remote sensing image; Deep convolutional
   neural networks; Cross-Layer Block (CLB); Cross-Layer Network (CLNet);
   UNet
ID UNSUPERVISED CHANGE DETECTION
AB Change detection plays a crucial role in observing earth surface transition and has been widely investigated using deep learning methods. However, the current deep learning methods for pixel-wise change detection still suffer from limited accuracy, mainly due to their insufficient feature extraction and context aggregation. To address this limitation, we propose a novel Cross Layer convolutional neural Network (CLNet) in this paper, where the UNet structure is used as the backbone and newly designed Cross Layer Blocks (CLBs) are embedded to incorporate the multi-scale features and multi-level context information. The designed CLB starts with one input and then split into two parallel but asymmetric branches, which are leveraged to extract the multi-scale features by using different strides; and the feature maps, which come from the opposite branches but have the same size, are concatenated to incorporate multi-level context information. The designed CLBs aggregate the multi-scale features and multi-level context information so that the proposed CLNet can reuse extracted feature information and capture accurate pixel-wise change in complex scenes. Quantitative and qualitative experiments were conducted on a public very-high-resolution satellite image dataset (VHR-Dataset), a newly released building change detection dataset (LEVIR-CD Dataset) and an aerial building change detection dataset (WHU Building Dataset). The CLNet reached an F1-score of 0.921 and an overall accuracy of 98.1% with the VHR-Dataset, an F1-score of 0.900 and an overall accuracy of 98.9% with the LEVIR-CD Dataset, and an F1-score of 0.963 and an overall accuracy of 99.7% with the WHU Building Dataset. The experimental results with all the selected datasets showed that the proposed CLNet outperformed several state-of-the-art (SOTA) methods and achieved competitive accuracy and efficiency trade-offs. The code of CLNet will be released soon at: https://skyearth.org/publication/project/CLNet.
C1 [Zheng, Zhi; Wan, Yi; Zhang, Yongjun; Xiang, Sizhe; Zhang, Bin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Peng, Daifeng] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Peoples R China.
   [Peng, Daifeng] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
RP Wan, Y; Zhang, YJ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zhengzhi@whu.edu.cn; yi.wan@whu.edu.cn; zhangyj@whu.edu.cn;
   xiangsizhe@whu.edu.cn; daifeng@nuist.edu.cn; bin.zhang@whu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42030102, 42001406, 41801386]; Fund for
   Innovative Research Groups of the Hubei Natural Science Foundation
   [2020CFA003]; China Postdoctoral Science FoundationChina Postdoctoral
   Science Foundation [2020M672416]
FX The authors are graceful to the authors of the three change detection
   datasets for providing the public remote sensing change detection data.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant No. 42030102, 42001406, and 41801386,
   the Fund for Innovative Research Groups of the Hubei Natural Science
   Foundation under Grant No. 2020CFA003, and China Postdoctoral Science
   Foundation under Grant No. 2020M672416. The numerical calculations in
   this paper have been done on the supercomputing system in the
   Supercomputing Center of Wuhan University.
CR Akcay HG, 2010, INT GEOSCI REMOTE SE, P1932, DOI 10.1109/IGARSS.2010.5652842
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen H, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519864971
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Chen L.-C., 2017, ARXIV170605587
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Daudt Caye, 2018, ARXIV181008462V1
   Daudt R.C., 2018, CORR
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Gevaert CM, 2020, INT J APPL EARTH OBS, V90, DOI 10.1016/j.jag.2020.102117
   Ghosh S, 2009, INT J APPROX REASON, V50, P37, DOI 10.1016/j.ijar.2008.01.008
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow I., 2016, ARXIV170100160
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Huo YF, 2017, IEEE INT SYMP ELEC
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji S., 2019, IEEE T GEOSCI REMOTE
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Koltun, 2015, 1511 ARXIV, DOI DOI 10.16373/J.CNKI.AHR.150049.ISSN
   Lebedev M., 2018, INT ARCH PHOTOGRAM R, V42
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Liang B., 2010, IEEE J SEL TOP QUANT, V4, P43
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu RY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232844
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Pelillo, 2020, ARXIV201005687
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Peng DF, 2017, INT J REMOTE SENS, V38, P3886, DOI 10.1080/01431161.2017.1308033
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Szegedy C, 2015, IEEE C COMP VIS PATT, P1
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Yu WJ, 2016, REMOTE SENS ENVIRON, V177, P37, DOI 10.1016/j.rse.2016.02.030
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 55
TC 2
Z9 2
U1 31
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAY
PY 2021
VL 175
BP 247
EP 267
DI 10.1016/j.isprsjprs.2021.03.005
PG 21
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA RT8HA
UT WOS:000644695700018
DA 2022-01-04
ER

PT J
AU Shi, J
   Zhang, X
   Liu, XD
   Lei, Y
AF Shi, Jiao
   Zhang, Xi
   Liu, Xiaodong
   Lei, Yu
TI Deep change feature analysis network for observing changes of land use
   or natural environment
SO SUSTAINABLE CITIES AND SOCIETY
LA English
DT Article
DE Change detection; Covariance features; Superpixel; Deep neural network
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION; IMAGES; RADAR; ALGORITHM;
   FUSION
AB Change detection on surface of earth plays an important role in global-scale pattern of climate and biogeochemistry of the world, which helps to comprehend the connections and associations between human and nature. Remote Sensing and Geographic Information Systems can possibly provide accurate data in regards to land use and land cover changes. However, pixel-based change detection methods are limited in suppressing outliers and noise; they often fail to process remote sensing images with high spatial-/spectral-resolution. To conquer these drawbacks, a superpixel-level change detection and analysis method is proposed in this paper. Superpixels are the atomic regions gathering pixels with similar property, which will be more efficient and robust than pixels. Deep neural network is a powerful feature learning and classification tool, it can represent superpixel abstractly and classify them robustly. The learning progress of deep architectures includes unsupervised sample selection and supervised feature learning, unsupervised progress aims at selecting training samples for deep neural network, supervised progress aims at learning the representation of superpixels and fine-tuning the whole network to finish classification. Experimental results on multi-temporal images have demonstrated that the proposed approach can handle the task of change detection and analysis effectively and accurately.
C1 [Shi, Jiao; Zhang, Xi; Liu, Xiaodong; Lei, Yu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Shi, Jiao; Lei, Yu] Northwestern Polytech Univ Shenzhen, Inst Res & Dev, Shenzhen 518057, Peoples R China.
RP Lei, Y (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
EM leiy@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62076204]; National Natural Science
   Foundation of Shaanxi Province [2018JQ6003, 2018JQ6030]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2017M613204, 2017M623246]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities;
   seed Foundation of Innovation and Creation for Graduate Students in
   Northwestern Polytechnical University
FX This work was supported in part by National Natural Science Foundation
   of China (Grant No. 62076204), the National Natural Science Foundation
   of Shaanxi Province under Grantnos. 2018JQ6003 and 2018JQ6030, the China
   Postdoctoral Science Foundation (Grantnos. 2017M613204 and 2017M623246),
   the Fundamental Research Funds for the Central Universities, and the
   seed Foundation of Innovation and Creation for Graduate Students in
   Northwestern Polytechnical University.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   Anusudha, 2017, 2017 4 INT C SIGN PR, P1
   Bengio Y., 2011, JMLR, V7
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu YY, 2018, IEEE GEOSCI REMOTE S, V15, P1050, DOI 10.1109/LGRS.2018.2829182
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jampani M, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102305
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu D, 2020, IEEE T CONTR SYST T, V28, P1132, DOI 10.1109/TCST.2019.2898975
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Mao W., 2020, SUSTAIN CITIES SOC
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Moore AP, 2008, PROC CVPR IEEE, P998
   Mori G, 2005, IEEE I CONF COMP VIS, P1417
   Mori G, 2004, PROC CVPR IEEE, P326
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rahnama MR, 2021, SUSTAIN CITIES SOC, V64, DOI 10.1016/j.scs.2020.102548
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Roy S, 2020, IEEE T MED IMAGING, V39, P2676, DOI 10.1109/TMI.2020.2994459
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi L, 2013, ISPRS J PHOTOGRAMM, V86, P124, DOI 10.1016/j.isprsjprs.2013.09.013
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Su LZ, 2016, IEEE IJCNN, P1269, DOI 10.1109/IJCNN.2016.7727343
   Vedaldi A, 2008, EUR C COMP VIS, P705
   Venugopalan S., 2014, COMPUTER SCI, P1494
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wang R., 2020, GEO SIMULATION LAND
   Wu Z., 2012, ISPRS ANN PHOTOGRAMM, V7, P257, DOI [10.5194/isprsannals-I-7-257-2012, DOI 10.5194/ISPRSANNALS-I-7-257-2012]
   Xia G. S, 2015, P 8 INT WORKSH AN MU, P1, DOI DOI 10.1109/MULTI-TEMP.2015.7245781
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhou H, 2019, SUSTAIN CITIES SOC, V50, DOI 10.1016/j.scs.2019.101605
NR 56
TC 0
Z9 0
U1 8
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 2210-6707
EI 2210-6715
J9 SUSTAIN CITIES SOC
JI Sust. Cities Soc.
PD MAY
PY 2021
VL 68
AR 102760
DI 10.1016/j.scs.2021.102760
PG 17
WC Construction & Building Technology; Green & Sustainable Science &
   Technology; Energy & Fuels
SC Construction & Building Technology; Science & Technology - Other Topics;
   Energy & Fuels
GA RI3HZ
UT WOS:000636799900001
DA 2022-01-04
ER

PT J
AU Qu, XF
   Gao, F
   Dong, JY
   Du, Q
   Li, HC
AF Qu, Xiaofan
   Gao, Feng
   Dong, Junyu
   Du, Qian
   Li, Heng-Chao
TI Change Detection in Synthetic Aperture Radar Images Using a Dual-Domain
   Network
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Frequency-domain analysis; Synthetic aperture radar;
   Discrete cosine transforms; Radar polarimetry; Speckle; Convolution;
   Change detection; deep learning; frequency domain; neural network;
   synthetic aperture radar (SAR)
ID ENERGY
AB Change detection from synthetic aperture radar (SAR) imagery is a critical yet challenging task. Existing methods mainly focus on feature extraction in the spatial domain, and little attention has been paid to the frequency domain. Furthermore, in patch-wise feature analysis, some noisy features in the marginal region may be introduced. To tackle the above two challenges, we propose a dual-domain network (DDNet). Specifically, we take features from the discrete cosine transform (DCT) domain into consideration and the reshaped DCT coefficients are integrated into the proposed model as the frequency domain branch. Feature representations from both frequency and spatial domain are exploited to alleviate the speckle noise. In addition, we further propose a multi-region convolution (MRC) module, which emphasizes the central region of each patch. The contextual information and central region features are modeled adaptively. The experimental results on three SAR data sets demonstrate the effectiveness of the proposed model. Our codes are available at https://github.com/summitgao/SAR_CD_DDNet.
C1 [Qu, Xiaofan; Gao, Feng; Dong, Junyu] Ocean Univ China, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Li, Heng-Chao] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM gaofeng@ouc.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Key Research and Development Program of China [2018AAA0100602];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1706218, 61871335]; Key Research and
   Development Program of Shandong Province [2019GHY112048]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100602, in part by the
   National Natural Science Foundation of China under Grant U1706218 and
   Grant 61871335, and in part by the Key Research and Development Program
   of Shandong Province under Grant 2019GHY112048.
CR Akbarizadeh G, 2012, IEEE T GEOSCI REMOTE, V50, P4358, DOI 10.1109/TGRS.2012.2194787
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Davari N, 2021, IEEE T POWER DELIVER, V36, P3640, DOI 10.1109/TPWRD.2020.3046161
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Tirandaz Z, 2016, IEEE J-STARS, V9, P1244, DOI 10.1109/JSTARS.2015.2492552
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang RF, 2020, IGARSS 2020 - 2020 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, P312, DOI 10.1109/IGARSS39084.2020.9324109
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Xu K, 2020, PROC CVPR IEEE, P1737, DOI 10.1109/CVPR42600.2020.00181
NR 18
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3073900
EA APR 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS5DR
UT WOS:000732930000001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Liu, J
   Zhang, WH
   Liu, F
   Xiao, L
AF Liu, Jia
   Zhang, Wenhua
   Liu, Fang
   Xiao, Liang
TI A Probabilistic Model Based on Bipartite Convolutional Neural Network
   for Unsupervised Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article; Early Access
DE Probabilistic logic; Feature extraction; Neural networks; Sensors; Image
   sensors; Remote sensing; Adaptation models; Change detection;
   contrastive divergence algorithm; neural network; probabilistic model;
   unsupervised learning
ID CHANGE DETECTION ALGORITHMS; CHANGE VECTOR ANALYSIS; IMAGES;
   CLASSIFICATION; REPRESENTATION; SAR; FRAMEWORK
AB This article presents a probabilistic model based on a bipartite convolutional architecture for unsupervised change detection. We aim to develop a robust change detection method that can adapt to different types of data and scenarios for multitemporal coregistered remote sensing images of the same spatial resolution. On the premise of coregistration, unsupervised change detection usually suffers from the distinct appearances (different intensities or data structures) of the same object in multitemporal images, such as images obtained in different climatic conditions (season, illumination, and so on), and by different and even heterogeneous sensors. Since change detection in heterogeneous images can also adapt to other scenarios, many methods have been proposed recently focusing on such data, but most of them are limited by the need for labeled data or by specific assumptions. With the excellent and flexible feature learning capability of neural networks, we model the change detection into a Gibbs probabilistic model based on a bipartite neural network. The model is driven by an energy function defined as the squared feature distance, which is the core of change detection. Via optimizing the model, the difference degree of each pixel is automatically obtained for further identification. The probabilistic model learns to capture the distribution in an unsupervised way. Therefore, the proposed method can adapt to various scenarios without being trained by labeled data. Experiments on different types of data and scenarios demonstrate the superiority of the proposed method.
C1 [Liu, Jia; Zhang, Wenhua; Xiao, Liang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Liu, Fang] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
RP Xiao, L (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM xiaoliang@njust.edu.cn
OI Liu, Jia/0000-0002-5999-2361
FU National Nature Science Foundations of ChinaNational Natural Science
   Foundation of China (NSFC) [61906093, 61802190, 61871226]; Nature
   Science Foundations of Jiangsu Province, China [BK20190451]; Jiangsu
   Provincial Social Developing Project [BE2018727]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [30919011279, 30919011281]
FX This work was supported in part by the National Nature Science
   Foundations of China under Grant 61906093, Grant 61802190, and Grant
   61871226; in part by the Nature Science Foundations of Jiangsu Province,
   China, under Grant BK20190451; in part by the Jiangsu Provincial Social
   Developing Project under Grant BE2018727; and in part by the Fundamental
   Research Funds for the Central Universities under Grant 30919011279 and
   Grant 30919011281.
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Christophe E, 2011, IEEE J-STARS, V4, P643, DOI 10.1109/JSTARS.2010.2102340
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferraris V, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102817
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hedhli I, 2016, IEEE T GEOSCI REMOTE, V54, P6333, DOI 10.1109/TGRS.2016.2580321
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   KANO A, 1994, MED PHYS, V21, P453, DOI 10.1118/1.597308
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Liu J, 2019, NEURAL NETWORKS, V113, P41, DOI 10.1016/j.neunet.2019.01.004
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Marinelli D, 2019, IEEE T GEOSCI REMOTE, V57, P4913, DOI 10.1109/TGRS.2019.2894339
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Mertes CM, 2015, REMOTE SENS ENVIRON, V158, P331, DOI 10.1016/j.rse.2014.09.023
   Pham MT, 2016, IEEE T GEOSCI REMOTE, V54, P2020, DOI 10.1109/TGRS.2015.2493730
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sidiropoulos P, 2018, IEEE T GEOSCI REMOTE, V56, P78, DOI 10.1109/TGRS.2017.2734693
   Solano-Correa YT, 2019, IEEE T GEOSCI REMOTE, V57, P7579, DOI 10.1109/TGRS.2019.2914397
   Solano-Correa YT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040533
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Wang KF, 2016, IEEE T VEH TECHNOL, V65, P4144, DOI 10.1109/TVT.2015.2509465
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Yin H, 2018, REMOTE SENS ENVIRON, V204, P918, DOI 10.1016/j.rse.2017.08.030
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P4141, DOI 10.1109/TGRS.2017.2689018
NR 50
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PY 2021
DI 10.1109/TGRS.2021.3071347
EA APR 2021
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XS2RD
UT WOS:000732761500001
DA 2022-01-04
ER

PT J
AU Zhan, T
   Gong, MG
   Jiang, XM
   Zhao, W
AF Zhan, Tao
   Gong, Maoguo
   Jiang, Xiangming
   Zhao, Wei
TI Transfer Learning-Based Bilinear Convolutional Networks for Unsupervised
   Change Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Remote sensing; Image segmentation; Data models;
   Training; Reliability; Deep learning; Bilinear convolutional neural
   networks (BCNNs); change detection (CD); remote sensing images;
   superpixel segmentation; transfer learning (TL)
ID IMAGES
AB With the increasing popularity of deep learning, most recent developments of change detection (CD) approaches have taken advantage of deep learning techniques to improve the detection performance. However, it is usually necessary to elaborately design the network architecture and train the model with a large amount of labeled data, which are difficult to obtain in practice. To overcome these limitations, this letter proposed an unsupervised CD framework for high-resolution remote sensing images integrating transfer learning-based bilinear convolutional neural networks (BCNNs) and object-based change analysis. A difference image is first generated, which is used for the subsequent preclassification and superpixel segmentation. Then, two sets of superpixel samples with reliable labels derived from the bitemporal remote sensing images are input into two pretrained CNNs to extract representative features, respectively. On this basis, the matrix outer product is utilized to generate the combined bilinear features, which are input into the softmax classifier to discriminate the change and no-change information and thus obtaining the final change map by feeding all sample data into the well-trained model. The experimental results on three real data sets demonstrate the effectiveness and superiority of the proposed method over several existing CD approaches.
C1 [Zhan, Tao] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Gong, Maoguo; Jiang, Xiangming] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Zhao, Wei] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
RP Zhan, T (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
EM omegazhant@gmail.com; gong@ieee.org; omegajiangxm@gmail.com;
   ywzhao@mail.xidian.edu.cn
OI Jiang, Xiangming/0000-0002-4650-1308; Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61876145]; Innovation Capability Support
   Program of Shaanxi Province [2021TD-05]; Natural Science Basic Research
   Program of Shaanxi Province [2021JQ-195]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876145, in part by the Innovation
   Capability Support Program of Shaanxi Province under Grant 2021TD-05,
   and in part by the Natural Science Basic Research Program of Shaanxi
   Province under Grant 2021JQ-195.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Csillik O, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030243
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang QQ, 2020, IEEE GEOSCI REMOTE S, V17, P312, DOI 10.1109/LGRS.2019.2918254
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Lin Y, 2020, IEEE GEOSCI REMOTE S, V17, P1757, DOI 10.1109/LGRS.2019.2953754
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Saxena R, 2018, ISPRS J PHOTOGRAMM, V144, P217, DOI 10.1016/j.isprsjprs.2018.07.002
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wu C., 2019, ARXIV191208628
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
NR 21
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3070145
EA APR 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR6YW
UT WOS:000732372900001
DA 2022-01-04
ER

PT J
AU Yu, X
   Fan, JF
   Chen, JH
   Zhang, P
   Zhou, YK
   Han, LS
AF Yu, Xiao
   Fan, Junfu
   Chen, Jiahao
   Zhang, Peng
   Zhou, Yuke
   Han, Liusheng
TI NestNet: a multiscale convolutional neural network for remote sensing
   image change detection
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
AB With the rapid development of remote sensing technologies, the frequency of observations of the same location is increasing, and many satellites and sensors produced a large amount of time series images. These images make long-term change detection and dynamic characteristic estimation of ground features possible. However, conventional remote sensing image change detection methods mostly rely on manual visual interpretation and supervised or unsupervised computer-aided classification. Traditional methods always face many bottlenecks when processing big and fast-growing datasets, such as low computational efficiency, low level of automation, and different identification standards and accuracies caused by different operators. With the rapid accumulation of remote sensing data, it has become an important but more challenging task to conduct change detection in a more precise, automated and standardized way. The development of geointelligent computing technologies provides a means of solving these problems and improve the accuracy and efficiency of remote sensing image change detection. In this paper, we presented a novel deep learning model called nest network(NestNet) based on a convolutional neural network to improve the accuracy of the automatic change detection task by using remotely sensed time series images. NestNet extracts the respective features of bi-temporal images using an encoding parallel module and subsequently employs absolute different operations to process the features of two images. Compared with change detection method based on U-Shaped network plus plus (UNet++), the parallel module improves the efficiency of NestNet. Finally, a decoding module is used to generate a predicted change image. This paper compares NestNet to traditional methods and state-of-the-art deep learning models on two datasets. The experimental results demonstrate that the accuracy of NestNet is better than that of state-of-the-art methods. It can be concluded that the NestNet model is a potential approach for change detection using high resolution remote sensing images.
C1 [Yu, Xiao; Fan, Junfu; Chen, Jiahao; Zhang, Peng; Han, Liusheng] Shandong Univ Technol, Sch Civil & Architectural Engn, Zibo 255000, Peoples R China.
   [Zhou, Yuke] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Ecol Observing Network & Modeling Lab, Beijing, Peoples R China.
RP Fan, JF (corresponding author), Shandong Univ Technol, Sch Civil & Architectural Engn, Zibo 255000, Peoples R China.; Zhou, YK (corresponding author), Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Ecol Observing Network & Modeling Lab, Beijing, Peoples R China.
EM fanjf@sdut.edu.cn; zhouyk@igsnrr.ac.cn
FU National Key Research and Development Program of China [2017YFB0503500,
   2018YFB0505301]; Shandong Provincial Natural Science FoundationNatural
   Science Foundation of Shandong Province [ZR2020MD015, ZR2020MD018];
   Major Science and Technology Innovation Project of Shandong Province
   [2019JZZY020103]; Young Teacher Development Support Program of Shandong
   University of Technology [4072-115016]
FX This research was supported by the National Key Research and Development
   Program of China (Grant Nos. 2017YFB0503500 and 2018YFB0505301), the
   Shandong Provincial Natural Science Foundation (Grant No. ZR2020MD015
   and ZR2020MD018), the Major Science and Technology Innovation Project of
   Shandong Province (Grant No. 2019JZZY020103), and the Young Teacher
   Development Support Program of Shandong University of Technology (Grant
   No. 4072-115016).
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brown ME, 2015, PROCEDIA ENVIRON SCI, V29, P307, DOI 10.1016/j.proenv.2015.07.278
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Daniel K., 2011, 2011 IEEE INT C TECH, P1
   Daudt R.C., 2018, arXiv, DOI 10.21227/azv7-ta17
   Daudt R.C., 2018, 2018 IEEE INT GEOSC, DOI [10.1080/01431160801950162, DOI 10.1080/01431160801950162]
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Falco N, 2016, INT J REMOTE SENS, V37, P1505, DOI 10.1080/01431161.2016.1154226
   Fan JF, 2018, IEEE ACCESS, V6, P21427, DOI 10.1109/ACCESS.2018.2825452
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Hastie T., 2009, ELEMENTS STAT LEARNI, V27, P83, DOI [10.1007/b94608, DOI 10.1007/978-0-387-84858-7, 10.1007/978-0-387-84858-7]
   He K, 2016, CVPR, P770, DOI DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang R, 2020, NEUROCOMPUTING, V418, P102, DOI 10.1016/j.neucom.2020.08.027
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050711
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liu YX, 2018, REMOTE SENS ENVIRON, V204, P347, DOI 10.1016/j.rse.2017.10.019
   Lyu HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030471
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma Y, 2015, FUTURE GENER COMP SY, V51, P47, DOI 10.1016/j.future.2014.10.029
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qi ZX, 2015, ISPRS J PHOTOGRAMM, V107, P3, DOI 10.1016/j.isprsjprs.2015.02.004
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Xiaoxia Yan, 2015, 2015 23rd International Conference on Geoinformatics. Proceedings, P1, DOI 10.1109/GEOINFORMATICS.2015.7378603
   Yu WJ, 2016, REMOTE SENS ENVIRON, V177, P37, DOI 10.1016/j.rse.2016.02.030
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhang LF, 2011, IEEE GEOSCI REMOTE S, V8, P374, DOI 10.1109/LGRS.2010.2077272
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   [赵敏 Zhao Min], 2018, [遥感学报, Journal of Remote Sensing], V22, P119
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zisserman, 2015, ICLR, P1
NR 51
TC 2
Z9 2
U1 14
U2 55
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD APR 6
PY 2021
VL 42
IS 13
BP 4902
EP 4925
DI 10.1080/01431161.2021.1906982
PG 24
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA RI8ZR
UT WOS:000637195700001
DA 2022-01-04
ER

PT J
AU Zhou, H
   Zhang, M
   Hu, XY
   Li, K
   Sun, J
AF Zhou, Hao
   Zhang, Mi
   Hu, Xiangyun
   Li, Kun
   Sun, Jing
TI A Siamese convolutional neural network with high-low level feature
   fusion for change detection in remotely sensed images
SO REMOTE SENSING LETTERS
LA English
DT Article
AB Automatic change detection is an important and difficult task in the field of remote sensing. In this study, a deep Siamese convolutional network based on the fusion of high- and low-level features is proposed for change detection in remote sensing images. Given that low-level features correspond to low-order ones (e.g., texture) that are sensitive to change and that high-level features can accurately reflect image category information (e.g., semantic information), we fuse these features to enhance the abstractness and robustness of the extracted features in the change detection framework. The whole system is end-to-end and does not require any pre- or post-processing. Experimental results on three datasets show that our method is superior to other advanced methods by adding a high- and low-level fusion framework.
C1 [Zhou, Hao; Zhang, Mi; Hu, Xiangyun; Li, Kun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
   [Hu, Xiangyun] Wuhan Univ, Inst Artificial Intelligence Geomat, Wuhan, Peoples R China.
   [Sun, Jing] Wuhan Univ, Sch Resource & Environm Sci, Wuhan, Peoples R China.
RP Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Inst Artificial Intelligence Geomat, Wuhan, Peoples R China.
EM huxy@whu.edu.cn
OI Zhou, Loke/0000-0002-1692-4334; Li, Kun/0000-0001-8501-3916
FU Open Research Fund of State Key Laboratory of Information Engineering in
   Surveying, Mapping and Remote Sensing, Wuhan University [18R01];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41901265, 92038301]; State Key Laboratory of
   Information Engineering in Surveying, Mapping and Remote Sensing [18R01]
FX This work was partly supported in part by the Open Research Fund of
   State Key Laboratory of Information Engineering in Surveying, Mapping
   and Remote Sensing, Wuhan University, under Project 18R01, and in part
   by the National Natural Science Foundation of China under Project No.
   41901265; National Natural Science Foundation of China [92038301]; State
   Key Laboratory of Information Engineering in Surveying, Mapping and
   Remote Sensing [18R01].
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Chen Q, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070549
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding L., COMPUTER VISION PATT
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Han PC, 2019, NEUROCOMPUTING, V349, P190, DOI 10.1016/j.neucom.2019.04.029
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Luppino LT, 2017, LECT NOTES COMPUT SC, V10270, P181, DOI 10.1007/978-3-319-59129-2_16
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
NR 18
TC 1
Z9 1
U1 10
U2 24
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PD APR 3
PY 2021
VL 12
IS 4
BP 387
EP 396
DI 10.1080/2150704X.2021.1892851
PG 10
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA QU2UY
UT WOS:000627140100001
DA 2022-01-04
ER

PT J
AU Jian, P
   Chen, KM
   Cheng, W
AF Jian, Ping
   Chen, Keming
   Cheng, Wei
TI GAN-Based One-Class Classification for Remote-Sensing Image Change
   Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Remote sensing; Training data; Time series analysis;
   Training; Gallium nitride; Generators; Change detection; generative
   adversarial networks (GANs); one-class classification (OCC); time series
AB Currently, most of the supervised change detection approaches require a training data set that contains samples from both the changed and the unchanged data. However, under certain condition, such as natural disaster and military attack, the changed data samples are very few or even not available but the unchanged data are abundant. In this letter, we develop a generative adversarial networks (GANs)-based one-class classification (OCC) technique for time series remote-sensing image change detection. The proposed method is only trained with the unchanged data instead of both the changed and unchanged data. To achieve this purpose, first, spatial-spectral features are extracted from the time series remote-sensing images. Second, a GAN model is trained to detect the changes only with the extracted features of unchanged data. Remarkably, to offset the outlier errors caused by the incomplete supervision information provided by unchanged data alone, changed data, instead of unchanged data, are generated to improve power of discriminator. Finally, testing data are classified by the trained discriminator of GAN to produce a binary change map. Experimental results obtained on two optical time series remote-sensing data sets confirmed the effectiveness of our proposed method.
C1 [Jian, Ping; Cheng, Wei] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Jian, Ping; Cheng, Wei] Beijing Engn Applicat Res Ctr High Volume Languag, Beijing 100081, Peoples R China.
   [Chen, Keming] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100190, Peoples R China.
RP Jian, P (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM pingjian0121@gmail.com
FU National Key Research and Development Program of China [2017YFB1002103];
   Open Project Program of the National Defense Key Laboratory of
   Electronic Information Equipment System Research [DXZT-JCZZ-2017-009]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1002103 and in part by
   the Open Project Program of the National Defense Key Laboratory of
   Electronic Information Equipment System Research under Grant
   DXZT-JCZZ-2017-009.
CR Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jian P, 2016, INT J REMOTE SENS, V37, P1814, DOI 10.1080/2150704X.2016.1163744
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Kemmler M, 2013, PATTERN RECOGN, V46, P3507, DOI 10.1016/j.patcog.2013.06.005
   Li PJ, 2010, PHOTOGRAMM ENG REM S, V76, P255, DOI 10.14358/PERS.76.3.255
   Moya MM, 1996, NEURAL NETWORKS, V9, P463, DOI 10.1016/0893-6080(95)00120-4
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Ran Q, 2018, REMOTE SENS LETT, V9, P597, DOI [10.1080/2150704X.2018.1452063, 10.1080/2150704x.2018.1452063]
   Ren CJ, 2021, IEEE T GEOSCI REMOTE, V59, P10047, DOI 10.1109/TGRS.2020.3043766
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Song BQ, 2016, IEEE J-STARS, V9, P1613, DOI 10.1109/JSTARS.2015.2508285
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zheng PP, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P1286
NR 20
TC 0
Z9 0
U1 1
U2 1
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3066435
EA APR 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR7EZ
UT WOS:000732388900001
DA 2022-01-04
ER

PT J
AU Zhang, Y
   Fu, L
   Li, Y
   Zhang, YN
AF Zhang, Yi
   Fu, Lei
   Li, Ying
   Zhang, Yanning
TI HDFNet: Hierarchical Dynamic Fusion Network for Change Detection in
   Optical Aerial Images
SO REMOTE SENSING
LA English
DT Article
DE change detection; hierarchical; dynamic convolution; multilevel
   supervision
ID UNSUPERVISED CHANGE DETECTION; SATELLITE IMAGES
AB Accurate change detection in optical aerial images by using deep learning techniques has been attracting lots of research efforts in recent years. Correct change-detection results usually involve both global and local deep learning features. Existing deep learning approaches have achieved good performance on this task. However, under the scenarios of containing multiscale change areas within a bi-temporal image pair, existing methods still have shortcomings in adapting these change areas, such as false detection and limited completeness in detected areas. To deal with these problems, we design a hierarchical dynamic fusion network (HDFNet) to implement the optical aerial image-change detection task. Specifically, we propose a change-detection framework with hierarchical fusion strategy to provide sufficient information encouraging for change detection and introduce dynamic convolution modules to self-adaptively learn from this information. Also, we use a multilevel supervision strategy with multiscale loss functions to supervise the training process. Comprehensive experiments are conducted on two benchmark datasets, LEBEDEV and LEVIR-CD, to verify the effectiveness of the proposed method and the experimental results show that our model achieves state-of-the-art performance.
C1 [Zhang, Yi; Fu, Lei; Li, Ying; Zhang, Yanning] Northwestern Polytech Univ, Shaanxi Prov Key Lab Speech & Image Informat Proc, Natl Engn Lab Integrated Aerospace Ground Ocean B, Sch Comp Sci, Xian 710129, Peoples R China.
   [Fu, Lei] Shaanxi Satellite Applicat Ctr Nat Resources, Xian 710065, Peoples R China.
   [Li, Ying] Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Peoples R China.
RP Zhang, Y (corresponding author), Northwestern Polytech Univ, Shaanxi Prov Key Lab Speech & Image Informat Proc, Natl Engn Lab Integrated Aerospace Ground Ocean B, Sch Comp Sci, Xian 710129, Peoples R China.
EM yizhang1@mail.nwpu.edu.cn; bobbyfly@mail.nwpu.edu.cn; lybyp@nwpu.edu.cn;
   ynzhang@nwpu.edu.cn
OI , Yi/0000-0002-1751-3836
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U19B2037]
FX This work is supported by the National Natural Science Foundation of
   China under Grants U19B2037.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Guo E., 2018, ARXIV181009111
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jian P, 2016, INT J REMOTE SENS, V37, P1814, DOI 10.1080/2150704X.2016.1163744
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng X, 2020, IEEE T NEUR NET LEAR, V31, P4857, DOI 10.1109/TNNLS.2019.2958324
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K., 2015, P BRIT MACH VIS C, V61, P1, DOI DOI 10.5244/C.29.61
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang L., 2019, P 10 INT WORKSH AN M, P1
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236735
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 41
TC 0
Z9 0
U1 10
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR
PY 2021
VL 13
IS 8
AR 1440
DI 10.3390/rs13081440
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA RT7YZ
UT WOS:000644674700001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, HB
   Qi, JC
   Lei, YF
   Wu, J
   Li, B
   Jia, YL
AF Wang, Haibo
   Qi, Jianchao
   Lei, Yufei
   Wu, Jun
   Li, Bo
   Jia, Yilin
TI A Refined Method of High-Resolution Remote Sensing Change Detection
   Based on Machine Learning for Newly Constructed Building Areas
SO REMOTE SENSING
LA English
DT Article
DE high-resolution remote sensing; change detection; deep learning; areas
   registration; SVM; newly constructed building areas
ID LAND-COVER CHANGE; IMAGE-ANALYSIS; TIME-SERIES; OBJECT; CLASSIFICATION;
   MISREGISTRATION; FEATURES; ERROR
AB Automatic detection of newly constructed building areas (NCBAs) plays an important role in addressing issues of ecological environment monitoring, urban management, and urban planning. Compared with low-and-middle resolution remote sensing images, high-resolution remote sensing images are superior in spatial resolution and display of refined spatial details. Yet its problems of spectral heterogeneity and complexity have impeded research of change detection for high-resolution remote sensing images. As generalized machine learning (including deep learning) technologies proceed, the efficiency and accuracy of recognition for ground-object in remote sensing have been substantially improved, providing a new solution for change detection of high-resolution remote sensing images. To this end, this study proposes a refined NCBAs detection method consisting of four parts based on generalized machine learning: (1) pre-processing; (2) candidate NCBAs are obtained by means of bi-temporal building masks acquired by deep learning semantic segmentation, and then registered one by one; (3) rules and support vector machine (SVM) are jointly adopted for classification of NCBAs with high, medium and low confidence; and (4) the final vectors of NCBAs are obtained by post-processing. In addition, area-based and pixel-based methods are adopted for accuracy assessment. Firstly, the proposed method is applied to three groups of GF1 images covering the urban fringe areas of Jinan, whose experimental results are divided into three categories: high, high-medium, and high-medium-low confidence. The results show that NCBAs of high confidence share the highest F1 score and the best overall effect. Therefore, only NCBAs of high confidence are considered to be the final detection result by this method. Specifically, in NCBAs detection for three groups GF1 images in Jinan, the mean Recall of area-based and pixel-based assessment methods reach around 77% and 91%, respectively, the mean Pixel Accuracy (PA) 88% and 92%, and the mean F1 82% and 91%, confirming the effectiveness of this method on GF1. Similarly, the proposed method is applied to two groups of ZY302 images in Xi'an and Kunming. The scores of F1 for two groups of ZY302 images are also above 90% respectively, confirming the effectiveness of this method on ZY302. It can be concluded that adoption of area registration improves registration efficiency, and the joint use of prior rules and SVM classifier with probability features could avoid over and missing detection for NCBAs. In practical applications, this method is contributive to automatic NCBAs detection from high-resolution remote sensing images.
C1 [Wang, Haibo; Li, Bo] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Wang, Haibo; Qi, Jianchao; Lei, Yufei; Wu, Jun; Jia, Yilin] China Ctr Resources Satellite Data & Applicat, Beijing 100094, Peoples R China.
RP Jia, YL (corresponding author), China Ctr Resources Satellite Data & Applicat, Beijing 100094, Peoples R China.
EM wanghaibo_1989@buaa.edu.cn; qijianchao@chinasiwei.com;
   leiyufei@chinasiwei.com; wujun@chinasiwei.com; boli@buaa.edu.cn;
   jiayilin@chinasiwei.com
CR [Anonymous], CHINADAILY
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI 10.1109/ICIP.2019.8803050
   Bontemps S, 2008, REMOTE SENS ENVIRON, V112, P3181, DOI 10.1016/j.rse.2008.03.013
   Brown KM, 2007, INT J REMOTE SENS, V28, P2857, DOI 10.1080/01431160600981533
   Bruzzone L, 2003, IEEE T GEOSCI REMOTE, V41, P2455, DOI 10.1109/TGRS.2003.817268
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen L.-C., 2017, ARXIV170605587
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Erener A, 2009, RIV ITAL TELERILEVAM, V41, P47
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gamanya R, 2009, EXPERT SYST APPL, V36, P571, DOI 10.1016/j.eswa.2007.09.067
   Gonzales R. C., 2002, DIGITAL IMAGE PROCES
   He K, 2016, CVPR, P770, DOI DOI 10.1109/CVPR.2016.90
   He L.L., 2009, P 2009 JOINT URB REM, P1
   Howarth P, 1981, INT J REMOTE SENS, V2, P277, DOI DOI 10.1080/01431168108948362
   Huang X, 2020, REMOTE SENS ENVIRON, V244, DOI 10.1016/j.rse.2020.111802
   Huang X, 2014, REMOTE SENS LETT, V5, P713, DOI 10.1080/2150704X.2014.963732
   Huang ZM, 2016, INT GEOSCI REMOTE SE, P1835, DOI 10.1109/IGARSS.2016.7729471
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Janalipour M, 2016, IEEE J-STARS, V9, P1937, DOI 10.1109/JSTARS.2015.2458582
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Johansen K, 2010, PHOTOGRAMM ENG REM S, V76, P123, DOI 10.14358/PERS.76.2.123
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu YS, 2018, LAND USE POLICY, V74, P261, DOI 10.1016/j.landusepol.2017.03.030
   Lizarazo I, 2012, INT J APPL EARTH OBS, V15, P16, DOI 10.1016/j.jag.2011.05.012
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUDEKE AK, 1990, J ENVIRON MANAGE, V31, P247, DOI 10.1016/S0301-4797(05)80038-6
   Son NT, 2015, IEEE J-STARS, V8, P503, DOI 10.1109/JSTARS.2014.2360691
   QUARMBY NA, 1989, INT J REMOTE SENS, V10, P953, DOI 10.1080/01431168908903937
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sefrin O, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010078
   Shi WZ, 2013, INT J REMOTE SENS, V34, P6883, DOI 10.1080/01431161.2013.810353
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152345
   Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3
   Sun Yue, 2018, Geomatics and Information Science of Wuhan University, V43, P53, DOI 10.13203/j.whugis20150510
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Versluis A, 2010, GEOCARTO INT, V25, P85, DOI 10.1080/10106040902977584
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu GM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030407
   Wu Z., 2012, ISPRS ANN PHOTOGRAMM, V7, P257, DOI [10.5194/isprsannals-I-7-257-2012, DOI 10.5194/ISPRSANNALS-I-7-257-2012]
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xin QC, 2013, REMOTE SENS ENVIRON, V135, P234, DOI 10.1016/j.rse.2013.04.002
   Xu YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010144
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhang ZX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060696
   [张志强 Zhang Zhiqiang], 2018, [测绘学报, Acta Geodetica et Cartographica Sinica], V47, P102
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
NR 62
TC 1
Z9 1
U1 17
U2 22
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR
PY 2021
VL 13
IS 8
AR 1507
DI 10.3390/rs13081507
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA RT8CC
UT WOS:000644682800001
OA gold
DA 2022-01-04
ER

PT J
AU Shu, YJ
   Li, W
   Yang, ML
   Cheng, P
   Han, SC
AF Shu, Yuanjun
   Li, Wei
   Yang, Menglong
   Cheng, Peng
   Han, Songchen
TI Patch-Based Change Detection Method for SAR Images with Label Updating
   Strategy
SO REMOTE SENSING
LA English
DT Article
DE change detection; multilayer fusion convolutional neural network;
   end-to-end learning; updating strategy; synthetic aperture radar (SAR)
AB Convolutional neural networks (CNNs) have been widely used in change detection of synthetic aperture radar (SAR) images and have been proven to have better precision than traditional methods. A two-stage patch-based deep learning method with a label updating strategy is proposed in this paper. The initial label and mask are generated at the pre-classification stage. Then a two-stage updating strategy is applied to gradually recover changed areas. At the first stage, diversity of training data is gradually restored. The output of the designed CNN network is further processed to generate a new label and a new mask for the following learning iteration. As the diversity of data is ensured after the first stage, pixels within uncertain areas can be easily classified at the second stage. Experiment results on several representative datasets show the effectiveness of our proposed method compared with several existing competitive methods.
C1 [Shu, Yuanjun; Li, Wei; Yang, Menglong; Cheng, Peng; Han, Songchen] Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610000, Peoples R China.
   [Li, Wei; Yang, Menglong; Cheng, Peng; Han, Songchen] Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610000, Peoples R China.
RP Li, W (corresponding author), Sichuan Univ, Sch Aeronaut & Astronaut, Chengdu 610000, Peoples R China.; Li, W (corresponding author), Sichuan Univ, Natl Key Lab Fundamental Sci Synthet Vis, Chengdu 610000, Peoples R China.
EM 2018226215022@stu.scu.edu.cn; li.wei@scu.edu.cn; mlyang@scu.edu.cn;
   cheng.peng@scu.edu.cn; hansongchen@scu.edu.cn
FU Sichuan Science and Technology Program [2020YFG0134, 2018JY0602,
   2018GZDX0024]; Sichuan UniversitySichuan University [2020SCUNG205]
FX This work was supported in part by the Sichuan Science and Technology
   Program under Grants 2020YFG0134, 2018JY0602, and 2018GZDX0024, in part
   by the funding from Sichuan University under Grant 2020SCUNG205
   (corresponding author: W.L.).
CR Azzouzi SA, 2017, IEEE ACCESS, V5, P9065, DOI 10.1109/ACCESS.2017.2700405
   Barreto TLM, 2016, IEEE J-STARS, V9, P5436, DOI 10.1109/JSTARS.2016.2621818
   Barreto TLM, 2016, INT GEOSCI REMOTE SE, P5201, DOI 10.1109/IGARSS.2016.7730355
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Brisco B, 2013, INT J DIGIT EARTH, V6, P103, DOI 10.1080/17538947.2011.608813
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Chen J., 2020, DASNET DUAL ATTENTIV, DOI DOI 10.1109/JSTARS.2020.3037893
   Chen J, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7060213
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Guo E., 2018, ARXIV181009111
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hur J, 2019, PROC CVPR IEEE, P5747, DOI 10.1109/CVPR.2019.00590
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Ji W, 2006, COMPUT ENVIRON URBAN, V30, P861, DOI 10.1016/j.compenvurbsys.2005.09.002
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lefebvre A., 2008, P IGARSS 2008 2008 I, V4
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu B, 2013, IEEE T GEOSCI REMOTE, V51, P907, DOI 10.1109/TGRS.2012.2203358
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Nackaerts K, 2005, INT J REMOTE SENS, V26, P839, DOI 10.1080/0143116032000160462
   Pelillo, 2020, ARXIV201005687
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Qiu YJ, 2019, IEEE I CONF COMP VIS, P4179, DOI 10.1109/ICCV.2019.00428
   Quan SN, 2018, IEEE J-STARS, V11, P458, DOI 10.1109/JSTARS.2017.2787591
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Song DM, 2020, INT J REMOTE SENS, V41, P1040, DOI 10.1080/01431161.2019.1655175
   Wang F, 2013, IEEE GEOSCI REMOTE S, V10, P697, DOI 10.1109/LGRS.2012.2219494
   Wu Z., 2012, ISPRS ANN PHOTOGRAMM, V7, P257, DOI [10.5194/isprsannals-I-7-257-2012, DOI 10.5194/ISPRSANNALS-I-7-257-2012]
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030548
NR 63
TC 2
Z9 2
U1 10
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR
PY 2021
VL 13
IS 7
AR 1236
DI 10.3390/rs13071236
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA RL2FW
UT WOS:000638796500001
OA gold
DA 2022-01-04
ER

PT J
AU Liu, Y
   Sun, YJ
   Tao, SK
   Wang, M
   Shen, Q
   Huang, JR
AF Liu, Yang
   Sun, Yujie
   Tao, Shikang
   Wang, Min
   Shen, Qian
   Huang, Jiru
TI Discovering Potential Illegal Construction Within Building Roofs from
   UAV Images Using Semantic Segmentation and Object-Based Change Detection
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
ID MAD
AB A novel potential illegal construction (PIC) detection method by bitemporal unmanned aerial vehicle (UAV) image comparison (change detection) within building roof areas is proposed. In this method, roofs are first extracted from UAV images using a depth-channel improved UNet model. A two-step change detection scheme is then implemented for PIC detection. In the change detection stage, roofs with appearance, disappearance, and shape changes are first extracted by morphological analysis. Subroof primitives are then obtained by roof-constrained image segmentation within the remaining roof areas, and object-based iteratively reweighted multivariate alteration detection (IR-MAD) is implemented to extract the small PICs from the subroof primitives. The proposed method organically combines deep learning and object-based image analysis, which can identify entire roof changes and locate small object changes within the roofs. Experiments show that the proposed method has better accuracy compared with the other counterparts, including the original IR-MAD, change vector analysis, and principal components analysis-K-means.
C1 [Liu, Yang; Wang, Min] Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.
   [Liu, Yang; Sun, Yujie; Tao, Shikang; Wang, Min; Shen, Qian; Huang, Jiru] Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, Nanjing 210023, Peoples R China.
   [Liu, Yang; Sun, Yujie; Tao, Shikang; Wang, Min; Shen, Qian; Huang, Jiru] Nanjing Normal Univ, Sch Geog, Nanjing 210023, Peoples R China.
   [Liu, Yang; Sun, Yujie; Tao, Shikang; Wang, Min; Shen, Qian; Huang, Jiru] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China.
   [Liu, Yang; Sun, Yujie; Tao, Shikang; Wang, Min; Shen, Qian; Huang, Jiru] State Key Lab Cultivat Base Geog Environm Evolut, Nanjing 210023, Peoples R China.
RP Wang, M (corresponding author), Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518034, Peoples R China.; Wang, M (corresponding author), Nanjing Normal Univ, Minist Educ, Key Lab Virtual Geog Environm, Nanjing 210023, Peoples R China.; Wang, M (corresponding author), Nanjing Normal Univ, Sch Geog, Nanjing 210023, Peoples R China.; Wang, M (corresponding author), Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China.; Wang, M (corresponding author), State Key Lab Cultivat Base Geog Environm Evolut, Nanjing 210023, Peoples R China.
EM sysj0918@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42071301, 41671341]; National Key Research
   and Development Program of China [2017YFB0503902]; Major Science and
   Technology Program for Water Pollution Control and Treatment
   [2017ZX07302003]; Open Fund of Key Laboratory of Urban Land Resources
   Monitoring and Simulation, Ministry of Natural Resources
   [KF-2019-04-008]
FX This work is jointly supported by the National Natural Science
   Foundation of China [42071301, 41671341], the National Key Research and
   Development Program of China [2017YFB0503902], the Major Science and
   Technology Program for Water Pollution Control and Treatment
   [2017ZX07302003], and the Project Supported by the Open Fund of Key
   Laboratory of Urban Land Resources Monitoring and Simulation, Ministry
   of Natural Resources [KF-2019-04-008].
CR Ahmed N., 2020, INT J REMOTE SENS, P1
   [Anonymous], 2013, PREPRINT ARXIV 1308, DOI DOI 10.1145/2661829.2661935.ISSN
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chaabane F, 2019, INT GEOSCI REMOTE SE, P9398, DOI 10.1109/IGARSS.2019.8898732
   Chen L.-C., 2017, RETHINKING ATROUS CO
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XF, 2018, INT CONF SOFTW ENG, P545, DOI 10.1109/ICSESS.2018.8663938
   Denton E., 2014, EXPLOITING LINEAR ST
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Doxani G, 2015, PHOTOGRAMM ENG REM S, V81, P481, DOI 10.14358/PERS.81.6.481
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   He NJ, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2791-7
   Hu HT, 2019, LECT NOTES COMPUT SC, V11903, P292, DOI 10.1007/978-3-030-34113-8_25
   Jaderberg M., 2014, COMPUTER SCI, V4, pXIII
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Khalilimoghadam N., 2017, INT ARCH PHOTOGRAMME, P505
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Moghadam NK, 2015, INT ARCH PHOTOGRAMM, V41, P387, DOI 10.5194/isprsarchives-XL-1-W5-387-2015
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ostankovich V, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P616, DOI 10.1109/IS.2018.8710565
   Pajares G, 2015, PHOTOGRAMM ENG REM S, V81, P281, DOI 10.14358/PERS.81.4.281
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao ZF, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12061050
   Shao ZF, 2019, IEEE T GEOSCI REMOTE, V57, P4062, DOI 10.1109/TGRS.2018.2889677
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Varol B, 2019, EUR J REMOTE SENS, V52, P335, DOI 10.1080/22797254.2019.1604082
   Wang LP, 2020, CHIN CONT DECIS CONF, P539, DOI 10.1109/CCDC49329.2020.9164476
   Wang M, 2018, ISPRS J PHOTOGRAMM, V141, P100, DOI 10.1016/j.isprsjprs.2018.04.010
   Wang M, 2017, ISPRS J PHOTOGRAMM, V130, P202, DOI 10.1016/j.isprsjprs.2017.06.002
   Wang M, 2017, IEEE J-STARS, V10, P628, DOI 10.1109/JSTARS.2016.2539239
   Wang M, 2016, PHOTOGRAMM ENG REM S, V82, P149, DOI 10.14358/PERS.82.2.149
   Wang M, 2014, IEEE T GEOSCI REMOTE, V52, P5712, DOI 10.1109/TGRS.2013.2292053
   Wang SS, 2020, IEEE ACCESS, V8, P7313, DOI 10.1109/ACCESS.2020.2964043
   Ye S, 2015, PHOTOGRAMM ENG REM S, V81, P637, DOI 10.14358/PERS.81.8.637
   Yu F., 2016, IEEE T COMPUTER VISI
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang RQ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193140
   Zhang Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071195
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 46
TC 0
Z9 0
U1 21
U2 29
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
EI 2374-8079
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD APR
PY 2021
VL 87
IS 4
BP 263
EP 271
DI 10.14358/PERS.87.4.263
PG 9
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA QY7VX
UT WOS:000630246500005
DA 2022-01-04
ER

PT J
AU Saha, S
   Mou, LC
   Zhu, XX
   Bovolo, F
   Bruzzone, L
AF Saha, Sudipan
   Mou, Lichao
   Zhu, Xiao Xiang
   Bovolo, Francesca
   Bruzzone, Lorenzo
TI Semisupervised Change Detection Using Graph Convolutional Network
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Image segmentation; Training; Spatial resolution; Convolution; Feature
   extraction; Training data; Data models; Change detection (CD); deep
   learning; graph convolutional network (GCN); high resolution;
   semisupervised
AB Most change detection (CD) methods are unsupervised as collecting substantial multitemporal training data is challenging. Unsupervised CD methods are driven by heuristics and lack the capability to learn from data. However, in many real-world applications, it is possible to collect a small amount of labeled data scattered across the analyzed scene. Such a few scattered labeled samples in the pool of unlabeled samples can be effectively handled by graph convolutional network (GCN) that has recently shown good performance in semisupervised single-date analysis, to improve change detection performance. Based on this, we propose a semisupervised CD method that encodes multitemporal images as a graph via multiscale parcel segmentation that effectively captures the spatial and spectral aspects of the multitemporal images. The graph is further processed through GCN to learn a multitemporal model. Information from the labeled parcels is propagated to the unlabeled ones over training iterations. By exploiting the homogeneity of the parcels, the model is used to infer the label at a pixel level. To show the effectiveness of the proposed method, we tested it on a multitemporal Very High spatial Resolution (VHR) data set acquired by Pleiades sensor over Trento, Italy.
C1 [Saha, Sudipan; Bovolo, Francesca] Fdn Bruno Kessler, I-38123 Trento, Italy.
   [Saha, Sudipan; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
   [Mou, Lichao; Zhu, Xiao Xiang] German Aerosp Ctr, Remote Sensing Technol Inst IMF, D-82234 Wessling, Germany.
   [Mou, Lichao; Zhu, Xiao Xiang] Tech Univ Munich, Signal Proc Earth Observat, D-80333 Munich, Germany.
RP Bovolo, F (corresponding author), Fdn Bruno Kessler, I-38123 Trento, Italy.
EM saha@fbk.eu; bovolo@fbk.eu
RI Zhu, Xiao Xiang/ABE-7138-2020; Bovolo, Francesca/R-7491-2017; Bruzzone,
   Lorenzo/A-2076-2012
OI Zhu, Xiao Xiang/0000-0001-5530-3613; Bovolo,
   Francesca/0000-0003-3104-7656; Bruzzone, Lorenzo/0000-0002-6036-459X;
   Saha, Sudipan/0000-0002-9440-0720
CR Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Ienco D., 2018, P INT JOINT C NEUR N, P1
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Ngo, 2015, IEEE INT C FUZZ SYST, P1, DOI DOI 10.1109/FUZZ-IEEE.2015.7337978
   Patra S, 2007, LECT NOTES COMPUT SC, V4815, P161
   Roy M., 2013, INT J KNOWL ENG SOFT, V4, P118
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Welling M., 2016, ARXIV160902907
NR 13
TC 13
Z9 13
U1 23
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD APR
PY 2021
VL 18
IS 4
BP 607
EP 611
DI 10.1109/LGRS.2020.2985340
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA RD3PM
UT WOS:000633394400009
DA 2022-01-04
ER

PT J
AU Liu, T
   Yang, LX
   Lunga, D
AF Liu, Tao
   Yang, Lexie
   Lunga, Dalton
TI Change detection using deep learning approach with object-based image
   analysis
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Change detection; OBIA; Deep learning; Pixel-based; Feature fusion
ID NEURAL-NETWORKS; CONVOLUTIONAL NETWORKS; RANDOM FOREST; CLASSIFICATION;
   MISREGISTRATION; SEGMENTATION; MACHINE
AB In their applications, both deep learning techniques and object-based image analysis (OBIA) have shown better performance separately than conventional methods on change detection tasks. However, efforts to investigate the effect of combining these two techniques for advancing change detection techniques are unexplored in current literature. This study proposes a novel change detection method implementing change feature extraction using convolutional neural networks under an OBIA framework. To demonstrate the effectiveness of our proposed method, we compare the proposed method against benchmark pixel-based counterparts on aerial images for the task of multi-class change detection. To thoroughly assess the performance of our proposed method, this study also for the first time compared three common feature fusion schemes for change detection architecture: concatenation, differencing, and Long Short-Term Memory (LSTM). The proposed method was also tested on simulated misregistered images to evaluate its robustness, a factor that plays an important role in compromising change detection accuracy but has not been investigated for supervised change detection methods in the literature. Finally, the proposed change detection method was also tested using very high resolution (VHR) satellite images for binary class change detection to map an impacted area caused by natural disaster and the result was evaluated using reference data from the Federal Emergency Management Agency (FEMA). With the experimental results from these two sets of experiments, we showed that (1) our proposed method achieved substantially higher accuracy and computational efficiency when compared to pixel-based methods, (2) three feature fusion schemes did not show a significant difference for overall accuracy, (3) our proposed method was robust in image misregistration in both testing and training data, (4) we demonstrate the potential impact of automation to decision making by deploying our method to map a large geographic area affected by a recent natural disaster.
C1 [Liu, Tao; Yang, Lexie; Lunga, Dalton] Oak Ridge Natl Lab, Geospatial Sci & Human Dynam Div, GeoAI, Oak Ridge, TN USA.
   [Liu, Tao] Michigan Technol Univ, Coll Forest Resources & Environm Sci, Houghton, MI 49931 USA.
RP Liu, T (corresponding author), Michigan Technol Univ, Coll Forest Resources & Environm Sci, Houghton, MI 49931 USA.
EM taoliu@mtu.edu
FU US Department of Energy (DOE)United States Department of Energy (DOE)
   [DE-AC05-00OR22725]
FX This manuscript has been authored by UT-Battelle, LLC, under contract
   DE-AC05-00OR22725 with the US Department of Energy (DOE). The US
   government retains and the publisher, by accepting the article for
   publication, acknowledges that the US government retains a nonexclusive,
   paid-up, irrevocable, worldwide license to publish or reproduce the
   published form of this manuscript, or allow others to do so, for US
   government purposes. DOE will provide public access to these results of
   federally sponsored research in accordance with the DOE Public Access
   Plan (http://energy.gov/downloads/doe-public-acce ss-plan). Finally, we
   thank the editors and five anonymous reviewers for their valuable
   comments, which helped improve the quality of this manuscript
   substantially.
CR Abd El-Kawy OR, 2011, APPL GEOGR, V31, P483, DOI 10.1016/j.apgeog.2010.10.012
   Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Boardman J. W., 1992, P SUMM 3 ANN JPL AIR, V1, P147
   Boldt M, 2012, PROC SPIE, V8538, DOI 10.1117/12.973687
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2014, ISPRS J PHOTOGRAMM, V87, P19, DOI 10.1016/j.isprsjprs.2013.10.007
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Cleve C, 2008, COMPUT ENVIRON URBAN, V32, P317, DOI 10.1016/j.compenvurbsys.2007.10.001
   Comber A, 2004, PHOTOGRAMM ENG REM S, V70, P931, DOI 10.14358/PERS.70.8.931
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Duro DC, 2013, PHOTOGRAMM ENG REM S, V79, P259, DOI 10.14358/PERS.79.3.259
   Ehlers M., 2014, GLOBAL URBAN MONITOR, P346
   FEMA, 2016, DAMAGE ASSESSMENT OP
   FEMA, 2019, HIST DAMAGE ASSESSME
   Fu BL, 2017, ECOL INDIC, V73, P105, DOI 10.1016/j.ecolind.2016.09.029
   Gao P., 2012, GEOINF GEOINFORMATIC, P1, DOI DOI 10.1109/GEOINFORMATICS.2012.6270319
   Gong JH, 2012, INT J REMOTE SENS, V33, P3907, DOI 10.1080/01431161.2011.636767
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Healey SP, 2018, REMOTE SENS ENVIRON, V204, P717, DOI 10.1016/j.rse.2017.09.029
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu T, 2020, IGARSS 2020 - 2020 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM, P6906, DOI 10.1109/IGARSS39084.2020.9323634
   Liu T, 2018, ISPRS J PHOTOGRAMM, V139, P154, DOI 10.1016/j.isprsjprs.2018.03.006
   Liu T, 2018, GISCI REMOTE SENS, V55, P243, DOI 10.1080/15481603.2018.1426091
   Liu X, 2002, INT J REMOTE SENS, V23, P2513, DOI 10.1080/01431160110097240
   Lunga D, 2018, IEEE J-STARS, V11, P962, DOI 10.1109/JSTARS.2018.2795753
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Microsoft, 2020, COMPUTER GENERATED B
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   NOAA, 2020, US CLIMATE EXTREMES
   Pande-Chhetri R, 2017, EUR J REMOTE SENS, V50, P564, DOI 10.1080/22797254.2017.1373602
   Raj A, 2016, INT CONF IND INF SYS, P54, DOI 10.1109/ICIINFS.2016.8262907
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Szegedy, 2015, ARXIV 1502 03167
   TOWNSHEND JRG, 1992, IEEE T GEOSCI REMOTE, V30, P1054, DOI 10.1109/36.175340
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Vu TT, 2004, INT GEOSCI REMOTE SE, P3413
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Wang SM, 2018, RESOUR CONSERV RECY, V128, P526, DOI 10.1016/j.resconrec.2016.05.011
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang HL, 2018, IEEE J-STARS, V11, P2600, DOI [10.1109/JSTARS.2018.2835377, 10.1080/09585192.2018.1443956]
   Yang LM, 2003, PHOTOGRAMM ENG REM S, V69, P1003, DOI 10.14358/PERS.69.9.1003
   Yuan JY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P2703, DOI 10.1109/BigData.2016.7840915
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhu Z, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2019.03.009
NR 62
TC 8
Z9 8
U1 42
U2 60
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD APR
PY 2021
VL 256
AR 112308
DI 10.1016/j.rse.2021.112308
PG 16
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA QT5NB
UT WOS:000626633100001
DA 2022-01-04
ER

PT J
AU Zhang, TG
   Gao, F
   Dong, JY
   Du, Q
AF Zhang, Tiange
   Gao, Feng
   Dong, Junyu
   Du, Qian
TI Remote Sensing Image Translation via Style-Based Recalibration Module
   and Improved Style Discriminator
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Gallium nitride; Generators; Remote sensing; Generative adversarial
   networks; Feature extraction; Correlation; Vegetation mapping; Change
   detection; GAN; image-to-image translation; remote sensing
AB Existing remote sensing change detection methods are heavily affected by seasonal variation. Since vegetation colors are different between winter and summer, such variations are inclined to be falsely detected as changes. In this letter, we proposed an image translation method to solve the problem. A style-based recalibration module is introduced to capture seasonal features effectively. Then, a new style discriminator is designed to improve the translation performance. The discriminator can not only produce a decision for the fake or real sample but also return a style vector according to the channel-wise correlations. Extensive experiments are conducted on the season-varying data set. The experimental results show that the proposed method can effectively perform image translation, thereby consistently improving the season-varying image change detection performance. Our codes and data are available at https://github.com/summitgao/RSIT_SRM_ISD.
C1 [Zhang, Tiange; Gao, Feng; Dong, Junyu] Ocean Univ China, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
RP Dong, JY (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM zhangtiange@stu.ouc.edu.cn; gaofeng@ouc.edu.cn; dongjunyu@ouc.edu.cn;
   du@ece.msstate.edu
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Key Research and Development Program of China [2018AAA0100602];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1706218]; Key Research and Development
   Program of Shandong Province [2019GHY112048]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018AAA0100602, in part by the
   National Natural Science Foundation of China under Grant U1706218, and
   in part by the Key Research and Development Program of Shandong Province
   under Grant 2019GHY112048.
CR Bi <prime>nkowski M., 2018, INT C LEARN REPR
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Enomoto K, 2018, INT GEOSCI REMOTE SE, P1752, DOI 10.1109/IGARSS.2018.8518719
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2018, IEEE IND APPLIC SOC, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kahraman F, 2016, IEEE GEOSCI REMOTE S, V13, P1188, DOI 10.1109/LGRS.2016.2574960
   Lee H, 2019, IEEE I CONF COMP VIS, P1854, DOI 10.1109/ICCV.2019.00194
   Lee K. H., 2020, ARXIV190710830
   Niu X, 2018, LECT NOTES COMPUT SC, V11166, P245, DOI 10.1007/978-3-030-00764-5_23
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Salimans T., 2016, ADV NEURAL INF PROCE, V29
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI [10.1109/TNNLS.2020.3039675, 10.1007/s11263-020-01365-4]
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 17
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3068558
EA MAR 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR7HA
UT WOS:000732394200001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Wang, CC
   Su, WM
   Gu, H
AF Wang, Chenchen
   Su, Weimin
   Gu, Hong
TI A joint change detection method on complex-valued polarimetric synthetic
   aperture radar images based on feature fusion and similarity learning
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
AB Existing deep learning-based change detection methods in the field of polarimetric synthetic aperture radar (POLSAR) usually directly deal with intensity images. Methods can be easily transferred from optical image processing to synthetic aperture radar (SAR) image processing. However, the polarization information, which is critical in POLSAR data, has been discarded under normal situations. This paper introduces a novel joint change detection network based on similarity learning for coregistered complex-valued SAR data. A pseudo-siamese network takes both amplitude information and polarization information of POLSAR data as the input. The fusion of low-level, middle-level and high-level features enables the network to keep high-resolution and have strong representation ability during training procedures. Our novel sub-networks, which we term C2-Net and Intensity-Net, deal with the covariance matrix of complex SAR data and amplitude SAR data, respectively. The Intensity-Net works as a typical classification network and detects targets directly. The C2-Net attempts to find the relationship between two SAR data patches. An improved cosine similarity function is used to measure the similarity between two generated feature vectors in C2-Net. Output probability vectors of the two sub-networks are combined for final change detection. The two sub-networks are trained jointly and simultaneously. Control experiments show that proposed improvements are working. Experimental results on dual-polarization complex-valued SAR data from Sentinel-1 demonstrate the effectiveness of the proposed method.
C1 [Wang, Chenchen; Su, Weimin; Gu, Hong] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing, Peoples R China.
RP Su, WM (corresponding author), Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing, Peoples R China.
EM suweimin_rceet@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61671246, 61801221, 62001229]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61671246, Grant 61801221, and Grant 62001229.
CR Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Ke S., 2019, CVPR, P5693
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Torres R, 2012, REMOTE SENS ENVIRON, V120, P9, DOI 10.1016/j.rse.2011.05.028
   Wang JL, 2020, ACTA MECH SINICA-PRC, V36, P592, DOI 10.1007/s10409-020-00928-5
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 16
TC 1
Z9 1
U1 12
U2 52
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD MAR 25
PY 2021
VL 42
IS 13
BP 4868
EP 4885
DI 10.1080/01431161.2021.1899332
PG 18
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA RC2WF
UT WOS:000632664700001
DA 2022-01-04
ER

PT J
AU Fang, B
   Chen, G
   Pan, L
   Kou, R
   Wang, LZ
AF Fang, Bo
   Chen, Gang
   Pan, Li
   Kou, Rong
   Wang, Lizhe
TI GAN-Based Siamese Framework for Landslide Inventory Mapping Using
   Bi-Temporal Optical Remote Sensing Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Terrain factors; Gallium nitride; Feature extraction; Remote sensing;
   Optical imaging; Optical sensors; Generative adversarial networks;
   Change detection; domain adaptation; generative adversarial network
   (GAN); landslide inventory mapping (LIM); Siamese network
AB Regarding landslide inventory mapping (LIM) as a task similar to change detection, current methods for LIM using bi-temporal optical remote sensing images are generally derived from change detection methods. In practice, not all changed regions belong to landslides, e.g., new roads, canals, and vegetation. Therefore, an ideal strategy is supposed to present two steps: discriminating changed and unchanged regions, and detecting landslides apart from other changed regions. Owing to the complexity and uncertainty of landslides, it is difficult to simultaneously separate landslides with unchanged and other changed regions by a single model. Addressing this problem, in this letter, we apply a generative adversarial network (GAN) in a Siamese neural network, and then propose a GAN-based Siamese framework (GSF) for LIM. The GSF comprises two cascaded modules, namely, domain adaptation and landslide detection. The former module aims to make a cross-domain mapping between prelandslide and postlandslide images with adversarial learning, then translate paired images into the same domain to suppress the domain discrepancies of bi-temporal remote sensing images. Meanwhile, the latter module aims to perform pixel-level landslide detection with a Siamese model. By training this cascaded framework, our method learns to produce landslide inventory maps without any preprocessing or postprocessing. Extensive experiments and comparison with other state-of-the-art methods verify the efficiency and superiority of our method.
C1 [Fang, Bo; Chen, Gang] China Univ Geosci, Coll Marine Sci & Technol, Wuhan 430074, Peoples R China.
   [Pan, Li; Kou, Rong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
RP Chen, G (corresponding author), China Univ Geosci, Coll Marine Sci & Technol, Wuhan 430074, Peoples R China.
EM fangbo@cug.edu.cn; ddwhcg@cug.edu.cn; panli@whu.edu.cn;
   kourong@whu.edu.cn; lizhe.wang@gmail.com
RI Wang, Lizhe/L-7453-2014
OI Wang, Lizhe/0000-0003-2766-0845; Fang, Bo/0000-0001-7694-5527
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41674015, U1711266, 41925007]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 41674015, Grant U1711266, and Grant 41925007.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Guzzetti F, 2012, EARTH-SCI REV, V112, P42, DOI 10.1016/j.earscirev.2012.02.001
   Isola P., 2017, P IEEE C COMP VIS PA, P632
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei T, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091381
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 13
TC 3
Z9 3
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAR
PY 2021
VL 18
IS 3
BP 391
EP 395
DI 10.1109/LGRS.2020.2979693
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA QM9MX
UT WOS:000622098500004
DA 2022-01-04
ER

PT J
AU Zhang, XZ
   Su, H
   Zhang, C
   Gu, XW
   Tan, XH
   Atkinson, PM
AF Zhang, Xinzheng
   Su, Hang
   Zhang, Ce
   Gu, Xiaowei
   Tan, Xiaoheng
   Atkinson, Peter M.
TI Robust unsupervised small area change detection from SAR imagery using
   deep learning
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Synthetic aperture radar; Difference image; Fuzzy
   c-means algorithm; Deep learning
ID RATIO APPROACH; NETWORK
AB Small area change detection using synthetic aperture radar (SAR) imagery is a highly challenging task, due to speckle noise and imbalance between classes (changed and unchanged). In this paper, a robust unsupervised approach is proposed for small area change detection using deep learning techniques. First, a multi-scale superpixel reconstruction method is developed to generate a difference image (DI), which can suppress the speckle noise effectively and enhance edges by exploiting local, spatially homogeneous information. Second, a two-stage centre-constrained fuzzy c-means clustering algorithm is proposed to divide the pixels of the DI into changed, unchanged and intermediate classes with a parallel clustering strategy. Image patches belonging to the first two classes are then constructed as pseudo-label training samples, and image patches of the intermediate class are treated as testing samples. Finally, a convolutional wavelet neural network (CWNN) is designed and trained to classify testing samples into changed or unchanged classes, coupled with a deep convolutional generative adversarial network (DCGAN) to increase the number of changed class within the pseudo-label training samples. Numerical experiments on four real SAR datasets demonstrate the validity and robustness of the proposed approach, achieving up to 99.61% accuracy for small area change detection.
C1 [Zhang, Xinzheng; Su, Hang; Tan, Xiaoheng] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
   [Zhang, Xinzheng; Tan, Xiaoheng] Chongqing Key Lab Space Informat Network & Intell, Chongqing 400044, Peoples R China.
   [Zhang, Ce; Atkinson, Peter M.] Univ Lancaster, Lancaster Environm Ctr, Lancaster LA1 4YQ, England.
   [Zhang, Ce] UK Ctr Ecol & Hydrol, Lib Ave, Lancaster LA1 4AP, England.
   [Gu, Xiaowei] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
   [Atkinson, Peter M.] Univ Southampton, Geog & Environm Sci, Southampton SO17 1BJ, Hants, England.
   [Atkinson, Peter M.] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, 11A Datun Rd, Beijing 100101, Peoples R China.
RP Zhang, XZ (corresponding author), Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.; Zhang, XZ (corresponding author), Chongqing Key Lab Space Informat Network & Intell, Chongqing 400044, Peoples R China.; Zhang, C (corresponding author), Univ Lancaster, Lancaster Environm Ctr, Lancaster LA1 4YQ, England.; Zhang, C (corresponding author), UK Ctr Ecol & Hydrol, Lib Ave, Lancaster LA1 4AP, England.
EM zhangxinzheng03@126.com; c.zhang9@lancaster.ac.uk
OI Gu, Xiaowei/0000-0001-9116-4761; Atkinson, Peter/0000-0002-5489-6880;
   Zhang, Ce/0000-0001-5100-3584
FU National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61301224]; Chongqing Basic and Frontier Research
   Project [cstc2017jcyjA1378]
FX This work was supported by the National Science Foundation of China
   (61301224) and the Chongqing Basic and Frontier Research Project
   (cstc2017jcyjA1378). The authors are grateful to the anonymous reviewers
   for their constructive comments which increased greatly the quality of
   this manuscript.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Cao SS, 2020, ISPRS J PHOTOGRAMM, V167, P54, DOI 10.1016/j.isprsjprs.2020.06.020
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chintala S., 2016, ARXIV151106434
   Cozzolino D., 2020, REMOTE SENS-BASEL, V17, P1097
   Deledalle CA, 2015, IEEE T GEOSCI REMOTE, V53, P2021, DOI 10.1109/TGRS.2014.2352555
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Huang SQ, 2011, INT J APPL EARTH OBS, V13, P863, DOI 10.1016/j.jag.2011.05.018
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Kalaiselvi S, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106510
   Kim Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12121978
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li H, 2018, APPL SOFT COMPUT, V71, P698, DOI 10.1016/j.asoc.2018.07.021
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091091
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Pantze A, 2014, REMOTE SENS ENVIRON, V155, P120, DOI 10.1016/j.rse.2013.08.050
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sun ZG, 2020, IEEE GEOSCI REMOTE S, V17, P1097, DOI 10.1109/LGRS.2019.2939208
   Tian DY, 2018, INFORM SCIENCES, V467, P415, DOI 10.1016/j.ins.2018.08.015
   Wang J, 2020, ISPRS J PHOTOGRAMM, V164, P61, DOI 10.1016/j.isprsjprs.2020.04.007
   Wang SN, 2016, IEEE J-STARS, V9, P3452, DOI 10.1109/JSTARS.2016.2547638
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
   Zhuang HF, 2020, IEEE GEOSCI REMOTE S, V17, P416, DOI 10.1109/LGRS.2019.2922198
   Zhuang HF, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081295
NR 43
TC 1
Z9 1
U1 17
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD MAR
PY 2021
VL 173
BP 79
EP 94
DI 10.1016/j.isprsjprs.2021.01.004
PG 16
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA RO3ZZ
UT WOS:000640986100006
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Zhan, TM
   Song, B
   Xu, Y
   Wan, MH
   Wang, X
   Yang, GW
   Wu, ZB
AF Zhan, Tianming
   Song, Bo
   Xu, Yang
   Wan, Minghua
   Wang, Xin
   Yang, Guowei
   Wu, Zebin
TI SSCNN-S: A Spectral-Spatial Convolution Neural Network with Siamese
   Architecture for Change Detection
SO REMOTE SENSING
LA English
DT Article
DE spectral-spatial combination; hyperspectral image (HSI); change
   detection (CD); Siamese network
ID BAND SELECTION; EXTRACTION; FRAMEWORK; DISTANCE; MAD
AB In this paper, a spectral-spatial convolution neural network with Siamese architecture (SSCNN-S) for hyperspectral image (HSI) change detection (CD) is proposed. First, tensors are extracted in two HSIs recorded at different time points separately and tensor pairs are constructed. The tensor pairs are then incorporated into the spectral-spatial network to obtain two spectral-spatial vectors. Thereafter, the Euclidean distances of the two spectral-spatial vectors are calculated to represent the similarity of the tensor pairs. We use a Siamese network based on contrastive loss to train and optimize the network so that the Euclidean distance output by the network describes the similarity of tensor pairs as accurately as possible. Finally, the values obtained by inputting all tensor pairs into the trained model are used to judge whether a pixel belongs to the change area. SSCNN-S aims to transform the problem of HSI CD into a problem of similarity measurement for tensor pairs by introducing the Siamese network. The network used to extract tensor features in SSCNN-S combines spectral and spatial information to reduce the impact of noise on CD. Additionally, a useful four-test scoring method is proposed to improve the experimental efficiency instead of taking the mean value from multiple measurements. Experiments on real data sets have demonstrated the validity of the SSCNN-S method.
C1 [Zhan, Tianming; Wan, Minghua] Nanjing Audit Univ, Jiangsu Key Construct Lab Audit Informat Engn, Nanjing 211815, Peoples R China.
   [Zhan, Tianming; Song, Bo; Wan, Minghua; Wang, Xin; Yang, Guowei] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Peoples R China.
   [Xu, Yang; Wu, Zebin] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Yang, Guowei] Qingdao Univ, Sch Elect Informat, Qingdao 266071, Peoples R China.
RP Wu, ZB (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM ztm@nau.edu.cn; mg1909003@stu.nau.edu.cn; xuyangth90@njust.edu.cn;
   270223@nau.edu.cn; 209204@nau.edu.cn; 270178@nau.edu.cn;
   wuzb@njust.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61976117, 62071233, 61876213, 61772274,
   61772277]; Natural Science Foundation of Jiangsu ProvinceNatural Science
   Foundation of Jiangsu Province [BK20191409, BK20201397, BK20180018,
   BK20171494]; Key Projects of University Natural Science Fund of Jiangsu
   Province [19KJA360001, 18KJA520005]; National Key RD Program
   [2017YFC0804002]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [30917015104, 30919011103, 30919011402]; Collaborative Innovation Center
   of Audit Information Engineering and Technology [18CICA09]; Young
   Teacher Research and Cultivation Project of Nanjing Audit University
   [18QNPY015]; Postgraduate Research and Practice Innovation Program of
   Jiangsu Province [KYCX20_1680]
FX This research was funded by the National Natural Science Foundation of
   China under Grant 61976117, 62071233, 61876213, 61772274 and 61772277 in
   part by the Natural Science Foundation of Jiangsu Province under Grant
   BK20191409, BK20201397, BK20180018 and BK20171494, in part by the Key
   Projects of University Natural Science Fund of Jiangsu Province under
   Grant 19KJA360001 and 18KJA520005, in part of the National Key R&D
   Program under Grant 2017YFC0804002, in part by the Fundamental Research
   Funds for the Central Universities under Grant 30917015104, 30919011103
   and 30919011402, in part by the Collaborative Innovation Center of Audit
   Information Engineering and Technology under Grant 18CICA09, in part by
   the Young Teacher Research and Cultivation Project of Nanjing Audit
   University under Grant 18QNPY015 and in part by the Postgraduate
   Research and Practice Innovation Program of Jiangsu Province under Grant
   KYCX20_1680.
CR Ansari RA, 2020, REMOTE SENS APPL, V20, DOI 10.1016/j.rsase.2020.100418
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2016, REMOTE SENS DIGIT IM, V20, P63, DOI 10.1007/978-3-319-47037-5_4
   Chen LL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091395
   Chen Z, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101044
   Dalmiya CP, 2019, EGYPT J REMOTE SENS, V22, P183, DOI 10.1016/j.ejrs.2018.03.005
   Fu Liyong, 2020, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2020.3027588
   Guo YC, 2019, CMC-COMPUT MATER CON, V58, P829, DOI 10.32604/cmc.2019.03729
   Hadsell Raia, 2006, P IEEE COMP SOC C CO, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Heidari M., 2020, P INT C MACH VIS IM, P1
   Henrot S, 2016, IEEE T IMAGE PROCESS, V25, P3219, DOI 10.1109/TIP.2016.2562562
   Hou YN, 2019, INTELL AUTOM SOFT CO, V25, P805, DOI 10.31209/2019.100000084
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Hung CW, 2019, INTELL AUTOM SOFT CO, V25, P329
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Weichao, 2020, IEEE Trans Cybern, VPP, DOI 10.1109/TCYB.2020.2985398
   Li YQ, 2020, IEEE T MOBILE COMPUT, V19, P2833, DOI [10.1109/TMC.2019.2934103, 10.1109/LGRS.2020.3022435]
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101008
   Lu LL, 2019, SCI TOTAL ENVIRON, V684, P567, DOI 10.1016/j.scitotenv.2019.05.344
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma LY, 2019, IEEE ACCESS, V7, P27948, DOI 10.1109/ACCESS.2019.2901286
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Mohanapriya N, 2019, INTELL AUTOM SOFT CO, V25, P663, DOI 10.31209/2018.100000041
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Padron-Hidalgo JA, 2020, IEEE J-STARS, V13, P5480, DOI 10.1109/JSTARS.2020.3020913
   Plaza, P 2010 2 WORKSH HYP, P1
   Ran Q, 2018, INT WORKS EARTH OB, P458
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Sharma A, 2017, NEURAL NETWORKS, V95, P19, DOI 10.1016/j.neunet.2017.07.017
   Sun L, 2020, IEEE T CIRC SYST VID, V30, P3829, DOI 10.1109/TCSVT.2019.2946723
   Szegedy, 2015, ARXIV 1502 03167
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang W, 2019, INT J COMPUT INT SYS, V12, P1592, DOI 10.2991/ijcis.d.191209.001
   Wang WJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071068
   Wanxin Cui, 2019, 2019 International Conference on Intelligent Computing, Automation and Systems (ICICAS), P746, DOI 10.1109/ICICAS48597.2019.00161
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Wu C, 2015, NEUROCOMPUTING, V151, P175, DOI 10.1016/j.neucom.2014.09.058
   Wu H, 2019, CMC-COMPUT MATER CON, V60, P575, DOI 10.32604/cmc.2019.03595
   Xu F, 2019, CMC-COMPUT MATER CON, V58, P697, DOI 10.32604/cmc.2019.05375
   Yasir M, 2020, IEEE ACCESS, V8, P180156, DOI 10.1109/ACCESS.2020.3027881
   Ye QL, 2019, IEEE T NEUR NET LEAR, V30, P3818, DOI 10.1109/TNNLS.2019.2944869
   Ye QL, 2018, IEEE T NEUR NET LEAR, V29, P4494, DOI 10.1109/TNNLS.2017.2749428
   Ye QL, 2018, IEEE T CIRC SYST VID, V28, P114, DOI 10.1109/TCSVT.2016.2596158
   Yu WB, 2019, SIGNAL PROCESS, V164, P20, DOI 10.1016/j.sigpro.2019.05.034
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang X, 2019, CMC-COMPUT MATER CON, V61, P601, DOI 10.32604/cmc.2019.06045
   Zhao JQ, 2017, INT GEOSCI REMOTE SE, P1896, DOI 10.1109/IGARSS.2017.8127348
   Zhou SR, 2020, CMC-COMPUT MATER CON, V63, P1545, DOI 10.32604/cmc.2020.09867
   Zhou SR, 2019, J VIS COMMUN IMAGE R, V59, P393, DOI 10.1016/j.jvcir.2019.01.029
NR 56
TC 1
Z9 1
U1 8
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2021
VL 13
IS 5
AR 895
DI 10.3390/rs13050895
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA QW2SW
UT WOS:000628505900001
OA Green Published, gold
DA 2022-01-04
ER

PT J
AU Saha, S
   Bovolo, F
   Bruzzone, L
AF Saha, Sudipan
   Bovolo, Francesca
   Bruzzone, Lorenzo
TI Building Change Detection in VHR SAR Images via Unsupervised Deep
   Transcoding
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection (CD); deep change vector analysis (DCVA); generative
   adversarial network (GAN); multitemporal images; remote sensing;
   synthetic aperture radar (SAR); very high-resolution images
AB Building change detection (CD), important for its application in urban monitoring, can be performed in near real time by comparing prechange and postchange very-highspatial-resolution (VHR) synthetic-aperture-radar (SAR) images. However, multitemporal VHR SAR images are complex as they show high spatial correlation, prone to shadows, and show an inhomogeneous signature. Spatial context needs to be taken into account to effectively detect a change in such images. Recently, convolutional-neural-network (CNN)-based transfer learning techniques have shown strong performance for CD in VHR multispectral images. However, its direct use for SAR CD is impeded by the absence of labeled SAR data and, thus, pretrained networks. To overcome this, we exploit the availability of paired unlabeled SAR and optical images to train for the suboptimal task of transcoding SAR images into optical images using a cycle-consistent generative adversarial network (CycleGAN). The CycleGAN consists of two generator networks: one for transcoding SAR images into the optical image domain and the other for projecting optical images into the SAR image domain. After unsupervised training, the generator transcoding SAR images into optical ones is used as a bitemporal deep feature extractor to extract optical-like features from bitemporal SAR images. Thus, deep change vector analysis (DCVA) and fuzzy rules can be applied to identify changed buildings (new/destroyed). We validate our method on two data sets made up of pairs of bitemporal VHR SAR images on the city of L'Aquila (Italy) and Trento (Italy).
C1 [Saha, Sudipan; Bovolo, Francesca] Fdn Bruno Kessler, I-38123 Trento, Italy.
   [Saha, Sudipan; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
RP Bovolo, F (corresponding author), Fdn Bruno Kessler, I-38123 Trento, Italy.
EM saha@fbk.eu; bovolo@fbk.eu
CR Aiazzi B, 2013, IEEE T GEOSCI REMOTE, V51, P2022, DOI 10.1109/TGRS.2013.2238946
   [Anonymous], GOOGL MAPS
   Ba J., 2014, ARXIV14126980
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2012, INT GEOSCI REMOTE SE, P1992, DOI 10.1109/IGARSS.2012.6351110
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Brenner AR, 2008, IEEE T GEOSCI REMOTE, V46, P2971, DOI 10.1109/TGRS.2008.920911
   Brett PTB, 2013, IEEE T GEOSCI REMOTE, V51, P4877, DOI 10.1109/TGRS.2013.2271564
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Chen F, 2019, IEEE ACCESS, V7, P181396, DOI 10.1109/ACCESS.2019.2958983
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Chini M, 2015, INT GEOSCI REMOTE SE, P2723, DOI 10.1109/IGARSS.2015.7326376
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Darrell, 2016, ARXIV160509782
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Jiang K., 2009, P IEEE INT GEOSC REM, V5, pV
   Keshk HM, 2020, INT J AERONAUT SPACE, V21, P549, DOI 10.1007/s42405-019-00222-0
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ley A., 2018, P EUSAR 2018 12 EUR, P1
   Li L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091091
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu S., IEEE J SEL TOPICS AP, V10, P4124
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Odena A, 2017, PR MACH LEARN RES, V70
   Oliva, 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Qiu F., 2004, GISCIENCE REMOTE SEN, V41, P244, DOI DOI 10.2747/1548-1603.41.3.244
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Reyes MF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11172067
   Roy S, 2018, IEEE IMAGE PROC, P684, DOI 10.1109/ICIP.2018.8451836
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shin B.S., 2018, ADV COMPUTER SCI UBI, P8
   Soergel U, 2006, IEE P-RADAR SON NAV, V153, P294, DOI 10.1049/ip-rsn:20045088
   Uprety P., 2010, P 8 INT WORKSH REM S, V9, P1
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang YY, 2018, INT GEOSCI REMOTE SE, P6840, DOI 10.1109/IGARSS.2018.8518298
   Wang Z., 2019, ARXIV190601529
   Yousif O, 2017, INT J REMOTE SENS, V38, P1765, DOI 10.1080/01431161.2016.1217442
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhu J.-Y., 2017, IEEE ICC
NR 57
TC 22
Z9 22
U1 57
U2 75
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAR
PY 2021
VL 59
IS 3
BP 1917
EP 1929
DI 10.1109/TGRS.2020.3000296
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA QN2TP
UT WOS:000622319000009
DA 2022-01-04
ER

PT J
AU Yang, MJ
   Jiao, LC
   Hou, B
   Liu, F
   Yang, SY
AF Yang, Meijuan
   Jiao, Licheng
   Hou, Biao
   Liu, Fang
   Yang, Shuyuan
TI Selective Adversarial Adaptation-Based Cross-Scene Change Detection
   Framework in Remote Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Adaptation; adversarial learning; change detection; deep neural networks
   (DNNs); domain discriminator; remote sensing images
AB Supervised change detection methods always face a big challenge that the current scene (target domain) is fully unlabeled. In remote sensing, it is common that we have sufficient labels in another scene (source domain) with a different but related data distribution. In this article, we try to detect changes in the target domain with the help of the prior knowledge learned from multiple source domains. To achieve this goal, we propose a change detection framework based on selective adversarial adaptation. The adaptation between multisource and target domains is fulfilled by two domain discriminators. First, the first domain discriminator regards each scene as an individual domain and is designed for identifying the domain to which each input sample belongs. According to the output of the first domain discriminator, a subset of important samples is selected from multisource domains to train a deep neural network (DNN)-based change detection model. As a result, not only the positive transfer is enhanced but also the negative transfer is alleviated. Second, as for the second domain discriminator, all the selected samples are thought from one domain. Adversarial learning is introduced to align the distributions of the selected source samples and the target ones. Consequently, it further adapts the knowledge of change from the source domain to the target one. At the fine-tuning stage, target samples with reliable labels and the selected source ones are used to jointly fine-tune the change detection model. As the target domain is fully unlabeled, homogeneity- and boundary-based strategies are exploited to make the pseudolabels from a preclassification map reliable. The proposed method is evaluated on three SAR and two optical data sets, and the experimental results have demonstrated its effectiveness and superiority.
C1 [Yang, Meijuan; Jiao, Licheng; Hou, Biao; Liu, Fang; Yang, Shuyuan] Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Yang, Meijuan; Jiao, Licheng; Hou, Biao; Liu, Fang; Yang, Shuyuan] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Peoples R China.
   [Yang, Meijuan; Jiao, Licheng; Hou, Biao; Liu, Fang; Yang, Shuyuan] Xidian Univ, Joint Int Res Lab Intelligent Percept & Computat, Xian 710071, Peoples R China.
   [Yang, Meijuan; Jiao, Licheng; Hou, Biao; Liu, Fang; Yang, Shuyuan] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
RP Jiao, LC (corresponding author), Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM lchjiao@mail.xidian.edu.cn
OI Jiao, Licheng/0000-0003-3354-9617; Yang, Meijuan/0000-0002-9277-7751
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1701267]; State Key Program of National
   Natural Science of ChinaNational Natural Science Foundation of China
   (NSFC) [61836009]; Major Research Plan of the National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [91438201]; Foundation for Innovative Research Groups of the National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61621005]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1701267, in part by the State Key
   Program of National Natural Science of China under Grant 61836009, in
   part by the Major Research Plan of the National Natural Science
   Foundation of China under Grant 91438201, and in part by the Foundation
   for Innovative Research Groups of the National Natural Science
   Foundation of China under Grant 61621005.
CR Aiazzi B, 2013, IEEE T GEOSCI REMOTE, V51, P2022, DOI 10.1109/TGRS.2013.2238946
   Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bejiga MB, 2018, INT GEOSCI REMOTE SE, P1264, DOI 10.1109/IGARSS.2018.8518649
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Deng B, 2020, IEEE T GEOSCI REMOTE, V58, P1422, DOI 10.1109/TGRS.2019.2946318
   Deng XQ, 2019, INT GEOSCI REMOTE SE, P4955, DOI 10.1109/IGARSS.2019.8900277
   Elshamli A, 2017, IEEE J-STARS, V10, P4198, DOI 10.1109/JSTARS.2017.2711360
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ge Weifeng, 2017, P IEEE C COMP VIS PA, P1086
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang ZL, 2020, IEEE T GEOSCI REMOTE, V58, P2324, DOI 10.1109/TGRS.2019.2947634
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Jaturapitpornchai R, 2019, INT GEOSCI REMOTE SE, P7403, DOI 10.1109/IGARSS.2019.8899341
   Kang CY, 2016, INT GEOSCI REMOTE SE, P1146, DOI 10.1109/IGARSS.2016.7729290
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Li L, 2018, IEEE T GEOSCI REMOTE, V56, P4605, DOI 10.1109/TGRS.2018.2829630
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li YY, 2017, INT GEOSCI REMOTE SE, P3090, DOI 10.1109/IGARSS.2017.8127652
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu GC, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106971
   Liu GC, 2015, PATTERN RECOGN, V48, P685, DOI 10.1016/j.patcog.2014.09.027
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu Ming-Yu, 2016, NIPS, P469
   LOPES A, 1993, INT J REMOTE SENS, V14, P1735, DOI 10.1080/01431169308953999
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P2504, DOI 10.1109/TGRS.2019.2951779
   Merkle N, 2018, IEEE J-STARS, V11, P1811, DOI 10.1109/JSTARS.2018.2803212
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Othman E, 2017, IEEE T GEOSCI REMOTE, V55, P4441, DOI 10.1109/TGRS.2017.2692281
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S, 2019, INT GEOSCI REMOTE SE, P5033, DOI 10.1109/IGARSS.2019.8900173
   Shang RH, 2014, ENG APPL ARTIF INTEL, V31, P53, DOI 10.1016/j.engappai.2014.02.004
   Tuia D, 2016, IEEE GEOSC REM SEN M, V4, P41, DOI 10.1109/MGRS.2016.2548504
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang K, 2019, IEEE ACCESS, V7, P153391, DOI 10.1109/ACCESS.2019.2948618
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang ZM, 2019, IEEE GEOSCI REMOTE S, V16, P1155, DOI 10.1109/LGRS.2018.2889967
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Ye FM, 2019, IEEE GEOSCI REMOTE S, V16, P1482, DOI 10.1109/LGRS.2019.2896948
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang YH, 2018, PROC CVPR IEEE, P6810, DOI 10.1109/CVPR.2018.00712
   Zhao LJ, 2019, PATTERN RECOGN, V88, P356, DOI 10.1016/j.patcog.2018.11.028
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zhou X, 2018, IEEE T GEOSCI REMOTE, V56, P5863, DOI 10.1109/TGRS.2018.2827308
NR 62
TC 3
Z9 3
U1 18
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAR
PY 2021
VL 59
IS 3
BP 2188
EP 2203
DI 10.1109/TGRS.2020.3001584
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA QN2TP
UT WOS:000622319000025
DA 2022-01-04
ER

PT J
AU Gao, YH
   Gao, F
   Dong, JY
   Li, HC
AF Gao, Yunhao
   Gao, Feng
   Dong, Junyu
   Li, Heng-Chao
TI SAR Image Change Detection Based on Multiscale Capsule Network
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Radar polarimetry; Synthetic aperture radar;
   Speckle; Task analysis; Semantics; Routing; Change detection; deep
   learning; multiscale capsule network (Ms-CapsNet); synthetic-aperture
   radar (SAR)
AB Traditional synthetic-aperture radar (SAR) image change detection methods based on convolutional neural networks (CNNs) face the challenges of speckle noise and deformation sensitivity. To mitigate these issues, we proposed a multiscale capsule network (Ms-CapsNet) to extract the discriminative information between the changed and unchanged pixels. On the one hand, the multiscale capsule module is employed to exploit the spatial relationship of features. Therefore, equivariant properties can be achieved by aggregating the features from different positions. On the other hand, an adaptive fusion convolution (AFC) module is designed for the proposed Ms-CapsNet. The higher semantic features can be captured for the primary capsules. Feature extracted by the AFC module significantly improves the robustness to speckle noise. The effectiveness of the proposed Ms-CapsNet is verified on three real SAR data sets. The comparison experiments with four state-of-the-art methods demonstrate the efficiency of the proposed method. Our codes are available at https://github.com/summitgao/SAR_CD_MS_CapsNet.
C1 [Gao, Yunhao; Gao, Feng; Dong, Junyu] Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
   [Li, Heng-Chao] Southwest Jiaotong Univ, Sichuan Prov Key Lab Informat Coding & Transmiss, Chengdu 610031, Peoples R China.
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
EM gaofeng@ouc.edu.cn
OI Gao, Feng/0000-0002-1825-328X; Dong, Junyu/0000-0001-7012-2087
FU Next Generation AI Project of China [2018AAA0100602]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [U1706218, 41927805]
FX This work was supported in part by the Next Generation AI Project of
   China under Grant 2018AAA0100602 and in part by the National Natural
   Science Foundation of China under Grant U1706218 and Grant 41927805.
CR Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Paoletti ME, 2019, IEEE T GEOSCI REMOTE, V57, P2145, DOI 10.1109/TGRS.2018.2871782
   Quan SN, 2018, IEEE J-STARS, V11, P458, DOI 10.1109/JSTARS.2017.2787591
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Sabour S., 2017, P ADV NEURAL INF PRO, P3859, DOI DOI 10.1371/JOURNAL.PONE.0035195
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Zhu KQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030223
NR 20
TC 12
Z9 12
U1 25
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAR
PY 2021
VL 18
IS 3
BP 484
EP 488
DI 10.1109/LGRS.2020.2977838
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA QM9MX
UT WOS:000622098500023
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Wu, Y
   Li, JH
   Yuan, YZ
   Qin, AK
   Miao, QG
   Gong, MG
AF Wu, Yue
   Li, Jiaheng
   Yuan, Yongzhe
   Qin, A. K.
   Miao, Qi-Guang
   Gong, Mao-Guo
TI Commonality Autoencoder: Learning Common Features for Change Detection
   From Heterogeneous Images
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
LA English
DT Article; Early Access
DE Remote sensing; Feature extraction; Optical sensors; Optical imaging;
   Radar polarimetry; Image segmentation; Decoding; Change detection;
   commonality autoencoder; convolutional autoencoder (CAE); deep neural
   networks (DNNs)
ID UNSUPERVISED CHANGE DETECTION; LAND-COVER CHANGE; FEATURE
   REPRESENTATION; CLASSIFICATION
AB Change detection based on heterogeneous images, such as optical images and synthetic aperture radar images, is a challenging problem because of their huge appearance differences. To combat this problem, we propose an unsupervised change detection method that contains only a convolutional autoencoder (CAE) for feature extraction and the commonality autoencoder for commonalities exploration. The CAE can eliminate a large part of redundancies in two heterogeneous images and obtain more consistent feature representations. The proposed commonality autoencoder has the ability to discover common features of ground objects between two heterogeneous images by transforming one heterogeneous image representation into another. The unchanged regions with the same ground objects share much more common features than the changed regions. Therefore, the number of common features can indicate changed regions and unchanged regions, and then a difference map can be calculated. At last, the change detection result is generated by applying a segmentation algorithm to the difference map. In our method, the network parameters of the commonality autoencoder are learned by the relevance of unchanged regions instead of the labels. Our experimental results on five real data sets demonstrate the promising performance of the proposed framework compared with several existing approaches.
C1 [Wu, Yue; Yuan, Yongzhe; Miao, Qi-Guang] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Li, Jiaheng; Gong, Mao-Guo] Xidian Univ, Key Lab Intel Iigent Percept & Image Understandin, Minist Educ China, Xian 710071, Peoples R China.
   [Qin, A. K.] Swinburne Univ Technol, Dept Comp Sci & Software Engn, Melbourne, Vic 3122, Australia.
RP Gong, MG (corresponding author), Xidian Univ, Key Lab Intel Iigent Percept & Image Understandin, Minist Educ China, Xian 710071, Peoples R China.
EM ywu@xidian.edu.cn; jeahenng@163.com; magicyyz111@gmail.com;
   kqin@swin.edu.au; qgmiao@mail.xidian.edu.cn; gong@ieee.org
RI Qin, Kai/AAH-4943-2021
OI Qin, Kai/0000-0001-6631-1651
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62036006]; Australian Research
   CouncilAustralian Research Council [LP180100114, DP200102611]
FX Manuscript received June 22, 2020; revised December 10, 2020; accepted
   January 26, 2021. This work was supported in part by the National
   Natural Science Foundation of China under Grant 62036006 and in part by
   the Australian Research Council under Grant LP180100114 and Grant
   DP200102611. (Corresponding author: Mao-Guo Gong.)
CR BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Colditz RR, 2012, INT J REMOTE SENS, V33, P6426, DOI 10.1080/01431161.2012.688148
   De S, 2017, INT GEOSCI REMOTE SE, P5193, DOI 10.1109/IGARSS.2017.8128171
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gong MG, 2019, INT J REMOTE SENS, V40, P3647, DOI 10.1080/01431161.2018.1547934
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Jin SM, 2017, REMOTE SENS ENVIRON, V195, P44, DOI 10.1016/j.rse.2017.04.021
   King DB, 2015, ACS SYM SER, V1214, P1
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Leichtle T, 2017, INT J APPL EARTH OBS, V60, P83, DOI 10.1016/j.jag.2017.04.002
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li WB, 2020, IEEE T GEOSCI REMOTE, V58, P2865, DOI 10.1109/TGRS.2019.2956959
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Touati R, 2018, IEEE IMAGE PROC, P3998, DOI 10.1109/ICIP.2018.8451184
   Touati R, 2017, INT CONF IMAG PROC
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wang SM, 2018, RESOUR CONSERV RECY, V128, P526, DOI 10.1016/j.resconrec.2016.05.011
   Wei J, 2019, IEEE T GEOSCI REMOTE, V57, P9534, DOI 10.1109/TGRS.2019.2927432
   Welling, 2013, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Wu H, 2019, 2019 10TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTITEMPORAL REMOTE SENSING IMAGES (MULTITEMP)
   Wu Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132098
   Xiang YM, 2020, IEEE T GEOSCI REMOTE, V58, P6451, DOI 10.1109/TGRS.2020.2976865
   Xiang YM, 2019, IEEE T GEOSCI REMOTE, V57, P6335, DOI 10.1109/TGRS.2019.2905585
   Yin H, 2018, REMOTE SENS ENVIRON, V204, P918, DOI 10.1016/j.rse.2017.08.030
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao MD, 2019, IEEE GEOSCI REMOTE S, V16, P231, DOI 10.1109/LGRS.2018.2871849
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
NR 45
TC 0
Z9 0
U1 3
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2162-237X
EI 2162-2388
J9 IEEE T NEUR NET LEAR
JI IEEE Trans. Neural Netw. Learn. Syst.
PY 2021
DI 10.1109/TNNLS.2021.3056238
EA FEB 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
SC Computer Science; Engineering
GA XR4UU
UT WOS:000732226900001
PM 33600325
DA 2022-01-04
ER

PT J
AU Fang, S
   Li, KY
   Shao, JY
   Li, Z
AF Fang, Sheng
   Li, Kaiyu
   Shao, Jinyuan
   Li, Zhe
TI SNUNet-CD: A Densely Connected Siamese Network for Change Detection of
   VHR Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Feature extraction; Decoding; Semantics; Location awareness;
   Convolution; Task analysis; Neural networks; Change detection; deep
   learning; fully convolutional siamese network; remote sensing (RS)
   images
AB Change detection is an important task in remote sensing (RS) image analysis. It is widely used in natural disaster monitoring and assessment, land resource planning, and other fields. As a pixel-to-pixel prediction task, change detection is sensitive about the utilization of the original position information. Recent change detection methods always focus on the extraction of deep change semantic feature, but ignore the importance of shallow-layer information containing high-resolution and fine-grained features, this often leads to the uncertainty of the pixels at the edge of the changed target and the determination miss of small targets. In this letter, we propose a densely connected siamese network for change detection, namely SNUNet-CD (the combination of Siamese network and NestedUNet). SNUNet-CD alleviates the loss of localization information in the deep layers of neural network through compact information transmission between encoder and decoder, and between decoder and decoder. In addition, Ensemble Channel Attention Module (ECAM) is proposed for deep supervision. Through ECAM, the most representative features of different semantic levels can be refined and used for the final classification. Experimental results show that our method improves greatly on many evaluation criteria and has a better tradeoff between accuracy and calculation amount than other state-of-the-art (SOTA) change detection methods.
C1 [Fang, Sheng; Li, Kaiyu; Li, Zhe] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266100, Peoples R China.
   [Shao, Jinyuan] Chinese Acad Sci, Inst Urban Environm, Key Lab Urban Environm & Hlth, Xiamen 364021, Peoples R China.
   [Shao, Jinyuan] Univ Chinese Acad Sci, Sch Resources & Environm, Beijing 100049, Peoples R China.
RP Li, Z (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266100, Peoples R China.
EM fangs99@126.com; likyoo@sdust.edu.cn; jyshao@iue.ac.cn;
   lizhe@sdust.edu.cn
RI CAS, KLUEH/T-5743-2019
OI Li, Kaiyu/0000-0002-8015-6245; Shao, Jinyuan/0000-0003-0441-9565
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61502278]; National Key Research and
   Development Program of China [2018YFC0831002]; Key Research and
   Development Program of Shandong Province [2018GGX101045]; Natural
   Science Foundation of Shandong ProvinceNatural Science Foundation of
   Shandong Province [ZR2020MF132]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61502278, in part by the National Key
   Research and Development Program of China under Grant 2018YFC0831002, in
   part by the Key Research and Development Program of Shandong Province
   under Grant 2018GGX101045, and in part by the Natural Science Foundation
   of Shandong Province under Grant ZR2020MF132.
CR Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo E., 2018, ARXIV181009111
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Komodakis N., 2016, ARXIV160507146, V87, P1, DOI [DOI 10.5244/C.30.87, 10.5244/C.30.87]
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 20
TC 5
Z9 5
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3056416
EA FEB 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR3IF
UT WOS:000732126600001
DA 2022-01-04
ER

PT J
AU Pouliot, D
   Alavi, N
   Wilson, S
   Duffe, J
   Pasher, J
   Davidson, A
   Daneshfar, B
   Lindsay, E
AF Pouliot, Darren
   Alavi, Niloofar
   Wilson, Scott
   Duffe, Jason
   Pasher, Jon
   Davidson, Andrew
   Daneshfar, Bahram
   Lindsay, Emily
TI Assessment of Landsat Based Deep-Learning Membership Analysis for
   Development of from-to Change Time Series in the Prairie Region of
   Canada from 1984 to 2018
SO REMOTE SENSING
LA English
DT Article
DE change detection; prairie; agriculture; grassland; deep learning;
   membership; Landsat
ID CONTERMINOUS UNITED-STATES; COVER DATABASE; GRASSLAND; CLASSIFICATION;
   METHODOLOGY; MISREGISTRATION; RECONSTRUCTION; ACCURACY; WATER
AB The prairie region of Canada is a dynamically changing landscape in relation to past and present anthropogenic activities and recent climate change. Improving our understanding of the rate, timing, and distribution of landscape change is needed to determine the impact on wildlife populations and biodiversity, ultimately leading to better-informed management regarding requirements for habitat amount and its connectedness. In this research, we assessed the viability of an approach to detect from-to class changes designed to be scalable to the prairie region with the capacity for local refinement. It employed a deep-learning convolutional neural network to model general land covers and examined class memberships to identify land-cover conversions. For this implementation, eight land-cover categories were derived from the Agriculture and Agri-Food Canada Annual Space-Based Crop Inventory. Change was assessed in three study areas that contained different mixes of grassland, pasture, and forest cover. Results showed that the deep-learning method produced the highest accuracy across all classes relative to an implementation of random forest that included some first-order texture measures. Overall accuracy was 4% greater with the deep-learning classifier and class accuracies were more balanced. Evaluation of change accuracy suggested good performance for many conversions such as grassland to crop, forest to crop, water to dryland covers, and most bare/developed-related changes. Changes involving pasture with grassland or cropland were more difficult to detect due to spectral confusion among classes. Similarly, conversion to forests in some cases was poorly detected due to gradual and subtle change characteristics combined with confusion between forest, shrub, and croplands. The proposed framework involved several processing steps that can be explored to enhance the thematic content and accuracy for large regional implementation. Evaluation for understanding connectivity in natural land covers and related declines in species at risk is planned for future research.
C1 [Pouliot, Darren; Alavi, Niloofar; Duffe, Jason; Pasher, Jon] Environm & Climate Change Canada, Landscape Sci & Technol Div, 1125 Colonel Dr, Ottawa, ON K1A 0H3, Canada.
   [Wilson, Scott] Environm & Climate Change Canada, Wildlife Res Div, 1125 Colonel Dr, Ottawa, ON K1A 0H3, Canada.
   [Davidson, Andrew; Daneshfar, Bahram; Lindsay, Emily] Agr & Agri Food Canada, Sci & Technol Branch, KW Neatby Bldg,960 Carling Ave, Ottawa, ON K1A 0C6, Canada.
RP Pouliot, D (corresponding author), Environm & Climate Change Canada, Landscape Sci & Technol Div, 1125 Colonel Dr, Ottawa, ON K1A 0H3, Canada.
EM darren.pouliot@canada.ca; niloofar.alavi@Canada.ca;
   scott.wilson@canada.ca; jason.duffe@canada.ca; jon.pasher@canada.ca;
   andrew.davidson2@canada.ca; bahram.daneshfar@canada.ca;
   emily.lindsay@canada.ca
FU Canadian Space AgencyCanadian Space Agency
FX Research was supported through a Canadian Space Agency grant for the
   project "Integrated Earth Observation Monitoring for Essential Ecosystem
   Information: Resilience to Ecosystem Stress and Climate Change".
CR [Anonymous], 2010, CAN BIOD EC STAT TRE
   Bonsal BR, 2011, ATMOS OCEAN, V49, P320, DOI 10.1080/07055900.2011.594024
   Boryan C, 2011, GEOCARTO INT, V26, P341, DOI 10.1080/10106049.2011.562309
   Brodribb K.E., 2007, CONSERVATION BLUEPRI
   Brown JF, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2019.111356
   Canadian Wildlife Service, 1991, FED POL WETL CONS
   CHEN J, 2014, ISPRS J PHOTOGRAMM, V103, P7, DOI DOI 10.1016/J.ISPRSJPRS.2014.09.002
   Colditz RR, 2014, PHOTOGRAMM ENG REM S, V80, P918
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Davidson AM., 2017, HDB REMOTE SENSING A
   Fisette T, 2014, INT GEOSCI REMOTE SE, P5095, DOI 10.1109/IGARSS.2014.6947643
   Fisher RJ, 2018, REMOTE SENS ENVIRON, V218, P201, DOI 10.1016/j.rse.2018.10.003
   Gage Anne M., 2016, Great Plains Research, V26, P107
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Gimpel K., 2016, ARXIV161002136
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo X., 2005, PRAIRIE PERSPECT
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermosilla T, 2018, CAN J REMOTE SENS, V44, P67, DOI 10.1080/07038992.2018.1437719
   Hoekstra JM, 2005, ECOL LETT, V8, P23, DOI 10.1111/j.1461-0248.2004.00686.x
   Homer C, 2020, ISPRS J PHOTOGRAMM, V162, P184, DOI 10.1016/j.isprsjprs.2020.02.019
   Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
   http://maps.elie.ucl.ac.be/CCI/viewer/download/ESACCI-LC-Ph2-PUGv2_2.0.pdf, LAND COVER CCI PRODU
   Hu XF, 2019, INT J HYG ENVIR HEAL, V222, P319, DOI 10.1016/j.ijheh.2018.12.003
   Jin SM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242971
   Kovalskyy V, 2013, REMOTE SENS ENVIRON, V130, P280, DOI 10.1016/j.rse.2012.12.003
   Latifovic R., 2016, REMOTE SENSING LAND, P303
   Latifovic R, 2005, CAN J REMOTE SENS, V31, P347, DOI 10.5589/m05-019
   Latifovic R, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111098
   Lindsay EJ, 2019, RANGELAND ECOL MANAG, V72, P92, DOI 10.1016/j.rama.2018.07.005
   Luthcke SB, 2013, J GLACIOL, V59, P613, DOI 10.3189/2013JoG12J147
   McInnes WS, 2015, IEEE J-STARS, V8, P1395, DOI 10.1109/JSTARS.2015.2416713
   North American Bird Conservation Initiative, 2016, STAT N AM BIRDS 2016, P8
   Olimb S, 2018, GEOJOURNAL, V83, P819, DOI 10.1007/s10708-017-9805-8
   Olofsson P, 2014, REMOTE SENS ENVIRON, V148, P42, DOI 10.1016/j.rse.2014.02.015
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pekel JF, 2016, NATURE, V540, P418, DOI 10.1038/nature20584
   Pouliot D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11070772
   Pouliot D, 2018, REMOTE SENS ENVIRON, V204, P979, DOI 10.1016/j.rse.2017.07.036
   Pouliot D, 2016, GISCI REMOTE SENS, V53, P382, DOI 10.1080/15481603.2015.1137112
   Pouliot D, 2014, REMOTE SENS ENVIRON, V140, P731, DOI 10.1016/j.rse.2013.10.004
   Rabinovich A., 2015, PROC CVPR IEEE, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Roch L, 2014, ENVIRON MONIT ASSESS, V186, P2505, DOI 10.1007/s10661-013-3557-9
   Rosenberg KV, 2019, SCIENCE, V366, P120, DOI 10.1126/science.aaw1313
   Roy DP, 2000, IEEE T GEOSCI REMOTE, V38, P2017, DOI 10.1109/36.851783
   Schmoll M.J., 2007, TECHNICAL REPORT
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229
   Stow D. A., 1980, P 14 INT S REM SENS, P1227
   Sutton A, 2007, CAN J FOREST RES, V37, P1643, DOI 10.1139/X07-021
   Truong C, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107299
   United States Geological Survey, LANDS COLL 1 VS COLL
   van Oort PAJ, 2007, REMOTE SENS ENVIRON, V108, P1, DOI 10.1016/j.rse.2006.10.012
   WEAVER JE, 1958, ECOLOGY, V39, P393, DOI 10.2307/1931749
   Wickham J, 2017, REMOTE SENS ENVIRON, V191, P328, DOI 10.1016/j.rse.2016.12.026
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Yang XH, 2017, CAN J REMOTE SENS, V43, P62, DOI 10.1080/07038992.2017.1263151
   Zhang X., 2019, CANADAS CHANGING CLI, P112
   Zhu Z, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2019.03.009
   Zhu Z, 2015, REMOTE SENS ENVIRON, V162, P67, DOI 10.1016/j.rse.2015.02.009
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zhu Z, 2012, REMOTE SENS ENVIRON, V122, P75, DOI 10.1016/j.rse.2011.10.030
NR 61
TC 0
Z9 0
U1 7
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB
PY 2021
VL 13
IS 4
AR 634
DI 10.3390/rs13040634
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA QQ3SY
UT WOS:000624445200001
OA gold
DA 2022-01-04
ER

PT J
AU Zhang, HM
   Wang, MC
   Wang, FY
   Yang, GD
   Zhang, Y
   Jia, JQ
   Wang, SQ
AF Zhang, Haiming
   Wang, Mingchang
   Wang, Fengyan
   Yang, Guodong
   Zhang, Ying
   Jia, Junqian
   Wang, Siqi
TI A Novel Squeeze-and-Excitation W-Net for 2D and 3D Building Change
   Detection with Multi-Source and Multi-Feature Remote Sensing Data
SO REMOTE SENSING
LA English
DT Article
DE multi-source; multi-feature; W-Net; squeeze-and-excitation; 2D; 3D
   building change detection
AB Building Change Detection (BCD) is one of the core issues in earth observation and has received extensive attention in recent years. With the rapid development of earth observation technology, the data source of remote sensing change detection is continuously enriched, which provides the possibility to describe the spatial details of the ground objects more finely and to characterize the ground objects with multiple perspectives and levels. However, due to the different physical mechanisms of multi-source remote sensing data, BCD based on heterogeneous data is a challenge. Previous studies mostly focused on the BCD of homogeneous remote sensing data, while the use of multi-source remote sensing data and considering multiple features to conduct 2D and 3D BCD research is sporadic. In this article, we propose a novel and general squeeze-and-excitation W-Net, which is developed from U-Net and SE-Net. Its unique advantage is that it can not only be used for BCD of homogeneous and heterogeneous remote sensing data respectively but also can input both homogeneous and heterogeneous remote sensing data for 2D or 3D BCD by relying on its bidirectional symmetric end-to-end network architecture. Moreover, from a unique perspective, we use image features that are stable in performance and less affected by radiation differences and temporal changes. We innovatively introduced the squeeze-and-excitation module to explicitly model the interdependence between feature channels so that the response between the feature channels is adaptively recalibrated to improve the information mining ability and detection accuracy of the model. As far as we know, this is the first proposed network architecture that can simultaneously use multi-source and multi-feature remote sensing data for 2D and 3D BCD. The experimental results in two 2D data sets and two challenging 3D data sets demonstrate that the promising performances of the squeeze-and-excitation W-Net outperform several traditional and state-of-the-art approaches. Moreover, both visual and quantitative analyses of the experimental results demonstrate competitive performance in the proposed network. This demonstrates that the proposed network and method are practical, physically justified, and have great potential application value in large-scale 2D and 3D BCD and qualitative and quantitative research.
C1 [Zhang, Haiming; Wang, Mingchang; Wang, Fengyan; Yang, Guodong; Zhang, Ying; Jia, Junqian; Wang, Siqi] Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun 130026, Peoples R China.
   [Wang, Mingchang] Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518000, Peoples R China.
   [Wang, Siqi] China Geol Survey, Xian Ctr Mineral Resources Survey, Xian 710100, Peoples R China.
RP Wang, MC (corresponding author), Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun 130026, Peoples R China.; Wang, MC (corresponding author), Minist Nat Resources, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518000, Peoples R China.
EM zhanghm18@mails.jlu.edu.cn; wangmc@jlu.edu.cn; wangfy@jlu.edu.cn;
   ygd@jlu.edu.cn; zhangying_cc@jlu.edu.cn; jiajq@jlu.edu.cn;
   wsq18@mails.jlu.edu.cn
OI wang, mingchang/0000-0002-2806-858X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [42077242]; Open Fund of Key Laboratory of
   Urban Land Resources Monitoring and Simulation, Ministry Natural
   Resources [KF-2019-04-080, KF-2020-05-024]; Scientific Research Project
   of the 13th Five-Year Plan of Jilin province's education department
   [JJKH20200999KJ]
FX This research was funded by the National Natural Science Foundation of
   China (42077242); the Open Fund of Key Laboratory of Urban Land
   Resources Monitoring and Simulation, Ministry Natural Resources
   (KF-2019-04-080, KF-2020-05-024); the Scientific Research Project of the
   13th Five-Year Plan of Jilin province's education department
   (JJKH20200999KJ).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1350, DOI 10.1109/36.763299
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen L, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/6430627
   Chen RX, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030451
   Das S, 2019, PROCEDIA COMPUT SCI, V159, P1479, DOI 10.1016/j.procs.2019.09.318
   Demir B, 2012, IEEE T GEOSCI REMOTE, V50, P1930, DOI 10.1109/TGRS.2011.2168534
   Dong LF, 2020, IEEE J-STARS, V13, P113, DOI 10.1109/JSTARS.2019.2953234
   Du B, 2018, IEEE J-STARS, V11, P4676, DOI 10.1109/JSTARS.2018.2869549
   [杜守基 Du Shouji], 2018, [测绘学报, Acta Geodetica et Cartographica Sinica], V47, P519
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Gamba P, 2006, IEEE T GEOSCI REMOTE, V44, P2820, DOI 10.1109/TGRS.2006.879498
   Gargiulo M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102969
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2020, REMOTE SENS ENVIRON, V244, DOI 10.1016/j.rse.2020.111802
   Huang X, 2014, REMOTE SENS-BASEL, V6, P8424, DOI 10.3390/rs6098424
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jia M, 2018, INT J REMOTE SENS, V39, P1068, DOI 10.1080/01431161.2017.1395966
   Li L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091091
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Liu P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050894
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Mnih V., 2014, P ADV NEURAL INF PRO, P2204, DOI DOI 10.1017/S037346330300239X
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Pang SY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040966
   Perconti P, 2020, COGNITION, V203, DOI 10.1016/j.cognition.2020.104365
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   [任凤雷 Ren Fenglei], 2019, [光学精密工程, Optics and Precision Engineering], V27, P2722
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salcedo-Sanz S, 2014, WIRES DATA MIN KNOWL, V4, P234, DOI 10.1002/widm.1125
   Seydi ST, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122010
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Shirowzhan S, 2019, AUTOMAT CONSTR, V105, DOI 10.1016/j.autcon.2019.102841
   Sinha P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020107
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Solorzano JV, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.036006
   Wang MC, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12121933
   Wang MC, 2019, J GEOVIS SPAT ANAL, V3, DOI 10.1007/s41651-019-0039-9
   Wang Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020342
   Wang YY, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017)
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Xu L, 2019, IEEE ACCESS, V7, P78909, DOI 10.1109/ACCESS.2019.2922839
   [徐真 Xu Zhen], 2017, [雷达学报, Journal of Radars], V6, P483
   Yi YN, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151774
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, IEEE T NEUR NET LEAR, V30, P109, DOI 10.1109/TNNLS.2018.2832648
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang N, 2019, APPL INTELL, V49, P1925, DOI 10.1007/s10489-018-1379-8
   Zhang WM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060501
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao J., 2015, IMAGE FEATURE EXTRAC, P59
NR 70
TC 1
Z9 1
U1 20
U2 24
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB
PY 2021
VL 13
IS 3
AR 440
DI 10.3390/rs13030440
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA QD4GK
UT WOS:000615478600001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, CC
   Su, WM
   Gu, H
AF Wang, Chenchen
   Su, Weimin
   Gu, Hong
TI SAR Image Change Detection Based on Semisupervised Learning and Two-Step
   Training
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Change detection; channel-attention; feature fusion; pseudolabels;
   semisupervised; synthetic aperture radar (SAR)
ID SEGMENTATION; NETWORK; ENERGY
AB Change detection, as an essential part of synthetic aperture radar (SAR) automatic target recognition (ATR) systems, remains a challenging problem. The lack of labeled data seriously impedes the development of deep learning-based methods in SAR applications. In this letter, we propose a patch-based semisupervised method to detect changed pixels from limited training data in the field of SAR. The complete approach includes the unsupervised pretraining stage and the iterative discrimination stage. The states of pixels are determined by comparing the corresponding image patches. First, to reduce the impact of insufficient data, we train a trapezium U-Net-like structure to extract representative and generalized features by unsupervised training on all pixels. Feature maps contain detailed and semantic information due to repetitive feature fusions. A designed feature activation module is utilized to recalibrate fused features. Finally, the discrimination is finished by a simple classification convolutional neural network (CNN) following a two-step training strategy. Ablation studies indicate the function provided by the proposed modifications. Experiments on real SAR images demonstrate that the proposed method can improve the detection accuracy by more than 1.2% compared with other state-of-the-art deep learning-based methods.
C1 [Wang, Chenchen; Su, Weimin; Gu, Hong] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing 210094, Peoples R China.
RP Su, WM (corresponding author), Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing 210094, Peoples R China.
EM suweimin_rceet@163.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61671246, 61801221, 62001229]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61671246, Grant 61801221, and Grant 62001229.
CR Akbarizadeh G, 2012, IEEE T GEOSCI REMOTE, V50, P4358, DOI 10.1109/TGRS.2012.2194787
   Brox, 2015, INT C MED IM COMP CO, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Rahmani M, 2015, IET COMPUT VIS, V9, P629, DOI 10.1049/iet-cvi.2014.0295
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Sharifzadeh F, 2019, J INDIAN SOC REMOTE, V47, P551, DOI 10.1007/s12524-018-0891-y
   Tirandaz Z, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107432
   Tirandaz Z, 2016, IEEE J-STARS, V9, P1244, DOI 10.1109/JSTARS.2015.2492552
   Vinholi JG, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3027382
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
NR 16
TC 0
Z9 0
U1 0
U2 0
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3050746
EA JAN 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR4SL
UT WOS:000732220800001
DA 2022-01-04
ER

PT J
AU Zhang, XW
   Yue, YZ
   Gao, WX
   Yun, S
   Su, Q
   Yin, HL
   Zhang, YN
AF Zhang, Xiuwei
   Yue, Yuanzeng
   Gao, Wenxiang
   Yun, Shuai
   Su, Qian
   Yin, Hanlin
   Zhang, Yanning
TI DifUnet plus plus : A Satellite Images Change Detection Network Based on
   Unet plus plus and Differential Pyramid
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article; Early Access
DE Convolution; Feature extraction; Remote sensing; Semantics; Image
   segmentation; Decoding; Satellites; Change detection (CD); deep
   learning; differential information; semantic learning
AB Change detection (CD) is one of the most important topics in the field of remote sensing. In this letter, we propose an effective satellite images CD network named DifUnet++. As the presentation of explicit difference is more conducive to extract change features, we design a differential pyramid of two input images as the input of Unet++. Considering the scale diversity of changed regions in remote sensing images, a multiply side-outs fusion strategy is adopted to predict the detection results of different scales. Furthermore, a learning upsampling method is utilized to refine the details of CD. The proposed architecture is evaluated on two public satellite image CD data sets. The experimental results show that our method performs much better than state-of-the-art methods.
C1 [Zhang, Xiuwei; Yue, Yuanzeng; Yun, Shuai; Su, Qian; Yin, Hanlin; Zhang, Yanning] Dept Natl Engn Lab Integrated Aerosp Ground Ocean, Xian 710072, Peoples R China.
   [Zhang, Xiuwei; Su, Qian; Yin, Hanlin; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci & Technol, Xian 710072, Peoples R China.
   [Yue, Yuanzeng; Gao, Wenxiang; Yun, Shuai] Northwestern Polytech Univ, Sch Software, Xian 710072, Peoples R China.
RP Zhang, XW (corresponding author), Dept Natl Engn Lab Integrated Aerosp Ground Ocean, Xian 710072, Peoples R China.
EM xwzhang@nwpu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971356, 61801395, 61971273]; National
   Natural Science Foundation of Shaanxi Province [2020GM-137]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61971356, Grant 61801395, and Grant
   No.61971273; and in part by the National Natural Science Foundation of
   Shaanxi Province under Grant 2020GM-137.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhao XW, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P525, DOI 10.5220/0007407905250532
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 21
TC 12
Z9 12
U1 6
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PY 2021
DI 10.1109/LGRS.2021.3049370
EA JAN 2021
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA XR6PQ
UT WOS:000732348900001
DA 2022-01-04
ER

PT J
AU Mahmoud, AS
   Mohamed, SA
   Moustafa, MS
   El-Khorib, RA
   Abdelsalam, HM
   El-Khodary, IA
AF Mahmoud, Amira S.
   Mohamed, Sayed A.
   Moustafa, Marwa S.
   El-Khorib, Reda A.
   Abdelsalam, Hisham M.
   El-Khodary, Ihab A.
TI Training Compact Change Detection Network for Remote Sensing Imagery
SO IEEE ACCESS
LA English
DT Article
DE Change detection (CD); deep learning (DL); knowledge distillation (KD);
   Siamese network; teacher-student setting; practical swarm optimization
   (PSO)
AB Change Detection (CD) is a hot remote sensing topic where the change zones are highlighted by analyzing bi-temporal or multi-temporal images. Recently, Deep learning (DL) paved the road to implement various reliable change detection approaches that overcome traditional CD methods limitation. However, high performance DL based approaches have explosion number of parameters that demanded extensive computation and memory usage in addition to large volumes of training data. To address this issue, we proposed a teacher-student setting for remote sensing imagery change detection. To distill the knowledge from the over-parameterized Siamese teacher network, we proposed tiny student network that was trained using the obtained categorical distribution of probability from the teacher paired Softmax output at high temperature. Practical Swarm Optimization (PSO) was applied in order to optimally configure student architecture. Finally, ample experiments were conducted on LEVIR-CD dataset. Also, we introduced EGSAR-CD dataset, which contains of a large set of bi-temporal SAR images with 460 image pairs (256 x 256). Experiment results indicate that we can reach up to 5.4 x reduction rate in number of parameters with loss of accuracy between 5% and 6% on the LEVIR-CD and EGSAR-CD datasets utilizing self-knowledge distillation.
C1 [Mahmoud, Amira S.; Mohamed, Sayed A.; Moustafa, Marwa S.] Natl Author Remote Sensing & Space Sci, Cairo 11843, Egypt.
   [El-Khorib, Reda A.; Abdelsalam, Hisham M.; El-Khodary, Ihab A.] Cairo Univ, Fac Comp & Artificial Intelligence, Giza 12613, Egypt.
RP Mahmoud, AS (corresponding author), Natl Author Remote Sensing & Space Sci, Cairo 11843, Egypt.
EM fci.amira@gmail.com
RI Moustafa, Marwa/AAW-3476-2021
OI Moustafa, Marwa/0000-0003-3805-9668
CR Aditya S, 2019, IEEE WINT CONF APPL, P227, DOI 10.1109/WACV.2019.00030
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Ashok A., 2017, ARXIV170906030
   Ba J., 2014, ADV NEURAL INFORM PR, V27
   Chen GZ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050719
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen T, 2015, ARXIV151105641
   Chu Y, 2016, ADV INTEL SYS RES, V133, P262
   Cunha A, 2020, COMPUT GEOSCI-UK, V135, DOI 10.1016/j.cageo.2019.104344
   Daudt R. C., ARXIV181008452
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   de Jong K. L., 2018, ARXIV181205815
   Dean, 2015, ARXIV150302531
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Elkholy MM, 2020, INT J REMOTE SENS, V41, P4797, DOI 10.1080/01431161.2020.1724346
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Gu YT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9102110
   Guerra L., ARXIV200200523
   Han PC, 2019, NEUROCOMPUTING, V349, P190, DOI 10.1016/j.neucom.2019.04.029
   Heo B., 2018, ARXIV180505532
   Hughes LH, 2018, IEEE GEOSCI REMOTE S, V15, P784, DOI 10.1109/LGRS.2018.2799232
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kim K., ARXIV200612000
   Lee SH, 2018, LECT NOTES COMPUT SC, V11210, P339, DOI 10.1007/978-3-030-01231-1_21
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Mahmoud A., 2020, INT J INTELL ENG SYS, V13, P65, DOI DOI 10.22266/IJIES2020.0229.07
   Minu S, 2015, AQUAT PR, V4, P1366, DOI 10.1016/j.aqpro.2015.02.177
   Mirzadeh S.-I., ARXIV190203393
   Mishra Asit, 2017, ARXIV171105852
   Neftci EO, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00324
   Niculescu-Mizil, 2006, P 12 ACM SIGKDD INT, DOI DOI 10.1145/1150402.1150464
   Romero A., 2014, ARXIV14126550, DOI 10.1109/acpr.2015.7486451
   Tian Y., ARXIV191010699
   Vasilev I., PYTHON DEEP LEARNING
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Welling, 2015, ADV NEURAL INFORM PR
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xu JD, 2019, COMPUT GEOSCI-UK, V131, P132, DOI 10.1016/j.cageo.2019.06.005
   Xu Z., 2017, ARXIV170900513
   Yaguchi A., ARXIV191013141
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Ye S, 2016, ISPRS J PHOTOGRAMM, V114, P115, DOI 10.1016/j.isprsjprs.2016.01.018
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yu B, 2020, COMPUT GEOSCI-UK, V135, DOI 10.1016/j.cageo.2019.104388
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou D., ARXIV190705642
   Zou FY, 2019, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2019.01138
NR 53
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2021
VL 9
BP 90366
EP 90378
DI 10.1109/ACCESS.2021.3089766
PG 13
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA TJ8UP
UT WOS:000673749800001
OA gold
DA 2022-01-04
ER

PT J
AU Saha, S
   Kondmann, L
   Song, Q
   Zhu, XX
AF Saha, Sudipan
   Kondmann, Lukas
   Song, Qian
   Zhu, Xiao Xiang
TI Change Detection in Hyperdimensional Images Using Untrained Models
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Hyperspectral imaging; Feature extraction; Earth; Data models; Transfer
   learning; Deep learning; Synthetic aperture radar; Change detection
   (CD); deep image prior; deep learning; hyperdimensional images;
   hyperspectral images
ID CHANGE VECTOR ANALYSIS; HYPERSPECTRAL IMAGE
AB Deep transfer-learning-based change detection methods are dependent on the availability of sensor-specific pretrained feature extractors. Such feature extractors are not always available due to lack of training data, especially for hyperspectral sensors and other hyperdimensional images. Moreover models trained on easily available multispectral (RGB/RGB-NIR) images cannot be reused on such hyperdimensional images due to their irregular number of bands. While hyperdimensional images show large number of spectral bands, they generally show much less spatial complexity, thus reducing the requirement of large receptive fields of convolution filters. Recent works in the computer vision have shown that even untrained deep models can yield remarkable result in some tasks like super-resolution and surface reconstruction. This motivates us to make a bold proposition that untrained lightweight deep model, initialized with some weight initialization strategy, can be used to extract useful semantic features from bi-temporal hyperdimensional images. Based on this proposition, we design a novel change detection framework for hyperdimensional images by extracting bitemporal features using an untrained model and further comparing the extracted features using deep change vector analysis to distinguish changed pixels from the unchanged ones. We further use the deep change hypervectors to cluster the changed pixels into different semantic groups. We conduct experiments on four change detection datasets: three hyperspectral datasets and a hyperdimensional polarimetric synthetic aperture radar dataset. The results clearly demonstrate that the proposed method is suitable for change detection in hyperdimensional remote sensing data.
C1 [Saha, Sudipan] Tech Univ Munich, Dept Aerosp & Geodesy, Data Sci Earth Observat, D-85521 Ottobrunn, Germany.
   [Kondmann, Lukas; Song, Qian; Zhu, Xiao Xiang] German Aerosp Ctr DLR, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
   [Kondmann, Lukas; Song, Qian] Tech Univ Munich, Dept Aerosp & Geodesy, Data Sci Earth Observat SiPEO, Signal Proc Earth Observat, D-85521 Ottobrunn, Germany.
RP Zhu, XX (corresponding author), German Aerosp Ctr DLR, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
EM sudipan.saha@tum.de; Lukas.Kondmann@dlr.de; qian.song@dlr.de;
   xiaoxiang.zhu@dlr.de
OI Saha, Sudipan/0000-0002-9440-0720; Song, Qian/0000-0003-2746-6858; Zhu,
   Xiao Xiang/0000-0001-5530-3613
FU German Federal Ministry of Education, and Research (BMBF)Federal
   Ministry of Education & Research (BMBF) [01DD20001]; European Research
   Council (ERC) under the European UnionEuropean Research Council (ERC)
   [ERC-2016-StG-714087]; Helmholtz AssociationHelmholtz Association
   [ZT-I-PF-5-01]; Helmholtz Excellent Professorship "Data Science in Earth
   Observation -Big Data Fusion for Urban Research" [W2-W3-100]
FX The work was supported in part by the German Federal Ministry of
   Education, and Research (BMBF) in the framework of the International
   Future AI lab "AI4EO -Artificial Intelligence for Earth Observation:
   Reasoning, Uncertainties, Ethics, and Beyond" under Grant number:
   01DD20001, in part by the European Research Council (ERC) under the
   European Union's Horizon 2020 research, and innovation programme
   underGrant ERC-2016-StG-714087, Acronym: So2Sat, in part by the
   Helmholtz Association through the Framework of Helmholtz AI under Grant
   ZT-I-PF-5-01 -Local Unit "Munich Unit @Aeronautics, Space, and Transport
   (MASTr)," and Helmholtz Excellent Professorship "Data Science in Earth
   Observation -Big Data Fusion for Urban Research" under Grant W2-W3-100.
CR Appice A., 2019, P CEUR WORKSH, V2466, P1
   Audebert N, 2019, IEEE GEOSC REM SEN M, V7, P159, DOI 10.1109/MGRS.2019.2912563
   Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023
   Bengio Y., 2010, P 13 INT C ART INT S, P249, DOI DOI 10.1038/S41593-021-00857-X
   Bergamasco L, 2019, PROC SPIE, V11155, DOI 10.1117/12.2533812
   Bi HX, 2017, IEEE T GEOSCI REMOTE, V55, P3531, DOI 10.1109/TGRS.2017.2675906
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chaudhuri S., 2020, P IEEE CVF C COMP VI
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen Z, 2019, 2019 10TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTITEMPORAL REMOTE SENSING IMAGES (MULTITEMP)
   Cloude SR, 1996, IEEE T GEOSCI REMOTE, V34, P498, DOI 10.1109/36.485127
   Ehrler C., 2011, P 34 INT S REM SENS, P1
   Falco N, 2016, INT GEOSCI REMOTE SE, P3374, DOI 10.1109/IGARSS.2016.7729872
   Fang LY, 2020, IEEE GEOSCI REMOTE S, V17, P1593, DOI 10.1109/LGRS.2019.2950441
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Hasanlou M, 2018, IAPR WORKS PATTERN
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang ZH, 2020, IEEE T GEOSCI REMOTE, V58, P5998, DOI 10.1109/TGRS.2019.2961703
   Lee JA, 2007, INFORM SCI STAT, P1
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Liu SC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101008
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Marinelli D, 2017, 2017 9TH INTERNATIONAL WORKSHOP ON THE ANALYSIS OF MULTITEMPORAL REMOTE SENSING IMAGES (MULTITEMP)
   Molinier M, 2019, INT GEOSCI REMOTE SE, P5049, DOI 10.1109/IGARSS.2019.8900328
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Najafi A, 2017, INT ARCH PHOTOGRAMM, V42-4, P195, DOI 10.5194/isprs-archives-XLII-4-W4-195-2017
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P607, DOI 10.1109/LGRS.2020.2985340
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P856, DOI 10.1109/LGRS.2020.2990284
   Saha S, 2021, IEEE T GEOSCI REMOTE, V59, P1917, DOI 10.1109/TGRS.2020.3000296
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Seydi ST, 2017, EUR J REMOTE SENS, V50, P517, DOI 10.1080/22797254.2017.1367963
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Song Q, 2018, IEEE ACCESS, V6, P1647, DOI 10.1109/ACCESS.2017.2779875
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Tong XH, 2020, IEEE J-STARS, V13, P2056, DOI 10.1109/JSTARS.2020.2990481
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vinyals, 2016, ARXIV161103530
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Wojcik P. I, 2018, ARXIV181209489
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhang Z., 2018, ARXIV PREPRINT ARXIV
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 55
TC 0
Z9 0
U1 3
U2 3
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 11029
EP 11041
DI 10.1109/JSTARS.2021.3121556
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA WU7CJ
UT WOS:000716698800012
OA gold, Green Accepted
DA 2022-01-04
ER

PT J
AU Gao, YH
   Gao, F
   Dong, JY
   Du, Q
   Li, HC
AF Gao, Yunhao
   Gao, Feng
   Dong, Junyu
   Du, Qian
   Li, Heng-Chao
TI Synthetic Aperture Radar Image Change Detection via Siamese Adaptive
   Fusion Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Radar polarimetry; Correlation; Synthetic aperture
   radar; Convolutional neural networks; Task analysis; Speckle; Attention
   mechanism; change detection; deep learning; siamese adaptive fusion
   network (SAFNet); synthetic aperture radar (SAR)
ID AUTOMATIC CHANGE DETECTION; UNSUPERVISED CHANGE DETECTION; SAR
AB Synthetic aperture radar (SAR) image change detection is a critical yet challenging task in the field of remote sensing image analysis. The task is nontrivial due to the following challenges: First, intrinsic speckle noise of SAR images inevitably degrades the neural network because of error gradient accumulation. Furthermore, the correlation among various levels or scales of feature maps is difficult to be achieved through summation or concatenation. Toward this end, we proposed a siamese adaptive fusion (AF) network for SAR image change detection. To be more specific, two-branch CNN is utilized to extract high-level semantic features of multitemporal SAR images. Besides, an AF module is designed to adaptively combine multiscale responses in convolutional layers. Therefore, the complementary information is exploited, and feature learning in change detection is further improved. Moreover, a correlation layer is designed to further explore the correlation between multitemporal images. Thereafter, robust feature representation is utilized for classification through a fully connected layer with softmax. Experimental results on four real SAR datasets demonstrate that the proposed method exhibits superior performance against several state-of-the-art methods. Our codes are available at https://github.com/summitgao/SAR_CD_SAFNet.
C1 [Gao, Yunhao; Gao, Feng; Dong, Junyu] Ocean Univ China, Sch Informat Sci, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Li, Heng-Chao] Southwest Jiaotong Univ, Sichuan Prov Key Lab Informat Coding & Transmiss, Chengdu 610031, Peoples R China.
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
EM 914283361@qq.com; gaofeng@ouc.edu.cn; dongjunyu@ouc.edu.cn;
   du@ece.msstate.edu; hcli@swjtu.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Key Research, and Development Program of China
   [2018AAA0100602]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [U1706218, 61871335]; Key
   Research, and Development Program of Shandong Province [2019GHY112048]
FX This work was supported in part by the National Key Research, and
   Development Program of China under Grant 2018AAA0100602, in part by the
   National Natural Science Foundation of China under Grant U1706218
   andGrant 61871335, and in part by the Key Research, and Development
   Program of Shandong Province under Grant 2019GHY112048.
CR Bai XZ, 2010, PATTERN RECOGN, V43, P2145, DOI 10.1016/j.patcog.2009.12.023
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio Yoshua., 2013, ARXIV13083432
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3097093
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T EVOLUT COMPUT, V21, P234, DOI 10.1109/TEVC.2016.2598858
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Quin G, 2014, IEEE T GEOSCI REMOTE, V52, P5349, DOI 10.1109/TGRS.2013.2288271
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P5028, DOI 10.1109/TGRS.2020.3011002
   Wang Qi, 2020, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2020.3042276
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang SN, 2016, REMOTE SENS LETT, V7, P1043, DOI 10.1080/2150704X.2016.1212417
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang B, 2019, ADV NEUR IN, V32
   Zhang HY, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3089332
   Zhang Mingyang, 2020, IEEE Trans Cybern, VPP, DOI 10.1109/TCYB.2020.3020540
NR 42
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 10748
EP 10760
DI 10.1109/JSTARS.2021.3120381
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA WR0MR
UT WOS:000714204000012
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Ke, QT
   Zhang, P
AF Ke, Qingtian
   Zhang, Peng
TI CS-HSNet: A Cross-Siamese Change Detection Network Based on
   Hierarchical-Split Attention
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Task analysis; Semantics; Remote sensing;
   Computational efficiency; Transformers; Licenses; Attention mechanism;
   hierarchical-split structure; image change detection; multiscale
   features
ID UNSUPERVISED CHANGE DETECTION; FUSION NETWORK; IMAGES
AB Change detection methods for optical remote sensing images play an important role in environmental resource management. Although recent methods based on deep learning demonstrate incredible ability by constructing networks, first, extracting bitemporal features in a separate manner; second, fusing bitemporal images before forwarding them into the single-level network. Both severely neglect the effect of spatial-temporal feature correlation between bitemporal images. In addition, most existing methods represent multiscale feature pairs in a layer-wise manner like ResNet, failing to consider the inner multilevel structure. In this work, we propose a new siamese change detection feature encoder backbone named cross-siamese Res2Net (CSRes2Net), by establishing crossed and hierarchical residual-like connections within one single residual block. The CSRes2Net represents dual features in a fine-grained manner and fully leads to the flow of bitemporal features. In addition, recent learning-based methods designed some spatial-temporal relation modules to capture the pixel-level pairwise relationship and channel dependency based on self-attention mechanism, but they only consider spatial and channel dimension corrections separately with excessive parameters. So we propose a lightweight cross spatial-channel triplet attention module to capture cross-dimensional long-range relationship between triplet combinations: channel with height, channel with width, channel with channel. Finally, we propose a hierarchical-split block for generating multiscale feature representations in a coarse-to-fine fashion. The experiments results on LEVIR-CD and season-varying change detection dataset outperform most state-of-the-art models.
C1 [Ke, Qingtian; Zhang, Peng] Sun Yat Sen Univ, Sch Elect & Commun Engn, Shenzhen Campus, Shenzhen 518107, Peoples R China.
RP Zhang, P (corresponding author), Sun Yat Sen Univ, Sch Elect & Commun Engn, Shenzhen Campus, Shenzhen 518107, Peoples R China.
EM keqt3@mail2.sysu.edu.cn; zhangpeng5@mail.sysu.edu.cn
OI Ke, Qingtian/0000-0001-7375-8320
FU Shenzhen Science and Technology Program [KQTD20190929172704911]
FX This work was supported in part by the Shenzhen Science and Technology
   Program under Grant KQTD20190929172704911.
CR Adam, 2017, ARXIV170404861, DOI DOI 10.1016/J.JAL.2014.11.010
   Cai L, REMOTE SENS-BASEL, V13, P2021
   Chen H, 2021, IEEE T GEOSCI REMOTE, DOI 10.1109/TGRS.2021.3095166
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen J, 2021, IEEE J-STARS, V14, P1194, DOI 10.1109/JSTARS.2020.3037893
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YP, 2018, ADV NEUR IN, V31
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Fang S, 2021, IEEE GEOSCI REMOTE S, DOI 10.1109/LGRS.2021.3056416
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hao M, 2021, INT J REMOTE SENS, V42, P4005, DOI 10.1080/01431161.2021.1881182
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu, 2020, ARXIV191003151, P11531, DOI [10.1109/CVPR42600.2020.01155, DOI 10.1109/CVPR42600.2020.01155]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Kingma D., 2014, 14126980 ARXIV
   Lei YJ, 2021, IEEE T IMAGE PROCESS, V30, P55, DOI 10.1109/TIP.2020.3031173
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu Y, 2021, IEEE GEOSCI REMOTE S, V18, P811, DOI 10.1109/LGRS.2020.2988032
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Misra D, 2021, IEEE WINT CONF APPL, P3138, DOI 10.1109/WACV48630.2021.00318
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Touati R, 2020, IEEE J-STARS, V13, P588, DOI 10.1109/JSTARS.2020.2964409
   van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YY, 2020, INT J PROD RES, V58, P4808, DOI 10.1080/00207543.2019.1665202
   Yang, P INT C AC SPEECH SI, V2021, P2235
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   You YN, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152460
   Yuan P., 2020, ARXIV201007621
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, REMOTE SENS-BASEL, V13, P2021
   Zhang Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236735
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 57
TC 0
Z9 0
U1 4
U2 4
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 9987
EP 10002
DI 10.1109/JSTARS.2021.3113831
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA WH1JB
UT WOS:000707442300003
OA gold
DA 2022-01-04
ER

PT J
AU Tang, HK
   Wang, HL
   Zhang, XP
AF Tang, Huakang
   Wang, Honglei
   Zhang, Xiaoping
TI A Segmentation Map Difference-Based Domain Adaptive Change Detection
   Method
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Image segmentation; Remote sensing; Task analysis;
   Data mining; Deep learning; Neural networks; Change detection (CD);
   channel attention; domain adaptive; feature extraction; remote sensing
ID IMAGE; ALGORITHMS
AB Deep neural network (DNN) has been widely used in remote sensing image change detection (CD) in recent years. Due to the scarcity of training data, a large number of labeled data onto other fields become the source of DNN concept learning in remote sensing image CD. However, the distribution of features of the CD data and other data varies greatly, which prevents DNN from being better applied for one task to another. To solve this problem, a domain adaptive CD method based on segmentation map difference is proposed to this article, which includes the pretraining stage and the CD stage. In the pretraining stage, the domain adaptive UNet (Ada-UNet) is applied as the basic network of remote sensing image segmentation for network training with the purpose of learning the concepts of different features. In the CD stage, strict threshold segmentation results are used to train the channel attention network, which makes it more efficient to utilize the high-dimensional feature map. The probabilistic map generated by the three-channel attention networks is evaluated, and then it is used to accurately classify the changing pixels. In this article, experiments are carried out on datasets with different feature distributions. The results show that this method has strong domain adaptability and can greatly reduce the influence of the difference in feature distributions of the CD results.
C1 [Tang, Huakang; Wang, Honglei] Guizhou Univ, Sch Elect Engn, Guiyang 550025, Peoples R China.
   [Wang, Honglei] Key Lab Internet Collaborat Intelligent Mfg Guizh, Guiyang, Peoples R China.
   [Zhang, Xiaoping] Sci & Technol Dept Guizhou Prov, Guiyang 550000, Peoples R China.
RP Wang, HL (corresponding author), Guizhou Univ, Sch Elect Engn, Guiyang 550025, Peoples R China.
EM 18311744452@163.com; gzdxhlwang@163.com; 2215093175@qq.com
OI Wang, Honglei/0000-0002-8261-748X
FU Science and Technology Cooperation Program of Guizhou Province
   underGrant (QKH) [[2016]5103]
FX This work was supported by the Science and Technology Cooperation
   Program of Guizhou Province underGrant (QKH[2016]5103)
CR Azorin-Lopez J, 2017, NEURAL COMPUT APPL, V28, pS439, DOI 10.1007/s00521-016-2346-0
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   BHANU B, 1995, IEEE T SYST MAN CYB, V25, P1543, DOI 10.1109/21.478442
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cracknell MJ, 2014, COMPUT GEOSCI-UK, V63, P22, DOI 10.1016/j.cageo.2013.10.008
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Erturk A, 2017, IEEE J-STARS, V10, P321, DOI 10.1109/JSTARS.2016.2606514
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gulcehre Caglar, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P530, DOI 10.1007/978-3-662-44848-9_34
   Hamel P., 2010, ISMIR, P339
   Hegazy Ibrahim Rizk, 2015, International Journal of Sustainable Built Environment, V4, P117, DOI 10.1016/j.ijsbe.2015.02.005
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang Zilong, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3007032
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Li J, 2016, P 25 INT JOINT C ART, P1697
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li YH, 2018, PATTERN RECOGN, V80, P109, DOI 10.1016/j.patcog.2018.03.005
   Li Z., IEEE GEOSCI REMOTE S, DOI [10.1109/LGRS.2020.3017542, DOI 10.1109/LGRS.2020.3017542]
   Liu DS, 2008, REMOTE SENS ENVIRON, V112, P2222, DOI 10.1016/j.rse.2007.10.002
   Liu DN, 2021, IEEE T MED IMAGING, V40, P154, DOI 10.1109/TMI.2020.3023466
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Mohamad I. B., 2013, RES J APPL SCI ENG T, V6, P3299
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Panboonyuen T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010083
   Peng DF, 2021, IEEE T GEOSCI REMOTE, V59, P5891, DOI 10.1109/TGRS.2020.3011913
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Saito K, 2019, PROC CVPR IEEE, P6949, DOI 10.1109/CVPR.2019.00712
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stingo FC, 2013, J AM STAT ASSOC, V108, P876, DOI 10.1080/01621459.2013.804409
   Talo M, 2019, COGN SYST RES, V54, P176, DOI 10.1016/j.cogsys.2018.12.007
   Teney D, 2014, COMPUT VIS IMAGE UND, V125, P265, DOI 10.1016/j.cviu.2014.04.012
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tong XY, 2018, INT GEOSCI REMOTE SE, P3599, DOI 10.1109/IGARSS.2018.8518389
   Volpi M., 2015, P JOINT URB REM SENS, P1
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wang ZH, 2017, APPL SOFT COMPUT, V61, P1113, DOI 10.1016/j.asoc.2017.02.035
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu X, 2021, ISPRS J PHOTOGRAMM, V174, P87, DOI 10.1016/j.isprsjprs.2021.01.023
   Xia Fen, 2008, P INT C MACH LEARN, P1192
   Xie J., 2016, IEEE INT C PROGN HLT, P1, DOI DOI 10.1109/ICPHM.2016.7542845
   Xing C, 2016, J SENSORS, V2016, DOI 10.1155/2016/3632943
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang L, 2020, IEEE T NEUR NET LEAR, V31, P3374, DOI 10.1109/TNNLS.2019.2944455
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103003
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang Z., 2018, ARXIV PREPRINT ARXIV
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhou ZH, 2016, FRONT COMPUT SCI-CHI, V10, P589, DOI 10.1007/s11704-016-6906-3
NR 65
TC 0
Z9 0
U1 6
U2 6
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 9571
EP 9583
DI 10.1109/JSTARS.2021.3113327
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA WC2SC
UT WOS:000704110600006
OA gold
DA 2022-01-04
ER

PT J
AU Li, QX
   Gong, H
   Dai, HS
   Li, CL
   He, ZP
   Wang, WJ
   Feng, YS
   Han, F
   Tuniyazi, A
   Li, HY
   Mu, TK
AF Li, Qiuxia
   Gong, Hang
   Dai, Haishan
   Li, Chunlai
   He, Zhiping
   Wang, Wenjing
   Feng, Yusen
   Han, Feng
   Tuniyazi, Abudusalamu
   Li, Haoyang
   Mu, Tingkui
TI Unsupervised Hyperspectral Image Change Detection via Deep Learning
   Self-Generated Credible Labels
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Deep learning; Training; Task analysis;
   Hyperspectral imaging; Classification algorithms; Convolutional neural
   networks; Change detection (CD); deep learning; heterogeneous images;
   hyperspectral image (HSI); structural similarity (SSIM)
ID SLOW FEATURE ANALYSIS; EO-1 HYPERION; URBAN; MAD
AB Change detection (CD) aims to identify differences in scenes observed at different times. Hyperspectral image (HSI) is preferred for the understanding of land surface changes, since it can provide essential and unique features for CD. However, due to the high-dimensionality and limited data, the HSI-CD task is challenged. While model-driven CD methods are hard to achieve high accuracy due to the weak detection performance for fine changes, data-driven CD methods are hard to be generalized due to the limited datasets. The state-of-art method is to combine a single model-driven method with a data-driven convolutional neural network (CNN). Wherein the pseudolabels can be generated automatically by the model-driven method and then fed to CNN for training. However, the final detection accuracy is limited by the model-driven method which produces pseudolabels with one-sidedness and low accuracy. Therefore, the generation of credible pseudolabels is anticipated and crucial for such a combination. Herein, a novel strategy, the combination of two complementary model-driven methods, structural similarity (SSIM) and change vector analysis (CVA), is proposed to generate credible labels for training a subsequent CNN. The results show that the final accuracy is higher than that of SSIM and CVA. The main contributions of this article are threefold: First, a new paradigm for generating credible labels is proposed. Second, SSIM is used for the first time for HSI-CD tasks. Third, an unsupervised end-to-end framework is presented for the HSI-CD. Experimental results demonstrate the effectiveness of the proposed framework.
C1 [Li, Qiuxia; Gong, Hang; Wang, Wenjing; Feng, Yusen; Han, Feng; Tuniyazi, Abudusalamu; Li, Haoyang; Mu, Tingkui] Xi An Jiao Tong Univ, Minist Educ,Sch Phys, Key Lab Nonequilibrium Synth & Modulat Condensed, Shaanxi Prov Key Lab Quantum Informat & Quantum O, Xian 710049, Peoples R China.
   [Dai, Haishan] Shanghai Acad Spaceflight Technol, Shanghai Inst Satellite Engn, Shanghai 201109, Peoples R China.
   [Li, Chunlai; He, Zhiping] Chinese Acad Sci, Shanghai Inst Tech Phys, Shanghai 200083, Peoples R China.
RP Mu, TK (corresponding author), Xi An Jiao Tong Univ, Minist Educ,Sch Phys, Key Lab Nonequilibrium Synth & Modulat Condensed, Shaanxi Prov Key Lab Quantum Informat & Quantum O, Xian 710049, Peoples R China.
EM lqx0324@stu.xjtu.edu.cn; gh0000@stu.xjtu.edu.cn; dhs1314@126.com;
   lichunlai@mail.sitp.ac.cn; hzping@mail.sitp.ac.cn;
   wjwang@stu.xjtu.edu.cn; 3207650009@qq.com; 573378205@qq.com;
   abdusalam1112@stu.xjtu.edu.cn; lihaoyang@stu.xjtu.edu.cn;
   tkmu@mail.xjtu.edu.cn
RI LI, Chunlai/ABG-3649-2021
OI Mu, Tingkui/0000-0002-7927-7760
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61775176, 62175196]; National Major Special
   Projects of China [GFZX04014308]; Shaanxi Province Key Research and
   Development Program [2021GXLH-Z-058, 2020GY-131, 2021SF-135]; Innovation
   Capability Support Program of Shaanxi [2021TD-57]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [xjh012020021]; Natural Science Foundation of
   ShanghaiNatural Science Foundation of Shanghai [8ZR1437200]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61775176 and Grant 62175196, in part by
   the National Major Special Projects of China under Grant GFZX04014308,
   in part by the Shaanxi Province Key Research and Development Program
   under Grant 2021GXLH-Z-058, Garnt 2020GY-131, and Grant 2021SF-135, in
   part by the Innovation Capability Support Program of Shaanxi under Grant
   2021TD-57, in part by the Fundamental Research Funds for the Central
   Universities under Grant xjh012020021, and in part by the Natural
   Science Foundation of Shanghai under Grant 8ZR1437200.
CR Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen Z., 2017, REMOTE SENS-BASEL, V9, P1
   Datt B, 2003, IEEE T GEOSCI REMOTE, V41, P1246, DOI 10.1109/TGRS.2003.813206
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Eismann MT, 2008, IEEE T GEOSCI REMOTE, V46, P237, DOI 10.1109/TGRS.2007.907973
   Erturk A, 2016, IEEE J-STARS, V9, P708, DOI 10.1109/JSTARS.2015.2477431
   Erturk A, 2015, IEEE GEOSCI REMOTE S, V12, P1252, DOI 10.1109/LGRS.2015.2390973
   Folkman M, 2001, P SOC PHOTO-OPT INS, V4151, P40, DOI 10.1117/12.417022
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   JACKSON RD, 1983, REMOTE SENS ENVIRON, V13, P409, DOI 10.1016/0034-4257(83)90010-X
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Mundia CN, 2005, INT J REMOTE SENS, V26, P2831, DOI 10.1080/01431160500117865
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Pearlman JS, 2003, IEEE T GEOSCI REMOTE, V41, P1160, DOI 10.1109/TGRS.2003.815018
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Qian D., 2005, P INT WORKSH AN MULT
   Ronneberger O., 2015, P INT C MED IM COMP
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Singh B. A, 1996, CHANGE DETECTION TRO
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen DW, 2016, IEEE T GEOSCI REMOTE, V54, P609, DOI 10.1109/TGRS.2015.2463075
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wiskott L., 2011, SCHOLARPEDIA, V6
   Wu C, 2018, ISPRS J PHOTOGRAMM, V146, P137, DOI 10.1016/j.isprsjprs.2018.09.005
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 54
TC 0
Z9 0
U1 7
U2 7
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 9012
EP 9024
DI 10.1109/JSTARS.2021.3108777
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA UT0NW
UT WOS:000697823200004
OA gold
DA 2022-01-04
ER

PT J
AU Isaienkov, K
   Yushchuk, M
   Khramtsov, V
   Seliverstov, O
AF Isaienkov, Kostiantyn
   Yushchuk, Mykhailo
   Khramtsov, Vladyslav
   Seliverstov, Oleg
TI Deep Learning for Regular Change Detection in Ukrainian Forest Ecosystem
   With Sentinel-2
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; convolutional neural network (CNN); deep learning;
   deforestation; logging; LSTM; optical imagery; semantic segmentation;
   U-Net
ID DEFORESTATION; COVER
AB The logging is the leading cause for the reduction in the forest area in the world. At the same time, the number of forest clearcuts continues to grow. However, despite the massive scale, such incidents are difficult to track in time. As a result, huge areas of forests are gradually being cut down. Therefore, there is a need for regular and effective monitoring of changes in forest cover. The multitemporal data sources like Copernicus Sentinel-2 allow enhancing the potential of monitoring the Earth's surface and environmental dynamics including forest plantations. In this article, we present a baseline U-Net model for deforestation detection in the forest-steppe zone. Training and evaluation are conducted on our own dataset created on Sentinel-2 imagery for the Kharkiv region of Ukraine (31 400 km(2)). As a part of the research, we present several models with the ability to work with time-dependent imagery. The main contribution of this article is to provide a baseline model for the forest change detection inside Ukraine and improve it adding the ability to use several sequential images as an input of the segmentation model.
C1 [Isaienkov, Kostiantyn; Yushchuk, Mykhailo; Khramtsov, Vladyslav] Quantum, UA-61072 Kharkiv, Ukraine.
   [Seliverstov, Oleg] Kharkov Natl Univ, SCGIS Ukraine, UA-61022 Kharkiv, Ukraine.
RP Khramtsov, V (corresponding author), Quantum, UA-61072 Kharkiv, Ukraine.
EM k.isaienkov@quantumobile.com; m.yushchuk@quantumobile.com;
   v.khramtsov@quantumobile.com; oleg.seliverstov@physgeo.com
OI Khramtsov, Vladislav/0000-0003-1744-7071
CR Aide TM, 2013, BIOTROPICA, V45, P262, DOI 10.1111/j.1744-7429.2012.00908.x
   Amin A, 2019, J ENVIRON ECON MANAG, V93, P272, DOI 10.1016/j.jeem.2018.11.006
   Asner GP, 2009, J APPL REMOTE SENS, V3, DOI 10.1117/1.3223675
   Banskota A, 2014, CAN J REMOTE SENS, V40, P362, DOI 10.1080/07038992.2014.987376
   Bolyn C, 2018, BIOTECHNOL AGRON SOC, V22, P172
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Buchhorn M, 2019, ESA LIV PLAN S MIL I
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chernyavsky MV, 1997, NATO ASI 2, V30, P195
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Council of Europe, 2020, BERN CONV CONS EUR W
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060901
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   ESA Sentinel-2 Team, 2007, EOPSM1163MRDR ESA SE
   Ghulam A, 2008, AGR FOREST METEOROL, V148, P1679, DOI 10.1016/j.agrformet.2008.05.020
   Goodwin NR, 2008, REMOTE SENS ENVIRON, V112, P3680, DOI 10.1016/j.rse.2008.05.005
   Hamunyela E, 2016, REMOTE SENS ENVIRON, V172, P126, DOI 10.1016/j.rse.2015.11.006
   Hansen MC, 2008, REMOTE SENS ENVIRON, V112, P2495, DOI 10.1016/j.rse.2007.11.012
   Hanson MA, 2012, SCIENCE, V335, P851, DOI [10.1126/science.1215904, 10.1126/science.1244693]
   Hayes DJ, 2001, PHOTOGRAMM ENG REM S, V67, P1067
   He K., P IEEE INT C COMP VI, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hethcoat MG, 2019, REMOTE SENS ENVIRON, V221, P569, DOI 10.1016/j.rse.2018.11.044
   HINTON GE, 1989, ARTIF INTELL, V40, P185, DOI 10.1016/0004-3702(89)90049-0
   Hirschmugl M, 2017, CURR FOR REP, V3, P32, DOI 10.1007/s40725-017-0047-2
   Housman IW, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081184
   Iqbal, 2018, HARISIQBAL88 PLOTNEU
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kingma D., 2014, 14126980 ARXIV
   KNIPLING E B, 1970, Remote Sensing of Environment, V1, P155, DOI 10.1016/S0034-4257(70)80021-9
   KOROBOV RM, 1993, REMOTE SENS ENVIRON, V43, P1, DOI 10.1016/0034-4257(93)90059-7
   Lima TA, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080961
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   MacDicken K., 2016, GLOBAL FOREST RESOUR
   Masiliunas D., 2017, EVALUATING POTENTIAL
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Ministry of ecology and natural resources of Ukraine, 26022020 MIN EC NAT
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   NASA, MODIS
   NASA, LANDSAT
   Ortega M, ISPRS ANN PHOTOGRAMM
   Papadomanolaki M, 2019, ARXIV191007778
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   QGISDevelopment Team, 2009, QGIS GEOGR INF SYST
   Rasuly A, 2010, PROCEDIA ENVIRON SCI, V2, P454, DOI 10.1016/j.proenv.2010.10.050
   Ronneberger O., 2015, INT C MEDICAL IMAGE, P234
   Rouse Jr J. W, 1974, P 3 EARTH RES TECHN, V351
   Sentinel-Hub, SENTINEL2 CLOUD DET
   Shi X., 2015, ARXIV150604214
   Simard PY, 2003, PROC INT CONF DOC, P958
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wu L, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020341
   WWF-Ukraine, 2019, WWF INT TEAM ADDR FO
   Xie QY, 2018, IEEE J-STARS, V11, P1482, DOI 10.1109/JSTARS.2018.2813281
   Yismaw A, 2014, INT J ENV MONIT ANAL, V2
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zupanc A, 2019, P LIV PLAN S MAY
NR 61
TC 2
Z9 3
U1 5
U2 5
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 364
EP 376
DI 10.1109/JSTARS.2020.3034186
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA TS9IX
UT WOS:000679962200001
OA gold
DA 2022-01-04
ER

PT J
AU Zhan, TM
   Song, B
   Sun, L
   Jia, XP
   Wan, MH
   Yang, GW
   Wu, ZB
AF Zhan, Tianming
   Song, Bo
   Sun, Le
   Jia, Xiuping
   Wan, Minghua
   Yang, Guowei
   Wu, Zebin
TI TDSSC: A Three-Directions Spectral-Spatial Convolution Neural Network
   for Hyperspectral Image Change Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection (CD); hyperspectral image (HSI); spectral-spatial
   combination; three directions convolution neural network
ID ANOMALY DETECTION; FRAMEWORK; MAD
AB Change detection (CD) is a hot issue in the research of remote sensing technology. Hyperspectral images (HSIs) greatly promote the development of CD technology because of their high resolution in the spectral domain. However, some traditional CD methods currently applied to low-dimensional and multispectral images cannot adapt to the complex high-dimensional features of the HSIs. In addition, the spectral measurements of the HSI contain a lot of noise and redundancy, which greatly contaminates spectral-only information for CD. In order to fully extract the discriminant features of HSI to improve the accuracy of CD, this article proposes a three-directions spectral-spatial convolution neural network (TDSSC). A novel method for three-direction decomposition of hyperspectral change tensors is proposed-change tensor is decomposed along the spectral direction and two spatial directions to get a single tensor containing the spectral information and two kinds of tensors containing the spectral-spatial information. TDSSC uses 1-D convolution to extract spectral features from the spectral direction as well as reducing the tensor dimension, which helps the latter network to be lightweight and significantly improves the speed of change detection. Also, it uses 2-D convolution to extract spectral-spatial features from two spatial directions of the reduced tensor, and to extract features from different directions to improve the accuracy and Kappa value of CD. The experimental results of three real hyperspectral datasets show that TDSSC is superior to most existing CD methods.
C1 [Zhan, Tianming; Song, Bo] Nanjing Audit Univ, Collaborat Innovat Ctr Audit Informat Engn & Tech, Nanjing 211815, Peoples R China.
   [Zhan, Tianming; Song, Bo; Wan, Minghua; Yang, Guowei] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Peoples R China.
   [Sun, Le] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
   [Jia, Xiuping] Univ New South Wales, Sch Engn & Informat Technol, Canberra, BC 2610, Australia.
   [Wu, Zebin] Nanjing Univ Sci & Technol, Nanjing 210094, Peoples R China.
RP Wu, ZB (corresponding author), Nanjing Univ Sci & Technol, Nanjing 210094, Peoples R China.
EM ztm@nau.edu.cn; mg1909003@stu.nau.edu; sunlecncom@nuist.edu.cn;
   x.jia@adfa.edu.au; wanmh@sina.com; ygw_ustb@163.com; zebin.wu@gmail.com
OI Le, Sun/0000-0001-6465-8678; Wu, Zebin/0000-0002-7162-0202
FU National Natural Science Foundation ofChinaNational Natural Science
   Foundation of China (NSFC) [61976117, 61876213, 61772274]; Natural
   Science Foundation of Jiangsu ProvinceNatural Science Foundation of
   Jiangsu Province [BK20191409, BK20180018]; Key Projects of University
   Natural Science Fund of Jiangsu Province [19KJA360001, 18KJA520005];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [30917015104, 30919011103,
   30919011402]; Collaborative Innovation Center of Audit Information
   Engineering and Technology [18CICA09]; Young Teacher Research and
   Cultivation Project of Nanjing Audit University [18QNPY015];
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX20_1680]
FX This work was supported in part by the National Natural Science
   Foundation ofChina underGrant 61976117, Grant 61876213, and Grant
   61772274, in part by the Natural Science Foundation of Jiangsu Province
   under Grant BK20191409 and Grant BK20180018, in part by the Key Projects
   of University Natural Science Fund of Jiangsu Province underGrant
   19KJA360001 and Grant 18KJA520005, in part by the Fundamental Research
   Funds for the Central Universities, under Grant 30917015104, Grant
   30919011103, and Grant 30919011402, in part by the Collaborative
   Innovation Center of Audit Information Engineering and Technology under
   Grant 18CICA09, in part by the Young Teacher Research and Cultivation
   Project of Nanjing Audit University under Grant 18QNPY015, and in part
   by the Postgraduate Research & Practice Innovation Program of Jiangsu
   Province under Grant KYCX20_1680.
CR Acito N, 2017, IEEE AERO EL SYS MAG, V32, P2, DOI 10.1109/MAES.2017.160155
   Benedetti A, 2018, INT GEOSCI REMOTE SE, P1962, DOI 10.1109/IGARSS.2018.8517586
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2016, REMOTE SENS DIGIT IM, V20, P63, DOI 10.1007/978-3-319-47037-5_4
   Chen LL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091395
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen Z, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101044
   Chen Z, 2017, SEC 2017: 2017 THE SECOND ACM/IEEE SYMPOSIUM ON EDGE COMPUTING (SEC'17), DOI [10.1145/3132211.3134458, 10.1080/09537104.2017.1384542]
   Dalmiya CP, 2019, EGYPT J REMOTE SENS, V22, P183, DOI 10.1016/j.ejrs.2018.03.005
   Erturk A., 2015, P 7 WORKSH HYP IM SI P 7 WORKSH HYP IM SI, P1
   Erturk A, 2016, IEEE J-STARS, V9, P708, DOI 10.1109/JSTARS.2015.2477431
   Ferraris V, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102817
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Henrot S, 2016, IEEE T IMAGE PROCESS, V25, P3219, DOI 10.1109/TIP.2016.2562562
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Huang M., 2010, P IEEE GLOB TEL C GL, P1, DOI DOI 10.1109/ICIECS.2010.5678245
   Ioffe S, 2015, P 32 INT C MACH LEAR
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LIU S, 2017, REMOTE SENS, V9, P1, DOI DOI 10.3390/rs9121329
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Lu LL, 2019, SCI TOTAL ENVIRON, V684, P567, DOI 10.1016/j.scitotenv.2019.05.344
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594
   Mu CH, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105727
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ran Q., 2018, P 5 INT WORKSH EARTH P 5 INT WORKSH EARTH, P1
   Song SZ, 2019, INFRARED PHYS TECHN, V96, P340, DOI 10.1016/j.infrared.2018.12.008
   Tao R, 2019, IEEE J-STARS, V12, P4920, DOI 10.1109/JSTARS.2019.2940278
   [佟国峰 Tong Guofeng], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1561
   Tu B, 2020, PATTERN RECOGN LETT, V129, P144, DOI 10.1016/j.patrec.2019.11.022
   Vongsy K., 2016, P 8 WORKSH HYP IMAG P 8 WORKSH HYP IMAG, P1
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Xie WY, 2019, NEURAL NETWORKS, V119, P222, DOI 10.1016/j.neunet.2019.08.012
   Yan JN, 2019, ISPRS J PHOTOGRAMM, V158, P249, DOI 10.1016/j.isprsjprs.2019.10.003
   Yao XF, 2018, INFRARED PHYS TECHN, V92, P144, DOI 10.1016/j.infrared.2018.05.028
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao JQ, 2017, INT GEOSCI REMOTE SE, P1896, DOI 10.1109/IGARSS.2017.8127348
NR 46
TC 1
Z9 1
U1 7
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 377
EP 388
DI 10.1109/JSTARS.2020.3037070
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA TS9IX
UT WOS:000679962200002
OA gold
DA 2022-01-04
ER

PT J
AU Luo, X
   Li, XX
   Wu, YX
   Hou, WM
   Wang, M
   Jin, YW
   Xu, WB
AF Luo, Xin
   Li, Xiaoxi
   Wu, Yuxuan
   Hou, Weimin
   Wang, Meng
   Jin, Yuwei
   Xu, Wenbo
TI Research on Change Detection Method of High-Resolution Remote Sensing
   Images Based on Subpixel Convolution
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; DeepLabv3+; deep convolutional generative adversarial
   networks (DCGAN); deep learning; subpixel convolution
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION
AB Remote sensing image change detection method plays a great role in land cover research, disaster assessment, medical diagnosis, video surveillance, and other fields, so it has attracted wide attention. Based on a small sample dataset from SZTAKI Air-Change Benchmark Set, in order to solve the problem that the deep learning network needs a large number of samples, this work first uses nongenerative sample augmentation method and generative sample augmentation method based on deep convolutional generative adversarial networks, and then, constructs a remote sensing image change detection model based on an improved DeepLabv3+ network. This model can realize end-to-end training and prediction of remote sensing image change detection with subpixel convolution. Finally, Landsat 8, Google Earth, and Onera satellite change detection datasets are used to verify the generalization performance of this network. The experimental results show that the improved network accuracy is 95.1% and the generalization performance is acceptable.
C1 [Luo, Xin; Li, Xiaoxi; Wu, Yuxuan; Wang, Meng; Jin, Yuwei; Xu, Wenbo] Univ Elect Sci & Technol China, Sch Resources & Environm, Chengdu 611731, Peoples R China.
   [Hou, Weimin] Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang 050018, Hebei, Peoples R China.
RP Luo, X (corresponding author), Univ Elect Sci & Technol China, Sch Resources & Environm, Chengdu 611731, Peoples R China.; Hou, WM (corresponding author), Hebei Univ Sci & Technol, Sch Informat Sci & Engn, Shijiazhuang 050018, Hebei, Peoples R China.
EM luoxin@uestc.edu.cn; wulala@std.uestc.edu.cn; wuyuxuan@std.uestc.edu.cn;
   hwm@hebust.edu.cn; wangmengkkk@std.uestc.edu.cn; yuweijin@163.com;
   xuwenbo@uestc.edu
OI Li, Xiaoxi/0000-0002-7062-8747; Luo, Xin/0000-0002-9534-592X
FU Science and Technology Program of Sichuan [2017GZ0327]; Science and
   Technology Program of Hebei [19255901D]; National Defense Science and
   Technology Key Laboratory of Remote Sensing Information and Image
   Analysis Technology of China [6142A010301]; Chinese Air-Force Equipment
   Pre-Research Project [10305***02]
FX This work was supported in part by the Science and Technology Program of
   Sichuan under Grant 2017GZ0327, in part by the Science and Technology
   Program of Hebei under Grant 20355901D, in part by the Science and
   Technology Program of Hebei under Grant 19255901D, in part by the
   National Defense Science and Technology Key Laboratory of Remote Sensing
   Information and Image Analysis Technology of China under Grant
   6142A010301, and in part by the Chinese Air-Force Equipment Pre-Research
   Project under Grant 10305***02
CR Alberga V, 2007, INT J REMOTE SENS, V28, P3851, DOI 10.1080/01431160601075541
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedek C, 2008, INT C PATT RECOG, P1686
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen L. C., 2017, COMPT VIS PATTERN RE
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   [杜培军 Du Peijun], 2016, [遥感学报, Journal of Remote Sensing], V20, P236
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hagner O, 2007, REMOTE SENS ENVIRON, V110, P438, DOI 10.1016/j.rse.2006.08.017
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   HEERMANN PD, 1992, IEEE T GEOSCI REMOTE, V30, P81, DOI 10.1109/36.124218
   Huang QQ, 2017, INT GEOSCI REMOTE SE, P1095, DOI 10.1109/IGARSS.2017.8127147
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jia L, 2016, IEEE J-STARS, V9, P3405, DOI 10.1109/JSTARS.2015.2508043
   Jipu Gao, 2017, 2017 International Conference on Computing Intelligence and Information System (CIIS). Proceedings, P332, DOI 10.1109/CIIS.2017.54
   Kesikoglu Mustafa Hayri, 2017, 2017 8th International Conference on Information Technology (ICIT). Proceedings, P737, DOI 10.1109/ICITECH.2017.8079936
   Kokkinos, 2014, COMPUT SCI, P357, DOI DOI 10.1080/17476938708814211
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2003, IEEE T GEOSCI REMOTE, V41, P2466, DOI 10.1109/TGRS.2003.817267
   Li W, 2015, INT GEOSCI REMOTE SE, P1686, DOI 10.1109/IGARSS.2015.7326111
   Lin Wu, 2017, 2017 International Conference on Computing Intelligence and Information System (CIIS). Proceedings, P214, DOI 10.1109/CIIS.2017.39
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu X, 2013, INT J REMOTE SENS, V34, P1, DOI 10.1080/01431161.2012.700133
   Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ponce J, 2006, P IEEE INT C COMP VI, V2, P2169, DOI DOI 10.1109/CVPR.2006.68
   Radford A, 2015, ARXIV 1511 06434
   Robert Christian, 2014, CHANCE, V27, P62, DOI DOI 10.1080/09332480.2014.914768
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shao Y., 2017, 2017 2 INT C REL SYS, P1
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Su R., 2019, COMPUT VIS PATTERN R
   Sumaiya MN, 2016, IEEE GEOSCI REMOTE S, V13, P1726, DOI 10.1109/LGRS.2016.2606119
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhong YF, 2015, IEEE GEOSCI REMOTE S, V12, P537, DOI 10.1109/LGRS.2014.2349937
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 44
TC 1
Z9 1
U1 31
U2 34
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 1447
EP 1457
DI 10.1109/JSTARS.2020.3044060
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA SW4EB
UT WOS:000664467600001
OA gold
DA 2022-01-04
ER

PT J
AU Song, KQ
   Jiang, J
AF Song, Kaiqiang
   Jiang, Jie
TI AGCDetNet:An Attention-Guided Network for Building Change Detection in
   High-Resolution Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Buildings; Feature extraction; Training; Task analysis; Semantics;
   Remote sensing; Spatial resolution; Attention mechanism; end-to-end
   change detection (CD); fully convolutional network (FCN); high
   resolution; remote sensing (RS) images
ID CHANGE VECTOR ANALYSIS; SENSED IMAGES; LAND-COVER
AB While deep learning-based methods have gained considerable improvements in remote sensing (RS) image change detection (CD), scale variations and pseudochanges hinder most supervised methods' performance. The CD networks derived from other fields can be fronted with false alarms and miss detections in high-resolution RS images due to the weak feature representation ability. In this article, an attention-guided end-to-end change detection network (AGCDetNet) is proposed based on the fully convolutional network and attention mechanism. AGCDetNet learns to enhance the feature representation of change information and achieve accuracy improvements using spatial attention and channel attention. A spatial attention module (SPAM) promotes the discrimination between the changed objects and the background by adding the learned spatial attention to the deep features. Channelwise attention-guided interference filtering unit (CIFU)/atrous spatial pyramid pooling (CG-ASPP) module enhances the representation of multilevel features and multiscale context, respectively. Extensive experiments have been conducted on several public datasets for performance evaluation, including LEVIR-CD, WHU, Season-Varying, WV2, and ZY3. Experiment results demonstrate that AGCDetNet outperforms several state-of-the-art methods of accuracy and robustness. Specifically, AGCDetNet achieves the best F1-score on two datasets, i.e., LEVIR-CD (0.9076) and Season-Varying (0.9654).
C1 [Song, Kaiqiang; Jiang, Jie] Beihang Univ, Beijing Adv Innovat Ctr Big Data Based Precis Med, Sch Instrumentat & Optoelect Engn, Key Lab Precis Optomechatron Technol,Minist Educ, Beijing 100191, Peoples R China.
RP Jiang, J (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Big Data Based Precis Med, Sch Instrumentat & Optoelect Engn, Key Lab Precis Optomechatron Technol,Minist Educ, Beijing 100191, Peoples R China.
EM kaiqiangsong@buaa.edu.cn; jiangjie@buaa.edu.cn
OI Song, Kaiqiang/0000-0001-8203-9723
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61725501]; National Key Research and
   Development Program of China [2019YFA0706002]; High Performance
   Computing Resources at Beihang University
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61725501, in part by the National Key
   Research and Development Program of China under Grant 2019YFA0706002,
   and in part by the High Performance Computing Resources at Beihang
   University
CR Antiga L., 2019, ADV NEURAL INFORM PR, P8024, DOI DOI 10.1038/S41591-021-01287-9
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen H, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101662
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen J., 2020, DASNET DUAL ATTENTIV, DOI DOI 10.1109/JSTARS.2020.3037893
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gupta R., 2019, P IEEE C COMP VIS PA, P10
   HAN J, IN PRESS, DOI DOI 10.1109/TPAMI.2019.2933510
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   IGLOVIKOV V, 2018, PROC IEEE C COMPUT V, P237
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Li Q., IEEE T GEOSCI ELECT, DOI [10.1109/TPAMI.2019.2933510, DOI 10.1109/TPAMI.2019.2933510]
   Li XL, 2021, IEEE T CYBERNETICS, V51, P913, DOI 10.1109/TCYB.2019.2914351
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loshchilov I., 2019, J PHYS CONF SER
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P1985, DOI 10.1109/TGRS.2019.2951636
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pesaresi M, 2011, IEEE J-STARS, V4, P923, DOI 10.1109/JSTARS.2011.2162579
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Tengfei Bao, 2020, ICMLC 2020: Proceedings of the 2020 12th International Conference on Machine Learning and Computing, P259, DOI 10.1145/3383972.3383986
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Vaswani A, 2017, ADV NEUR IN, V30
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yavariabdi A, 2017, IEEE GEOSCI REMOTE S, V14, P414, DOI 10.1109/LGRS.2016.2645742
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CX, 2020, ISPRS J PHOTOGRAMM, V166, P183, DOI 10.1016/j.isprsjprs.2020.06.003
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhang Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236735
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zheng Z, 2020, PROC CVPR IEEE, P4095, DOI 10.1109/CVPR42600.2020.00415
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 72
TC 1
Z9 1
U1 21
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 4816
EP 4831
DI 10.1109/JSTARS.2021.3077545
PG 16
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA SN5OZ
UT WOS:000658340100002
OA gold
DA 2022-01-04
ER

PT J
AU Li, H
   Gong, MG
   Zhang, MY
   Wu, Y
AF Li, Hao
   Gong, Maoguo
   Zhang, Mingyang
   Wu, Yue
TI Spatially Self-Paced Convolutional Networks for Change Detection in
   Heterogeneous Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Training; Synthetic aperture radar; Optical sensors; Task analysis;
   Optical imaging; Image sensors; Speckle; Change detection; convolutional
   neural networks (CNNs); heterogeneous images; self-paced learning (SPL)
ID UNSUPERVISED CHANGE DETECTION; REMOTE-SENSING IMAGES; STATISTICAL-MODEL;
   FRAMEWORK
AB Change detection in heterogeneous remote sensing images is a challenging problem because it is hard to make a direct comparison in the original observation spaces, and most methods rely on a set of manually labeled samples. In this article, a spatially self-paced convolutional network (SSPCN) is constructed for change detection in an unsupervised way. Self-paced learning (SPL) is incorporated into convolutional networks to dynamically select reliable samples and learn the representation of the relations between the two heterogeneous images. In the proposed method, the pseudo labels are initialized by a classification-based method, and each sample is assigned to a weight to reflect the easiness of the sample. Then, SPL is used to learn the easy samples at first and then gradually take more complex samples into account. In the training process, the sample weights are dynamically updated based on the network parameters. Finally, a binary change map is acquired based on the trained convolutional network. The proposed SSPCN has three main advantages compared to the traditional methods. First, the proposed method is robust to noisy samples because the SSPCN involves the reliable samples into training. Second, the samples have different learning rates for converging to better values, and the learning rates are dynamically changed based on the current sample weights during iterations. Finally, we take the spatial information among the samples into account for further enhancing the robustness of the proposed method. Experimental results on four pairs of heterogeneous remote sensing images confirm the effectiveness of the proposed technique.
C1 [Li, Hao; Gong, Maoguo; Zhang, Mingyang] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Peoples R China.
   [Wu, Yue] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ China, Xian 710071, Peoples R China.
EM omegalihao@gmail.com; gong@ieee.org; OMEGAZhangMY@gmail.com;
   ywu@xidian.edu.cn
OI Li, Hao/0000-0002-6294-6761; Zhang, Mingyang/0000-0002-9768-516X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61906146, 62036006]; Fundamental Research
   Funds for the Central UniversitiesFundamental Research Funds for the
   Central Universities [JB210210]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61906146 and Grant 62036006, in part by
   the Fundamental Research Funds for the Central Universities under Grant
   JB210210, and in part by the CAAI Huawei MindSpore Open Fund.
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio Y., 2009, P 26 ANN INT C MACH, P41, DOI DOI 10.1145/1553374.1553380
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Gleich D, 2018, IEEE T GEOSCI REMOTE, V56, P6674, DOI 10.1109/TGRS.2018.2841191
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Jiang L., 2014, P ADV NEURAL INF PRO, V27, P2078
   Jiang L, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P547, DOI 10.1145/2647868.2654918
   Jiang L, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2694
   Jin JQ, 2014, IEEE T INTELL TRANSP, V15, P1991, DOI 10.1109/TITS.2014.2308281
   Kumar M. P., 2010, ADV NEURAL INFORM PR
   Kumar MP, 2011, IEEE I CONF COMP VIS, P1800, DOI 10.1109/ICCV.2011.6126446
   Lee YJ, 2011, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2011.5995523
   Li H, 2021, IEEE T CYBERNETICS, V51, P4187, DOI 10.1109/TCYB.2019.2935762
   Li H, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1802
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Liu SC, 2019, IEEE J-STARS, V12, P3578, DOI 10.1109/JSTARS.2019.2929514
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Omati M, 2018, IEEE J-STARS, V11, P4170, DOI 10.1109/JSTARS.2018.2874517
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Shang R, 2018, SIGNAL PROCESS, V142, P375, DOI 10.1016/j.sigpro.2017.07.023
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tang K., 2012, ADV NEURAL INFORM PR, V25, P638
   Tong XH, 2020, IEEE J-STARS, V13, P2056, DOI 10.1109/JSTARS.2020.2990481
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhao Q, 2015, PROCEEDINGS OF THE TWENTY-NINTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3196
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 41
TC 0
Z9 0
U1 11
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 4966
EP 4979
DI 10.1109/JSTARS.2021.3078437
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA SN5OZ
UT WOS:000658340100006
OA gold
DA 2022-01-04
ER

PT J
AU Lee, H
   Lee, K
   Kim, JH
   Na, Y
   Park, J
   Choi, JP
   Hwang, JY
AF Lee, Haeyun
   Lee, Kyungsu
   Kim, Jun Hee
   Na, Younghwan
   Park, Juhum
   Choi, Jihwan P.
   Hwang, Jae Youn
TI Local Similarity Siamese Network for Urban Land Change Detection on
   Remote Sensing Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Remote sensing; Feature extraction; Decoding; Training; Network
   architecture; Task analysis; Deep learning; Change detection; remote
   sensing; Siamese network; similarity attention
ID ATTENTION
AB Change detection is an important task in the field of remote sensing. Various change detection methods based on convolutional neural networks (CNNs) have recently been proposed for remote sensing using satellite or aerial images. However, existing methods allow only the partial use of content information in images during change detection because they adopt simple feature similarity measurements or pixel-level loss functions to construct their network architectures. Therefore, when these methods are applied to complex urban areas, their performance in terms of change detection tends to be limited. In this article, a novel CNN-based change detection approach, referred to as a local similarity Siamese network (LSS-Net), with a cosine similarity measurement, was proposed for better urban land change detection in remote sensing images. To use content information on two sequential images, a new change attention map-based content loss function was developed in this study. In addition, to enhance the performance of the LSS-Net in terms of change detection, a suitable feature similarity measurement method, incorporated into a local similarity attention module, was determined through systemic experiments. To verify the change detection performance of the LSS-Net, it was compared with other state-of-the-art methods. The experimental results show that the proposed method outperforms the state-of-the-art methods in terms of the F1 score (0.9630, 0.9377, and 0.7751) and kappa (0.9581, 0.9351, and 0.7646) on the three test datasets, thus suggesting its potential for various remote sensing applications.
C1 [Lee, Haeyun; Lee, Kyungsu; Na, Younghwan; Hwang, Jae Youn] Daegu Gyeongbuk Inst Sci & Technol, Informat & Commun Engn, Daegu 42988, South Korea.
   [Kim, Jun Hee] Agcy Def Dev, Daejoen 34186, South Korea.
   [Park, Juhum] Dabeeo Inc, Seoul 04107, South Korea.
   [Choi, Jihwan P.] Korea Adv Inst Sci & Technol, Dept Aerosp Engn, Daejoen 34141, South Korea.
RP Hwang, JY (corresponding author), Daegu Gyeongbuk Inst Sci & Technol, Informat & Commun Engn, Daegu 42988, South Korea.
EM haeyun@dgist.ac.kr; ks_lee@dgist.ac.kr; kjh1127@add.re.kr;
   nyh0426@dgist.ac.kr; juhum.park@dabeeo.com; jhch@kaist.ac.kr;
   jyhwang@dgist.ac.kr
OI Lee, Haeyun/0000-0002-7572-1705; Lee, Kyung su/0000-0003-2516-7598;
   Hwang, Jae Youn/0000-0003-4659-6009
FU National Research Fundation of Korea (NRF) [NRF-2020R1A2B5B01002786];
   Bio & Medical Technology Development Program of the National Research
   Foundation (NRF) through the Korean Government (MSIT)
   [NRF-2017M3A9G8084463]
FX This work was supported in part by the National Research Fundation of
   Korea (NRF) under Grant NRF-2020R1A2B5B01002786. The work of
   JaeYounHwangwas supported in part by the Bio & Medical Technology
   Development Program of the National Research Foundation (NRF) through
   the Korean Government (MSIT) under Grant NRF-2017M3A9G8084463.
CR Adamko P, 2017, GLOBALIZATION AND ITS SOCIO-ECONOMIC CONSEQUENCES, PTS I - VI, P1
   Atzberger C, 2013, REMOTE SENS-BASEL, V5, P949, DOI 10.3390/rs5020949
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Chen H, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519864971
   Chen LC, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3525560
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Kingma D. P., 2015, P INT C LEARN REPR
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI [10.1109/TCYB.2020.2971638, 10.1109/TGRS.2020.3018879]
   Munyati C, 2000, INT J REMOTE SENS, V21, P1787, DOI 10.1080/014311600209742
   Na Y, 2021, IEEE T GEOSCI REMOTE, V59, P5171, DOI 10.1109/TGRS.2020.3010055
   Nghiem SV, 2001, J GLACIOL, V47, P539, DOI 10.3189/172756501781831738
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh PP, 2013, J INDIAN SOC REMOTE, V41, P631, DOI 10.1007/s12524-012-0241-4
   Varghese A., 2018, P EUR C COMP VIS ECC, P1
   Wei Z., 2020, IEEE GEOSCI REMOTE S, DOI 10.1109/LGRS. 2020.3026587
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang JP, 2016, IEEE J-STARS, V9, P2343, DOI 10.1109/JSTARS.2016.2536943
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 36
TC 1
Z9 1
U1 24
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 4139
EP 4149
DI 10.1109/JSTARS.2021.3069242
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA RU3XE
UT WOS:000645081200011
OA gold
DA 2022-01-04
ER

PT J
AU Hu, MQ
   Wu, C
   Zhang, LP
   Du, B
AF Hu, Meiqi
   Wu, Chen
   Zhang, Liangpei
   Du, Bo
TI Hyperspectral Anomaly Change Detection Based on Autoencoder
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Hyperspectral imaging; Predictive models; Imaging;
   Decoding; Training; Image reconstruction; Anomaly change detection;
   autoencoder (AE); feature extraction; hyperspectral image (HSI)
AB With the hyperspectral imaging technology, hyperspectral data provides abundant spectral information and plays a more important role in the geological survey, vegetation analysis, and military reconnaissance. Different from normal change detection, hyperspectral anomaly change detection (HACD) helps to find those small but important anomaly changes between multitemporal hyperspectral images (HSI). In previous works, most classical methods use linear regression to establish the mapping relationship between two HSIs and then detect the anomalies from the residual image. However, the real spectral differences between multi-temporal HSIs are likely to be quite complex and of nonlinearity, leading to the limited performance of these linear predictors. In this article, we propose an original HACD algorithm based on autoencoder (ACDA) to give a nonlinear solution. The proposed ACDA can construct an effective predictor model when facing complex imaging conditions. In the ACDA model, two siamese autoencoder networks are deployed to construct two predictors from two directions. The predictor is used to model the spectral variation of the background to obtain the predicted image under another imaging condition. Then the mean square error between the predictive image and corresponding expected image is computed to obtain the loss map, where the spectral differences of the unchanged pixels are highly suppressed and anomaly changes are highlighted. Ultimately, we take the minimum of the two loss maps of two directions as the final anomaly change intensity map. The experiments results on public "Viareggio 2013" datasets demonstrate the efficiency and superiority over traditional methods.
C1 [Hu, Meiqi; Wu, Chen; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Du, Bo] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
RP Wu, C (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM meiqi.hu@whu.edu.cn; chen.wu@whu.edu.cn; zlp62@whu.edu.cn;
   gunspace@163.com
OI Wu, Chen/0000-0001-6461-8377
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971317, 61822113]; Natural Science
   Foundation of Hubei ProvinceNatural Science Foundation of Hubei Province
   [2020CFB594, 2018CFA050]; National Key Research and Development Program
   of China [2018YFA0605500]; Science and Technology Major Project of Hubei
   Province (Next-Generation AI Technologies) [2019AEA170]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61971317 and Grant 61822113, in part by
   the Natural Science Foundation of Hubei Province under Grant 2020CFB594
   and Grant 2018CFA050, in part by the National Key Research and
   Development Program of China under Grant 2018YFA0605500, and in part by
   the Science and Technology Major Project of Hubei Province
   (Next-Generation AI Technologies) under Grant 2019AEA170.
CR Acito N., 2014, HYPERSPECTRAL ANOMAL
   Acito N, 2017, IEEE AERO EL SYS MAG, V32, P2, DOI 10.1109/MAES.2017.160155
   Acito N, 2016, IEEE J-STARS, V9, P2365, DOI 10.1109/JSTARS.2016.2531747
   Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481
   Chang SZ, 2019, INT GEOSCI REMOTE SE, P5488, DOI 10.1109/IGARSS.2019.8898697
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   CHEN JY, 1987, IEEE T AERO ELEC SYS, V23, P46, DOI 10.1109/TAES.1987.313335
   Clifton C, 2003, APPL INTELL, V18, P215, DOI 10.1023/A:1021942526896
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Datt B, 2003, IEEE T GEOSCI REMOTE, V41, P1246, DOI 10.1109/TGRS.2003.813206
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Eismann MT, 2008, APPL OPTICS, V47, pF27, DOI 10.1364/AO.47.000F27
   Eismann MT, 2008, IEEE T GEOSCI REMOTE, V46, P237, DOI 10.1109/TGRS.2007.907973
   HANLEY JA, 1983, RADIOLOGY, V148, P839, DOI 10.1148/radiology.148.3.6878708
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Kingma D., 2014, P INT C LEARN REPR
   Koltunov A, 2007, REMOTE SENS ENVIRON, V110, P18, DOI 10.1016/j.rse.2007.02.010
   Kruse FA, 1996, INT J REMOTE SENS, V17, P1623, DOI 10.1080/01431169608948728
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI [10.1109/TCYB.2020.2971638, 10.1109/TGRS.2020.3018879]
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma XR, 2016, IEEE J-STARS, V9, P4073, DOI 10.1109/JSTARS.2016.2517204
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Mayer R, 2003, IEEE T GEOSCI REMOTE, V41, P1136, DOI 10.1109/TGRS.2003.813553
   Meola J, 2012, IEEE T GEOSCI REMOTE, V50, P3693, DOI 10.1109/TGRS.2012.2186305
   Peng JT, 2021, IEEE T GEOSCI REMOTE, V59, P1501, DOI 10.1109/TGRS.2020.2996688
   REED IS, 1990, IEEE T ACOUST SPEECH, V38, P1760, DOI 10.1109/29.60107
   Resta S., 2011, Proceedings of the 2011 6th International Workshop on the Analysis of Multi-temporal Remote Sensing Images (Multi-Temp), P5, DOI 10.1109/Multi-Temp.2011.6005033
   Schaum A, 2004, P SOC PHOTO-OPT INS, V5425, P77, DOI 10.1117/12.544026
   Schaum S. A., 1998, P INT S SPECTR SENS, P1760
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   Shimoni M, 2010, INT GEOSCI REMOTE SE, P4757, DOI 10.1109/IGARSS.2010.5653711
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Su YC, 2019, IEEE T GEOSCI REMOTE, V57, P4309, DOI 10.1109/TGRS.2018.2890633
   Sun WW, 2020, IEEE T GEOSCI REMOTE, V58, P3906, DOI 10.1109/TGRS.2019.2959342
   Theiler J., 2006, PROPOSED FRAMEWORK A
   Theiler J, 2008, APPL OPTICS, V47, pF12, DOI 10.1364/AO.47.000F12
   Theiler J, 2012, IEEE T GEOSCI REMOTE, V50, P3107, DOI 10.1109/TGRS.2011.2179942
   Wang YS, 2016, NEUROCOMPUTING, V184, P232, DOI 10.1016/j.neucom.2015.08.104
   Wu CH, 2019, IEEE INT C ELECTR TA, DOI 10.1109/ECBIOS.2019.8807878
   Wu C, 2015, NEUROCOMPUTING, V151, P175, DOI 10.1016/j.neucom.2014.09.058
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
NR 46
TC 3
Z9 3
U1 12
U2 13
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 3750
EP 3762
DI 10.1109/JSTARS.2021.3066508
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA RP8FA
UT WOS:000641957800002
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Liu, W
   Xu, JW
   Guo, ZH
   Li, EZ
   Li, X
   Zhang, LP
   Liu, WS
AF Liu, Wei
   Xu, Jiawei
   Guo, Zihui
   Li, Erzhu
   Li, Xing
   Zhang, Lianpeng
   Liu, Wensong
TI Building Footprint Extraction From Unmanned Aerial Vehicle Images Via
   PRU-Net: Application to Change Detection
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Buildings; Licenses; Semantics; Predictive models;
   Image segmentation; Data mining; Building footprint change detection;
   deep convolutional neural network (DCNN); U-Net; unmanned aerial vehicle
   (UAV) image
ID REMOTE-SENSING IMAGERY
AB As the manual detection of building footprint is inefficient and labor-intensive, this study proposed a method of building footprint extraction and change detection based on deep convolutional neural networks. The study modified the existing U-Net model to develop the "PRU-Net" model. PRU-Net incorporates pyramid scene parsing (PSP) to allow multiscale scene parsing, a residual block (RB) in ResNet for feature extraction, and focal loss to address sample imbalance. Within the proposed method, building footprint extraction is conducted as follows: 1) unmanned aerial vehicle images are cropped, denoised, and semantically marked, and datasets are created (including training/validation and prediction datasets); 2) the training/validation and prediction datasets are input into the full convolutional neural network PRU-Net for model training/validation and prediction. Compared with the U-Net, PSP+U-Net (PU-Net), and U-Net++ models, PRU-Net offers improved footprint extraction of buildings with a range of sizes and shapes. The large-scale experimental results demonstrated the effectiveness of the PSP module for multiscale scene analysis and the RB module for feature extraction. After demonstrating the improvements in building extraction offered by PRU-Net, the building footprint results were further processed to generate a building change map.
C1 [Liu, Wei; Xu, Jiawei; Guo, Zihui; Li, Erzhu; Li, Xing; Zhang, Lianpeng; Liu, Wensong] Jiangsu Normal Univ, Sch Geog Geomat & Planning, Xuzhou 221116, Jiangsu, Peoples R China.
RP Liu, W (corresponding author), Jiangsu Normal Univ, Sch Geog Geomat & Planning, Xuzhou 221116, Jiangsu, Peoples R China.
EM liuw@jsnu.eud.cn; xujiawei@jsnu.edu.cn; guozihui@jsnu.edu.cn;
   liezrs2018@jsnu.edu.cn; lixing@jsnu.edu.cn; zhanglp2000@126.com;
   liuwensongupc@163.com
OI LIU, WEI/0000-0001-8808-7961
FU Xuzhou Science and Technology Key R&D Program (Social Development)
   [KC20172]; Priority Academic Program Development of Jiangsu Higher
   Education Institutions; State Key Laboratory of Resources and
   Environmental Information System
FX This work was supported in part by the Xuzhou Science and Technology Key
   R&D Program (Social Development) under Project KC20172, in part by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions, and in part by the Grant from the State Key Laboratory of
   Resources and Environmental Information System.
CR Alshehhi R, 2017, ISPRS J PHOTOGRAMM, V130, P139, DOI 10.1016/j.isprsjprs.2017.05.002
   Beumier Charles, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P648, DOI 10.1007/978-3-642-33275-3_80
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Wei Xie, 2018, ARXIV180406242
   Drozdzal M, 2016, LECT NOTES COMPUT SC, V10008, P179, DOI 10.1007/978-3-319-46976-8_19
   [顾炼 Gu Lian], 2020, [自动化学报, Acta Automatica Sinica], V46, P1291
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23
   Huang JF, 2019, ISPRS J PHOTOGRAMM, V151, P91, DOI 10.1016/j.isprsjprs.2019.02.019
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Jabari S, 2019, ISPRS J PHOTOGRAMM, V147, P163, DOI 10.1016/j.isprsjprs.2018.11.014
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121444
   Ji HY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12172832
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Koltun V, 2016, INT C LEARN REPR
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li QY, 2020, IEEE T GEOSCI REMOTE, V58, P7502, DOI 10.1109/TGRS.2020.2973720
   [李炜明 LI Wei-Ming], 2009, [自动化学报, Acta Automatica Sinica], V35, P449
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu B, 2017, IEEE GEOSCI REMOTE S, V14, P926, DOI 10.1109/LGRS.2017.2687946
   Liu S., IEEE J SEL TOPICS AP, V10, P4124
   Liu W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242912
   Liu YB, 2018, IEEE J-STARS, V11, P3688, DOI 10.1109/JSTARS.2018.2866284
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lukashevich P, 2017, 2017 INTERNATIONAL CONFERENCE ON INFORMATION AND DIGITAL TECHNOLOGIES (IDT), P246, DOI 10.1109/DT.2017.8024304
   Majd RD, 2019, IEEE J-STARS, V12, P2627, DOI 10.1109/JSTARS.2019.2924582
   Marmanis D, 2018, ISPRS J PHOTOGRAMM, V135, P158, DOI 10.1016/j.isprsjprs.2017.11.009
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shi YL, 2019, IEEE GEOSCI REMOTE S, V16, P603, DOI 10.1109/LGRS.2018.2878486
   Solano-Correa YT, 2019, IEEE GEOSCI REMOTE S, V16, P1334, DOI 10.1109/LGRS.2019.2896385
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su HJ, 2020, IEEE T GEOSCI REMOTE, V58, P3778, DOI 10.1109/TGRS.2019.2957135
   Szegedy, 2015, ARXIV 1502 03167
   Turker M, 2008, INT J REMOTE SENS, V29, P3073, DOI 10.1080/01431160701442096
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Yang L., IEEE J SEL TOPICS AP, V11, P2600
   Yuan, 2016, ARXIV160206564
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 42
TC 2
Z9 3
U1 15
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 2236
EP 2248
DI 10.1109/JSTARS.2021.3052495
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA QG1UD
UT WOS:000617374800007
OA gold
DA 2022-01-04
ER

PT J
AU Chen, J
   Yuan, ZY
   Peng, J
   Chen, L
   Huang, HZ
   Zhu, JW
   Liu, Y
   Li, HF
AF Chen, Jie
   Yuan, Ziyang
   Peng, Jian
   Chen, Li
   Huang, Haozhe
   Zhu, Jiawei
   Liu, Yu
   Li, Haifeng
TI DASNet: Dual Attentive Fully Convolutional Siamese Networks for Change
   Detection in High-Resolution Satellite Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; dual attention; high-resolution images; Siamese
   network; weighted double-margin contrastive (WDMC) loss
ID REMOTE-SENSING IMAGES; LEVEL; SET
AB Change detection is a basic task of remote sensing image processing. The research objective is to identify the change information of interest and filter out the irrelevant change information as interference factors. Recently, the rise in deep learning has provided new tools for change detection, which have yielded impressive results. However, the available methods focus mainly on the difference information between multitemporal remote sensing images and lack robustness to pseudochange information. To overcome the lack of resistance in current methods to pseudochanges, in this article, we propose a new method, namely, dual attentive fully convolutional Siamese networks, for change detection in high-resolution images. Through the dual attention mechanism, long-range dependencies are captured to obtain more discriminant feature representations to enhance the recognition performance of the model. Moreover, the imbalanced sample is a serious problem in change detection, i.e., unchanged samples are much more abundant than changed samples, which is one of the main reasons for pseudochanges. We propose the weighted double-margin contrastive loss to address this problem by punishing attention to unchanged feature pairs and increasing attention to changed feature pairs. The experimental results of our method on the change detection dataset and the building change detection dataset demonstrate that compared with other baseline methods, the proposed method realizes maximum improvements of 2.9% and 4.2%, respectively, in the F1 score. Our PyTorch implementation is available at https://github.com/lehaifeng/DASNet.
C1 [Chen, Jie; Yuan, Ziyang; Peng, Jian; Chen, Li; Huang, Haozhe; Zhu, Jiawei; Li, Haifeng] Cent South Univ, Sch Geosci & Info Phys, Changsha 410083, Peoples R China.
   [Liu, Yu] Natl Univ Def Technol, Dept Syst Engn, Changsha 410073, Peoples R China.
RP Li, HF (corresponding author), Cent South Univ, Sch Geosci & Info Phys, Changsha 410083, Peoples R China.; Liu, Y (corresponding author), Natl Univ Def Technol, Dept Syst Engn, Changsha 410073, Peoples R China.
EM cj2011@csu.edu.cn; yuanziyang@csu.edu.cn; PengJ2017@csu.edu.cn;
   vchenlil@csu.edu.cn; hz_huang@csu.edu.cn; jw_zhu@csu.edu.cn;
   jasonyuliu@nudt.edu.cn; lihaifeng@csu.edu.cn
OI Chen, Li/0000-0002-4761-5913; Li, Haifeng/0000-0003-1173-6593; chen,
   jie/0000-0002-3864-9265
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41671357, 41871364, 41871276, 41871302]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 41671357, Grant 41871364, Grant 41871276, and Grant
   41871302.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Byeon W, 2015, PROC CVPR IEEE, P3547, DOI 10.1109/CVPR.2015.7298977
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo E., 2018, ARXIV181009111
   Hadsell Raia, 2006, P IEEE COMP SOC C CO, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin Z., 2017, ARXIV PREPRINT
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI 10.1109/ICPHM.2017.7998297
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7
   Shen T, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5446
   Shuai B, 2018, IEEE T PATTERN ANAL, V40, P1480, DOI 10.1109/TPAMI.2017.2712691
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Sun YC, 2016, IEEE ACCESS, V4, P766, DOI 10.1109/ACCESS.2016.2529723
   Tang JH, 2015, IEEE T MULTIMEDIA, V17, P1899, DOI 10.1109/TMM.2015.2476660
   Tang JH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899418
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varghese A., 2018, P EUR C COMP VIS ECC, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Xu L, 2019, IEEE ACCESS, V7, P78909, DOI 10.1109/ACCESS.2019.2922839
   Yang JC, 2018, IEEE ACCESS, V6, P38669, DOI 10.1109/ACCESS.2018.2854922
   Zelinski ME, 2014, IEEE J-STARS, V7, P3453, DOI 10.1109/JSTARS.2013.2294322
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang CS, 2018, IEEE J-STARS, V11, P2440, DOI 10.1109/JSTARS.2018.2817121
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 63
TC 25
Z9 25
U1 27
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 1194
EP 1206
DI 10.1109/JSTARS.2020.3037893
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA PS3FD
UT WOS:000607810600006
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Zerrouki, Y
   Harrou, F
   Zerrouki, N
   Dairi, A
   Sun, Y
AF Zerrouki, Yacine
   Harrou, Fouzi
   Zerrouki, Nabil
   Dairi, Abdelkader
   Sun, Ying
TI Desertification Detection Using an Improved Variational
   Autoencoder-Based Approach Through ETM-Landsat Satellite Data
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Remote sensing; Feature extraction; Deep learning; Earth; Artificial
   satellites; Vegetation mapping; Indexes; Desertification detection;
   feature extraction; Landsat sensors; variational autoencoder (VAE)
   classification
ID CLASSIFICATION; IMAGERY
AB The accurate land cover change detection is critical to improve the landscape dynamics analysis and mitigate desertification problems efficiently. Desertification detection is a challenging problem because of the high degree of similarity between some desertification cases and like-desertification phenomena, such as deforestation. This article provides an effective approach to detect deserted regions based on Landsat imagery and variational autoencoder (VAE). The VAE model, as a deep learning-based model, has gained special attention in features extraction and modeling due to its distribution-free assumptions and superior nonlinear approximation. Here, a VAE approach is applied to spectral signatures for detecting pixels affected by the land cover change. The considered features are extracted from multitemporal images and include multispectral information, and no prior image segmentation is required. The proposed method was evaluated on the publicly available remote sensing data using multitemporal Landsat optical images taken from the freely available Landsat program. The arid region around Biskra in Algeria is selected as a study area since it is well-known that desertification phenomena strongly influence this region. The VAE model was evaluated and compared with restricted Boltzmann machines, deep learning model, and binary clustering algorithms, including Agglomerative, BIRCH, expected maximization, k-mean clustering algorithms, and one-class support vector machine. The comparative results showed that the VAE consistently outperformed the other models for detecting changes to the land cover, mainly deserted regions. This study also showed that VAE outperformed the state-of-the-art algorithms.
C1 [Zerrouki, Yacine] Conservatoire Natl Format Environnement, Bab El Oued 16000, Algeria.
   [Harrou, Fouzi; Sun, Ying] King Abdullah Univ Sci & Technol, Comp Elect & Math Sci & Engn, Thuwal 23955, Saudi Arabia.
   [Zerrouki, Nabil] Ctr Dev Adv Technol, Baba Hassen 16081, Algeria.
   [Dairi, Abdelkader] Univ Sci & Technol Oran Mohamed Boudiaf, Dept Comp Sci, SIMPA Lab, Bir El Djir 31000, Algeria.
RP Harrou, F (corresponding author), King Abdullah Univ Sci & Technol, Comp Elect & Math Sci & Engn, Thuwal 23955, Saudi Arabia.
EM yacine.zerrouki.eenv@gmail.com; fouzi.harrou@kaust.edu.sa;
   nzerrouki@ctda.dz; dairi.aek@gmail.com; ying.sun@kaust.edu.sa
RI Dairi, Abdelkader/AAK-8749-2021; Harrou, Fouzi/AAY-5178-2021; Sun,
   Ying/N-2009-2017
OI Dairi, Abdelkader/0000-0003-4712-6949; Sun, Ying/0000-0001-6703-4270;
   Harrou, Fouzi/0000-0002-2138-319X
FU King Abdullah University of Science and Technology, Office of Sponsored
   Research (OSR) [OSR-2019-CRG7-3800]
FX This work was supported in part by the King Abdullah University of
   Science and Technology, Office of Sponsored Research (OSR) under Grant
   OSR-2019-CRG7-3800.
CR Azzouzi SA, 2017, IEEE ACCESS, V5, P9065, DOI 10.1109/ACCESS.2017.2700405
   Afrasinei G. M., 2016, THESIS U CAGLIARI CA, DOI [10.13140/RG.2.1.2412.6327, DOI 10.13140/RG.2.1.2412.6327]
   Ainiwaer M, 2020, ENVIRON EARTH SCI, V79, DOI 10.1007/s12665-020-08965-w
   Bernstein L. S., 2012, P 4 WORKSH HYP IM SI, P1, DOI [10.1109/WHISPERS, DOI 10.1109/WHISPERS.2012.6874311]
   Bernstein LS, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.11.111719
   Boulghobra N, 2014, GEOGR TECH, V9, P1
   Chen L.-C., 2017, ARXIV170605587
   Cui Zhang, 2010, Proceedings of the Third International Conference on Information and Computing Science (ICIC 2010), P322, DOI 10.1109/ICIC.2010.267
   Dairi A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238400
   Dairi A, 2018, IEEE SENS J, V18, P5122, DOI 10.1109/JSEN.2018.2831082
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ding HP, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER MODELING AND SIMULATION, PROCEEDINGS, P324, DOI 10.1109/ICCMS.2009.39
   Dixit S, 2020, IEEE SENS J, V20, P14337, DOI 10.1109/JSEN.2020.3008177
   Doersch C., 2016, ARXIV160605908
   Guo B, 2020, IEEE ACCESS, V8, P4761, DOI 10.1109/ACCESS.2019.2962909
   Harrou F, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1651, DOI 10.1109/SSCI.2018.8628774
   Kacem HA, 2021, GEOCARTO INT, V36, P563, DOI 10.1080/10106049.2019.1611949
   Kim J., 2017, AM GEOPH UN FALL M D
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma D.P., 2013, ARXIV13126114STATML
   Kundu A, 2017, NAT HAZARDS, V86, P297, DOI 10.1007/s11069-016-2689-y
   Lamchin M, 2016, ADV SPACE RES, V57, P64, DOI 10.1016/j.asr.2015.10.006
   Li JY, 2014, IEEE J-STARS, V7, P4393, DOI 10.1109/JSTARS.2014.2348612
   Li WK, 2011, IEEE T GEOSCI REMOTE, V49, P717, DOI 10.1109/TGRS.2010.2058578
   Lyalko VI, 2020, J GEOL GEOGR GEOECOL, V29, P102, DOI 10.15421/112010
   Madakyaru F, 2020, STAT PROCESS MONITOR
   Nag S, 2017, IEEE SENS J, V17, P5252, DOI 10.1109/JSEN.2017.2717384
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Zanchetta A, 2016, NAT HAZARDS, V83, pS223, DOI 10.1007/s11069-016-2342-9
   Zeroual A, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110121
   Zerrouki N, 2019, IEEE SENS J, V19, P5843, DOI 10.1109/JSEN.2019.2904137
   Zerrouki N, 2018, IEEE GEOSCI REMOTE S, V15, P927, DOI 10.1109/LGRS.2018.2817522
   Zerrouki N, 2014, IEEE SYS MAN CYBERN, P864, DOI 10.1109/SMC.2014.6974020
NR 33
TC 3
Z9 3
U1 8
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 202
EP 213
DI 10.1109/JSTARS.2020.3042760
PG 12
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA PR7LT
UT WOS:000607413900007
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Zhou, N
   Li, X
   Shen, ZF
   Wu, TJ
   Luo, JC
AF Zhou, Nan
   Li, Xiang
   Shen, Zhanfeng
   Wu, Tianjun
   Luo, Jiancheng
TI Geo-Parcel-Based Change Detection Using Optical and SAR Images in Cloudy
   and Rainy Areas
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; cloudy and rainy; geo-parcel; multisource images
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION; FUSION
AB In this article, we deal with the problem of change detection in cloudy and rainy areas using multisource remote sensing images. While previous methods mostly focus on change detection on pixel or super-pixel levels, in this article, we introduce the concept of geo-parcel and use it as the basic processing unit for our change detection method. Concretely, we first extract geo-parcel from an optical high spatial resolution remote sensing image. Then, we divide each geo-parcel into fine-grained segments with refined boundaries using image segmentation methods. These fine-grained segments are used as the basic processing units for our change detection method. After that, an unsupervised learning-based method is adopted to obtain the difference map by comparing synthetic aperture radar images of two periods. Training samples with labels are automatically generated from the difference map. Finally, a deep neural network is trained using the generated samples and is further used to predict the refined change map. Experiments on the collected images from Gui'an, Guizhou Province, China demonstrate the effectiveness of the proposed method for change detection in a cloudy and rainy area with an overall accuracy surpasses 94%.
C1 [Zhou, Nan] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
   [Zhou, Nan] Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
   [Li, Xiang] NYU Tandon & Abu Dhabi, NYU Multimedia & Visual Comp Lab, Abu Dhabi 129188, U Arab Emirates.
   [Shen, Zhanfeng; Luo, Jiancheng] Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
   [Wu, Tianjun] Changan Univ, Sch Sci, Xian 710064, Peoples R China.
RP Shen, ZF (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Beijing 100049, Peoples R China.
EM zhounan@aircas.ac.cn; xl1845@nyu.edu; shenzf@aircas.ac.cn;
   tjwu@chd.edu.cn; luojc@radi.ac.cn
FU National Key Research and Development Program of China [2017YFB0504204,
   2018YFB0505000]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [41971375, 41631179];
   Xinjiang Uygur Autonomous Region Flexible Talent Award
FX This work was supported in part by the National Key Research and
   Development Program of China under Grants 2017YFB0504204 and
   2018YFB0505000, in part by the National Natural Science Foundation of
   China under Grant 41971375 and 41631179, and in part by the Xinjiang
   Uygur Autonomous Region Flexible Talent Award in 2018. (Nan Zhou and
   Xiang Li contributed equally to this work.)
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, P228, DOI 10.1109/CVPRW.2018.00042
   Li L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091091
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Liu Y, 2017, PROC CVPR IEEE, P5872, DOI 10.1109/CVPR.2017.622
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mnih V, 2013, MACHINE LEARNING AER
   Niemeyer J, 2014, ISPRS J PHOTOGRAMM, V87, P152, DOI 10.1016/j.isprsjprs.2013.11.001
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Shen, 2018, LEARNING TRANSFERABL
   Tiwari Y., INT J ENV AGR BIOTEC, V2, P1726
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Yokoya N, 2018, IEEE J-STARS, V11, P1363, DOI 10.1109/JSTARS.2018.2799698
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhou LC, 2018, IEEE COMPUT SOC CONF, P192, DOI 10.1109/CVPRW.2018.00034
NR 24
TC 2
Z9 2
U1 7
U2 10
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2021
VL 14
BP 1326
EP 1332
DI 10.1109/JSTARS.2020.3038169
PG 7
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA PR7LT
UT WOS:000607413900043
OA gold
DA 2022-01-04
ER

PT J
AU Sefrin, O
   Riese, FM
   Keller, S
AF Sefrin, Oliver
   Riese, Felix M.
   Keller, Sina
TI Deep Learning for Land Cover Change Detection
SO REMOTE SENSING
LA English
DT Article
DE machine learning; multi-class classification; long short-term memory
   network (LSTM); fully convolutional neural network (FCN); multitemporal;
   time series; Sentinel-2
ID TIME-SERIES; CLASSIFICATION; ATTENTION; IMAGERY; AREA
AB Land cover and its change are crucial for many environmental applications. This study focuses on the land cover classification and change detection with multitemporal and multispectral Sentinel-2 satellite data. To address the challenging land cover change detection task, we rely on two different deep learning architectures and selected pre-processing steps. For example, we define an excluded class and deal with temporal water shoreline changes in the pre-processing. We employ a fully convolutional neural network (FCN), and we combine the FCN with long short-term memory (LSTM) networks. The FCN can only handle monotemporal input data, while the FCN combined with LSTM can use sequential information (multitemporal). Besides, we provided fixed and variable sequences as training sequences for the combined FCN and LSTM approach. The former refers to using six defined satellite images, while the latter consists of image sequences from an extended training pool of ten images. Further, we propose measures for the robustness concerning the selection of Sentinel-2 image data as evaluation metrics. We can distinguish between actual land cover changes and misclassifications of the deep learning approaches with these metrics. According to the provided metrics, both multitemporal LSTM approaches outperform the monotemporal FCN approach, about 3 to 5 percentage points (p.p.). The LSTM approach trained on the variable sequences detects 3 p.p. more land cover changes than the LSTM approach trained on the fixed sequences. Besides, applying our selected pre-processing improves the water classification and avoids reducing the dataset effectively by 17.6%. The presented LSTM approaches can be modified to provide applicability for a variable number of image sequences since we published the code of the deep learning models. The Sentinel-2 data and the ground truth are also freely available.
C1 [Sefrin, Oliver; Riese, Felix M.; Keller, Sina] Karlsruhe Inst Technol, Inst Photogrammetry & Remote Sensing, D-76131 Karlsruhe, Germany.
RP Keller, S (corresponding author), Karlsruhe Inst Technol, Inst Photogrammetry & Remote Sensing, D-76131 Karlsruhe, Germany.
EM oliver.sefrin@student.kit.edu; felix.riese@kit.edu; sina.keller@kit.edu
RI Keller, Sina/AAD-6848-2019
OI Keller, Sina/0000-0002-7710-5316; Riese, Felix M./0000-0003-0596-9585
CR Camps-Valls G., 2012, SYNTHESIS LECT IMAGE, V12, P194, DOI [10.2200/S00392ED1V01Y201107IVM012, DOI 10.2200/S00392ED1V01Y201107IVM012]
   Chanussot, 2020, HYPERSPECTRAL IMAGE, P187, DOI [10.1007/978-3-030-38617-7_7, DOI 10.1007/978-3-030-38617-7_7]
   Clark ML, 2012, REMOTE SENS ENVIRON, V126, P84, DOI 10.1016/j.rse.2012.08.013
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Drusch M, 2012, REMOTE SENS ENVIRON, V120, P25, DOI 10.1016/j.rse.2011.11.026
   Foody GM, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5110199
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   de Macedo MMG, 2020, IEEE J-STARS, V13, P1134, DOI 10.1109/JSTARS.2020.2973602
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   GREEN K, 1994, PHOTOGRAMM ENG REM S, V60, P331
   HELBER P, 2019, IEEE J-STARS, V12, P2217, DOI [DOI 10.1109/JSTARS.2019.2918242, 10.1109/IGARSS.2018.8519248]
   Hua YS, 2019, ISPRS J PHOTOGRAMM, V149, P188, DOI 10.1016/j.isprsjprs.2019.01.015
   Interdonato R, 2019, ISPRS J PHOTOGRAMM, V149, P91, DOI 10.1016/j.isprsjprs.2019.01.011
   Joshi A.V., 2020, MACHINE LEARNING ART, DOI [10.1007/978-3-030-26622-6, DOI 10.1007/978-3-030-26622-6]
   Kaviani Baghbaderani Razieh, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P1, DOI 10.1007/978-3-030-58577-8_1
   Keller S., 2016, P 2016 8 WORKSH HYP, P1, DOI [10.1109/NSSMIC.2016.8069467, DOI 10.1109/NSSMIC.2016.8069467, 10.1109/WHISPERS.2016.8071759, DOI 10.1109/WHISPERS.2016.8071759]
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SJ, 2021, IEEE T GEOSCI REMOTE, V59, P5085, DOI [10.1109/TCYB.2020.2971638, 10.1109/TGRS.2020.3018879]
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loveland TR, 2002, PHOTOGRAMM ENG REM S, V68, P1091
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mazzia V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010238
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050523
   Qiu CP, 2020, IEEE GEOSCI REMOTE S, V17, P1787, DOI 10.1109/LGRS.2019.2953497
   Qiu CP, 2019, ISPRS J PHOTOGRAMM, V154, P151, DOI 10.1016/j.isprsjprs.2019.05.004
   Ren TW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132140
   Riese F.M., 2019, ARXIV PREPRINT ARXIV, P615, DOI 10.5194/isprs-annals-IV-2-W5-615-2019
   Riese F.M., 2020, THESIS, DOI [10.5445/IR/1000120067, DOI 10.5445/IR/1000120067]
   Riese FM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010007
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russwurm M, 2017, INT ARCH PHOTOGRAMM, V42-1, P551, DOI 10.5194/isprs-archives-XLII-1-W1-551-2017
   Russwurm M, 2020, ISPRS J PHOTOGRAMM, V169, P421, DOI 10.1016/j.isprsjprs.2020.06.006
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7040129
   Sefrin, 2020, THESIS
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Staatsbetrieb Geobasisinformation und Vermessung Sachsen (GeoSN), 2014, DIG BAS LANDSCH
   van Duynhoven A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232784
   Vidal M, 2012, CHEMOMETR INTELL LAB, V117, P138, DOI 10.1016/j.chemolab.2012.05.009
   Yakubovskiy P., SEGMENTATION MODELS
   Yang LM, 2003, PHOTOGRAMM ENG REM S, V69, P1003, DOI 10.14358/PERS.69.9.1003
   Yang X, 2002, INT J REMOTE SENS, V23, P1775, DOI 10.1080/01431160110075802
   You JX, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4559
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 45
TC 8
Z9 8
U1 13
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN
PY 2021
VL 13
IS 1
AR 78
DI 10.3390/rs13010078
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA PP9HU
UT WOS:000606165500001
OA Green Published, gold
DA 2022-01-04
ER

PT J
AU Liu, F
   Tang, X
   Zhang, XR
   Jiao, LC
   Liu, J
AF Liu, Fang
   Tang, Xu
   Zhang, Xiangrong
   Jiao, Licheng
   Liu, Jia
TI Large-Scope PolSAR Image Change Detection Based on
   Looking-Around-and-Into Mode
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Task analysis; Shape; Visualization; Image segmentation; Polarimetric
   synthetic aperture radar; Proposals; Convolutional neural networks;
   Attention proposal network (APN); change detection; large-scope
   Polarimetric Synthetic Aperture Radar~(PolSAR) image;
   Looking-Around-and-Into (LAaI); recurrent convolutional neural network
   (CNN) (Recurrent CNN)\looseness-1
ID UNSUPERVISED CHANGE DETECTION; MULTITEMPORAL SAR IMAGES; POLARIMETRIC
   SAR; ALGORITHMS; FUSION
AB A new method based on the Looking-Around-and-Into (LAaI) mode is proposed for the task of change detection in large-scope Polarimetric Synthetic Aperture Radar (PolSAR) image. Specifically, the LAaI mode consists of two processes named Look-Around and Look-Into, which are accomplished by attention proposal network (APN) and recurrent convolutional neural network (CNN) (Recurrent CNN), respectively. The former provides certain subregions efficiently, and the latter detects changes in subregions accurately. In Look-Around, difference image (DI) of whole PolSAR images is calculated first to get global information; then, APN is established to locate the position of interested subregions intentionally by paying special attention to; next interested subregions that contain changed area in high probability are picked out as candidate-regions. Moreover, candidate-regions are sorted in importance descending order so that highly interested regions have priority to be detected. In Look-Into, candidate-regions of different scales are selected at first; then, Recurrent CNN is constructed and employed to deal with multiscale PolSAR subimages so that clearer and finer change detection results are generated. The process is repeated until all candidate-regions are detected. As a whole, the proposed algorithm based on the LAaI mode looks around whole images first to find out the possible position of changes (candidate-regions generation in Look-Around) and then reveal the exact shape of changes in different scales (multiscale change detection in Look-Into). The effect of APN and Recurrent CNN is verified in experiments, and it shows that the proposed method performs well in the task of change detection in the large-scope PolSAR image.
C1 [Liu, Fang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Peoples R China.
   [Tang, Xu] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Peoples R China.
   [Zhang, Xiangrong] Xidian Univ, Natl Key Lab Radar Signal Proc, Dept Elect Engn, Xian 710071, Peoples R China.
   [Zhang, Xiangrong] Xidian Univ, Inst Intelligent Informat Proc, Dept Elect Engn, Xian 710071, Peoples R China.
   [Jiao, Licheng] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Liu, Jia] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
RP Liu, F (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Peoples R China.
EM comeonliufang@163.com
OI Liu, Jia/0000-0002-5999-2361; Jiao, Licheng/0000-0003-3354-9617
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61802190, 61801351, 61906093]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities [30919011281, 30919011279]; Open Fund of
   Key Laboratory of Intelligent Perception and Image Understanding of
   Ministry of Education, Xidian University [IPIU2019001]; Nature Science
   Foundation of Jiangsu Province, ChinaNatural Science Foundation of
   Jiangsu Province [BK20190451]
FX The work was supported in part by the National Natural Science
   Foundation of China under Grant 61802190, Grant 61801351, and Grant
   61906093, in part by the Fundamental Research Funds for the Central
   Universities under Grant 30919011281 and Grant 30919011279, in part by
   the Open Fund of Key Laboratory of Intelligent Perception and Image
   Understanding of Ministry of Education, Xidian University under Grant
   IPIU2019001, and in part by the Nature Science Foundation of Jiangsu
   Province, China under Grant BK20190451.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akbari V, 2016, IEEE T GEOSCI REMOTE, V54, P3953, DOI 10.1109/TGRS.2016.2532320
   Atto AM, 2013, IEEE T GEOSCI REMOTE, V51, P1922, DOI 10.1109/TGRS.2012.2210228
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Carotenuto V, 2016, IEEE T GEOSCI REMOTE, V54, P36, DOI 10.1109/TGRS.2015.2449332
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Chen K., 2010, CONTAMINATION CONTRO
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Eckstein MP, 2011, J VISION, V11, DOI 10.1167/11.5.14
   Ferrazzoli P, 1997, IEEE T GEOSCI REMOTE, V35, P5, DOI 10.1109/36.551929
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   He W, 2016, IEEE T GEOSCI REMOTE, V54, P176, DOI 10.1109/TGRS.2015.2452812
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Joyce KE, 2009, PROG PHYS GEOG, V33, P183, DOI 10.1177/0309133309339563
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li W, 2012, INT GEOSCI REMOTE SE, P6165, DOI 10.1109/IGARSS.2012.6352664
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu GC, 2015, PATTERN RECOGN, V48, P685, DOI 10.1016/j.patcog.2014.09.027
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Marino A, 2014, IEEE T GEOSCI REMOTE, V52, P4781, DOI 10.1109/TGRS.2013.2284510
   Marino A, 2013, IEEE T GEOSCI REMOTE, V51, P2986, DOI 10.1109/TGRS.2012.2211883
   Mohan R., 2014, COMPUT SCI
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Mura MD, 2015, P IEEE, V103, P1585, DOI 10.1109/JPROC.2015.2462751
   Nascimento ADC, 2019, IEEE T GEOSCI REMOTE, V57, P1380, DOI 10.1109/TGRS.2018.2866367
   Pajares G, 2006, IEEE T NEURAL NETWOR, V17, P1250, DOI 10.1109/TNN.2006.875978
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Pinheiro P. H., 2014, P ICML
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176
   Sharma A, 2015, PROC CVPR IEEE, P530, DOI 10.1109/CVPR.2015.7298651
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Zhu W, 2017, IEEE T GEOSCI REMOTE, V55, P2786, DOI 10.1109/TGRS.2017.2654486
NR 53
TC 1
Z9 1
U1 4
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JAN
PY 2021
VL 59
IS 1
BP 363
EP 378
DI 10.1109/TGRS.2020.2992032
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA PL4FE
UT WOS:000603079000028
DA 2022-01-04
ER

PT J
AU Lu, N
   Chen, C
   Shi, WB
   Zhang, JW
   Ma, JF
AF Lu, Ning
   Chen, Can
   Shi, Wenbo
   Zhang, Junwei
   Ma, Jianfeng
TI Weakly Supervised Change Detection Based on Edge Mapping and SDAE
   Network in High-Resolution Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE image classification; neural networks; remote sensing image; edge
   mapping; change detection
AB Change detection for high-resolution remote sensing images is more and more widespread in the application of monitoring the Earth's surface. However, on the one hand, the ground truth could facilitate the distinction between changed and unchanged areas, but it is hard to acquire them. On the other hand, due to the complexity of remote sensing images, it is difficult to extract features of difference, let alone the construction of the classification model that performs change detection based on the features of difference in each pixel pair. Aiming at these challenges, this paper proposes a weakly supervised change detection method based on edge mapping and Stacked Denoising Auto-Encoders (SDAE) network called EM-SDAE. We analyze the difference in edge maps of bi-temporal remote sensing images to acquire part of the ground truth at a relatively low cost. Moreover, we design a neural network based on SDAE with a deep structure, which extracts the features of difference so as to efficiently classify changed and unchanged regions after being trained with the ground truth. In our experiments, three real sets of high-resolution remote sensing images are employed to validate the high efficiency of our proposed method. The results show that accuracy can even reach up to 91.18% with our method. In particular, compared with the state-of-the-art work (e.g., IR-MAD, PCA-k-means, CaffeNet, USFA, and DSFA), it improves the Kappa coefficient by 27.19% on average.
C1 [Lu, Ning; Chen, Can; Shi, Wenbo] Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110000, Peoples R China.
   [Lu, Ning; Zhang, Junwei; Ma, Jianfeng] Xidian Univ, Sch Cyber Engn, Xian 710071, Peoples R China.
RP Shi, WB (corresponding author), Northeastern Univ, Coll Comp Sci & Engn, Shenyang 110000, Peoples R China.
EM luning@neuq.edu.cn; 1801903@stu.neu.edu.cn; shiwb@neuq.edu.cn;
   jwzhang@xidian.edu.cn; jfma@mail.xidian.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [62072092, U1708262, 62072093]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2019M653568]; Fundamental Research Funds for the Central
   UniversitiesFundamental Research Funds for the Central Universities
   [N2023020]; Natural Science Foundation of Hebei Province of ChinaNatural
   Science Foundation of Hebei Province
FX This work was supported by the National Natural Science Foundation of
   China (No.62072092, U1708262 and 62072093); China Postdoctoral Science
   Foundation (No.2019M653568); the Fundamental Research Funds for the
   Central Universities (No.N172304023 and N2023020); the Natural Science
   Foundation of Hebei Province of China (No.F2020501013).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arnici V, 2017, ECOL INFORM, V40, P40, DOI 10.1016/j.ecoinf.2017.04.005
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Awrangjeb M, 2015, REMOTE SENS-BASEL, V7, P14119, DOI 10.3390/rs71014119
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Feizizadeh B, 2017, GEOMORPHOLOGY, V293, P240, DOI 10.1016/j.geomorph.2017.06.002
   Feng WQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071015
   Gargees RS, 2020, IEEE GEOSCI REMOTE S, V17, P1386, DOI 10.1109/LGRS.2019.2948799
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Guo J, 2013, INFORM SCIENCES, V221, P84, DOI 10.1016/j.ins.2012.09.024
   Guo Q., 2019, P 6 AS PAC C SYNTH A P EUR C COMP VIS, P1
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Long T, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9811-0
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Lv ZY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030472
   Malila W., 1980, CHANGE VECTOR ANAL A
   Ngo, 2015, IEEE INT C FUZZ SYST, P1, DOI DOI 10.1109/FUZZ-IEEE.2015.7337978
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pitts DAD, 2017, INT J APPL EARTH OBS, V57, P49, DOI 10.1016/j.jag.2016.12.004
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan K, 2016, IEEE J-STARS, V9, P3439, DOI 10.1109/JSTARS.2016.2541678
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xiang M., 2019, INT S ADV OPT MAN TE, V10837
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Xv J., 2019, J APPL REMOTE SENS, V13
   Yanling Hao, 2018, Advances in Brain Inspired Cognitive Systems. 9th International Conference, BICS 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 10989), P139, DOI 10.1007/978-3-030-00563-4_14
   Yu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121233
   Zadbagher E, 2018, ENVIRON MONIT ASSESS, V190, DOI 10.1007/s10661-018-6877-y
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 49
TC 1
Z9 1
U1 9
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC
PY 2020
VL 12
IS 23
AR 3907
DI 10.3390/rs12233907
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA PD2CB
UT WOS:000597498400001
OA gold
DA 2022-01-04
ER

PT J
AU Kou, R
   Fang, B
   Chen, G
   Wang, LZ
AF Kou, Rong
   Fang, Bo
   Chen, Gang
   Wang, Lizhe
TI Progressive Domain Adaptation for Change Detection Using Season-Varying
   Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE domain adaptation; change detection; remote sensing images;
   convolutional long short-term memory; generative adversarial network;
   image-to-image translation
ID CLASSIFICATION; NETWORKS; DESIGN
AB The development of artificial intelligence technology has prompted an immense amount of researches on improving the performance of change detection approaches. Existing deep learning-driven methods generally regard changes as a specific type of land cover, and try to identify them relying on the powerful expression capabilities of neural networks. However, in practice, different types of land cover changes are generally influenced by environmental factors at different degrees. Furthermore, seasonal variation-induced spectral differences seriously interfere with those of real changes in different land cover types. All these problems pose great challenges for season-varying change detection because the real and seasonal variation-induced changes are technically difficult to separate by a single end-to-end model. In this paper, by embedding a convolutional long short-term memory (ConvLSTM) network into a conditional generative adversarial network (cGAN), we develop a novel method, named progressive domain adaptation (PDA), for change detection using season-varying remote sensing images. In our idea, two cascaded modules, progressive translation and group discrimination, are introduced to progressively translate pre-event images from their own domain to the post-event one, where their seasonal features are consistent and their intrinsic land cover distribution features are retained. By training this hybrid multi-model framework with certain reference change maps, the seasonal variation-induced changes between paired images are effectively suppressed, and meanwhile the natural and human activity-caused changes are greatly emphasized. Extensive experiments on two types of season-varying change detection datasets and a comparison with other state-of-the-art methods verify the effectiveness and competitiveness of our proposed PDA.
C1 [Kou, Rong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Fang, Bo; Chen, Gang] China Univ Geosci, Coll Marine Sci & Technol, Wuhan 430074, Peoples R China.
   [Wang, Lizhe] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Peoples R China.
RP Kou, R (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM kourong@whu.edu.cn; fangbo@cug.edu.cn; ddwhcg@cug.edu.cn;
   lzwang@cug.edu.cn
RI Wang, Lizhe/L-7453-2014
OI Wang, Lizhe/0000-0003-2766-0845
FU Scientific Research Project of Hubei Province [1232039]; National
   Natural Science Foundation of China (NSFC)National Natural Science
   Foundation of China (NSFC) [41674015, 41925007, U1711266]
FX This research was supported and funded in part by the Scientific
   Research Project of Hubei Province under Grant 1232039 and in part by
   the National Natural Science Foundation of China (NSFC) under Grant
   41674015, Grant 41925007, and Grant U1711266.
CR Benaim S., 2017, ARXIV170600826V2
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Cho W, 2019, PROC CVPR IEEE, P10631, DOI 10.1109/CVPR.2019.01089
   Connell J, 2018, ROUTL PAC RIM GEOGR, P1
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding JS, 2020, IEEE T GEOSCI REMOTE, V58, P7194, DOI 10.1109/TGRS.2020.2980419
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Feng SJ, 2018, MICRO-NANO TECHNOLOGY XVII-XVIII, P7
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Huang X, 2018, IEEE IND APPLIC SOC, DOI 10.1007/978-3-030-01219-9_11
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   JACKSON RD, 1983, REMOTE SENS ENVIRON, V13, P409, DOI 10.1016/0034-4257(83)90010-X
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kennedy RE, 2009, REMOTE SENS ENVIRON, V113, P1382, DOI 10.1016/j.rse.2008.07.018
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma DP., 2015, INT C LEARN REPR SAN
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C., 2017, P IEEE C COMP VIS PA, P5892
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu QS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121330
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Malila W.A, 1980, P LARS S, P385
   Malmir M, 2015, ENVIRON MONIT ASSESS, V187, DOI 10.1007/s10661-015-4295-y
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   Petrou ZI, 2019, IEEE T GEOSCI REMOTE, V57, P6865, DOI 10.1109/TGRS.2019.2909057
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Rokni K, 2014, REMOTE SENS-BASEL, V6, P4173, DOI 10.3390/rs6054173
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Simonyan K., 2015, INT C LEARNING REPRE
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sutskever I., 2014, P 27 INT C NEUR INF, V3104, P3112, DOI DOI 10.1021/acs.analchem.7b05329
   Taigman Y., 2017, P INT C LEARN REPR T
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 66
TC 2
Z9 2
U1 11
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2020
VL 12
IS 22
AR 3815
DI 10.3390/rs12223815
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA OZ6TH
UT WOS:000595055500001
OA gold
DA 2022-01-04
ER

PT J
AU Senthilkumar, R
   Srinidhi, V
   Neelavathi, S
   Devi, SR
AF Senthilkumar, Radha
   Srinidhi, V.
   Neelavathi, S.
   Renuga Devi, S.
TI Forest Change Detection Using an Optimized Convolution Neural Network
SO IETE TECHNICAL REVIEW
LA English
DT Article; Early Access
DE Band fusion; change detection; deep Learning; genetic algorithm; missing
   data prediction; remote sensing; time series
ID LANDSAT TIME-SERIES
AB Forest plays a pivotal role in maintaining the ecological balance. It is necessary to detect the changes in forest cover as the forests have a significant role in promoting carbon cycle. Remote sensing domain has shown a promising potential for monitoring forest degradation. However, the problem arising due to missing satellite images in temporal domain and problems due to artefacts such as clouds need to be addressed. To detect the changes in the forest area, an index for mapping forest cover known as Normalized Difference Fraction Index (NDFI) has been used. NDFI is calculated for three satellite images (Landsat7, Landsat8, and Sentinal2) and for the fusion of all these satellite images. Following this, the missing image is predicted by applying regression methods and the best regression method was identified. For change detection problem, optimal values for Convolution Neural Network (CNN) parameters were obtained using the Genetic Algorithm (GA). Later, various filters were applied for the optimal CNN and best filter was identified.
C1 [Senthilkumar, Radha; Srinidhi, V.; Neelavathi, S.; Renuga Devi, S.] Anna Univ, Dept Informat Technol, Madras Inst Technol Campus, Chennai, Tamil Nadu, India.
RP Srinidhi, V (corresponding author), Anna Univ, Dept Informat Technol, Madras Inst Technol Campus, Chennai, Tamil Nadu, India.
EM radhasenthil@annauniv.edu; srinidhi.venky97@gmail.com;
   neelas479@gmail.com; renugadevi22111997@gmail.com
RI senthilkumar, !/C-7287-2011
OI senthilkumar, !/0000-0003-2656-4237
CR Bullock EL, 2020, REMOTE SENS ENVIRON, V238, DOI 10.1016/j.rse.2018.11.011
   Candra DS, 2017, INT CONF AGRO-GEOINF, P25
   Das M, 2017, IEEE J-STARS, V10, P5228, DOI 10.1109/JSTARS.2017.2760202
   Gao F, 2015, IEEE GEOSC REM SEN M, V3, P47, DOI 10.1109/MGRS.2015.2434351
   Irish R. R., 2000, P SOC PHOTO-OPT INS, V4049, pVI
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   KUMAR S, 2018, EGYPT J REMOTE SENS, V21, P343, DOI DOI 10.1016/J.EJRS.2018.01.006
   Manikanta C, 2015, 2015 INTERNATIONAL CONFERENCE ON SMART SENSORS AND SYSTEMS (IC-SSS 2015)
   Sahana M, 2015, MODEL EARTH SYST ENV, V1, DOI 10.1007/s40808-015-0043-0
   Schultz M, 2016, INT J APPL EARTH OBS, V52, P318, DOI 10.1016/j.jag.2016.06.020
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
NR 12
TC 0
Z9 0
U1 1
U2 12
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0256-4602
EI 0974-5971
J9 IETE TECH REV
JI IETE Tech. Rev.
PY 2020
DI 10.1080/02564602.2020.1827987
EA OCT 2020
PG 8
WC Engineering, Electrical & Electronic; Telecommunications
SC Engineering; Telecommunications
GA OC7YK
UT WOS:000579373300001
DA 2022-01-04
ER

PT J
AU Zhang, YS
   Zhu, YC
   Li, HF
   Chen, SY
   Peng, J
   Zhao, L
AF Zhang, Yunsheng
   Zhu, Yaochen
   Li, Haifeng
   Chen, Siyang
   Peng, Jian
   Zhao, Ling
TI Automatic Changes Detection between Outdated Building Maps and New VHR
   Images Based on Pre-Trained Fully Convolutional Feature Maps
SO SENSORS
LA English
DT Article
DE changes detection; fully convolutional feature maps; outdated building
   map; VHR images
ID CLASSIFICATION; ALGORITHMS; NETWORKS
AB Detecting changes between the existing building basemaps and newly acquired high spatial resolution remotely sensed (HRS) images is a time-consuming task. This is mainly because of the data labeling and poor performance of hand-crafted features. In this paper, for efficient feature extraction, we propose a fully convolutional feature extractor that is reconstructed from the deep convolutional neural network (DCNN) and pre-trained on the Pascal VOC dataset. Our proposed method extract pixel-wise features, and choose salient features based on a random forest (RF) algorithm using the existing basemaps. A data cleaning method through cross-validation and label-uncertainty estimation is also proposed to select potential correct labels and use them for training an RF classifier to extract the building from new HRS images. The pixel-wise initial classification results are refined based on a superpixel-based graph cuts algorithm and compared to the existing building basemaps to obtain the change map. Experiments with two simulated and three real datasets confirm the effectiveness of our proposed method and indicate high accuracy and low false alarm rate.
C1 [Zhang, Yunsheng; Li, Haifeng; Chen, Siyang; Peng, Jian; Zhao, Ling] Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
   [Zhu, Yaochen] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China.
RP Zhao, L (corresponding author), Cent South Univ, Sch Geosci & Infophys, Changsha 410083, Peoples R China.
EM zhangys@csu.edu.cn; 0107150110@csu.edu.cn; lehaifeng@csu.edu.cn;
   siyangchen@csu.edu.cn; PengJ2017@csu.edu.cn; zhaoling@csu.edn.cn
OI zhang, yunsheng/0000-0002-2779-2015
FU Hunan Provincial Natural Science Foundation of ChinaNatural Science
   Foundation of Hunan Province [2018JJ3637]; Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [51978283];
   Open Fund of Key Laboratory of Urban Land Resource Monitoring and
   Simulation, Ministry of Land and Resource [KF-2018-03-047]
FX This research was funded by Hunan Provincial Natural Science Foundation
   of China (No. 2018JJ3637), Natural Science Foundation of China (No.
   51978283), Open Fund of Key Laboratory of Urban Land Resource Monitoring
   and Simulation, Ministry of Land and Resource (No. KF-2018-03-047).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen J.J., 2017, ARXIV170801420
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Chen SY, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9010018
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P6712, DOI 10.1109/TGRS.2018.2841823
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   Dianat R, 2010, IEEE GEOSCI REMOTE S, V7, P215, DOI 10.1109/LGRS.2009.2031686
   Dong LG, 2013, ISPRS J PHOTOGRAMM, V84, P85, DOI 10.1016/j.isprsjprs.2013.06.011
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Gevaert CM, 2018, IEEE J-STARS, V11, P2731, DOI 10.1109/JSTARS.2017.2762905
   Gong JQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071557
   Griffiths P, 2010, REMOTE SENS ENVIRON, V114, P426, DOI 10.1016/j.rse.2009.09.012
   Guo Z, 2017, GISCI REMOTE SENS, V54, P38, DOI 10.1080/15481603.2016.1250328
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI [DOI 10.1162/153244303322753616, DOI 10.1038/S41746-021-00402-X]
   Han D, 2013, INT MULTI SCI GEOCO, P595
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiser P, 2017, IEEE T GEOSCI REMOTE, V55, P6054, DOI 10.1109/TGRS.2017.2719738
   Kalnay E, 2003, NATURE, V423, P528, DOI 10.1038/nature01675
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MA L, 2016, REMOTE SENS BASEL, V0008, DOI DOI 10.3390/rs8090761
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Matthew D., 2014, P 13 EUR C COMP VIS, P6
   Mirzapour F, 2013, IRAN CONF ELECTR ENG
   Mnih V, 2013, MACHINE LEARNING AER
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Ren SQ, 2015, ADV NEUR IN, V28
   Simonyan K., 2015, P INT C LEARN REPR I
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan TL, 2017, IEEE GEOSCI REMOTE S, V14, P2305, DOI 10.1109/LGRS.2017.2762466
   Wiener, 2002, R NEWS, V2, P18, DOI DOI 10.1177/154405910408300516
   Yao CC, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1947, DOI 10.1109/CompComm.2017.8322878
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao B, 2017, IEEE GEOSCI REMOTE S, V14, P1436, DOI 10.1109/LGRS.2017.2691013
   Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8
   Zhuqiang L., 2017, IEEE J SEL TOP APPL, V10, P1
NR 51
TC 0
Z9 0
U1 7
U2 11
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD OCT
PY 2020
VL 20
IS 19
AR 5538
DI 10.3390/s20195538
PG 20
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA ON2CK
UT WOS:000586515700001
PM 32992580
OA gold, Green Published
DA 2022-01-04
ER

PT J
AU Lin, Y
   Li, ST
   Fang, LY
   Ghamisi, P
AF Lin, Yun
   Li, Shutao
   Fang, Leyuan
   Ghamisi, Pedram
TI Multispectral Change Detection With Bilinear Convolutional Neural
   Networks
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Training; Image color analysis; Convolutional neural
   networks; Remote sensing; Indexes; Kernel; Bilinear convolutional neural
   networks (BCNNs) model; change detection; multispectral images
ID IMAGE
AB Recently, deep learning has been demonstrated to be an effective tool to detect changes in bitemporal remote sensing images. However, most existing methods based on deep learning obtain the ultimate change map by analyzing the difference image (DI) or the stacked feature vectors of input images, which cannot sufficiently capture the relationship between the two input images to obtain the change information. In this letter, a new method named bilinear convolutional neural networks (BCNNs) is proposed to detect changes in bitemporal multispectral images. The model can be trained end to end with two symmetric convolutional neural networks (CNNs), which are capable of learning the feature representation from bitemporal images and utilizing the relations between the two input images by a linear outer product operation in an effective way. Specifically, two sets of patches obtained from two multispectral images of different times are first input into two CNNs to extract deep features, respectively. Then, the matrix outer product is applied on the output feature maps to obtain the combined bilinear features. Finally, the ultimate change detected result can be produced by applying the softmax classifier on the combined features. Experimental results on real multispectral data sets demonstrate the superiority of the proposed method over several well-known change-detection approaches.
C1 [Lin, Yun; Li, Shutao; Fang, Leyuan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
   [Lin, Yun; Li, Shutao; Fang, Leyuan] Key Lab Visual Percept & Artificial Intelligence, Changsha 410082, Peoples R China.
   [Ghamisi, Pedram] Helmholtz Inst Freiberg Resource Technol, Helmholtz Zentrum Dresden Rossendorf, D-09599 Freiberg, Germany.
RP Fang, LY (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Peoples R China.
EM linyun@hnu.edu.cn; shutao_li@hnu.edu.cn; fangleyuan@gmail.com;
   p.ghamisi@gmail.com
RI Ghamisi, Pedram/ABD-5419-2021
OI Li, Shutao/0000-0002-0585-9848; Fang, Leyuan/0000-0003-2351-4461
FU National Natural Science Fund of China for International Cooperation and
   Exchanges [61520106001]; National Natural Science FoundationNational
   Natural Science Foundation of China (NSFC) [61922029]; Science and
   Technology Plan Project Fund of Hunan Province [CX2018B171, 2017RS3024,
   2018TP1013]; Science and Technology Talents Program of Hunan Association
   for Science and Technology [2017TJ-Q09]
FX This work was supported in part by the National Natural Science Fund of
   China for International Cooperation and Exchanges under Grant
   61520106001, in part by the National Natural Science Foundation under
   Grant 61922029, in part by the Science and Technology Plan Project Fund
   of Hunan Province under Grant CX2018B171, Grant 2017RS3024, and Grant
   2018TP1013, and in part by the Science and Technology Talents Program of
   Hunan Association for Science and Technology under Grant 2017TJ-Q09.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2017, IEEE GEOSCI REMOTE S, V14, P324, DOI 10.1109/LGRS.2016.2639540
   Liu SC, 2016, IEEE T GEOSCI REMOTE, V54, P2733, DOI 10.1109/TGRS.2015.2505183
   Matasci G, 2015, IEEE T GEOSCI REMOTE, V53, P3550, DOI 10.1109/TGRS.2014.2377785
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
NR 19
TC 4
Z9 4
U1 12
U2 36
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2020
VL 17
IS 10
BP 1757
EP 1761
DI 10.1109/LGRS.2019.2953754
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA NU7GL
UT WOS:000573808500020
DA 2022-01-04
ER

PT J
AU Bao, TF
   Fu, CQ
   Fang, T
   Huo, H
AF Bao, Tengfei
   Fu, Chenqin
   Fang, Tao
   Huo, Hong
TI PPCNET: A Combined Patch-Level and Pixel-Level End-to-End Deep Network
   for High-Resolution Remote Sensing Image Change Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Remote sensing; Satellites; Training; Convolution;
   Change detection algorithms; Decoding; Bitemporal images; change or
   unchange pairs; combining patch-level and pixel-level information;
   pixel-patch combination net
AB Extracting change regions from bitemporal images is crucial to urban planning, land, and resources survey. In the literature, many methods obtaining difference between bitemporal remote sensing images have been proposed. However, there are still some problems due to the complexity of change conditions. In order to solve the above-mentioned problems, we propose a novel network called PPCNET, combining patch-level and pixel-level change detection for bitemporal remote sensing images. This network is divided into three branches: the dual structure is used to extract features of bitemporal images, respectively; changed or unchanged image regions are then detected through fully connected layers, and a soft-max layer at patch level. Once a change is detected at patch level, feature encoder and decoder at pixel level are activated to obtain accurate change boundary. Furthermore, a feature pyramid network-based architecture is employed to fuse information in different layers to further improve change detection effectiveness. Experiments on both satellite and aerial remote sensing images have verified that PPCNET network yields higher change detection accuracy with faster detection speed.
C1 [Bao, Tengfei; Fu, Chenqin; Fang, Tao] Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
   [Huo, Hong] Shanghai Jiao Tong Univ, Coll Elect Informat & Elect Engn, Shanghai, Peoples R China.
RP Bao, TF (corresponding author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
EM btflmqy1314@sjtu.edu.cn
OI Bao, tengfei/0000-0001-5412-7718; Huo, Hong/0000-0002-2862-9455
FU National Key Research and Development Program of China [2018YFB0505000];
   National Science and Technology Major Project [21-Y20A069001-17/18];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41571402]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2018YFB0505000, in part by the
   National Science and Technology Major Project under Grant
   21-Y20A069001-17/18, and in part by the National Natural Science
   Foundation of China under Grant 41571402.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Lei Z, 2014, IEEE T GEOSCI REMOTE, V52, P1227, DOI 10.1109/TGRS.2013.2248738
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Simonyan K, 2014, ArXiv:1409.1556
   Solano-Correa YT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040533
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 13
TC 6
Z9 6
U1 18
U2 42
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2020
VL 17
IS 10
BP 1797
EP 1801
DI 10.1109/LGRS.2019.2955309
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA NU7GL
UT WOS:000573808500028
DA 2022-01-04
ER

PT J
AU Zhang, M
   Shi, WZ
AF Zhang, Min
   Shi, Wenzhong
TI A Feature Difference Convolutional Neural Network-Based Change Detection
   Method
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Training; Sensors; Task analysis; Convolutional
   neural networks; Spatial resolution; Deep learning; Change detection;
   convolutional neural network (CNN); deep feature; high spatial
   resolution; remote sensing (RS)
ID UNSUPERVISED CHANGE-DETECTION; CHANGE VECTOR ANALYSIS; IMAGE
   CLASSIFICATION; SATELLITE IMAGES
AB Change detection based on remote sensing (RS) images has a wide range of applications in many fields. However, many existing approaches for detecting changes in RS images with complex land covers still have room for improvement. In this article, a high-resolution RS image change detection approach based on a deep feature difference convolutional neural network (CNN) is proposed. This approach uses a CNN to learn the deep features from RS images and then uses transfer learning to compose a two-channel network with shared weight to generate a multiscale and multidepth feature difference map for change detection. The network is trained by a change magnitude guided loss function proposed in this article and needs to train with only a few pixel-level samples to generate change magnitude maps, which can help to remove some of the pseudochanges. Finally, the binary change map can be obtained by a threshold. The approach is tested on several data sets from different sensors, including WorldView-3, QuickBird, and Ziyuan-3. The experimental results show that the proposed approach achieves better performance compared with other classic approaches and has fewer missed detections and false alarms, which proves that the proposed approach has strong robustness and generalization ability.
C1 [Zhang, Min; Shi, Wenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
RP Shi, WZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM 007zhangmin@whu.edu.cn; lswzshi@polyu.edu.hk
RI ZHANG, Min/AAV-9787-2020
OI ZHANG, Min/0000-0003-1643-5271
FU Ministry of Science and Technology of the People's Republic of
   ChinaMinistry of Science and Technology, China [2017YFB0503604]
FX This work was supported in part by the Ministry of Science and
   Technology of the People's Republic of China under Project
   2017YFB0503604.
CR Alidoost F, 2016, INT ARCH PHOTOGRAMM, V41, P833, DOI 10.5194/isprsarchives-XLI-B3-833-2016
   Artur L, 2017, ARXIV170104949
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cao C, 2019, ENVIRONMENTS, V6, DOI 10.3390/environments6020025
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, INT GEOSCI REMOTE SE, P767, DOI 10.1109/IGARSS.2016.7729193
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Fang ZZ, 2016, INT GEOSCI REMOTE SE, P2610, DOI 10.1109/IGARSS.2016.7729674
   Geng J, 2015, IEEE GEOSCI REMOTE S, V12, P2351, DOI 10.1109/LGRS.2015.2478256
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang ZM, 2016, INT GEOSCI REMOTE SE, P1835, DOI 10.1109/IGARSS.2016.7729471
   Iino S, 2017, PROC SPIE, V10428, DOI 10.1117/12.2277901
   Jia PY, 2016, INT GEOSCI REMOTE SE, P5075, DOI 10.1109/IGARSS.2016.7730323
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Ma XR, 2018, IEEE T GEOSCI REMOTE, V56, P4781, DOI 10.1109/TGRS.2018.2837142
   Melgani F, 2002, OPT ENG, V41, P3288, DOI 10.1117/1.1518995
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Saito S, 2015, PROC SPIE, V9405, DOI 10.1117/12.2083273
   Sherrah J., 2016, ARXIV160602585
   Shi C, 2017, INFORM SCIENCES, V420, P49, DOI 10.1016/j.ins.2017.08.051
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wiemker R., 1997, P 3 INT AIRB REM SEN, P640
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Yang JX, 2016, INT GEOSCI REMOTE SE, P5079, DOI 10.1109/IGARSS.2016.7730324
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zeggada A, 2016, INT GEOSCI REMOTE SE, P5083, DOI 10.1109/IGARSS.2016.7730325
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang FZ, 2018, PROC SPIE, V10615, DOI 10.1117/12.2304916
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang QC, 2016, INT GEOSCI REMOTE SE, P661, DOI 10.1109/IGARSS.2016.7729166
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhi L, 2019, REMOTE SENS LETT, V10, P59, DOI 10.1080/2150704X.2018.1526424
   Zhong J, 2006, INT J REMOTE SENS, V27, P2055, DOI 10.1080/01431160500444756
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhong YF, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025006
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 67
TC 21
Z9 22
U1 22
U2 69
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD OCT
PY 2020
VL 58
IS 10
BP 7232
EP 7246
DI 10.1109/TGRS.2020.2981051
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA NU8YK
UT WOS:000573923100035
DA 2022-01-04
ER

PT J
AU Shi, N
   Chen, KM
   Zhou, GY
   Sun, X
AF Shi, Nian
   Chen, Keming
   Zhou, Guangyao
   Sun, Xian
TI A Feature Space Constraint-Based Method for Change Detection in
   Heterogeneous Images
SO REMOTE SENSING
LA English
DT Article
DE change detection; heterogeneous images; feature space constraint
ID REMOTE-SENSING IMAGES; CLASSIFICATION; NETWORK
AB With the development of remote sensing technologies, change detection in heterogeneous images becomes much more necessary and significant. The main difficulty lies in how to make input heterogeneous images comparable so that the changes can be detected. In this paper, we propose an end-to-end heterogeneous change detection method based on the feature space constraint. First, considering that the input heterogeneous images are in two distinct feature spaces, two encoders with the same structure are used to extract features, respectively. A decoder is used to obtain the change map from the extracted features. Then, the Gram matrices, which include the correlations between features, are calculated to represent different feature spaces, respectively. The squared Euclidean distance between Gram matrices, termed as feature space loss, is used to constrain the extracted features. After that, a combined loss function consisting of the binary cross entropy loss and feature space loss is designed for training the model. Finally, the change detection results between heterogeneous images can be obtained when the model is trained well. The proposed method can constrain the features of two heterogeneous images to the same feature space while keeping their unique features so that the comparability between features can be enhanced and better detection results can be achieved. Experiments on two heterogeneous image datasets consisting of optical and SAR images demonstrate the effectiveness and superiority of the proposed method.
C1 [Shi, Nian] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
   [Shi, Nian; Chen, Keming; Zhou, Guangyao; Sun, Xian] Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol NIST, Beijing 100094, Peoples R China.
RP Chen, KM (corresponding author), Chinese Acad Sci, Aerosp Informat Res Inst, Key Lab Network Informat Syst Technol NIST, Beijing 100094, Peoples R China.
EM shinian.work@gmail.com; ckmdejob@hotmail.com; zhouguangyao@aircas.ac.cn;
   sunxian@aircas.ac.cn
OI Shi, Nian/0000-0002-5737-9846; Sun, Xian/0000-0002-0038-9816
FU Aerospace Information Research Institute, Chinese Academy of Sciences
FX This work was finished when Nian Shi was an intern at the Key Laboratory
   of Network Information System Technology (NIST), Aerospace Information
   Research Institute, Chinese Academy of Sciences.
CR Auer S, 2017, IEEE J-STARS, V10, P4779, DOI 10.1109/JSTARS.2017.2723082
   Bethge, 2015, ADV NEURAL INFORM PR, P219
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   GATYS LA, 2016, PROC CVPR IEEE, P2414, DOI DOI 10.1109/CVPR.2016.265
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hedhli I, 2016, IEEE T GEOSCI REMOTE, V54, P6333, DOI 10.1109/TGRS.2016.2580321
   Jiang X, 2020, IEEE J-STARS, V13, P1551, DOI 10.1109/JSTARS.2020.2983993
   Jiang X, 2019, INT GEOSCI REMOTE SE, P206, DOI 10.1109/IGARSS.2019.8899123
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Li SD, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111177
   Liu HR, 2019, PROC INT CONF DOC, P8, DOI 10.1109/ICDARW.2019.40073
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu JF, 2019, INT GEOSCI REMOTE SE, P74, DOI 10.1109/IGARSS.2019.8898913
   Liu ZG, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P263
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Manonmani R, 2010, International Journal of Geomatics and Geosciences, V1, P60
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Pang SY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060729
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Touati R, 2018, IEEE IMAGE PROC, P3998, DOI 10.1109/ICIP.2018.8451184
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Wan L, 2019, IEEE T GEOSCI REMOTE, V57, P9941, DOI 10.1109/TGRS.2019.2930322
   Wang HZ, 2011, COMPUT MED IMAG GRAP, V35, P116, DOI 10.1016/j.compmedimag.2010.09.006
   WU B, 2018, IEEE GEOSCI REMOTE S, V16, P266, DOI DOI 10.1109/LGRS.2018.2869608
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu L, 2012, INT J REMOTE SENS, V33, P3966, DOI 10.1080/01431161.2011.636081
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   [张庆君 Zhang Qingjun], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P269
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhou WQ, 2008, SENSORS-BASEL, V8, P1613, DOI 10.3390/s8031613
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
NR 46
TC 2
Z9 2
U1 9
U2 13
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2020
VL 12
IS 18
AR 3057
DI 10.3390/rs12183057
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA OF4XJ
UT WOS:000581212300001
OA gold
DA 2022-01-04
ER

PT J
AU Timilsina, S
   Aryal, J
   Kirkpatrick, JB
AF Timilsina, Shirisa
   Aryal, Jagannath
   Kirkpatrick, Jamie B.
TI Mapping Urban Tree Cover Changes Using Object-Based Convolution Neural
   Network (OB-CNN)
SO REMOTE SENSING
LA English
DT Article
DE convolution neural networks (CNNs); deep learning; GEOBIA; object-based
   CNN; urban tree mapping; socioeconomic predictor variables
ID MONITORING LAND-COVER; REAL TIME DETECTION; IMAGE-ANALYSIS; BEETLE
   INFESTATION; ECOSYSTEM SERVICES; METROPOLITAN-AREA; ORIENTED APPROACH;
   SCALE PARAMETER; CANOPY COVER; FOREST
AB Urban trees provide social, economic, environmental and ecosystem services benefits that improve the liveability of cities and contribute to individual and community wellbeing. There is thus a need for effective mapping, monitoring and maintenance of urban trees. Remote sensing technologies can effectively map and monitor urban tree coverage and changes over time as an efficient and low-cost alternative to field-based measurements, which are time consuming and costly. Automatic extraction of urban land cover features with high accuracy is a challenging task, and it demands object based artificial intelligence workflows for efficiency and thematic accuracy. The aim of this research is to effectively map urban tree cover changes and model the relationship of such changes with socioeconomic variables. The object-based convolutional neural network (CNN) method is illustrated by mapping urban tree cover changes between 2005 and 2015/16 using satellite, Google Earth imageries and Light Detection and Ranging (LiDAR) datasets. The training sample for CNN model was generated by Object Based Image Analysis (OBIA) using thresholds in a Canopy Height Model (CHM) and the Normalised Difference Vegetation Index (NDVI). The tree heatmap produced from the CNN model was further refined using OBIA. Tree cover loss, gain and persistence was extracted, and multiple regression analysis was applied to model the relationship with socioeconomic variables. The overall accuracy and kappa coefficient of tree cover extraction was 96% and 0.77 for 2005 images and 98% and 0.93 for 2015/16 images, indicating that the object-based CNN technique can be effectively implemented for urban tree coverage mapping and monitoring. There was a decline in tree coverage in all suburbs. Mean parcel size and median household income were significantly related to tree cover loss (R-2= 58.5%). Tree cover gain and persistence had positive relationship with tertiary education, parcel size and ownership change (gain: R-2= 67.8% and persistence: R-2= 75.3%). The research findings demonstrated that remote sensing data with intelligent processing can contribute to the development of policy input for management of tree coverage in cities.
C1 [Timilsina, Shirisa; Aryal, Jagannath; Kirkpatrick, Jamie B.] Univ Tasmania, Discipline Geog & Spatial Sci, Sch Technol Environm & Design, Hobart, Tas 7001, Australia.
   [Aryal, Jagannath] Univ Melbourne, Melbourne Sch Engn, Parkville, Vic 3010, Australia.
RP Aryal, J (corresponding author), Univ Tasmania, Discipline Geog & Spatial Sci, Sch Technol Environm & Design, Hobart, Tas 7001, Australia.; Aryal, J (corresponding author), Univ Melbourne, Melbourne Sch Engn, Parkville, Vic 3010, Australia.
EM shirisa.timilsina@utas.edu.au; Jagannath.aryal@unimelb.edu.au;
   J.Kirkpatrick@utas.edu.au
RI Aryal, Jagannath/E-8529-2012
OI Aryal, Jagannath/0000-0002-4875-2127; Kirkpatrick,
   James/0000-0003-2763-2692
CR Alom M. Z., 2018, ARXIV180301164
   Anees A, 2014, IEEE GEOSCI REMOTE S, V11, P1717, DOI 10.1109/LGRS.2014.2306712
   Anees A, 2016, IEEE J-STARS, V9, P3359, DOI 10.1109/JSTARS.2015.2428306
   Anees A, 2014, IEEE J-STARS, V7, P3713, DOI 10.1109/JSTARS.2014.2330830
   Ardila JP, 2012, INT J APPL EARTH OBS, V15, P57, DOI 10.1016/j.jag.2011.06.005
   Australian Bureau of Statistics, 2019, AUSTR BUR STAT BELC
   Ballantyne M, 2015, J ENVIRON MANAGE, V159, P94, DOI 10.1016/j.jenvman.2015.05.007
   Banzhaf E, 2015, INT ARCH PHOTOGRAMM, V47, P301, DOI 10.5194/isprsarchives-XL-7-W3-301-2015
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Belgiu M, 2014, REMOTE SENS-BASEL, V6, P1347, DOI 10.3390/rs6021347
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Bolstad P., 2012, GIS FUNDAMENTALS 1 T
   Bolund P, 1999, ECOL ECON, V29, P293, DOI 10.1016/S0921-8009(99)00013-0
   Bowden L.W., 1975, MAN REMOTE SENS, V12, P1815
   Branson S, 2018, ISPRS J PHOTOGRAMM, V135, P13, DOI 10.1016/j.isprsjprs.2017.11.008
   Brunner J, 2013, PLAN PRACT RES, V28, P231, DOI 10.1080/02697459.2012.733525
   CHEN LC, 2016, PROC CVPR IEEE, P4545, DOI DOI 10.1109/CVPR.2016.492
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Csillik O, 2018, DRONES-BASEL, V2, DOI 10.3390/drones2040039
   Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
   Du SH, 2019, GISCI REMOTE SENS, V56, P184, DOI 10.1080/15481603.2018.1502399
   Dubayah RO, 2000, J FOREST, V98, P44
   Duro DC, 2012, REMOTE SENS ENVIRON, V118, P259, DOI 10.1016/j.rse.2011.11.020
   Ehlers M, 2003, ISPRS J PHOTOGRAMM, V57, P315, DOI 10.1016/S0924-2716(02)00161-2
   Ejares JA, 2016, INT ARCH PHOTOGRAMM, V41, P611, DOI 10.5194/isprsarchives-XLI-B8-611-2016
   Ellis EA, 2019, COMPUT ENVIRON URBAN, V73, P85, DOI 10.1016/j.compenvurbsys.2018.08.006
   Erker T, 2019, REMOTE SENS ENVIRON, V229, P148, DOI 10.1016/j.rse.2019.03.037
   Fan C, 2019, LANDSCAPE URBAN PLAN, V181, P10, DOI 10.1016/j.landurbplan.2018.09.012
   Fu TY, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.025010
   FUKUSHIMA K, 1988, NEURAL NETWORKS, V1, P119, DOI 10.1016/0893-6080(88)90014-7
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Grove JM, 2006, ECOSYSTEMS, V9, P578, DOI 10.1007/s10021-006-0116-z
   Grove J.M., 1997, URBAN ECOSYST, V1, P259, DOI [DOI 10.1023/A:1018591931544, 10.1023/A:1018591931544]
   Guo TD, 2019, SCI TOTAL ENVIRON, V681, P202, DOI 10.1016/j.scitotenv.2019.05.122
   Heumann BW, 2011, REMOTE SENS-BASEL, V3, P2440, DOI 10.3390/rs3112440
   Huete A.R., 1995, REMOTE SENSING REV, V13, P95, DOI [DOI 10.1080/02757259509532298, 10.1080/02757259509532298]
   Iverson L.R., 2000, URBAN ECOSYST, V4, P105, DOI DOI 10.1023/A:1011307327314
   Jin BX, 2019, J INDIAN SOC REMOTE, V47, P951, DOI 10.1007/s12524-019-00945-3
   Kaspar J, 2017, URBAN FOR URBAN GREE, V24, P26, DOI 10.1016/j.ufug.2017.03.013
   Ke YH, 2011, INT J REMOTE SENS, V32, P4725, DOI 10.1080/01431161.2010.494184
   Kirkpatrick JB, 2007, LANDSCAPE URBAN PLAN, V79, P314, DOI 10.1016/j.landurbplan.2006.03.006
   Kirkpatrick JB, 2012, LANDSCAPE URBAN PLAN, V107, P147, DOI 10.1016/j.landurbplan.2012.05.015
   Kirkpatrick JB, 2011, LANDSCAPE URBAN PLAN, V101, P244, DOI 10.1016/j.landurbplan.2011.02.029
   Kirkpatrick JB, 2013, GEOFORUM, V48, P165, DOI 10.1016/j.geoforum.2013.04.018
   Li WJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010011
   Lima JMT, 2013, LANDSCAPE URBAN PLAN, V120, P96, DOI 10.1016/j.landurbplan.2013.08.007
   Lin B, 2015, URBAN FOR URBAN GREE, V14, P952, DOI 10.1016/j.ufug.2015.09.003
   Lohr Virginia I., 2004, Journal of Arboriculture, V30, P28
   Martin CA, 2004, LANDSCAPE URBAN PLAN, V69, P355, DOI 10.1016/j.landurbplan.2003.10.034
   Mikita T, 2016, FORESTS, V7, DOI 10.3390/f7080165
   Ming DP, 2015, ISPRS J PHOTOGRAMM, V106, P28, DOI 10.1016/j.isprsjprs.2015.04.010
   Minitab Inc, 1998, US GUID DAT AN QUAL
   Moskal LM, 2011, REMOTE SENS-BASEL, V3, P2243, DOI 10.3390/rs3102243
   Nowak DJ, 1996, LANDSCAPE URBAN PLAN, V36, P49, DOI 10.1016/S0169-2046(96)00324-6
   O'Neil-Dunne J, 2014, REMOTE SENS-BASEL, V6, P12837, DOI 10.3390/rs61212837
   Ossola A, 2018, SCI TOTAL ENVIRON, V612, P940, DOI 10.1016/j.scitotenv.2017.08.103
   Pauleit S, 2005, LANDSCAPE URBAN PLAN, V71, P295, DOI [10.1016/S0169-2046(04)00083-0, 10.1016/j.landurbplan.2004.03.009]
   Potapov PV, 2012, REMOTE SENS ENVIRON, V122, P106, DOI 10.1016/j.rse.2011.08.027
   Rogan J, 2004, PROG PLANN, V61, P301, DOI 10.1016/S0305-9006(03)00066-7
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Shackleton S, 2015, LANDSCAPE URBAN PLAN, V136, P76, DOI 10.1016/j.landurbplan.2014.12.004
   SOLECKI WD, 1995, LANDSCAPE URBAN PLAN, V32, P93, DOI 10.1016/0169-2046(94)00193-7
   Stave J, 2001, ENVIRON CONSERV, V28, P150, DOI 10.1017/S0376892901000157
   Steenberg JWN, 2019, ENVIRON PLAN B-URBAN, V46, P1115, DOI 10.1177/2399808317752927
   TALARCHEK GM, 1990, URBAN GEOGR, V11, P65, DOI 10.2747/0272-3638.11.1.65
   TheLIST, 2019, LAND INF SYST TASM D
   Timilsina S., 2019, CONVOLUTIONAL NEURAL, P111, DOI [10.5194/isprs-annals-IV-5-W2-111-2019, DOI 10.5194/ISPRS-ANNALS-IV-5-W2-111-2019]
   Trimble eCogntion Software, 2019, TUT 7 CONV NEUR NETW
   Tyrvainen Liisa, 2003, Urban Forestry & Urban Greening, V1, P135, DOI 10.1078/1618-8667-00014
   Walker JS, 2008, INT J REMOTE SENS, V29, P2021, DOI 10.1080/01431160701408337
   Walker JS, 2007, PHOTOGRAMM ENG REM S, V73, P577, DOI 10.14358/PERS.73.5.577
   Wang ZL, 2018, COMPUT ELECTRON AGR, V151, P501, DOI 10.1016/j.compag.2018.06.040
   Xiao Qingfu, 2005, Urban Ecosystems, V8, P349, DOI 10.1007/s11252-005-4867-7
   Yang CH, 2012, COMPUT ELECTRON AGR, V88, P13, DOI 10.1016/j.compag.2012.07.003
   Zhang QC, 2016, INT GEOSCI REMOTE SE, P661, DOI 10.1109/IGARSS.2016.7729166
   Zhou JH, 2014, REMOTE SENS-BASEL, V6, P9086, DOI 10.3390/rs6099086
   Zhou WQ, 2008, SENSORS-BASEL, V8, P1613, DOI 10.3390/s8031613
   Zhou WX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050489
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 81
TC 10
Z9 10
U1 14
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2020
VL 12
IS 18
AR 3017
DI 10.3390/rs12183017
PG 27
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA OD7PL
UT WOS:000580040900001
OA Green Submitted, Green Accepted, gold
DA 2022-01-04
ER

PT J
AU Qiao, HJ
   Wa, X
   Wan, YC
   Li, SY
   Zhang, WF
AF Qiao, Huijiao
   Wa, Xue
   Wan, Youchuan
   Li, Shengyang
   Zhang, Wanfeng
TI A Novel Change Detection Method for Natural Disaster Detection and
   Segmentation from Video Sequence
SO SENSORS
LA English
DT Article
DE change detection; natural disasters; deep learning; threshold selection;
   optical flow estimation
ID OPTICAL-FLOW; EARTHQUAKE
AB Change detection (CD) is critical for natural disaster detection, monitoring and evaluation. Video satellites, new types of satellites being launched recently, are able to record the motion change during natural disasters. This raises a new problem for traditional CD methods, as they can only detect areas with highly changed radiometric and geometric information. Optical flow-based methods are able to detect the pixel-based motion tracking at fast speed; however, they are difficult to determine an optimal threshold for separating the changed from the unchanged part for CD problems. To overcome the above problems, this paper proposed a novel automatic change detection framework: OFATS (optical flow-based adaptive thresholding segmentation). Combining the characteristics of optical flow data, a new objective function based on the ratio of maximum between-class variance and minimum within-class variance has been constructed and two key steps are motion detection based on optical flow estimation using deep learning (DL) method and changed area segmentation based on an adaptive threshold selection. Experiments are carried out using two groups of video sequences, which demonstrated that the proposed method is able to achieve high accuracy with F1 value of 0.98 and 0.94, respectively.
C1 [Qiao, Huijiao; Wan, Youchuan] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Qiao, Huijiao; Wa, Xue; Li, Shengyang; Zhang, Wanfeng] Chinese Acad Sci, Technol & Engn Ctr Space Utilizat, Beijing 100094, Peoples R China.
   [Wa, Xue; Li, Shengyang; Zhang, Wanfeng] Chinese Acad Sci, Key Lab Space Utilizat, Beijing 100094, Peoples R China.
RP Wan, YC (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM qiaohj@whu.edu.cn; wanxue@csu.ac.cn; ychwan@whu.edu.cn; shyli@csu.ac.cn;
   wfzhang@csu.ac.cn
OI li, sheng yang/0000-0002-9888-9869
FU National Key Research and Development Program of China [2018YFD1100405];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41701468]
FX This work was supported in part by the National Key Research and
   Development Program of China (No. 2018YFD1100405) and the National
   Natural Science Foundation of China (No. 41701468).
CR Alizadeh M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060975
   [Anonymous], **NON-TRADITIONAL**
   [Anonymous], **NON-TRADITIONAL**
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Bejiga MB, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020100
   Cai JH, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080830
   Cao Y., 2008, IFAC P VOL, V41, P158, DOI [10.3182/20080706-5-KR-1001.00027, DOI 10.3182/20080706-5-KR-1001.00027]
   Carlotto MJ, 1997, IEEE T IMAGE PROCESS, V6, P189, DOI 10.1109/83.552106
   Ci TY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232858
   Crooks AT, 2013, COMPUT ENVIRON URBAN, V41, P100, DOI 10.1016/j.compenvurbsys.2013.05.003
   Curtis A.J., 2009, SPACE TIME CHANGES N, P373
   Curtis A, 2012, APPL GEOGR, V32, P393, DOI 10.1016/j.apgeog.2011.06.002
   Dosovitskiy A., 2003, P IEEE INT C COMP VI, P2758
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   ElGharbawi T, 2015, REMOTE SENS ENVIRON, V168, P374, DOI 10.1016/j.rse.2015.07.016
   Gautam D, 2018, J BUILD ENG, V17, P196, DOI 10.1016/j.jobe.2018.02.016
   Ghaffarian S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202427
   Gronskyte R, 2016, BIOSYST ENG, V141, P19, DOI 10.1016/j.biosystemseng.2015.10.002
   Guo YY, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.05.037
   Hall O, 2003, INT J APPL EARTH OBS, V4, P311, DOI [DOI 10.1016/S0303-2434(03)00010-, DOI 10.1016/S0303-2434(03)00010-2]
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Ilg E., 1996, P IEEE C COMP VIS PA, P2462
   Ji M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101202
   Khan Muhammad Waseem, 2014, International Journal of Future Computer and Communication, V3, P89, DOI 10.7763/IJFCC.2014.V3.274
   Klomp J, 2016, GLOBAL ENVIRON CHANG, V36, P67, DOI 10.1016/j.gloenvcha.2015.11.001
   Kung HK, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10124234
   Lacroix P, 2018, REMOTE SENS ENVIRON, V215, P507, DOI 10.1016/j.rse.2018.03.042
   Lee S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173495
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Liu Y, 2015, J HYDROL, V529, P354, DOI 10.1016/j.jhydrol.2015.07.042
   Lu CC, 2016, TRANSPORT RES E-LOG, V93, P1, DOI 10.1016/j.tre.2016.05.002
   Matsuoka M, 2005, EARTHQ SPECTRA, V21, pS285, DOI 10.1193/1.2101027
   Milly PCD, 2002, NATURE, V415, P514, DOI 10.1038/415514a
   Osman AB, 2020, MEASUREMENT, V153, DOI 10.1016/j.measurement.2019.107396
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pi YL, 2020, ADV ENG INFORM, V43, DOI 10.1016/j.aei.2019.101009
   Prajapati D., 2015, REV MOVING OBJECT DE
   Pulvirenti L, 2011, REMOTE SENS ENVIRON, V115, P990, DOI 10.1016/j.rse.2010.12.002
   Qiao H.J., 2020, ISPRS ANN PHOTOGRAMM, V3, P317, DOI [10.5194/isprs-annals-V-3-2020-317-2020, DOI 10.5194/ISPRS-ANNALS-V-3-2020-317-2020]
   Sharma K, 2018, J INDIAN SOC REMOTE, V46, P605, DOI 10.1007/s12524-017-0720-8
   Shi WZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101688
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Sudipan S., 2018, P IM SIGN PROC REM S
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Tchernykh V., 2006, Mechatronics 2006. 4th IFAC Symposium on Mechatronic Systems. Preprints, P590
   Tu ZG, 2019, SIGNAL PROCESS-IMAGE, V72, P9, DOI 10.1016/j.image.2018.12.002
   Vala H., 2013, INT J ADV RES COMPUT, V2, P387, DOI DOI 10.1007/S11548-009-0389-8
   Wang L, 2019, MED IMAGE ANAL, V57, P136, DOI 10.1016/j.media.2019.06.016
   Wei SG, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.650
   Yan WJ, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103356
   Yavariabdi A, 2017, IEEE GEOSCI REMOTE S, V14, P414, DOI 10.1109/LGRS.2016.2645742
   Yu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121233
   Yuan QQ, 2020, REMOTE SENS ENVIRON, V241, DOI 10.1016/j.rse.2020.111716
   Yuan W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202410
   Zhao R, 2016, OPT COMMUN, V371, P144, DOI 10.1016/j.optcom.2016.03.075
NR 59
TC 4
Z9 4
U1 5
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD SEP
PY 2020
VL 20
IS 18
AR 5076
DI 10.3390/s20185076
PG 20
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA OE7GP
UT WOS:000580695000001
PM 32906675
OA gold, Green Published
DA 2022-01-04
ER

PT J
AU Qian, JH
   Xia, M
   Zhang, YH
   Liu, J
   Xu, YQ
AF Qian, Junhao
   Xia, Min
   Zhang, Yonghong
   Liu, Jia
   Xu, Yiqing
TI TCDNet: Trilateral Change Detection Network for Google Earth Image
SO REMOTE SENSING
LA English
DT Article
DE change detection; convolutional neural networks; deep learning
ID CLASSIFICATION
AB Change detection is a very important technique for remote sensing data analysis. Its mainstream solutions are either supervised or unsupervised. In supervised methods, most of the existing change detection methods using deep learning are related to semantic segmentation. However, these methods only use deep learning models to process the global information of an image but do not carry out specific trainings on changed and unchanged areas. As a result, many details of local changes could not be detected. In this work, a trilateral change detection network is proposed. The proposed network has three branches (a main module and two auxiliary modules, all of them are composed of convolutional neural networks (CNNs)), which focus on the overall information of bitemporal Google Earth image pairs, the changed areas and the unchanged areas, respectively. The proposed method is end-to-end trainable, and each component in the network does not need to be trained separately.
C1 [Qian, Junhao; Xia, Min; Zhang, Yonghong; Liu, Jia] Nanjing Univ Informat Sci & Technol, Collaborat Innovat Ctr Atmospher Environm & Equip, Nanjing 210044, Peoples R China.
   [Xu, Yiqing] Nanjing Forestry Univ, Coll Informat Sci & Technol, Nanjing 210037, Peoples R China.
RP Xia, M (corresponding author), Nanjing Univ Informat Sci & Technol, Collaborat Innovat Ctr Atmospher Environm & Equip, Nanjing 210044, Peoples R China.
EM 20181223052@nuist.edu.cn; xiamin@nuist.edu.cn; zyh@nuist.edu.cn;
   liujia@nuist.edu.cn; yiqingxu@njfu.edu.cn
OI Xia, Min/0000-0003-4681-9129
FU National Natural Science Foundation of PR ChinaNational Natural Science
   Foundation of China (NSFC) [41875027, 61773219, 41661144039]
FX This research was funded by the National Natural Science Foundation of
   PR China of grant numbers 41875027, 61773219, and 41661144039.
CR Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bovolo F, 2017, COMPREHENSIVE REMOTE, P156
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Koltun, 2015, 1511 ARXIV, DOI DOI 10.16373/J.CNKI.AHR.150049.ISSN
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Mucia A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12122020
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Oktay O., 2018, ATTENTION U NET LEAR
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2021, IEEE GEOSCI REMOTE S, V18, P856, DOI 10.1109/LGRS.2020.2990284
   Sesnie SE, 2008, REMOTE SENS ENVIRON, V112, P2145, DOI 10.1016/j.rse.2007.08.025
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tian BW, 2015, REMOTE SENS-BASEL, V7, P2647, DOI 10.3390/rs70302647
   Tison C, 2004, IEEE T GEOSCI REMOTE, V42, P2046, DOI 10.1109/TGRS.2004.834630
   Wang J, ARXIV151107122
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wieland M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192330
   Xia M, 2019, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.032602
   Xia M, 2020, IEEE T INF FOREN SEC, V15, P2417, DOI 10.1109/TIFS.2020.2969552
   Xia M, 2019, NEURAL COMPUT APPL, V31, P8931, DOI 10.1007/s00521-019-04414-3
   Xia M, 2019, ELECTR POW SYST RES, V170, P277, DOI 10.1016/j.epsr.2019.01.034
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yokoya N, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030172
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 41
TC 6
Z9 6
U1 10
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD SEP
PY 2020
VL 12
IS 17
AR 2669
DI 10.3390/rs12172669
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA NR5JI
UT WOS:000571598200001
OA gold
DA 2022-01-04
ER

PT J
AU Chen, L
   Zhang, DZ
   Li, P
   Lv, P
AF Chen, Long
   Zhang, Dezheng
   Li, Peng
   Lv, Peng
TI Change Detection of Remote Sensing Images Based on Attention Mechanism
SO COMPUTATIONAL INTELLIGENCE AND NEUROSCIENCE
LA English
DT Article
ID FOREST; CNN
AB In recent years, image processing methods based on convolutional neural networks (CNNs) have achieved very good results. At the same time, many branch techniques have been proposed to improve accuracy. Aiming at the change detection task of remote sensing images, we propose a new network based on U-Net in this paper. The attention mechanism is cleverly applied in the change detection task, and the data-dependent upsampling (DUpsampling) method is used at the same time, so that the network shows improvement in accuracy, and the calculation amount is greatly reduced. The experimental results show that, in the two-phase images of Yinchuan City, the proposed network has a better antinoise ability and can avoid false detection to a certain extent.
C1 [Chen, Long; Zhang, Dezheng; Li, Peng; Lv, Peng] Univ Sci & Technol Beijing USTB, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Chen, Long; Zhang, Dezheng; Li, Peng; Lv, Peng] Beijing Key Lab Knowledge Engn Mat Sci, Beijing, Peoples R China.
RP Lv, P (corresponding author), Univ Sci & Technol Beijing USTB, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.; Lv, P (corresponding author), Beijing Key Lab Knowledge Engn Mat Sci, Beijing, Peoples R China.
EM g20188782@xs.ustb.edu.cn; zdzchina@126.com; b20180321@xs.ustb.edu.cn;
   b1901775@ustb.edu.cn
OI Li, Peng/0000-0001-5453-7389
FU Ningxia Hui Autonomous Region Key Research and Development Program of
   Ningxia Hui Autonomous Region [2019BFG02009]
FX This work was supported by Ningxia Hui Autonomous Region Key Research
   and Development Program of Ningxia Hui Autonomous Region under Grant
   2019BFG02009 (Key Technologies for Intelligent Monitoring of Spatial
   Planning Based on High-Resolution Remote Sensing).
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Carincotte C, 2006, IEEE T GEOSCI REMOTE, V44, P432, DOI 10.1109/TGRS.2005.861007
   Chen L.-C., 2017, RETHINKING ATROUS CO
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dean, 2015, ARXIV150302531
   Deren L. I., 2003, CHANGE DETECTION REM
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kingma D., 2014, 14126980 ARXIV
   KRIZHEVSKY A, 2012, P C NEUR INF PROC SY
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI [10.1109/TPAMI.2018.2858826, 10.1109/ICCV.2017.324]
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Ma M. D., 2013, COMPUTER VISION ECCV
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020142
   Mnih V., 2014, P C NEUR INF PROC SY
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O., 2015, P INT C MED IM COMP
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Szegedy C., 2015, P 2015 IEEE C COMP V, DOI [10.1109/CVPR.2015.72985942-s2.0-84937522268, DOI 10.1109/CVPR.2015.72985942-S2.0-84937522268]
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xu KY, 2015, BIOMARK RES, V3, DOI 10.1186/s40364-015-0030-7
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou F, 2017, CHIN J COMPUT, V7, P1
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 38
TC 3
Z9 3
U1 8
U2 16
PU HINDAWI LTD
PI LONDON
PA ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND
SN 1687-5265
EI 1687-5273
J9 COMPUT INTEL NEUROSC
JI Comput. Intell. Neurosci.
PD AUG 25
PY 2020
VL 2020
AR 6430627
DI 10.1155/2020/6430627
PG 11
WC Mathematical & Computational Biology; Neurosciences
SC Mathematical & Computational Biology; Neurosciences & Neurology
GA NQ3NM
UT WOS:000570771200002
PM 32908477
OA gold, Green Published
DA 2022-01-04
ER

PT J
AU Jing, R
   Liu, S
   Gong, ZN
   Wang, ZH
   Guan, HL
   Gautam, A
   Zhao, WJ
AF Jing, Ran
   Liu, Shuang
   Gong, Zhaoning
   Wang, Zhiheng
   Guan, Hongliang
   Gautam, Atul
   Zhao, Wenji
TI Object-based change detection for VHR remote sensing images based on a
   Trisiamese-LSTM
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID FRAMEWORK; SCALE
AB Change detection has been a research hotspot in remote sensing fields for decades. However, the increasing use of very high-resolution (VHR) remote sensing images have introduced more difficulties in change detection because of the complex details these images contain. In this paper, we propose a novel deep learning architecture for change detection composed of a Trisiamese subnetwork and a long short-term memory (LSTM) subnetwork that fully utilizes the spatial, spectral and multiphase information and improves the change detection capabilities for VHR remote sensing images. Multiscale simple linear iterative clustering (SLIC)-based image segmentation is first performed on multitemporal images at different image scales to obtain edge information-based objects. A Trisiamese subnetwork with six inputs can extract abundant spectral-spatial feature representations; the LSTM subnetwork then uses the extracted image features to effectively analyse the multiphase information in bitemporal images. The proposed method has the following advantages: 1) it can fully utilize the significant spatial information to improve the detection task; 2) it combines the advantages of convolutional architectures for image feature representation and recurrent neural network (RNN) architectures for sequential data representation, unlike most of the algorithms that use either method or that merely use image differencing or stacking operations. The controlled experiments reveal that the multiphase information extracted by the LSTM subnetwork is important to improve the accuracy of the change detection results. The influence of the Trisiamese subnetwork on change detection is even more significant than that of the LSTM subnetwork. Comparisons with other state-of-the-art change detection methods indicate that in areas with clear surface features and limited interference, the proposed method obtains more competitive results compared to state-of-the-art methods, and in regions where the changed objects occur in complex patterns, the proposed method exhibited an ideal performance.
C1 [Jing, Ran; Liu, Shuang; Guan, Hongliang; Gautam, Atul] Capital Normal Univ, Coll Geospatial Informat Sci & Technol, Beijing, Peoples R China.
   [Gong, Zhaoning; Zhao, Wenji] Capital Normal Univ, Coll Resource Environm & Tourism, Beijing, Peoples R China.
   [Wang, Zhiheng] Tianjin Chengjian Univ, Sch Geol & Geomat, Tianjin, Peoples R China.
RP Guan, HL (corresponding author), Capital Normal Univ, Coll Geospatial Informat Sci & Technol, Beijing, Peoples R China.; Gong, ZN (corresponding author), Capital Normal Univ, Coll Resource Environm & Tourism, Beijing, Peoples R China.
EM gongzhn@163.com; guanhongliang@yahoo.com
FU National Key Research and Development Plan [2017YFC1502901]
FX This work was supported by the National Key Research and Development
   Plan [2017YFC1502901].
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Chen ZY, 2016, IEEE T GEOSCI REMOTE, V54, P103, DOI 10.1109/TGRS.2015.2451002
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Collobert R., 2004, P 21 INT C MACH LEAR, DOI [10.1145/1015330.1015415, DOI 10.1145/1015330.1015415]
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Dozat T., 2016, INT C LEARN REPR
   Dragut L, 2014, ISPRS J PHOTOGRAMM, V88, P119, DOI 10.1016/j.isprsjprs.2013.11.018
   Dragut L, 2010, INT J GEOGR INF SCI, V24, P859, DOI 10.1080/13658810903174803
   Fu KR, 2013, SIGNAL PROCESS-IMAGE, V28, P1448, DOI 10.1016/j.image.2013.07.005
   Gong JY, 2008, SCI CHINA SER E, V51, P110, DOI 10.1007/s11431-008-6017-y
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hebel M, 2013, ISPRS J PHOTOGRAMM, V86, P52, DOI 10.1016/j.isprsjprs.2013.09.005
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jensen J.R., 1987, GEOCARTO INT, V2, P65, DOI [10.1080/10106048709354084, DOI 10.1080/10106048709354084]
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Langkvist M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040329
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JY, 2019, NATL SCI REV, V6, P1082, DOI 10.1093/nsr/nwz058
   Linke J, 2009, PHOTOGRAMM ENG REM S, V75, P981, DOI 10.14358/PERS.75.8.981
   Liu B, 2013, IEEE T GEOSCI REMOTE, V51, P907, DOI 10.1109/TGRS.2012.2203358
   Lu TT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091496
   Lv XW, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121946
   Lv XW, 2019, INT J REMOTE SENS, V40, P506, DOI 10.1080/01431161.2018.1513666
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   [马建文 Ma Jianwen], 2004, [地球科学进展, Advance in Earth Sciences], V19, P192
   Meinel G., 2004, INT ARCH PHOTOGRAM B, V35, P1097, DOI DOI 10.3390/RS6042912
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ruder, 2016, ARXIV160904747
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russwurm M, 2017, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2017.193
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tom M., 2003, MACHINE LEARNING
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   WOODCOCK CE, 1987, REMOTE SENS ENVIRON, V21, P311, DOI 10.1016/0034-4257(87)90015-0
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 46
TC 6
Z9 6
U1 16
U2 38
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD AUG 17
PY 2020
VL 41
IS 16
BP 6209
EP 6231
DI 10.1080/01431161.2020.1734253
PG 23
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA ME1PW
UT WOS:000544434600009
DA 2022-01-04
ER

PT J
AU Shi, AY
   Ma, ZL
AF Shi, Aiye
   Ma, Zhenli
TI Change detection of bitemporal multispectral images based on teacher
   student model
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; remote sensing; multispectral image; teacher student
   model; deep learning
ID UNSUPERVISED CHANGE DETECTION; SAR; CLASSIFICATION; FRAMEWORK; FUSION;
   MAD
AB Ordinary multispectral (MS) image change detection (CD) techniques have not excavated the inherent information of MS images. Deep learning methods are a type of effective method that grabs the changed and unchanged information by deep feature extraction. However, a larger number of labeled samples are difficult to obtain for CD in MS images. An unsupervised MS image CD method is proposed based on a teacher student (TS) model. First, pseudotrain samples are produced by an expectation-maximization algorithm, and then the reliable training samples are selected based on the information of local windows. Second, the pseudotraining samples are used as input of the TS model, which is a self-ensembling model and includes a student model and a teacher model. Then the better teacher model of the TS model is updated by the exponential moving average of the student's weight at each training step. Finally, the trained teacher model is utilized to generate the CD map. The experiments on four sets of bitemporal MS images demonstrate that the proposed CD method performs well in comprehensive indices compared with existing methods. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Shi, Aiye; Ma, Zhenli] Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
RP Shi, AY (corresponding author), Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
EM ayshi@hhu.edu.cn
CR Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Cao G, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083678
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Fan JC, 2019, IEEE J-STARS, V12, P685, DOI 10.1109/JSTARS.2019.2892951
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, ISPRS J PHOTOGRAMM, V93, P123, DOI 10.1016/j.isprsjprs.2014.04.010
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gupta N, 2019, IEEE SYST J EARLY AC, P1
   He PF, 2014, REMOTE SENS LETT, V5, P396, DOI 10.1080/2150704X.2014.912766
   Laine S., 2017, 5 INT C LEARN REPR I
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Shao P, 2016, REMOTE SENS, V8, P1
   Shi AY, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.016025
   Shi AY, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046028
   Shi AY, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0397-0
   Shi A, 2014, INT J REMOTE SENS, V35, P7555, DOI 10.1080/2150704X.2014.973998
   Tarvainen A., 2017, MEAN TEACHERS ARE BE, P1195
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   [钟家强 Zhong Jiaqiang], 2006, [电子与信息学报, Journal of electronics & information technology], V28, P994
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 42
TC 0
Z9 0
U1 4
U2 14
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD AUG 12
PY 2020
VL 14
IS 3
AR 034509
DI 10.1117/1.JRS.034509
PG 17
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA NA8FM
UT WOS:000560053200001
DA 2022-01-04
ER

PT J
AU de Bem, PP
   de Carvalho, OA
   de Carvalho, OLF
   Gomes, RAT
   Guimaraes, RF
AF de Bem, Pablo Pozzobon
   de Carvalho Junior, Osmar Abilio
   Ferreira de Carvalho, Osmar Luiz
   Trancoso Gomes, Roberto Arnaldo
   Guimaraes, Renato Fontes
TI Performance Analysis of Deep Convolutional Autoencoders with Different
   Patch Sizes for Change Detection from Burnt Areas
SO REMOTE SENSING
LA English
DT Article
DE deep learning; CNN; classification; fire; multitemporal image
ID FIRE OCCURRENCE; TIME-SERIES; LAND-COVER; CLASSIFICATION; SEVERITY;
   PATTERNS; INDEX; RATIO
AB Fire is one of the primary sources of damages to natural environments globally. Estimates show that approximately 4 million km(2)of land burns yearly. Studies have shown that such estimates often underestimate the real extent of burnt land, which highlights the need to find better, state-of-the-art methods to detect and classify these areas. This study aimed to analyze the use of deep convolutional Autoencoders in the classification of burnt areas, considering different sample patch sizes. A simple Autoencoder and the U-Net and ResUnet architectures were evaluated. We collected Landsat 8 OLI+ data from three scenes in four consecutive dates to detect the changes specifically in the form of burnt land. The data were sampled according to four different sampling strategies to evaluate possible performance changes related to sampling window sizes. The training stage used two scenes, while the validation stage used the remaining scene. The ground truth change mask was created using the Normalized Burn Ratio (NBR) spectral index through a thresholding approach. The classifications were evaluated according to theF1 index,Kappaindex, and mean Intersection over Union (mIoU) value. Results have shown that the U-Net and ResUnet architectures offered the best classifications with averageF1,Kappa, andmIoUvalues of approximately 0.96, representing excellent classification results. We have also verified that a sampling window size of 256 by 256 pixels offered the best results.
C1 [de Bem, Pablo Pozzobon; de Carvalho Junior, Osmar Abilio; Trancoso Gomes, Roberto Arnaldo; Guimaraes, Renato Fontes] Univ Brasilia, Dept Geog, Campus Univ Darcy Ribeiro,Asa Norte, BR-70910900 Brasilia, DF, Brazil.
   [Ferreira de Carvalho, Osmar Luiz] Univ Brasilia, Dept Engn Elect, Campus Univ Darcy Ribeiro, BR-70910900 Brasilia, DF, Brazil.
RP de Carvalho, OA (corresponding author), Univ Brasilia, Dept Geog, Campus Univ Darcy Ribeiro,Asa Norte, BR-70910900 Brasilia, DF, Brazil.
EM pablo.bem@aluno.unb.br; osmarjr@unb.br; osmarcarvalho@ieee.org;
   robertogomes@unb.br; renatofg@unb.br
RI De+Carvalho+Junior, Osmar/AAK-4880-2021; de, Pablo/AAW-5619-2020;
   Guimaraes, Renato/C-4601-2013
OI De+Carvalho+Junior, Osmar/0000-0002-0346-1684; de,
   Pablo/0000-0003-3868-8704; Guimaraes, Renato/0000-0002-9555-043X;
   Carvalho, Osmar Luiz/0000-0002-5619-8525; Trancoso Gomes, Roberto
   Arnaldo/0000-0003-4724-4064
FU National Council for Scientific and Technological DevelopmentConselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)
   [434838/2018-7]; Coordination for the Improvement of Higher Education
   PersonnelCoordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Union Heritage Secretariat of the Ministry of Economy
FX The following institutions funded this research: National Council for
   Scientific and Technological Development (434838/2018-7), Coordination
   for the Improvement of Higher Education Personnel and the Union Heritage
   Secretariat of the Ministry of Economy.
CR Abdel-Hamid O, 2012, INT CONF ACOUST SPEE, P4277, DOI 10.1109/ICASSP.2012.6288864
   Al-Rawi KR, 2001, INT J REMOTE SENS, V22, P2015, DOI 10.1080/01431160152043685
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Alvarado ST, 2017, ECOL INDIC, V78, P270, DOI 10.1016/j.ecolind.2017.02.037
   Ammour N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040312
   Axel AC, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030371
   Ba R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11141702
   Ban YF, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56967-x
   Bermudez JD, 2018, ISPRS ANN PHOTO REM, V4-1, P5, DOI 10.5194/isprs-annals-IV-1-5-2018
   Cao KL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071128
   Chuvieco E, 2019, REMOTE SENS ENVIRON, V225, P45, DOI 10.1016/j.rse.2019.02.013
   Chuvieco E, 2018, EARTH SYST SCI DATA, V10, P2015, DOI 10.5194/essd-10-2015-2018
   Chuvieco E, 2010, ECOL MODEL, V221, P46, DOI 10.1016/j.ecolmodel.2008.11.017
   Costafreda-Aumedes S, 2017, INT J WILDLAND FIRE, V26, P983, DOI [10.1071/WF17026, 10.1071/wf17026]
   Daldegan GA, 2014, REMOTE SENS-BASEL, V6, P9873, DOI 10.3390/rs6109873
   de Albuquerque AO, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132159
   de Araujo FM, 2012, REMOTE SENS-BASEL, V4, P1929, DOI 10.3390/rs4071929
   de Bem PP, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060901
   de Bem PP, 2019, INT J WILDLAND FIRE, V28, P35, DOI 10.1071/WF18018
   de Carvalho OA, 2015, REMOTE SENS-BASEL, V7, P6950, DOI 10.3390/rs70606950
   Escuin S, 2008, INT J REMOTE SENS, V29, P1053, DOI 10.1080/01431160701281072
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Giglio L., 2015, MCD64A1 MODIS TERRA, DOI [10.5067/MODIS/MCD64A1.006, 10.5067/MODIS/MCD64A1.006., DOI 10.5067/MODIS/MCD64A1.006]
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hall JV, 2016, REMOTE SENS ENVIRON, V184, P506, DOI 10.1016/j.rse.2016.07.022
   Hawbaker TJ, 2017, REMOTE SENS ENVIRON, V198, P504, DOI 10.1016/j.rse.2017.06.027
   Imamoglu N., 2017, P BRIT MACH VIS C BM
   Islam T., 2017, REMOTE SENSING HYDRO
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Kandel I, 2020, ICT EXPRESS, V6, P312, DOI 10.1016/j.icte.2020.04.010
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Langford ZL, 2018, INT CONF DAT MIN WOR, P770, DOI 10.1109/ICDMW.2018.00116
   Li LF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182142
   Li WJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010022
   Liu C, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020311
   Ma HJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020260
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Maratea A, 2014, INFORM SCIENCES, V257, P331, DOI 10.1016/j.ins.2013.04.016
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Melchiori A.E., 2014, ADV FOREST FIRE RES, V4, P1302
   Miller JD, 2007, REMOTE SENS ENVIRON, V109, P66, DOI 10.1016/j.rse.2006.12.006
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mithal V, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010069
   Mou LC, 2017, INT GEOSCI REMOTE SE, P5181, DOI 10.1109/IGARSS.2017.8128169
   Myers N, 2000, NATURE, V403, P853, DOI 10.1038/35002501
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Pereira AA, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111161
   Pereira I. M. S., 2018, Floresta, V48, P553
   Pereira JMC, 2003, INT J WILDLAND FIRE, V12, P259, DOI 10.1071/WF03028
   Pereira AC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102380
   Radiuk P., 2017, INF TECHNOL MANAG SC, V20, P20, DOI [10.1515/itms-2017-0003, DOI 10.1515/ITMS-2017-0003]
   Ramo R, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111193
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santana NC, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121904
   Saulino L, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12040741
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Shan TC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070736
   Tanase MA, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020334
   Wei SS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010068
   Yi YN, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151774
   Yohei K., 2018, REMOTE SENS, V10, P124, DOI [10.3390/rs10010124, DOI 10.3390/RS10010124]
   Yu L, 2017, INT J COMPUT INTELL, V16, DOI 10.1142/S1469026817500018
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
   Zeng XS, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON BIG DATA RESEARCH (ICBDR 2018), P174, DOI 10.1145/3291801.3291839
   Zhan YJ, 2017, IEEE GEOSCI REMOTE S, V14, P1785, DOI 10.1109/LGRS.2017.2735801
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2019, ISPRS J PHOTOGRAMM, V158, P50, DOI 10.1016/j.isprsjprs.2019.09.013
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang X., 2015, P NEURAL INFORM PROC, P649, DOI DOI 10.1063/1.4906785
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 75
TC 5
Z9 5
U1 6
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2020
VL 12
IS 16
AR 2576
DI 10.3390/rs12162576
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA NI6HH
UT WOS:000565451500001
OA gold
DA 2022-01-04
ER

PT J
AU Song, A
   Kim, Y
   Han, Y
AF Song, Ahram
   Kim, Yongil
   Han, Youkyung
TI Uncertainty Analysis for Object-Based Change Detection in Very
   High-Resolution Satellite Images Using Deep Learning Network
SO REMOTE SENSING
LA English
DT Article
DE change detection; object-based image analysis; very high-resolution
   satellite images; deep learning network
ID GEOMETRIC ACCURACY; CLASSIFICATION; PIXEL
AB Object-based image analysis (OBIA) is better than pixel-based image analysis for change detection (CD) in very high-resolution (VHR) remote sensing images. Although the effectiveness of deep learning approaches has recently been proved, few studies have investigated OBIA and deep learning for CD. Previously proposed methods use the object information obtained from the preprocessing and postprocessing phase of deep learning. In general, they use the dominant or most frequently used label information with respect to all the pixels inside an object without considering any quantitative criteria to integrate the deep learning network and object information. In this study, we developed an object-based CD method for VHR satellite images using a deep learning network to denote the uncertainty associated with an object and effectively detect the changes in an area without the ground truth data. The proposed method defines the uncertainty associated with an object and mainly includes two phases. Initially, CD objects were generated by unsupervised CD methods, and the objects were used to train the CD network comprising three-dimensional convolutional layers and convolutional long short-term memory layers. The CD objects were updated according to the uncertainty level after the learning process was completed. Further, the updated CD objects were considered as the training data for the CD network. This process was repeated until the entire area was classified into two classes, i.e., change and no-change, with respect to the object units or defined epoch. The experiments conducted using two different VHR satellite images confirmed that the proposed method achieved the best performance when compared with the performances obtained using the traditional CD approaches. The method was less affected by salt and pepper noise and could effectively extract the region of change in object units without ground truth data. Furthermore, the proposed method can offer advantages associated with unsupervised CD methods and a CD network subjected to postprocessing by effectively utilizing the deep learning technique and object information.
C1 [Song, Ahram; Kim, Yongil] Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Han, Youkyung] Kyungpook Natl Univ, Sch Convergence & Fus Syst Engn, Sangju 37224, South Korea.
RP Han, Y (corresponding author), Kyungpook Natl Univ, Sch Convergence & Fus Syst Engn, Sangju 37224, South Korea.
EM aram200@snu.ac.kr; yik@snu.ac.kr; han602@knu.ac.kr
OI song, ahram/0000-0002-9190-2848; Han, Youkyung/0000-0001-6586-8503
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2019R1A6A3A0109230211];
   Satellite Information Utilization Center Establishment Program of the
   Ministry of Land, Infrastructure, and Transport of Korean government
   [20SIUE-B148326-03]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2019R1A6A3A0109230211) and by the Satellite
   Information Utilization Center Establishment Program of the Ministry of
   Land, Infrastructure, and Transport of Korean government, grant number
   20SIUE-B148326-03.
CR Acquarelli J, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071156
   Aguilar MA, 2013, INT J APPL EARTH OBS, V21, P427, DOI 10.1016/j.jag.2012.06.004
   Al-Khudhairy DHA, 2005, PHOTOGRAMM ENG REM S, V71, P825, DOI 10.14358/PERS.71.7.825
   [Anonymous], 2008, FEAT EXTR MOD VERS 4
   [Anonymous], 2004, DEFINIENTS IMAGE ECO, P4
   [Anonymous], 2016, HEX GEOSP ERDAS IM
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Chehata N, 2014, INT J REMOTE SENS, V35, P4758, DOI 10.1080/01431161.2014.930199
   Chen G, 2018, GISCI REMOTE SENS, V55, P159, DOI 10.1080/15481603.2018.1426092
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Gao Y, 2008, J EARTH SCI, V2, P27
   Gasparovic M, 2019, PHOTOGRAMM REC, V34, P266, DOI 10.1111/phor.12292
   Han Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060983
   Han Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192235
   Han Y, 2019, J SENSORS, V2019, DOI 10.1155/2019/2962734
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jin BX, 2019, J INDIAN SOC REMOTE, V47, P951, DOI 10.1007/s12524-019-00945-3
   Laliberte AS, 2009, IEEE T GEOSCI REMOTE, V47, P761, DOI 10.1109/TGRS.2008.2009355
   Lang S, 2008, OBJECT BASED IMAGE A, P3, DOI DOI 10.1007/978-3-540-77058-9_1
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liu DS, 2010, REMOTE SENS LETT, V1, P187, DOI 10.1080/01431161003743173
   Liu SJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060690
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Malila W.A., 1980, LARS S LAB APPL REMO
   Mura MD, 2008, IEEE GEOSCI REMOTE S, V5, P433, DOI 10.1109/LGRS.2008.917726
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Nielsen A.A., 1999, MACHINE VISION ADV I, P37
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Niemeyer I., 2008, LECT NOTES GEOINFORM, P185
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060684
   Pu RL, 2011, INT J REMOTE SENS, V32, P3285, DOI 10.1080/01431161003745657
   Schallner L., 2019, EFFECT SUPERPIXEL AG, DOI [10.1007/978-3-030-43823-4_13, DOI 10.1007/978-3-030-43823-4_13]
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071099
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Stow D., 2010, HDB APPL SPATIAL STA, VVolume 4, P565
   Unsalan C., 2012, 2 DIMENSIONAL CHANGE
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Xingjian S., 2015, P 28 INT C NEUR INF, V1, P802, DOI DOI 10.1007/978-3-319-21233-3_6
   Ye S, 2018, ISPRS J PHOTOGRAMM, V141, P137, DOI 10.1016/j.isprsjprs.2018.04.002
   Zhang GY, 2012, INT GEOSCI REMOTE SE, P4335, DOI 10.1109/IGARSS.2012.6351708
NR 48
TC 8
Z9 8
U1 12
U2 25
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD AUG
PY 2020
VL 12
IS 15
AR 2345
DI 10.3390/rs12152345
PG 26
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MZ4CR
UT WOS:000559069900001
OA gold
DA 2022-01-04
ER

PT J
AU Zhan, T
   Gong, MG
   Jiang, XM
   Zhang, MY
AF Zhan, Tao
   Gong, Maoguo
   Jiang, Xiangming
   Zhang, Mingyang
TI Unsupervised Scale-Driven Change Detection With Deep Spatial-Spectral
   Features for VHR Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection (CD); feature extraction; fully convolutional network
   (FCN); multitemporal images; remote sensing; support vector machine
   (SVM)
ID CHANGE VECTOR ANALYSIS; AUTOMATIC CHANGE DETECTION; THEORETICAL
   FRAMEWORK; CLASSIFICATION; MODEL
AB The rapid development of remote sensing technology has enabled the acquisition of very high spatial resolution (VHR) multitemporal images in Earth observation. However, how to effectively exploit these existing data to accurately monitor land surface changes is still a challenging task. In this article, we propose an unsupervised scale-driven change detection (CD) framework for VHR images by jointly analyzing the spatial-spectral change information, which combines the advantages of deep feature learning and multiscale decision fusion. First, a well pretrained deep fully convolutional network (FCN) is used to automatically extract the deep spatial context information from the acquired images. Then, the uncertainty analysis incorporating the deep spatial feature and the image spectral feature is implemented to generate a pseudobinary change map. On this basis, it is easy to choose suitable samples to train an excellent support vector machine (SVM) classifier, thus detecting changes occurred on the ground. In addition, the multiscale superpixel segmentation technique is introduced to make full use of the spatial structural information, which takes an image-object as the basic analysis unit. Finally, a robust binary change map with high detection precision can be achieved by merging the CD results obtained at different scales. The impressive experimental results on four real data sets demonstrate the effectiveness and flexibility of the proposed framework.
C1 [Zhan, Tao] Xidian Univ, Sch Comp Sci & Technol, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
   [Gong, Maoguo; Jiang, Xiangming; Zhang, Mingyang] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
RP Zhan, T (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM omegazhant@gmail.com; gong@ieee.org; omegajiangxm@gmail.com;
   omegazhangmy@gmail.com
RI Jiang, Xiangming/AAY-9275-2020
OI Zhang, Mingyang/0000-0002-9768-516X; Zhan, Tao/0000-0002-9283-4488;
   Jiang, Xiangming/0000-0002-4650-1308
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393, 61906147]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]; China
   Post-Doctoral Science FoundationChina Postdoctoral Science Foundation
   [2019M663931XB]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393 and Grant 61906147, in part by
   the Key Research and Development Program of Shaanxi Province under Grant
   2018ZDXM-GY-045, and in part by the China Post-Doctoral Science
   Foundation under Grant 2019M663931XB.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Benedek C, 2015, ISPRS J PHOTOGRAMM, V107, P22, DOI 10.1016/j.isprsjprs.2015.02.006
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen Q, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070549
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chen Y, 2013, SIGNAL PROCESS, V93, P163, DOI 10.1016/j.sigpro.2012.07.013
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Csillik O, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030243
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Falco N, 2016, INT GEOSCI REMOTE SE, P3374, DOI 10.1109/IGARSS.2016.7729872
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P3534, DOI 10.1109/TGRS.2018.2801387
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Han Y, 2015, IEEE T GEOSCI REMOTE, V53, P6650, DOI 10.1109/TGRS.2015.2445632
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lopez-Fandino J, 2018, INT GEOSCI REMOTE SE, P1906, DOI 10.1109/IGARSS.2018.8518338
   Meddens AJH, 2013, REMOTE SENS ENVIRON, V132, P49, DOI 10.1016/j.rse.2013.01.002
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ortiz-Rivera V, 2006, PROC SPIE, V6233, DOI 10.1117/12.667961
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S., 2018, P SPIE IM SIGN PROC
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Serra P, 2003, INT J REMOTE SENS, V24, P4975, DOI 10.1080/714110283
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Yosinski J, 2014, ADV NEUR IN, V27
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yousif O, 2017, INT J REMOTE SENS, V38, P1765, DOI 10.1080/01431161.2016.1217442
   Yuan QQ, 2019, IEEE T GEOSCI REMOTE, V57, P1205, DOI 10.1109/TGRS.2018.2865197
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhan T., 2018, P GEN EV COMP C COMP, P1729
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zheng XT, 2017, IEEE T GEOSCI REMOTE, V55, P5185, DOI 10.1109/TGRS.2017.2703598
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
NR 61
TC 6
Z9 7
U1 13
U2 38
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD AUG
PY 2020
VL 58
IS 8
BP 5653
EP 5665
DI 10.1109/TGRS.2020.2968098
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA MP7HG
UT WOS:000552371900034
DA 2022-01-04
ER

PT J
AU Mesquita, DB
   dos Santos, RF
   Macharet, DG
   Campos, MFM
   Nascimento, ER
AF Mesquita, Daniel B.
   dos Santos, Ronaldo F.
   Macharet, Douglas G.
   Campos, Mario F. M.
   Nascimento, Erickson R.
TI Fully Convolutional Siamese Autoencoder for Change Detection in UAV
   Aerial Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Unmanned aerial vehicles; Feature extraction; Remote sensing;
   Satellites; Task analysis; Streaming media; Convolution; Aerial images;
   change detection; fully convolutional neural networks (FCNNs); fully
   convolutional Siamese networks; unmanned aerial vehicles (UAVs)
AB Different applications in remote sensing, such as crop monitoring and visual surveillance, demand the automatic detection of changes from sets of images acquired over time. Most traditional approaches use satellite imagery, which, besides the known issues such as cloud cover and image acquisition frequency for nongeostationary satellites, are very costly. In this context, with the recent technological advances, unmanned aerial vehicles (UAVs) have become ubiquitous in numerous applications. In this letter, we present a fully convolutional Siamese autoencoder method for change detection in aerial images, in particular for those obtained with UAVs. We show that, by using an autoencoder, we can further reduce the number of labeled samples required to achieve competitive results. We evaluated the performance of our approach on two different data sets, and the results showed that our methodology outperforms the state of the art, while demanding less training data.
C1 [Mesquita, Daniel B.; dos Santos, Ronaldo F.; Macharet, Douglas G.; Campos, Mario F. M.; Nascimento, Erickson R.] Univ Fed Minas Gerais UFMG, Dept Comp Sci, BR-31270901 Belo Horizonte, MG, Brazil.
   [dos Santos, Ronaldo F.] Univ Fed Mato Grosso Sul UFMS, Tres Lagoas Campus, BR-79613000 Campo Grande, MS, Brazil.
RP Mesquita, DB (corresponding author), Univ Fed Minas Gerais UFMG, Dept Comp Sci, BR-31270901 Belo Horizonte, MG, Brazil.
EM balbino@dcc.ufmg.br; ronaldo.santos@dcc.ufmg.br; doug@dcc.ufmg.br;
   mario@dcc.ufmg.br; erickson@dcc.ufmg.br
RI Nascimento, Erickson R./G-5374-2014; Campos, Mario F. M./C-4647-2013;
   Fiorilo dos Santos, Ronaldo/AAE-3050-2021
OI Nascimento, Erickson R./0000-0003-2973-2232; Campos, Mario F.
   M./0000-0002-8336-9190; Fiorilo dos Santos, Ronaldo/0000-0001-8143-8087
FU CAPESCoordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); FAPEMIGFundacao de Amparo a Pesquisa do Estado de Minas Gerais
   (FAPEMIG); CNPqConselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPQ); PetrobrasFundacao de Amparo a Pesquisa do Amapa
   (FAPEAP)Petrobras
FX This work was supported in part by CAPES, in part by FAPEMIG, in part by
   CNPq, and in part by Petrobras.
CR Ahamad N, 2017, 2017 INTERNATIONAL CONFERENCE ON POWER AND EMBEDDED DRIVE CONTROL (ICPEDC), P8, DOI 10.1109/ICPEDC.2017.8081051
   Rodrigues MTA, 2015, LECT NOTES COMPUT SC, V9423, P116, DOI 10.1007/978-3-319-25751-8_15
   Bashmal L, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020351
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Brock Andrew, 2016, ARXIV160907093
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Gueguen L, 2015, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2015.7298737
   Hadsell Raia, 2006, P 2006 IEEE COMP VIS, P1735, DOI DOI 10.1109/CVPR.2006.100
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miyato T., 2018, ARXIV180205957
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rodrigues MTAN, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013001
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
NR 19
TC 8
Z9 8
U1 5
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD AUG
PY 2020
VL 17
IS 8
BP 1455
EP 1459
DI 10.1109/LGRS.2019.2945906
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA MP5VK
UT WOS:000552271800034
DA 2022-01-04
ER

PT J
AU Zhang, CX
   Yue, P
   Tapete, D
   Jiang, LC
   Shangguan, BY
   Huang, L
   Liu, GC
AF Zhang, Chenxiao
   Yue, Peng
   Tapete, Deodato
   Jiang, Liangcun
   Shangguan, Boyi
   Huang, Li
   Liu, Guangchao
TI A deeply supervised image fusion network for change detection in high
   resolution bi-temporal remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Deep supervision network; Image fusion; High
   resolution remote sensing image; Image difference discrimination
ID URBAN
AB Change detection in high resolution remote sensing images is crucial to the understanding of land surface changes. As traditional change detection methods are not suitable for the task considering the challenges brought by the fine image details and complex texture features conveyed in high resolution images, a number of deep learning-based change detection methods have been proposed to improve the change detection performance. Although the state-of-the-art deep feature based methods outperform all the other deep learning-based change detection methods, networks in the existing deep feature based methods are mostly modified from architectures that are originally proposed for single-image semantic segmentation. Transferring these networks for change detection task still poses some key issues. In this paper, we propose a deeply supervised image fusion network (IFN) for change detection in high resolution bi-temporal remote sensing images. Specifically, highly representative deep features of bi-temporal images are firstly extracted through a fully convolutional two-stream architecture. Then, the extracted deep features are fed into a deeply supervised difference discrimination network (DDN) for change detection. To improve boundary completeness and internal compactness of objects in the output change maps, multi-level deep features of raw images are fused with image difference features by means of attention modules for change map reconstruction. DDN is further enhanced by directly introducing change map losses to intermediate layers in the network, and the whole network is trained in an end-to-end manner. IFN is applied to a publicly available dataset, as well as a challenging dataset consisting of multi-source bi-temporal images from Google Earth covering different cities in China. Both visual interpretation and quantitative assessment confirm that IFN outperforms four benchmark methods derived from the literature, by returning changed areas with complete boundaries and high internal compactness compared to the state-of-the-art methods.
C1 [Zhang, Chenxiao] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Yue, Peng; Jiang, Liangcun; Shangguan, Boyi; Huang, Li; Liu, Guangchao] Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Yue, Peng] Wuhan Univ, Hubei Prov Engn Ctr Intelligent Geoproc HPECIG, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Yue, Peng] Collaborat Innovat Ctr Geospatial Technol, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Tapete, Deodato] Italian Space Agcy ASI, Via Politecn Snc, I-00133 Rome, Italy.
RP Yue, P (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM pyue@whu.edu.cn
RI Tapete, Deodato/AAB-7528-2021
OI Tapete, Deodato/0000-0002-7242-4473; Yue, Peng/0000-0003-3006-4542
FU Major State Research Development Program of China [2017YFB0504103];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41722109]; Hubei Provincial Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [2018CFA053]; Wuhan Yellow Crane Talents (Science) Program
FX We appreciate the reviewers and editors for their constructive comments
   that helped improve the quality of the paper. The work was supported by
   Major State Research Development Program of China (No. 2017YFB0504103),
   National Natural Science Foundation of China (No. 41722109), Hubei
   Provincial Natural Science Foundation of China (No. 2018CFA053), and
   Wuhan Yellow Crane Talents (Science) Program (2016).
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Bengio, 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1177/1753193410395357
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Daudt R. Caye, 2018, ARXIV181008452
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Guo E., 2018, ARXIV181009111
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   JACKSON RD, 1983, REMOTE SENS ENVIRON, V13, P409, DOI 10.1016/0034-4257(83)90010-X
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kuncheva LI, 2014, IEEE T NEUR NET LEAR, V25, P69, DOI 10.1109/TNNLS.2013.2248094
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Liu J, 2020, IEEE T NEUR NET LEAR, V31, P876, DOI 10.1109/TNNLS.2019.2910571
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luppino LT, 2019, IEEE T GEOSCI REMOTE, V57, P9960, DOI 10.1109/TGRS.2019.2930348
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Mao T., 2018, 2018 3 IEEE INT C IM, DOI [10.1109/ICIVC.2018.8492796., DOI 10.1109/ICIVC.2018.8492796]
   Mundia CN, 2005, INT J REMOTE SENS, V26, P2831, DOI 10.1080/01431160500117865
   Padron-Hidalgo JA, 2019, IEEE T GEOSCI REMOTE, V57, P7743, DOI 10.1109/TGRS.2019.2916212
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh A., 1986, REMOTE SENSING TROPI, V44, P273, DOI DOI 10.1080/10106048809354188
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Wang FG, 2010, ENVIRON MONIT ASSESS, V162, P311, DOI 10.1007/s10661-009-0798-8
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Zerrouki N, 2018, IEEE GEOSCI REMOTE S, V15, P927, DOI 10.1109/LGRS.2018.2817522
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 43
TC 38
Z9 38
U1 42
U2 86
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD AUG
PY 2020
VL 166
BP 183
EP 200
DI 10.1016/j.isprsjprs.2020.06.003
PG 18
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA MO1AQ
UT WOS:000551268300015
DA 2022-01-04
ER

PT J
AU Wu, Y
   Bai, ZF
   Miao, QG
   Ma, WP
   Yang, YL
   Gong, MG
AF Wu, Yue
   Bai, Zhuangfei
   Miao, Qiguang
   Ma, Wenping
   Yang, Yuelei
   Gong, Maoguo
TI A Classified Adversarial Network for Multi-Spectral Remote Sensing Image
   Change Detection
SO REMOTE SENSING
LA English
DT Article
DE change detection; generative adversarial networks (GANs); multi-spectral
   remote sensing image
ID UNSUPERVISED CHANGE DETECTION; SAR IMAGES
AB Adversarial training has demonstrated advanced capabilities for generating image models. In this paper, we propose a deep neural network, named a classified adversarial network (CAN), for multi-spectral image change detection. This network is based on generative adversarial networks (GANs). The generator captures the distribution of the bitemporal multi-spectral image data and transforms it into change detection results, and these change detection results (as the fake data) are input into the discriminator to train the discriminator. The results obtained by pre-classification are also input into the discriminator as the real data. The adversarial training can facilitate the generator learning the transformation from a bitemporal image to a change map. When the generator is trained well, the generator has the ability to generate the final result. The bitemporal multi-spectral images are input into the generator, and then the final change detection results are obtained from the generator. The proposed method is completely unsupervised, and we only need to input the preprocessed data that were obtained from the pre-classification and training sample selection. Through adversarial training, the generator can better learn the relationship between the bitemporal multi-spectral image data and the corresponding labels. Finally, the well-trained generator can be applied to process the raw bitemporal multi-spectral images to obtain the final change map (CM). The effectiveness and robustness of the proposed method were verified by the experimental results on the real high-resolution multi-spectral image data sets.
C1 [Wu, Yue; Bai, Zhuangfei; Miao, Qiguang] Xidian Univ, Sch Comp Sci & Technol, Key Lab Big Data & Intelligent Vis, Xian 710071, Peoples R China.
   [Ma, Wenping] Xidian Univ, Sch Articial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
   [Yang, Yuelei; Gong, Maoguo] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM ywu@xidian.edu.cn; zfbai@stu.xidian.edu.cn; qgmiao@xidian.edu.cn;
   wpma@mail.xidian.edu.cn; yuelei_yang@163.com; gong@ieee.org
OI Wu, Yue/0000-0002-3459-5079
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61702392]; Natural Science Basic Research
   Program of Shaanxi [2019JQ-189]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61702392, and the Natural Science Basic
   Research Program of Shaanxi (Program No. 2019JQ-189).
CR Aminikhanghahi S, 2017, KNOWL INF SYST, V51, P339, DOI 10.1007/s10115-016-0987-z
   Buslaev A., 2018, P 2018 IEEE CVF C CO, V207, P210
   Cao XH, 2019, IET IMAGE PROCESS, V13, P1509, DOI 10.1049/iet-ipr.2018.5172
   Chen H., 2019, P 27 EUR SIGN PROC C, P1
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Dharani M., 2021, International Journal of Computers and Applications, V43, P462, DOI 10.1080/1206212X.2019.1578068
   Di Nucci D, 2017, IEEE TETCI, V1, P202, DOI 10.1109/TETCI.2017.2699224
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jin SM, 2017, REMOTE SENS ENVIRON, V195, P44, DOI 10.1016/j.rse.2017.04.021
   Kerekes A., 2019, AN U ORADEA G, V29, P52, DOI [10.30892/auog.292106-799, DOI 10.30892/AUOG.292106-799]
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Lin Y, 2020, IEEE GEOSCI REMOTE S, V17, P1757, DOI 10.1109/LGRS.2019.2953754
   Liu QJ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050438
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu XY, 2020, INFORM FUSION, V55, P1, DOI 10.1016/j.inffus.2019.07.010
   Liu Y., 2019, ARXIV19090772
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lou XM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051179
   Lv PY, 2016, IEEE GEOSCI REMOTE S, V13, P1965, DOI 10.1109/LGRS.2016.2619163
   Lv ZY, 2019, IEEE ACCESS, V7, P34425, DOI 10.1109/ACCESS.2019.2892648
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020142
   Ma WP, 2019, INT J REMOTE SENS, V40, P1066, DOI 10.1080/01431161.2018.1524172
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Polykretis C, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020319
   Qahtan A, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P935, DOI 10.1145/2783258.2783359
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Scheffler D, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070676
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Wan L, 2018, INT J REMOTE SENS, V39, P3753, DOI 10.1080/01431161.2018.1448481
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Xu HQ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202345
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang XZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030548
   Zhao SH, 2017, EARTH SCI INFORM, V10, P137, DOI 10.1007/s12145-017-0286-6
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 54
TC 3
Z9 3
U1 13
U2 19
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUL
PY 2020
VL 12
IS 13
AR 2098
DI 10.3390/rs12132098
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MN4VY
UT WOS:000550842400001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, RF
   Ding, F
   Jiao, LC
   Chen, JW
   Liu, B
   Ma, WP
   Wang, M
AF Wang, Rongfang
   Ding, Fan
   Jiao, Licheng
   Chen, Jia-Wei
   Liu, Bo
   Ma, Wenping
   Wang, Mi
TI Lightweight convolutional neural network for bitemporal SAR image change
   detection
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE light-weighted neural network; bitemporal SAR images; change detection
AB Recently, many convolutional neural networks (CNN) have been successfully employed in bitemporal synthetic aperture radar (SAR) image change detection. However, most of the existing networks are too heavy and occupy a large volume of memory for storage and calculation. Motivated by this, we propose a lightweight neural network to reduce the computational and spatial complexity and facilitate the change detection on an edge device. We replace normal convolutional layers with bottleneck layers that keep the same number of channels between input and output. Next, we employ dilated convolutional kernels with a few non-zero entries that reduce the running time in convolutional operators. Comparing with the conventional convolutional neural network, our lightweight neural network will be more efficient with fewer parameters. We verify our light-weighted neural network on four sets of bitemporal SAR images. The experimental results show that the proposed network can obtain better performance than the conventional CNN and has better model generalization, especially on the challenging datasets with complex scenes. (C) 2020 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Wang, Rongfang; Ding, Fan; Jiao, Licheng; Chen, Jia-Wei; Liu, Bo; Ma, Wenping] Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian, Peoples R China.
   [Wang, Mi] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Peoples R China.
RP Chen, JW (corresponding author), Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian, Peoples R China.
EM jawaechan@gmail.com
OI Jiao, Licheng/0000-0003-3354-9617
FU State Key Program of National Natural Science of ChinaNational Natural
   Science Foundation of China (NSFC) [61836009]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [61701361, 61806154]; Major Research Plan of National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [91838303]; Open Fund of Key Laboratory of Intelligent Perception and
   Image Understanding of Ministry of Education, Xidian University
   [IPIU2019006]; Natural Science Basic Research Plan in Shaanxi Province
   of China [2018JM6083]; Open Fund of State Laboratory of Information
   Engineering in Surveying, Mapping and Remote Sensing, Wuhan University
   [17E02]
FX This work was supported by the State Key Program of National Natural
   Science of China (Grant No. 61836009), the National Natural Science
   Foundation of China (Grant Nos. 61701361 and 61806154), the Major
   Research Plan of National Natural Science Foundation of China (Grant No.
   91838303), the Open Fund of Key Laboratory of Intelligent Perception and
   Image Understanding of Ministry of Education, Xidian University (Grant
   No. IPIU2019006), the Natural Science Basic Research Plan in Shaanxi
   Province of China (Grant No. 2018JM6083), and the Open Fund of State
   Laboratory of Information Engineering in Surveying, Mapping and Remote
   Sensing, Wuhan University (No. 17E02).
CR Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Chen JW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101619
   Cui SY, 2016, IEEE J-STARS, V9, P1101, DOI 10.1109/JSTARS.2015.2486038
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Howard, 2017, MOBILENETS EFFICIENT
   Howard A., 2019, ARXIV190502244
   Kingma D., 2014, 14126980 ARXIV
   Le Q. V., ARXIV190511946
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadowski P., 2016, NOTES BACKPROPAGATIO
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Visin F., 2016, ARXIV 1603 07285
   Wang R., 2018, IEEE GEOSCI REMOTE S, V16, P554
   Wang RF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11040421
   Wang SN, 2016, IEEE J-STARS, V9, P3452, DOI 10.1109/JSTARS.2016.2547638
   Yan S., 2013, ARXIV13124400, P1
   Zhao JQ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080846
NR 22
TC 1
Z9 1
U1 5
U2 20
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD JUL 1
PY 2020
VL 14
IS 3
AR 036501
DI 10.1117/1.JRS.14.036501
PG 11
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA MN1SY
UT WOS:000550629400001
DA 2022-01-04
ER

PT J
AU Wei, JJ
   Zhang, YH
   Wu, HA
   Cui, B
AF Wei, Jujie
   Zhang, Yonghong
   Wu, Hong'an
   Cui, Bin
TI An Efficient Change Detection for Large SAR Images Based on Modified
   U-Net Framework
SO CANADIAN JOURNAL OF REMOTE SENSING
LA English
DT Article
ID UNSUPERVISED CHANGE DETECTION; URBAN CHANGE DETECTION
AB Large SAR images usually contain a variety of land-cover types and accordingly complicated change types, which cause great difficulty for accurate change detection. The U-Net is a special fully convolutional neural network that not only can capture multiple features in the image context but also enables precise pixel-by-pixel image classification. Therefore, we explore the U-Net to describe accurately the differences between bi-temporal SAR images for high-precision change detection. However, large scene SAR images often have significantly different statistical distributions for various change types, which prevents the U-Net from working properly. We modified the U-Net by introducing the batch normalization (BN) operation at the input of every neuron to regularize the statistical distributions of its input data for avoiding the risk of gradient disappearance or dispersion during the network training. In addition, the ELU (Exponential Linear Unit) activation function replaces the ReLU (Rectified Linear Unit) function to improve further the gradients backpropagation. Then we selected bi-temporal Sentinel-1SAR data covering Jiangsu Province, China, to discuss quantitatively and qualitatively the detection performance and model complexity of the modified network with different numbers of convolutional kernels.
C1 [Wei, Jujie; Zhang, Yonghong; Wu, Hong'an; Cui, Bin] Chinese Acad Surveying & Mapping, Inst Photogrammetry & Remote Sensing, 28 Lianhuachi West Rd, Beijing 100036, Peoples R China.
   [Cui, Bin] Wuhan Univ, Sch Geodesy & Geomat, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
RP Zhang, YH (corresponding author), Chinese Acad Surveying & Mapping, Inst Photogrammetry & Remote Sensing, 28 Lianhuachi West Rd, Beijing 100036, Peoples R China.
EM yhzhang@casm.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801284, 41271430]
FX This research was supported by the National Natural Science Foundation
   of China under grants [41801284 and 41271430].
CR Bai YB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101626
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   Chollet F., 2017, DEEP LEARNING PYTHON
   Clevert D.-A., 2015, 4 INT C LEARN REPR S
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Ioffe S., 2015, 32 INT C INT C MACH
   Kingma D., 2014, 14126980 ARXIV
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Melgani F., 2002, SPIE INT C SOC OPT E
   Nair V, 2010, 27 INT C MACH LEARN
   Ng AL., 2013, 30 INT C MACH LEARN
   Park SE, 2013, REMOTE SENS ENVIRON, V132, P212, DOI 10.1016/j.rse.2013.01.018
   Powers DMW., 2011, J MACH LEARN TECHNOL, V2, P37, DOI DOI 10.9735/2229-3981
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scherer D., 2010, 20 INT C ART NEUR NE
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Visin F., 2016, ARXIV 1603 07285
   Wei JJ, 2018, CAN J REMOTE SENS, V44, P447, DOI 10.1080/07038992.2018.1543022
   Woods, 2006, DIGITAL IMAGE PROCES
   Xu B., 2015, ARXIV150500853
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zeiler Matthew D., 2010, 2010 IEEE COMP SOC C
   Zuhlke M., 2015, SENT 3 SCI WORKSH VE
NR 33
TC 2
Z9 2
U1 6
U2 22
PU TAYLOR & FRANCIS INC
PI PHILADELPHIA
PA 530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA
SN 0703-8992
EI 1712-7971
J9 CAN J REMOTE SENS
JI Can. J. Remote Sens.
PD MAY 3
PY 2020
VL 46
IS 3
BP 272
EP 294
DI 10.1080/07038992.2020.1783993
EA JUL 2020
PG 23
WC Remote Sensing
SC Remote Sensing
GA NM2MQ
UT WOS:000546335800001
DA 2022-01-04
ER

PT J
AU Jiang, FL
   Gong, MG
   Zhan, T
   Fan, XL
AF Jiang, Fenlong
   Gong, Maoguo
   Zhan, Tao
   Fan, Xiaolong
TI A Semisupervised GAN-Based Multiple Change Detection Framework in
   Multi-Spectral Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Gallium nitride; Task analysis; Training; Remote
   sensing; Data mining; Generative adversarial networks; Generative
   adversarial network (GAN); multi-spectral images; multiple change
   detection; semisupervised
AB Effectively highlighting multiple changes in the earth surface from multi-temporal remote sensing images is a meaningful but challenging task. In order to reduce costs and ensure the performance, it is advisable to employ a semisupervised strategy to achieve this goal. As a discriminative joint classification task, semisupervised change detection aims to extract useful and discriminative features from a large amount of unlabeled data in addition to limited labeled samples. The discriminator of a well-trained generative adversarial network (GAN) is just right for this. Therefore, in this letter, we proposed a semisupervised GAN-based multiple change detection framework for multi-spectral images. First, the GAN is trained by all data without any prior information. Then, we combine two identical trained discriminators to construct a dual-pipeline joint classifier. Finally, the classifier is fine-tuned by a very small amount of labeled data to detect multiple changes. The superior performance of the proposed model over both real multi-spectral data sets demonstrates its robustness and effectiveness.
C1 [Jiang, Fenlong; Gong, Maoguo; Zhan, Tao; Fan, Xiaolong] Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM gong@ieee.org
OI Jiang, Fenlong/0000-0002-3714-0600; Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; Key Research and Development
   Program of Shaanxi Province [2018ZDXM-GY-045]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393 and in part by the Key Research
   and Development Program of Shaanxi Province under Grant 2018ZDXM-GY-045.
CR Arjovsky Martin, 2017, ARXIV170107875
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chinchor N, 1993, PROC 5 MESSAGE UNDER, P69, DOI DOI 10.3115/1072017.1072026
   Cristianini Nello., 2000, INTRO SUPPORT VECTOR
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He Z, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101042
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Pitts DAD, 2017, INT J APPL EARTH OBS, V57, P49, DOI 10.1016/j.jag.2016.12.004
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Tangseng P, 2018, IEEE WINT CONF APPL, P269, DOI 10.1109/WACV.2018.00036
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Zhang MY, 2019, IEEE T GEOSCI REMOTE, V57, P2669, DOI 10.1109/TGRS.2018.2876123
NR 19
TC 4
Z9 4
U1 10
U2 23
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD JUL
PY 2020
VL 17
IS 7
BP 1223
EP 1227
DI 10.1109/LGRS.2019.2941318
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA MD1GS
UT WOS:000543724300024
DA 2022-01-04
ER

PT J
AU Zhang, XL
   Fan, R
   Ma, L
   Liao, XH
   Chen, XW
AF Zhang, Xinlong
   Fan, Rui
   Ma, Lei
   Liao, Xiaohan
   Chen, Xiuwan
TI Change detection in very high-resolution images based on ensemble CNNs
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID LAND-COVER CHANGE; CLASSIFICATION; PIXEL; MODEL
AB This paper presents a novel change detection method for very-high-resolution images based on deep learning. In the method, an ensemble CNN change detection framework is proposed. Different from other deep learning change detection methods, samples of changed and unchanged regions of two very-high-resolution images acquired at different times are fed into two CNN. The discriminative deep metric learning based on dissimilarity degree is used to adjust discriminative distance metric of two CNN output layers quantitatively, under which the distance of unchanged samples becomes smaller and that of changed samples becomes higher, respectively. During its training procedure, cost module function based on dissimilarity degree of samples is used to train the ensemble CNN and high-level and abstract features of changed and unchanged pair of samples are driven to learn by the proposed framework. After training, the discriminative distance of unchanged samples becomes smaller and that of changed samples becomes larger. The proposed method justifies the changed and unchanged area of original images and change detection results can be obtained. Experiments on real datasets and theoretical analysis validate the effectiveness and superiority of the proposed method.
C1 [Zhang, Xinlong; Fan, Rui; Ma, Lei] China Elect Technol Grp Corp, China Acad Elect & Informat Technol, Beijing, Peoples R China.
   [Liao, Xiaohan] Chinese Acad Sci, Inst Geog Sci & Nat Resources Res, Beijing, Peoples R China.
   [Chen, Xiuwan] Peking Univ, Sch Earth & Space Sci, Beijing, Peoples R China.
RP Zhang, XL (corresponding author), China Elect Technol Grp Corp, China Acad Elect & Informat Technol, Beijing, Peoples R China.
EM mtxinlong@126.com
FU National key research and development program of China [2017YFB0503005];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41771388]
FX This work was supported by National key research and development program
   of China [No.2017YFB0503005]; National Natural Science Foundation of
   China [No.41771388].
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bontemps S, 2012, INT J REMOTE SENS, V33, P4673, DOI 10.1080/01431161.2011.638336
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Dong YN, 2017, IEEE T GEOSCI REMOTE, V55, P2509, DOI 10.1109/TGRS.2016.2645703
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Gao F, 2012, INT J REMOTE SENS, V33, P7609, DOI 10.1080/01431161.2012.700424
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, NEURAL NETWORKS TRIC, P599, DOI DOI 10.1007/978-3-642-35289-8_32
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang F. H., 2016, INT J EARTH SCI ENG, V5, P2096
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Lan ZY, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7050175
   Listner C, 2011, PHOTOGRAMM FERNERKUN, P233, DOI 10.1127/1432-8364/2011/0085
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Lyu HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030471
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Robertson LD, 2011, INT J REMOTE SENS, V32, P1505, DOI 10.1080/01431160903571791
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang YQ, 2009, REMOTE SENS ENVIRON, V113, P1453, DOI 10.1016/j.rse.2008.09.017
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Warner T, 2011, GEOGR COMPASS, V5, P781, DOI 10.1111/j.1749-8198.2011.00451.x
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang Q, 2014, IEEE GEOSCI REMOTE S, V11, P612, DOI 10.1109/LGRS.2013.2272476
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 39
TC 5
Z9 6
U1 5
U2 73
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD JUN 17
PY 2020
VL 41
IS 12
BP 4755
EP 4777
DI 10.1080/01431161.2020.1723818
PG 23
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA KR1FZ
UT WOS:000517366000001
DA 2022-01-04
ER

PT J
AU Seydi, ST
   Hasanlou, M
   Amani, M
AF Seydi, Seyd Teymoor
   Hasanlou, Mahdi
   Amani, Meisam
TI A New End-to-End Multi-Dimensional CNN Framework for Land Cover/Land Use
   Change Detection in Multi-Source Remote Sensing Datasets
SO REMOTE SENSING
LA English
DT Article
DE remote sensing; change detection; deep learning; CNN; hyperspectral;
   multispectral; polarimetric SAR
ID MULTIPLE-CHANGE DETECTION; FEATURE-SELECTION; NEURAL-NETWORKS; IMAGES;
   CLASSIFICATION; MAD
AB The diversity of change detection (CD) methods and the limitations in generalizing these techniques using different types of remote sensing datasets over various study areas have been a challenge for CD applications. Additionally, most CD methods have been implemented in two intensive and time-consuming steps: (a) predictingchangeareas, and (b) decision on predicted areas. In this study, a novel CD framework based on the convolutional neural network (CNN) is proposed to not only address the aforementioned problems but also to considerably improve the level of accuracy. The proposed CNN-based CD network contains three parallel channels: the first and second channels, respectively, extract deep features on the original first- and second-time imagery and the third channel focuses on the extraction of change deep features based on differencing and staking deep features. Additionally, each channel includes three types of convolution kernels: 1D-, 2D-, and 3D-dilated-convolution. The effectiveness and reliability of the proposed CD method are evaluated using three different types of remote sensing benchmark datasets (i.e., multispectral, hyperspectral, and Polarimetric Synthetic Aperture RADAR (PolSAR)). The results of the CD maps are also evaluated both visually and statistically by calculating nine different accuracy indices. Moreover, the results of the CD using the proposed method are compared to those of several state-of-the-art CD algorithms. All the results prove that the proposed method outperforms the other remote sensing CD techniques. For instance, considering different scenarios, the Overall Accuracies (OAs) and Kappa Coefficients (KCs) of the proposed CD method are better than 95.89% and 0.805, respectively, and the Miss Detection (MD) and the False Alarm (FA) rates are lower than 12% and 3%, respectively.
C1 [Seydi, Seyd Teymoor; Hasanlou, Mahdi] Univ Tehran, Sch Surveying & Geospatial Engn, Coll Engn, Tehran 1417466191, Iran.
   [Amani, Meisam] Wood Environm & Infrastruct Solut, Ottawa, ON K2E 7K3, Canada.
RP Amani, M (corresponding author), Wood Environm & Infrastruct Solut, Ottawa, ON K2E 7K3, Canada.
EM seydi.teymoor@ut.ac.ir; hasanlou@ut.ac.ir; meisam.amani@woodplc.com
RI seydi, seyd teymoor/K-3366-2017; Amani, Meisam/X-4606-2018
OI Seydi, Seyd Teymoor/0000-0002-3678-4877; Hasanlou,
   Mahdi/0000-0002-7254-4475; Amani, Meisam/0000-0002-9495-4010
CR Agarap, 2018, ARXIV180308375
   Alexandari A.M., 2017, SEPARABLE FULLY CONN, P146431
   Carranza-Garcia M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   Chen C, 2019, LECT NOTES COMPUT SC, V11766, P184, DOI 10.1007/978-3-030-32248-9_21
   Chen X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020275
   Chen ZH, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ROBOTICS, INTELLIGENT CONTROL AND ARTIFICIAL INTELLIGENCE (RICAI 2019), P159, DOI 10.1145/3366194.3366222
   Chetouani A, 2020, PATTERN RECOGN LETT, V131, P1, DOI 10.1016/j.patrec.2019.12.009
   Christlein V., 2019, ARXIV190805040
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du JL, 2020, IEEE ACCESS, V8, P18938, DOI 10.1109/ACCESS.2020.2968395
   Du PJ, 2020, ISPRS J PHOTOGRAMM, V161, P278, DOI 10.1016/j.isprsjprs.2020.01.026
   Eckle K, 2019, NEURAL NETWORKS, V110, P232, DOI 10.1016/j.neunet.2018.11.005
   Feng F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235276
   Ghanbari M, 2018, IEEE J-STARS, V11, P4551, DOI 10.1109/JSTARS.2018.2882412
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Hasanlou M., 2018, EARTH OBSERV GEOMATI, V2, P9
   Hasanlou M, 2018, CAN J REMOTE SENS, V44, P601, DOI 10.1080/07038992.2019.1573137
   Hu W.-S., 2019, ARXIV190503577
   Hu ZX, 2018, NEUROCOMPUTING, V318, P151, DOI 10.1016/j.neucom.2018.08.042
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010075
   Kanai S, 2018, ADV NEURAL INFORM PR, P286
   Kiranyaz S., 2019, ARXIV190503554
   Kotsiantis S., 2006, COMPUT SCI ENG, V30, P25
   Kwan C, 2019, INFORMATION, V10, DOI 10.3390/info10110353
   Lameski P, 2015, LECT NOTES ARTIF INT, V9437, P464, DOI 10.1007/978-3-319-25783-9_41
   Leichtle T., 2020, THESIS
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P1660, DOI 10.1109/LGRS.2015.2418232
   Li JJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232859
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li Z, 2016, ADV NEURAL INFORM PR, P2523
   Lin ZY, 2009, LECT NOTES COMPUT SC, V5678, P536
   Liu F, 2018, IEEE T NEURAL NETWOR, V30, P818, DOI DOI 10.1109/TNNLS.2018.2847309
   Liu SC, 2020, EUR J REMOTE SENS, V53, P104, DOI 10.1080/22797254.2020.1738900
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu SC, 2016, IEEE T GEOSCI REMOTE, V54, P2733, DOI 10.1109/TGRS.2015.2505183
   Longadge R., 2013, 1305 ARXIV
   Lopez-Fandino J, 2019, INT J PARALLEL PROG, V47, P272, DOI 10.1007/s10766-017-0547-5
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Mahdavi S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161854
   Marinelli D, 2019, IEEE T GEOSCI REMOTE, V57, P4913, DOI 10.1109/TGRS.2019.2894339
   Najafi A, 2019, INT J REMOTE SENS, V40, P6084, DOI 10.1080/01431161.2019.1587202
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Oland A., 2017, ARXIV170704199
   Papadomanolaki M, 2019, INT GEOSCI REMOTE SE, P214, DOI 10.1109/IGARSS.2019.8900330
   Parikh H, 2020, INT J IMAGE DATA FUS, V11, P1, DOI 10.1080/19479832.2019.1655489
   Peduzzi P, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11040957
   Pirrone D, 2020, IEEE T GEOSCI REMOTE, V58, P4780, DOI 10.1109/TGRS.2020.2966865
   Qahtan A, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P935, DOI 10.1145/2783258.2783359
   Qi ZX, 2015, ISPRS J PHOTOGRAMM, V107, P3, DOI 10.1016/j.isprsjprs.2015.02.004
   Qing Z, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P544, DOI 10.1109/ICNC.2013.6818036
   Ramyachitra D., 2014, IMBALANCED DATASET C
   Roy SK, 2020, IEEE GEOSCI REMOTE S, V17, P277, DOI 10.1109/LGRS.2019.2918719
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Seydi S.T., 2020, P INT SOC PHOT REM S
   Seydi S.T., 2019, INT ARCH PHOTOGRAMM, V42, P963, DOI [10.5194/isprs-archives-XLII-4-W18-963-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-4-W18-963-2019]
   Shah-Hosseini R, 2015, REMOTE SENS-BASEL, V7, P12829, DOI 10.3390/rs71012829
   Slagter B, 2020, INT J APPL EARTH OBS, V86, DOI 10.1016/j.jag.2019.102009
   Solberg AHS, 1997, IEEE T GEOSCI REMOTE, V35, P475, DOI 10.1109/36.563288
   Song A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071099
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang B, 2015, REMOTE SENS LETT, V6, P578, DOI 10.1080/2150704X.2015.1062155
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Wu SL, 2019, CLUSTER COMPUT, V22, pS9951, DOI 10.1007/s10586-017-1022-1
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yekkehkhany B, 2014, INT ARCH PHOTOGRAMM, V40, P281, DOI 10.5194/isprsarchives-XL-2-W3-281-2014
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang LF, 2018, IEEE T CYBERNETICS, V48, P16, DOI 10.1109/TCYB.2016.2605044
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang Y., 2008, GEOSPATIAL INFORM TE, P91
   Zhao JQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051508
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
NR 81
TC 21
Z9 21
U1 23
U2 38
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN
PY 2020
VL 12
IS 12
AR 2010
DI 10.3390/rs12122010
PG 38
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MM7OR
UT WOS:000550343200001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, MC
   Zhang, HM
   Sun, WW
   Li, S
   Wang, FY
   Yang, GD
AF Wang, Mingchang
   Zhang, Haiming
   Sun, Weiwei
   Li, Sheng
   Wang, Fengyan
   Yang, Guodong
TI A Coarse-to-Fine Deep Learning Based Land Use Change Detection Method
   for High-Resolution Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE coarse-to-fine; change detection; deep learning; land-use;
   high-resolution
ID CHANGE VECTOR ANALYSIS; BUILDING CHANGE DETECTION; NEURAL-NETWORK;
   SENSED IMAGES; COVER; FRAMEWORK; MODEL
AB In recent decades, high-resolution (HR) remote sensing images have shown considerable potential for providing detailed information for change detection. The traditional change detection methods based on HR remote sensing images mostly only detect a single land type or only the change range, and cannot simultaneously detect the change of all object types and pixel-level range changes in the area. To overcome this difficulty, we propose a new coarse-to-fine deep learning-based land-use change detection method. We independently created a new scene classification dataset called NS-55, and innovatively considered the adaptation relationship between the convolutional neural network (CNN) and the scene complexity by selecting the CNN that best fit the scene complexity. The CNN trained by NS-55 was used to detect the category of the scene, define the final category of the scene according to the majority voting method, and obtain the changed scene by comparison to obtain the so-called coarse change result. Then, we created a multi-scale threshold (MST) method, which is a new method for obtaining high-quality training samples. We used the high-quality samples selected by MST to train the deep belief network to obtain the pixel-level range change detection results. By mapping coarse scene changes to range changes, we could obtain fine multi-type land-use change detection results. Experiments were conducted on the Multi-temporal Scene Wuhan dataset and aerial images of a particular area of Dapeng New District, Shenzhen, where promising results were achieved by the proposed method. This demonstrates that the proposed method is practical, easy-to-implement, and the NS-55 dataset is physically justified. The proposed method has the potential to be applied in the large scale land use fine change detection problem and qualitative and quantitative research on land use/cover change based on HR remote sensing data.
C1 [Wang, Mingchang; Zhang, Haiming; Wang, Fengyan; Yang, Guodong] Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun 130026, Peoples R China.
   [Wang, Mingchang; Li, Sheng] MNR, Key Lab Urban Land Resources Monitoring & Simulat, Shenzhen 518000, Peoples R China.
   [Sun, Weiwei] Ningbo Univ, Dept Geog & Spatial Informat Tech, Ningbo 315211, Peoples R China.
   [Li, Sheng] Shenzhen Municipal Planning & Land Real Estate In, Shenzhen 518034, Peoples R China.
RP Zhang, HM (corresponding author), Jilin Univ, Coll Geoexplorat Sci & Technol, Changchun 130026, Peoples R China.
EM wangmc@jlu.edu.cn; zhanghm18@mails.jlu.edu.cn; sunweiwei@nbu.edu.cn;
   shenglee@whu.edu.cn; wangfy@jlu.edu.cn; ygd@jlu.edu.cn
OI wang, mingchang/0000-0002-2806-858X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41472243]; Open Fund of Key Laboratory of
   Urban Land Resources Monitoring and Simulation, MNR [KF-2018-03-020,
   KF-2019-04-080]; Shanghai Institute of Geological Survey (Key Laboratory
   of Land Subsidence Detection and Prevention, Ministry of Land and
   Resources) open fund [KLLSMP201901]; Scientific Research Project of the
   13th Five-Year Plan of Jilin Province education department
   [JJKH20200999KJ]
FX This research was funded by the National Natural Science Foundation of
   China (41472243); the Open Fund of Key Laboratory of Urban Land
   Resources Monitoring and Simulation, MNR (KF-2018-03-020;
   KF-2019-04-080); the Shanghai Institute of Geological Survey (Key
   Laboratory of Land Subsidence Detection and Prevention, Ministry of Land
   and Resources) open fund (KLLSMP201901); and the Scientific Research
   Project of the 13th Five-Year Plan of Jilin Province education
   department (JJKH20200999KJ).
CR Arsalan M, 2019, EXPERT SYST APPL, V122, P217, DOI 10.1016/j.eswa.2019.01.010
   Barazzetti L, 2016, PHOTOGRAMM ENG REM S, V82, P161, DOI 10.14358/PERS.82.2.161
   Ben Hamida A, 2018, IEEE T GEOSCI REMOTE, V56, P4420, DOI 10.1109/TGRS.2018.2818945
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   CHEN Q, 2016, REMOTE SENS-BASEL, V8, P549, DOI DOI 10.3390/rs8070549
   Cheng DC, 2017, IEEE GEOSCI REMOTE S, V14, P247, DOI 10.1109/LGRS.2016.2637439
   Fadl S, 2020, MULTIMED TOOLS APPL, V79, P17619, DOI 10.1007/s11042-019-08603-z
   Feizizadeh B, 2017, GEOMORPHOLOGY, V293, P240, DOI 10.1016/j.geomorph.2017.06.002
   [冯文卿 Feng Wenqing], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1147
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gao XG, 2018, CHINESE J ELECTRON, V27, P483, DOI 10.1049/cje.2018.03.013
   Ge Y, 2018, MULTIMED TOOLS APPL, V77, P17489, DOI 10.1007/s11042-017-5314-5
   Han J, 2020, INT J ELEC POWER, V117, DOI 10.1016/j.ijepes.2019.105740
   Han Y, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060983
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Huang Gao, 2019, IEEE Trans Pattern Anal Mach Intell, DOI 10.1109/TPAMI.2019.2918284
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Jiang YN, 2019, IEEE GEOSCI REMOTE S, V16, P1949, DOI 10.1109/LGRS.2019.2913011
   Jin SM, 2017, REMOTE SENS ENVIRON, V195, P44, DOI 10.1016/j.rse.2017.04.021
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karydas CG, 2020, INT J REMOTE SENS, V41, P2905, DOI 10.1080/01431161.2019.1698071
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li EZ, 2017, IEEE T GEOSCI REMOTE, V55, P5653, DOI 10.1109/TGRS.2017.2711275
   Li H., 2017, ARXIV170507077
   LI JJ, 2018, REMOTE SENS-BASEL, V10, DOI DOI 10.3390/rs10030396
   Li K, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050789
   Li LW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101162
   Li ZX, 2017, IEEE GEOSCI REMOTE S, V14, P783, DOI 10.1109/LGRS.2017.2681198
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Lunetta RS, 2004, REMOTE SENS ENVIRON, V89, P444, DOI 10.1016/j.rse.2003.10.022
   Lv P.Y., 2016, P 2016 IEEE INT GEOS
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Saito Y, 2019, NEURAL COMPUT, V31, P784, DOI 10.1162/neco_a_01176
   Siravenha ACQ, 2018, INT J REMOTE SENS, V39, P4170, DOI 10.1080/01431161.2018.1452064
   Song F, 2019, REMOTE SENS LETT, V10, P573, DOI 10.1080/2150704X.2019.1576949
   TAO YT, 2018, REMOTE SENS-BASEL, V10, P779, DOI DOI 10.3390/rs10050779
   Teerakawanich N, 2020, ENERGY REP, V6, P526, DOI 10.1016/j.egyr.2019.11.114
   Traore BB, 2018, ECOL INFORM, V48, P257, DOI 10.1016/j.ecoinf.2018.10.002
   Wang MC, 2019, J GEOVIS SPAT ANAL, V3, DOI 10.1007/s41651-019-0039-9
   Wang YL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020136
   Wen DW, 2016, IEEE T GEOSCI REMOTE, V54, P609, DOI 10.1109/TGRS.2015.2463075
   Wu K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030284
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xie FY, 2017, IEEE J-STARS, V10, P3631, DOI 10.1109/JSTARS.2017.2686488
   Xu L, 2019, IEEE ACCESS, V7, P78909, DOI 10.1109/ACCESS.2019.2922839
   Xue LN, 2020, HIGH EDUC RES DEV, V39, P1290, DOI 10.1080/07294360.2020.1712679
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zeng D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050734
   Zhang GL, 2019, INT J DISAST RISK SC, V10, P386, DOI 10.1007/s13753-019-00233-1
   Zhao X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183844
   Zheng ZF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161903
   Zhong YF, 2020, REMOTE SENS LETT, V11, P515, DOI 10.1080/2150704X.2020.1731768
   Zhong YF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080868
   Zhou ZJ, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7110441
   Zhu JX, 2017, PHOTOGRAMM ENG REM S, V83, P225, DOI [10.14358/pers.83.3.225, 10.14358/PERS.83.3.225]
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
   Zulfa MI, 2019, AIP CONF PROC, V2094, DOI 10.1063/1.5097475
NR 66
TC 6
Z9 6
U1 11
U2 26
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN
PY 2020
VL 12
IS 12
AR 1933
DI 10.3390/rs12121933
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MM8CC
UT WOS:000550378100001
OA gold
DA 2022-01-04
ER

PT J
AU Dong, HH
   Ma, WP
   Wu, Y
   Zhang, J
   Jiao, LC
AF Dong, Huihui
   Ma, Wenping
   Wu, Yue
   Zhang, Jun
   Jiao, Licheng
TI Self-Supervised Representation Learning for Remote Sensing Image Change
   Detection Based on Temporal Prediction
SO REMOTE SENSING
LA English
DT Article
DE unsupervised change detection; generative adversarial networks; deep
   belief networks; self-supervised representation learning; remote sensing
   images
ID UNSUPERVISED CHANGE DETECTION; THEORETICAL FRAMEWORK; SEGMENTATION;
   NETWORK; MODEL
AB Traditional change detection (CD) methods operate in the simple image domain or hand-crafted features, which has less robustness to the inconsistencies (e.g., brightness and noise distribution, etc.) between bitemporal satellite images. Recently, deep learning techniques have reported compelling performance on robust feature learning. However, generating accurate semantic supervision that reveals real change information in satellite images still remains challenging, especially for manual annotation. To solve this problem, we propose a novel self-supervised representation learning method based on temporal prediction for remote sensing image CD. The main idea of our algorithm is to transform two satellite images into more consistent feature representations through a self-supervised mechanism without semantic supervision and any additional computations. Based on the transformed feature representations, a better difference image (DI) can be obtained, which reduces the propagated error of DI on the final detection result. In the self-supervised mechanism, the network is asked to identify different sample patches between two temporal images, namely, temporal prediction. By designing the network for the temporal prediction task to imitate the discriminator of generative adversarial networks, the distribution-aware feature representations are automatically captured and the result with powerful robustness can be acquired. Experimental results on real remote sensing data sets show the effectiveness and superiority of our method, improving the detection precision up to 0.94-35.49%.
C1 [Dong, Huihui; Ma, Wenping; Zhang, Jun; Jiao, Licheng] Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence, Xian 710071, Peoples R China.
   [Wu, Yue] Xidian Univ, Xian Key Lab Big Data & Intelligent Vis, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
RP Ma, WP (corresponding author), Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence, Xian 710071, Peoples R China.
EM donghuihui@stu.xidian.edu.cn; wpma@mail.xidian.edu.cn;
   ywu@xidian.edu.cn; zhangjun2018@stu.xidian.edu.cn;
   lchjiao@mail.xidian.edu.cn
OI Jiao, Licheng/0000-0003-3354-9617; Wu, Yue/0000-0002-3459-5079
FU Foundation for Innovative Research Groups of the National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61621005]; National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [U1701267, 61702392];
   Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities [JB181704, JBX170311]
FX This work was supported in part by the Project supported the Foundation
   for Innovative Research Groups of the National Natural Science
   Foundation of China (No. 61621005), National Natural Science Foundation
   of China (No. U1701267 and 61702392), and the Fundamental Research Funds
   for the Central Universities (No. JB181704 and JBX170311).
CR Ban Y., 2016, CHANGE DETECTION TEC
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Braga AM, 2017, IEEE GEOSCI REMOTE S, V14, P1171, DOI 10.1109/LGRS.2017.2702062
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chintala S., 2016, ARXIV151106434
   Ciecholewski M, 2017, EXPERT SYST APPL, V82, P196, DOI 10.1016/j.eswa.2017.04.018
   Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Daudt R.C., 2018, P INT GEOSC REM SENS
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Elvidge C.D., 1998, REMOTE SENSING CHANG
   Fernando B., 2017, P IEEE C COMP VIS PA, P3636
   Ferretti A., 2007, J FINANCIAL STABILIT, V10, P156, DOI DOI 10.1287/ITED.1100.0047
   Fischer Asja, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P14, DOI 10.1007/978-3-642-33275-3_2
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Ghanbari M., 2015, IEEE T GEOSCI REMOTE, V44, P2972
   Gong J., 2011, PROTEIN EXPRES PURIF, V82, P308
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2014, ISPRS J PHOTOGRAMM, V93, P123, DOI 10.1016/j.isprsjprs.2014.04.010
   Gong MG, 2014, INT J REMOTE SENS, V35, P4009, DOI 10.1080/01431161.2014.916054
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, NEURAL NETWORKS TRIC, P599, DOI DOI 10.1007/978-3-642-35289-8_32
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Huerta I, 2015, PATTERN RECOGN, V48, P709, DOI 10.1016/j.patcog.2014.09.023
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   JENSEN JR, 1987, PHOTOGRAMM ENG REM S, V53, P521
   Jin RJ, 2017, IEEE J-STARS, V10, P4565, DOI 10.1109/JSTARS.2017.2716620
   Jing L., 2019, ARXIV190206162
   Lang FK, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101592
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2015, APPL SOFT COMPUT, V34, P151, DOI 10.1016/j.asoc.2015.05.003
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Saxena R, 2018, ISPRS J PHOTOGRAMM, V144, P217, DOI 10.1016/j.isprsjprs.2018.07.002
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Turgay C., 2013, IEEE T IMAGE PROCESS, V22, P1258, DOI DOI 10.1109/TIP.2012.2226048
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang S, 2018, ISPRS J PHOTOGRAMM, V145, P148, DOI 10.1016/j.isprsjprs.2017.12.012
   Wang X., 2015, P IEEE INT C COMP VI
   Xing J, 2018, ISPRS J PHOTOGRAMM, V141, P252, DOI 10.1016/j.isprsjprs.2018.04.013
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 69
TC 8
Z9 8
U1 19
U2 25
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN
PY 2020
VL 12
IS 11
AR 1868
DI 10.3390/rs12111868
PG 38
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6LX
UT WOS:000543397000173
OA gold
DA 2022-01-04
ER

PT J
AU Huang, LJ
   An, R
   Zhao, SY
   Jiang, T
   Hu, H
AF Huang, Lijun
   An, Ru
   Zhao, Shengyin
   Jiang, Tong
   Hu, Hao
TI A Deep Learning-Based Robust Change Detection Approach for Very High
   Resolution Remotely Sensed Images with Multiple Features
SO REMOTE SENSING
LA English
DT Article
DE change detection; deep learning; multiple features; radius scalable
   circular; very high-resolution remote sensing
ID U-NET; FRAMEWORK; CLASSIFICATION; EXTRACTION; LAND
AB Very high-resolution remote sensing change detection has always been an important research issue due to the registration error, robustness of the method, and monitoring accuracy, etc. This paper proposes a robust and more accurate approach of change detection (CD), and it is applied on a smaller experimental area, and then extended to a wider range. A feature space, including object features, Visual Geometry Group (VGG) depth features, and texture features, is constructed. The difference image is obtained by considering the contextual information in a radius scalable circular. This is to overcome the registration error caused by the rotation and shift of the instantaneous field of view and also to improve the reliability and robustness of the CD. To enhance the robustness of the U-Net model, the training dataset is constructed manually via various operations, such as blurring the image, increasing noise, and rotating the image. After this, the trained model is used to predict the experimental areas, which achieved 92.3% accuracy. The proposed method is compared with Support Vector Machine (SVM) and Siamese Network, and the check error rate dropped to 7.86%, while the Kappa increased to 0.8254. The results revealed that our method outperforms SVM and Siamese Network.
C1 [Huang, Lijun; An, Ru; Zhao, Shengyin; Jiang, Tong] Hohai Univ, Sch Earth Sci & Engn, Nanjing 211100, Peoples R China.
   [Huang, Lijun; Hu, Hao] Suzhou Univ, Sch Mech & Elect Engn, Suzhou 234000, Peoples R China.
RP An, R (corresponding author), Hohai Univ, Sch Earth Sci & Engn, Nanjing 211100, Peoples R China.
EM ljhuang@mail.ustc.edu.cn; anrunj@hhu.edu.cn; zhaosy51@hhu.edu.cn;
   jiangtong@hhu.edu.cn; huhao@ahszu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41871326, 41271361]; Jiangsu Province Key
   Research and Development Plan [BE2017115]; Provincial Outstanding Young
   Talents Project of Anhui [2016XQNRL002]
FX This research was funded by National Natural Science Foundation of China
   (Grant Number 41871326 and 41271361), the Jiangsu Province Key Research
   and Development Plan(BE2017115), Provincial Outstanding Young Talents
   Project of Anhui(2016XQNRL002).
CR AL-Alimi D, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212525
   Cheng B, 2020, INT J REMOTE SENS, V41, P3575, DOI 10.1080/01431161.2019.1706009
   Dalmis MU, 2017, MED PHYS, V44, P533, DOI 10.1002/mp.12079
   Das A, 1997, P SOC PHOTO-OPT INS, V3026, P338, DOI 10.1117/12.271138
   Debayle J, 2006, J MATH IMAGING VIS, V25, P245, DOI 10.1007/s10851-006-7451-8
   Debayle J, 2006, LECT NOTES COMPUT SC, V4141, P29
   Debayle J, 2011, LECT NOTES COMPUT SC, V6671, P224, DOI 10.1007/978-3-642-21569-8_20
   Debayle J, 2011, J MATH IMAGING VIS, V41, P210, DOI 10.1007/s10851-011-0271-5
   [董岳 Dong Yue], 2019, [遥感信息, Remote Sensing Information], V34, P144
   [杜培军 Du Peijun], 2012, [遥感学报, Journal of Remote Sensing], V16, P663
   Dunnhofer M, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101631
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Fouladivanda M, 2016, IRAN CONF ELECTR ENG, P960, DOI 10.1109/IranianCEE.2016.7585660
   Gonzalez-Castro V, 2014, PATTERN RECOGN LETT, V47, P50, DOI 10.1016/j.patrec.2014.01.007
   Horch A, 2019, IET IMAGE PROCESS, V13, P2866, DOI 10.1049/iet-ipr.2019.0122
   Huang JR, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212484
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Li KY, 2019, IEEE ACCESS, V7, P110874, DOI 10.1109/ACCESS.2019.2933594
   LI L, 2019, REMOTE SENS-BASEL, V11, pNIL_2022, DOI DOI 10.3390/rs11091091
   Liu ZQ, 2019, AUTOMAT CONSTR, V104, P129, DOI 10.1016/j.autcon.2019.04.005
   Long FX, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-019-3332-1
   Lu XY, 2019, IEEE T GEOSCI REMOTE, V57, P9362, DOI 10.1109/TGRS.2019.2926397
   [梅树红 Mei Shuhong], 2019, [测绘通报, Bulletin of Surveying and Mapping], P140
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Neagoe VE, 2016, INT GEOSCI REMOTE SE, P3386, DOI 10.1109/IGARSS.2016.7729875
   Pinoli JC, 2012, IEEE J-STSP, V6, P820, DOI 10.1109/JSTSP.2012.2214762
   Pinoli JC, 2012, PATTERN RECOGN, V45, P2758, DOI 10.1016/j.patcog.2011.12.026
   Pinoli JC, 2009, 2009 16TH IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOLS 1-6, P2249, DOI 10.1109/ICIP.2009.5413979
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Song F, 2018, IEEE ACCESS, V6, P77494, DOI 10.1109/ACCESS.2018.2883254
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wen CL, 2019, ISPRS J PHOTOGRAMM, V147, P178, DOI 10.1016/j.isprsjprs.2018.10.007
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Xiao PF, 2014, IEEE J-STARS, V7, P4095, DOI 10.1109/JSTARS.2014.2302855
   Yan JN, 2019, ISPRS J PHOTOGRAMM, V158, P249, DOI 10.1016/j.isprsjprs.2019.10.003
   Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yao W, 2018, NEUROCOMPUTING, V312, P364, DOI 10.1016/j.neucom.2018.05.103
   [张良培 Zhang Liangpei], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1447
   [张鑫龙 Zhang Xinlong], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P999
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   [赵金奇 Zhao Jinqi], 2019, [测绘学报, Acta Geodetica et Cartographica Sinica], V48, P536
   [赵生银 Zhao Shengyin], 2019, [测绘学报, Acta Geodetica et Cartographica Sinica], V48, P1452
   ZHENG ZF, 2019, REMOTE SENS-BASEL, V11, pNIL_1411, DOI DOI 10.3390/rs11161903
NR 45
TC 2
Z9 2
U1 8
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2020
VL 12
IS 9
AR 1441
DI 10.3390/rs12091441
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6KT
UT WOS:000543394000088
OA gold
DA 2022-01-04
ER

PT J
AU Chen, H
   Shi, ZW
AF Chen, Hao
   Shi, Zhenwei
TI A Spatial-Temporal Attention-Based Method and a New Dataset for Remote
   Sensing Image Change Detection
SO REMOTE SENSING
LA English
DT Article
DE image change detection; attention mechanism; multi-scale;
   spatial-temporal dependency; image change detection dataset; fully
   convolutional networks (FCN)
ID BUILDING CHANGE DETECTION; LAND-COVER; CONTEXT; MODEL
AB Remote sensing image change detection (CD) is done to identify desired significant changes between bitemporal images. Given two co-registered images taken at different times, the illumination variations and misregistration errors overwhelm the real object changes. Exploring the relationships among different spatial-temporal pixels may improve the performances of CD methods. In our work, we propose a novel Siamese-based spatial-temporal attention neural network. In contrast to previous methods that separately encode the bitemporal images without referring to any useful spatial-temporal dependency, we design a CD self-attention mechanism to model the spatial-temporal relationships. We integrate a new CD self-attention module in the procedure of feature extraction. Our self-attention module calculates the attention weights between any two pixels at different times and positions and uses them to generate more discriminative features. Considering that the object may have different scales, we partition the image into multi-scale subregions and introduce the self-attention in each subregion. In this way, we could capture spatial-temporal dependencies at various scales, thereby generating better representations to accommodate objects of various sizes. We also introduce a CD dataset LEVIR-CD, which is two orders of magnitude larger than other public datasets of this field. LEVIR-CD consists of a large set of bitemporal Google Earth images, with 637 image pairs (1024 x 1024) and over 31 k independently labeled change instances. Our proposed attention module improves the F1-score of our baseline model from 83.9 to 87.3 with acceptable computational overhead. Experimental results on a public remote sensing image CD dataset show our method outperforms several other state-of-the-art methods.
C1 [Chen, Hao; Shi, Zhenwei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
   [Chen, Hao; Shi, Zhenwei] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Chen, Hao; Shi, Zhenwei] Beihang Univ, Sch Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
RP Shi, ZW (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.; Shi, ZW (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Shi, ZW (corresponding author), Beihang Univ, Sch Astronaut, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM justchenhao@buaa.edu.cn; shizhenwei@buaa.edu.cn
OI chen, hao/0000-0002-6418-3761
FU National Key R&D Program of China [2017YFC1405605]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61671037]; Beijing Natural Science FoundationBeijing Natural
   Science Foundation [4192034]; Shanghai Association for Science and
   Technology [SAST2018096]
FX This work was supported by the National Key R&D Program of China under
   the grant 2017YFC1405605, the National Natural Science Foundation of
   China under the grant 61671037, the Beijing Natural Science Foundation
   under the grant 4192034 and Shanghai Association for Science and
   Technology under the grant SAST2018096.
CR Bachofer F, 2019, DATA, V4, DOI 10.3390/data4030105
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bahdanau D., 2014, ARXIV14090473
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Castelluccio M., 2015, ARXIV150800092
   Chen CF, 2013, REMOTE SENS-BASEL, V5, P6408, DOI 10.3390/rs5126408
   Chen H., 2018, CHIN C IM GRAPH TECH, P330
   Chen KM, 2013, IEEE GEOSCI REMOTE S, V10, P236, DOI 10.1109/LGRS.2012.2199279
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   CHIANUCCI D, 2016, WEST NEW YORK IMAG, P1
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Duque JC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090895
   Gapper JJ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131525
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong ZQ, 2018, IEEE T GEOSCI REMOTE, V56, P371, DOI 10.1109/TGRS.2017.2748120
   Hadsell Raia, 2006, P 2006 IEEE COMP VIS, P1735, DOI DOI 10.1109/CVPR.2006.100
   Huang QQ, 2017, INT GEOSCI REMOTE SE, P1095, DOI 10.1109/IGARSS.2017.8127147
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Huo CL, 2016, IEEE J-STARS, V9, P3384, DOI 10.1109/JSTARS.2016.2569598
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Kingma D., 2014, 14126980 ARXIV
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lei S, 2020, IEEE T GEOSCI REMOTE, V58, P3633, DOI 10.1109/TGRS.2019.2959020
   Liu BY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081251
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Liu RY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232844
   Liu Y., 2019, ARXIV190907726
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   LV ZY, 2018, REMOTE SENS-BASEL, V10, DOI DOI 10.3390/rs10030472
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mahdavi S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11161854
   Malpica JA, 2013, INT J REMOTE SENS, V34, P1652, DOI 10.1080/01431161.2012.725483
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Ozer HG, 2009, 2009 OHIO COLLABORATIVE CONFERENCE ON BIOINFORMATICS, PROCEEDINGS, P21, DOI 10.1109/OCCBIO.2009.35
   Pan B, 2020, IEEE GEOSCI REMOTE S, V17, P1968, DOI 10.1109/LGRS.2019.2960528
   Paszke A., 2017, P 2017 NEUR INF PROC
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   Rokni K, 2014, REMOTE SENS-BASEL, V6, P4173, DOI 10.3390/rs6054173
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vaswani, 2017, ADV NEURAL INFORM PR, DOI [DOI 10.5555/3295222.3295349, DOI 10.HTTP://PAPERS.NIPS.CC/PAPER/7181-ATTENTI0N-IS-ALL-Y0U-NEED.PDF]
   Wang JQ, 2014, IEEE T CIRC SYST VID, V24, P1620, DOI 10.1109/TCSVT.2014.2308616
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   XunWang Xintong Han, 2019, P IEEE C COMP VIS PA, P5022
   Yang JM, 2014, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2014.415
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhao B, 2017, LECT NOTES GEOINF CA, P21, DOI 10.1007/978-3-319-57336-6_2
   Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P3978, DOI 10.1109/TGRS.2007.907109
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   Zong KB, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024514
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 74
TC 53
Z9 55
U1 36
U2 47
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2020
VL 12
IS 10
AR 1662
DI 10.3390/rs12101662
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6LB
UT WOS:000543394800129
OA gold
DA 2022-01-04
ER

PT J
AU Chen, JW
   Wang, RF
   Ding, F
   Liu, B
   Jiao, LC
   Zhang, J
AF Chen, Jia-Wei
   Wang, Rongfang
   Ding, Fan
   Liu, Bo
   Jiao, Licheng
   Zhang, Jie
TI A Convolutional Neural Network with Parallel Multi-Scale Spatial Pooling
   to Detect Temporal Changes in SAR Images
SO REMOTE SENSING
LA English
DT Article
DE change detection; SAR image; convolutional neural network; multi-scale
   spatial pooling
ID UNSUPERVISED CHANGE DETECTION
AB In synthetic aperture radar (SAR) image change detection, it is quite challenging to exploit the changing information from the noisy difference image subject to the speckle. In this paper, we propose a multi-scale spatial pooling (MSSP) network to exploit the changed information from the noisy difference image. Being different from the traditional convolutional network with only mono-scale pooling kernels, in the proposed method, multi-scale pooling kernels are equipped in a convolutional network to exploit the spatial context information on changed regions from the difference image. Furthermore, to verify the generalization of the proposed method, we apply our proposed method to the cross-dataset bitemporal SAR image change detection, where the MSSP network (MSSP-Net) is trained on a dataset and then applied to an unknown testing dataset. We compare the proposed method with other state-of-arts and the comparisons are performed on four challenging datasets of bitemporal SAR images. Experimental results demonstrate that our proposed method obtain comparable results with S-PCA-Net on YR-A and YR-B dataset and outperforms other state-of-art methods, especially on the Sendai-A and Sendai-B datasets with more complex scenes. More important, MSSP-Net is more efficient than S-PCA-Net and convolutional neural networks (CNN) with less executing time in both training and testing phases.
C1 [Chen, Jia-Wei; Wang, Rongfang; Ding, Fan; Liu, Bo; Jiao, Licheng; Zhang, Jie] Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
RP Wang, RF (corresponding author), Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Peoples R China.
EM jawaechan@gmail.com; rfwang@xidian.edu.cn; dfmamba@163.com;
   liub@xidian.edu.cn; lchjiao@mail.xidian.edu.cn;
   j_zhang@stu.xidian.edu.cn
OI WANG, RONGFANG/0000-0002-7253-7750; Chen, Jia-Wei/0000-0002-8195-1582;
   Jiao, Licheng/0000-0003-3354-9617
FU State Key Program of National Natural Science of ChinaNational Natural
   Science Foundation of China (NSFC) [61836009]; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [61701361, 61806154]; Open Fund of Key Laboratory of Intelligent
   Perception and Image Understanding of Ministry of Education, Xidian
   University [IPIU2019006]
FX This work was supported by the State Key Program of National Natural
   Science of China (No. 61836009), the National Natural Science Foundation
   of China (No. 61701361, 61806154) and the Open Fund of Key Laboratory of
   Intelligent Perception and Image Understanding of Ministry of Education,
   Xidian University (Grant No. IPIU2019006).
CR Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 2000, INT GEOSCI REMOTE SE, P2441, DOI 10.1109/IGARSS.2000.859602
   Cui SY, 2016, IEEE J-STARS, V9, P1101, DOI 10.1109/JSTARS.2015.2486038
   Cui W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091044
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Jiang YN, 2019, IEEE GEOSCI REMOTE S, V16, P1949, DOI 10.1109/LGRS.2019.2913011
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Kingma D., 2014, 14126980 ARXIV
   Li W, 2012, INT GEOSCI REMOTE SE, P6165, DOI 10.1109/IGARSS.2012.6352664
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Lu M, 2017, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2017.270
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sellami A, 2019, EXPERT SYST APPL, V129, P246, DOI 10.1016/j.eswa.2019.04.006
   Theau J, 2012, SPRINGER HANDBOOK OF GEOGRAPHIC INFORMATION, P175
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Zhang HK, 2019, IEEE T GEOSCI REMOTE, V57, P5813, DOI 10.1109/TGRS.2019.2902568
   Zhang XH, 2013, IEEE GEOSCI REMOTE S, V10, P14, DOI 10.1109/LGRS.2012.2189867
NR 20
TC 6
Z9 6
U1 7
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2020
VL 12
IS 10
AR 1619
DI 10.3390/rs12101619
PG 11
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6LB
UT WOS:000543394800086
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Shi, WZ
   Zhang, M
   Zhang, R
   Chen, SX
   Zhan, Z
AF Shi, Wenzhong
   Zhang, Min
   Zhang, Rui
   Chen, Shanxiong
   Zhan, Zhao
TI Change Detection Based on Artificial Intelligence: State-of-the-Art and
   Challenges
SO REMOTE SENSING
LA English
DT Review
DE artificial intelligence; change detection; remote sensing; deep
   learning; neural network; unsupervised learning; SAR; hyperspectral;
   multispectral; street view
ID IMAGE CHANGE DETECTION; UNSUPERVISED CHANGE DETECTION; REMOTE-SENSING
   IMAGES; CHANGE DETECTION FRAMEWORK; MULTIPLE-CHANGE DETECTION;
   NEURAL-NETWORK APPROACH; URBAN CHANGE DETECTION; LAND USE/COVER CHANGE;
   MARKOV RANDOM-FIELD; SAR IMAGES
AB Change detection based on remote sensing (RS) data is an important method of detecting changes on the Earth's surface and has a wide range of applications in urban planning, environmental monitoring, agriculture investigation, disaster assessment, and map revision. In recent years, integrated artificial intelligence (AI) technology has become a research focus in developing new change detection methods. Although some researchers claim that AI-based change detection approaches outperform traditional change detection approaches, it is not immediately obvious how and to what extent AI can improve the performance of change detection. This review focuses on the state-of-the-art methods, applications, and challenges of AI for change detection. Specifically, the implementation process of AI-based change detection is first introduced. Then, the data from different sensors used for change detection, including optical RS data, synthetic aperture radar (SAR) data, street view images, and combined heterogeneous data, are presented, and the available open datasets are also listed. The general frameworks of AI-based change detection methods are reviewed and analyzed systematically, and the unsupervised schemes used in AI-based change detection are further analyzed. Subsequently, the commonly used networks in AI for change detection are described. From a practical point of view, the application domains of AI-based change detection methods are classified based on their applicability. Finally, the major challenges and prospects of AI for change detection are discussed and delineated, including (a) heterogeneous big data processing, (b) unsupervised AI, and (c) the reliability of AI. This review will be beneficial for researchers in understanding this field.
C1 [Shi, Wenzhong; Zhang, Min; Zhang, Rui; Chen, Shanxiong; Zhan, Zhao] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Hong Kong, Peoples R China.
   [Zhang, Min; Chen, Shanxiong; Zhan, Zhao] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Zhang, Rui] China Univ Min & Technol, Sch Environm Sci & Spatial Informat, Xuzhou 221116, Jiangsu, Peoples R China.
RP Zhang, M (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hung Hom, Hong Kong, Peoples R China.; Zhang, M (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM lswzshi@polyu.edu.hk; 007zhangmin@whu.edu.cn; rzhang@cumt.edu.cn;
   shanxiongchen@whu.edu.cn; zhanzhao@whu.edu.cn
RI ZHANG, Min/AAV-9787-2020
OI ZHANG, Min/0000-0003-1643-5271; ZHAN, ZHAO/0000-0002-5092-715X; Chen,
   Shanxiong/0000-0002-9235-6340
FU Ministry of Science and Technology of the People's Republic of
   ChinaMinistry of Science and Technology, China [2017YFB0503604]
FX This research was funded by the Ministry of Science and Technology of
   the People's Republic of China, Grant No. 2017YFB0503604.
CR Abuelgasim AA, 1999, REMOTE SENS ENVIRON, V70, P208, DOI 10.1016/S0034-4257(99)00039-5
   Aghababaee H, 2013, SCI IRAN, V20, P15, DOI 10.1016/j.scient.2012.11.006
   Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Anees A, 2016, ISPRS J PHOTOGRAMM, V122, P167, DOI 10.1016/j.isprsjprs.2016.10.011
   Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Bai T, 2018, ACM/SIGIR PROCEEDINGS 2018, P1201, DOI 10.1145/3209978.3210129
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Baumgardner M., 2015, Purdue Univ. Res. Repos., V3, P10, DOI [10.4231/R7RX991C, DOI 10.4231/R7RX991C]
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedek C, 2008, INT C PATT RECOG, P1686
   Benedetti A, 2018, INT GEOSCI REMOTE SE, P1962, DOI 10.1109/IGARSS.2018.8517586
   Bengio Y., 2012, ARXIV12065538 CORR
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Bruzzone L, 2002, P SOC PHOTO-OPT INS, V4541, P223, DOI 10.1117/12.454156
   Bu SH, 2020, NEUROCOMPUTING, V378, P166, DOI 10.1016/j.neucom.2019.10.022
   Cao C, 2019, ENVIRONMENTS, V6, DOI 10.3390/environments6020025
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Castellana L, 2007, PATTERN RECOGN LETT, V28, P405, DOI 10.1016/j.patrec.2006.08.010
   Caye Daudt R., 2019, COMP VIS PATT REC WO
   Chan Y K, 2008, Progress In Electromagnetics Research B, V2, P27, DOI 10.2528/PIERB07110101
   Chang NB, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3518096
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen H, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.016021
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Chen H, 2019, NEUROCOMPUTING, V332, P56, DOI 10.1016/j.neucom.2018.11.077
   Chen JY, 2014, NEUROCOMPUTING, V128, P199, DOI 10.1016/j.neucom.2013.02.051
   Chen KM, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 4, PROCEEDINGS, P281, DOI 10.1109/ICNC.2008.456
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen X, 2004, INT GEOSCI REMOTE SE, P3428
   Chen Z, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030821
   Chu Y, 2016, ADV INTEL SYS RES, V133, P262
   Connors C, 2017, INT GEOSCI REMOTE SE, P1063, DOI 10.1109/IGARSS.2017.8127139
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cui B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111314
   Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187
   Dalmiya CP, 2020, EUR J REMOTE SENS, V53, P41, DOI 10.1080/22797254.2019.1692637
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   De S, 2017, INT GEOSCI REMOTE SE, P5193, DOI 10.1109/IGARSS.2017.8128171
   Deilmai BR, 2014, IOP C SER EARTH ENV, V18, DOI 10.1088/1755-1315/18/1/012069
   Del Frate F, 2008, IEEE J-STARS, V1, P87, DOI 10.1109/JSTARS.2008.2002221
   Dewan N, 2019, IIOAB J, V10, P61
   Dietterich TG, 2017, AI MAG, V38, P3, DOI 10.1609/aimag.v38i3.2756
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Durmusoglu ZO, 2017, J ENVIRON BIOL, V38, P981, DOI [10.22438/jeb/38/5(si)/gm-15, 10.22438/jeb/38/5(SI)/GM-15]
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Fan FL, 2008, ENVIRON MONIT ASSESS, V137, P127, DOI 10.1007/s10661-007-9734-y
   Fan JC, 2019, IEEE J-STARS, V12, P685, DOI 10.1109/JSTARS.2019.2892951
   Fang B, 2021, IEEE GEOSCI REMOTE S, V18, P391, DOI 10.1109/LGRS.2020.2979693
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Feldberg I, 2002, INT GEOSCI REMOTE SE, P1195, DOI 10.1109/IGARSS.2002.1025882
   Fujita A, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P5, DOI 10.23919/MVA.2017.7986759
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2019, IEEE J-STARS, V12, P4517, DOI 10.1109/JSTARS.2019.2953128
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Ge C, 2019, IEEE CONF COMPUT, P50, DOI 10.1109/INFCOMW.2019.8845246
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Geng J, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017)
   Ghaffarian S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202427
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Ghosh S, 2009, INT J APPROX REASON, V50, P37, DOI 10.1016/j.ijar.2008.01.008
   Ghouaiel N, 2016, GEO-SPAT INF SCI, V19, P222, DOI 10.1080/10095020.2016.1244998
   Gong MG, 2019, INT J REMOTE SENS, V40, P3647, DOI 10.1080/01431161.2018.1547934
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Goyette N, 2014, IEEE T IMAGE PROCESS, V23, P4663, DOI 10.1109/TIP.2014.2346013
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Guo E., 2018, ARXIV181009111
   Gupta R, 2019, 2019 CHINA-QATAR INTERNATIONAL WORKSHOP ON ARTIFICIAL INTELLIGENCE AND APPLICATIONS TO INTELLIGENT MANUFACTURING (AIAIM), P11, DOI 10.1109/AIAIM.2019.8632775
   Han M, 2018, GISCI REMOTE SENS, V55, P265, DOI 10.1080/15481603.2018.1430100
   Han PC, 2019, NEUROCOMPUTING, V349, P190, DOI 10.1016/j.neucom.2019.04.029
   He PF, 2015, REMOTE SENS LETT, V6, P667, DOI 10.1080/2150704X.2015.1054045
   Hedjam R, 2019, INT GEOSCI REMOTE SE, P1530, DOI 10.1109/IGARSS.2019.8898672
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang DM, 2015, PROC SPIE, V9808, DOI 10.1117/12.2214637
   Huang FH, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102585
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Huelamo C.G., 2018, P WORKSH PHYS AG MAD, P115
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Iino S, 2018, INT J IMAGE DATA FUS, V9, P302, DOI 10.1080/19479832.2018.1491897
   Iino S, 2017, PROC SPIE, V10428, DOI 10.1117/12.2277901
   Jaturapitpornchai R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11121444
   Ji M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101202
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Kang J, 2018, ISPRS J PHOTOGRAMM, V145, P44, DOI 10.1016/j.isprsjprs.2018.02.006
   Kaplan A, 2019, BUS HORIZONS, V62, P15, DOI 10.1016/j.bushor.2018.08.004
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   Kerner HR, 2019, IEEE J-STARS, V12, P3900, DOI 10.1109/JSTARS.2019.2936771
   Keshk HM, 2020, INT J AERONAUT SPACE, V21, P549, DOI 10.1007/s42405-019-00222-0
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Larabi ME, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.046512
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li HC, 2020, ISPRS J PHOTOGRAMM, V160, P167, DOI 10.1016/j.isprsjprs.2019.12.002
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li XD, 2014, ISPRS J PHOTOGRAMM, V93, P76, DOI 10.1016/j.isprsjprs.2014.03.013
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li YY, 2019, IEEE T GEOSCI REMOTE, V57, P5751, DOI 10.1109/TGRS.2019.2901945
   Li YY, 2018, INT GEOSCI REMOTE SE, P4479, DOI 10.1109/IGARSS.2018.8517880
   Liao Frank, 2017, 2017 International Conference on Computing, Networking and Communications (ICNC), P947, DOI 10.1109/ICCNC.2017.7876261
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Lindquist EJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080678
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu GC, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106971
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu R, 2016, J INDIAN SOC REMOTE, V44, P443, DOI 10.1007/s12524-015-0507-8
   Liu RC, 2019, IEEE ACCESS, V7, P156349, DOI 10.1109/ACCESS.2019.2947286
   Liu SC, 2019, IEEE GEOSC REM SEN M, V7, P140, DOI 10.1109/MGRS.2019.2898520
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Luo B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232740
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Lyu HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030471
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mehrotra A, 2015, NAT HAZARDS, V77, P367, DOI 10.1007/s11069-015-1595-z
   Mirici ME, 2018, APPL ECOL ENV RES, V16, P467, DOI 10.15666/aeer/1601_467486
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Mou LC, 2018, INT GEOSCI REMOTE SE, P4363, DOI 10.1109/IGARSS.2018.8517375
   Mueller S. T., 2019, ABS190201876 CORR
   Neagoe VE, 2016, INT GEOSCI REMOTE SE, P3386, DOI 10.1109/IGARSS.2016.7729875
   Neagoe VE, 2013, INT GEOSCI REMOTE SE, P3321, DOI 10.1109/IGARSS.2013.6723538
   Nemmour H, 2006, INT J REMOTE SENS, V27, P705, DOI 10.1080/01431160500275648
   Nemmour H, 2005, EURASIP J APPL SIG P, V2005, P2187, DOI 10.1155/ASP.2005.2187
   Nemoto K, 2017, PROC SPIE, V10431, DOI 10.1117/12.2277912
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Nourani V, 2018, J HYDROL, V562, P371, DOI 10.1016/j.jhydrol.2018.05.018
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Pacifici F, 2010, IEEE GEOSCI REMOTE S, V7, P58, DOI 10.1109/LGRS.2009.2021780
   Patra S, 2008, FUND INFORM, V84, P429
   Patra S, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P716
   Patra S, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P141
   Peng B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212492
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Pomente A, 2018, INT GEOSCI REMOTE SE, P6859, DOI 10.1109/IGARSS.2018.8519195
   Pratola C, 2013, IEEE T GEOSCI REMOTE, V51, P2055, DOI 10.1109/TGRS.2012.2236846
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Regmi K, 2019, IEEE I CONF COMP VIS, P470, DOI 10.1109/ICCV.2019.00056
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Roy M, 2014, INFORM SCIENCES, V269, P35, DOI 10.1016/j.ins.2014.01.037
   Roy M, 2014, IEEE J-STARS, V7, P1200, DOI 10.1109/JSTARS.2013.2293175
   Sadeghi V, 2018, MEASUREMENT, V127, P1, DOI 10.1016/j.measurement.2018.05.097
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Saha S, 2018, PROC SPIE, V10789, DOI 10.1117/12.2325149
   Saha S, 2018, INT GEOSCI REMOTE SE, P1902, DOI 10.1109/IGARSS.2018.8519440
   Sakurada K., 2015, P BRIT MACH VIS C, V61, P1, DOI DOI 10.5244/C.29.61
   Sakurada K, 2017, ARXIV171202941
   Sakurada K, 2017, COMPUT VIS IMAGE UND, V157, P55, DOI 10.1016/j.cviu.2017.01.012
   Sakurada K, 2013, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2013.25
   Samadi F, 2019, IET IMAGE PROCESS, V13, P2255, DOI 10.1049/iet-ipr.2018.6248
   Seto KC, 2003, PHOTOGRAMM ENG REM S, V69, P981, DOI 10.14358/PERS.69.9.981
   Shi WZ, 2013, INT J REMOTE SENS, V34, P6883, DOI 10.1080/01431161.2013.810353
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2019, J COASTAL RES, P426, DOI 10.2112/SI91-086.1
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Song Y, 2006, PROC SPIE, V6419, DOI 10.1117/12.713024
   Su LZ, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.035014
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Su LZ, 2016, IEEE IJCNN, P1269, DOI 10.1109/IJCNN.2016.7727343
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Subudhi BN, 2013, IEEE IMAGE PROC, P3815, DOI 10.1109/ICIP.2013.6738786
   Sun B, 2019, LECT NOTES COMPUT SC, V11555, P414, DOI 10.1007/978-3-030-22808-8_40
   Tang SH, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND ELECTRONICS SYSTEMS (ICCES), P1033
   Tarantino C, 2007, NAT HAZARDS, V41, P245, DOI 10.1007/s11069-006-9041-x
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Nguyen TP, 2019, IEEE T CIRC SYST VID, V29, P433, DOI 10.1109/TCSVT.2018.2795657
   Tomoya M., 2017, ARXIV170300552
   Tong XH, 2010, INT J REMOTE SENS, V31, P1485, DOI 10.1080/01431160903475290
   Touazi A, 2015, INT CONF INTELL SYST, P98, DOI 10.1109/ISDA.2015.7489208
   Varamesh S, 2017, APPL ECOL ENV RES, V15, P1443, DOI 10.15666/aeer/1503_14431454
   Varghese A., 2018, P EUR C COMP VIS ECC, P1
   Venugopal N, 2020, NEURAL PROCESS LETT, V51, P2355, DOI 10.1007/s11063-019-10174-x
   Venugopal N, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0252-0
   Wang L., 2017, AUTOM CONTROL INF SC, V3, P8, DOI 10.12691/acis-3-1-3
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wang Q, 2014, IEEE J-STARS, V8, P1339, DOI DOI 10.1109/JSTARS.2014.2355832
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang Y, 2019, INT GEOSCI REMOTE SE, P198, DOI 10.1109/IGARSS.2019.8898211
   Weng Q., 2018, HIGH SPATIAL RESOLUT
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Woodcock CE, 2001, REMOTE SENS ENVIRON, V78, P194, DOI 10.1016/S0034-4257(01)00259-0
   Wu C., 2019, ARXIV191208628
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Wu K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030284
   Xiao RL, 2018, IEEE ACCESS, V6, P35915, DOI 10.1109/ACCESS.2018.2849110
   Xu JF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024506
   Yang G, 2019, IEEE T GEOSCI REMOTE, V57, P8890, DOI 10.1109/TGRS.2019.2923643
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Ye QK, 2019, LECT NOTES ARTIF INT, V11441, P375, DOI 10.1007/978-3-030-16142-2_29
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang L., 2019, P 10 INT WORKSH AN M, P1
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang M, 2020, IEEE T GEOSCI REMOTE, V58, P7232, DOI 10.1109/TGRS.2020.2981051
   Zhang PL, 2013, REMOTE SENS-BASEL, V5, P1134, DOI 10.3390/rs5031134
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang XK, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232787
   Zhang ZC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11202417
   Zhao JJ, 2014, IEEE IJCNN, P397
   Zhao QN, 2015, COMM COM INF SC, V562, P696, DOI 10.1007/978-3-662-49014-3_62
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhao WZ, 2020, IEEE T GEOSCI REMOTE, V58, P2720, DOI 10.1109/TGRS.2019.2953879
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zhong YF, 2015, IEEE GEOSCI REMOTE S, V12, P537, DOI 10.1109/LGRS.2014.2349937
   Zhu B, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P55, DOI 10.1109/ICIVC.2018.8492747
NR 240
TC 47
Z9 48
U1 81
U2 126
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2020
VL 12
IS 10
AR 1688
DI 10.3390/rs12101688
PG 35
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA MC6LB
UT WOS:000543394800155
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Zhao, WZ
   Mou, LC
   Chen, JG
   Bo, YC
   Emery, WL
AF Zhao, Wenzhi
   Mou, Lichao
   Chen, Jiage
   Bo, Yanchen
   Emery, William J.
TI Incorporating Metric Learning and Adversarial Network for Seasonal
   Invariant Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Bitemporal images; change detection; metric learning; metric
   learning-based generative adversarial network (GAN) (MeGAN);
   pseudochanges
ID UNSUPERVISED CHANGE DETECTION; REMOTE-SENSING IMAGES; CHANGE VECTOR
   ANALYSIS; NEURAL-NETWORKS; CLASSIFICATION
AB Change detection by comparing two bitemporal images is one of the most fundamental challenges for dynamic monitoring of the Earth surface. In this article, we propose a metric learning-based generative adversarial network (GAN) (MeGAN) to automatically explore seasonal invariant features for pseudochange suppressing and real change detection. To achieve this purpose, a seasonal invariant term is introduced to maximally suppress pseudochanges, whereas the MeGAN explores the transition patterns between adjacent images in a self-learning fashion. Different from the previous works on bitemporal imagery change detection, the proposed MeGAN have the following contributions: 1) it automatically explores change patterns from the complex bitemporal background without human intervention and 2) it aims to maximally exclude pseudochanges from the seasonal transition term and map out real changes efficiently. To our best knowledge, this is the first time we incorporate the seasonal transition term and GAN for change detection between bitemporal images. At last, to demonstrate the robustness of the proposed method, we included two data sets which are the Google Earth data and the Landsat data, for bitemporal change detection and evaluation. The experimental results indicated that the proposed method is able to perform change detection with precision can be as high as 81% and 88% for the Google Earth and Landsat data set, respectively.
C1 [Zhao, Wenzhi; Bo, Yanchen] Beijing Normal Univ, State Key Lab Remote Sensing Sci, Beijing 100875, Peoples R China.
   [Zhao, Wenzhi; Bo, Yanchen] Chinese Acad Sci, State Key Lab Remote Sensing Sci, Inst Remote Sensing & Digital Earth, Beijing 100875, Peoples R China.
   [Zhao, Wenzhi; Bo, Yanchen] Beijing Normal Univ, Fac Geog Sci, Inst Remote Sensing Sci & Engn, Beijing Engn Res Ctr Global Land Remote Sensing P, Beijing 100875, Peoples R China.
   [Mou, Lichao] Tech Univ Munich TUM, Signal Proc Earth Observat SiPEO, D-80333 Munich, Germany.
   [Mou, Lichao] Remote Sensing Technol Inst IMF, German Aerosp Ctr DLR, D-82234 Wessling, Germany.
   [Chen, Jiage] Natl Geomat Ctr China, Beijing 100830, Peoples R China.
   [Emery, William J.] Univ Colorado, Colorado Ctr Astrodynam Res, Boulder, CO 80309 USA.
RP Bo, YC (corresponding author), Beijing Normal Univ, State Key Lab Remote Sensing Sci, Beijing 100875, Peoples R China.; Bo, YC (corresponding author), Chinese Acad Sci, State Key Lab Remote Sensing Sci, Inst Remote Sensing & Digital Earth, Beijing 100875, Peoples R China.
EM boyc@bnu.edu.cn
RI Zhao, Wenzhi/AAL-8077-2020; Bo, Yanchen/B-2073-2015; Zhao,
   Wenzhi/H-5230-2015
OI Bo, Yanchen/0000-0002-5136-9364; Zhao, Wenzhi/0000-0002-3125-2310
FU National Key Research and Development Program of China [2016YFB0501502];
   China Postdoctoral Science FoundationChina Postdoctoral Science
   Foundation [2018M640087, 2019T120063]; Fundamental Research Funds for
   the Central UniversitiesFundamental Research Funds for the Central
   Universities [2018NTST01]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFB0501502, in part by the
   China Postdoctoral Science Foundation under Grant 2018M640087 and Grant
   2019T120063, and in part by the Fundamental Research Funds for the
   Central Universities under Grant 2018NTST01.
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Cao G, 2016, EUR J REMOTE SENS, V49, P225, DOI 10.5721/EuJRS20164913
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Erbek FS, 2004, INT J REMOTE SENS, V25, P1733, DOI 10.1080/0143116031000150077
   Ferraris V, 2018, IEEE T GEOSCI REMOTE, V56, P1566, DOI 10.1109/TGRS.2017.2765348
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He H.J., 2016, P ADV NEUR INF PROC, P1235
   He PF, 2014, REMOTE SENS LETT, V5, P396, DOI 10.1080/2150704X.2014.912766
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Inglada J, 2007, ISPRS J PHOTOGRAMM, V62, P236, DOI 10.1016/j.isprsjprs.2007.05.011
   Isola P., 2016, P IEEE C COMP VIS PA
   Kampmann M, 2016, ASIAN TEST SYMPOSIUM, P1, DOI 10.1109/ATS.2016.20
   Katayama K, 2015, PHYSIOL REP, V3, DOI 10.14814/phy2.12421
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Maggiori E, 2016, INT GEOSCI REMOTE SE, P5071, DOI 10.1109/IGARSS.2016.7730322
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Romero A, 2016, IEEE T GEOSCI REMOTE, V54, P1349, DOI 10.1109/TGRS.2015.2478379
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   Shi Q, 2018, IEEE ACCESS, V6, P25486, DOI 10.1109/ACCESS.2017.2773142
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang LF, 2018, IEEE T CYBERNETICS, V48, P16, DOI 10.1109/TCYB.2016.2605044
   Zhao WZ, 2017, IEEE J-STARS, V10, P3386, DOI 10.1109/JSTARS.2017.2680324
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
NR 43
TC 6
Z9 6
U1 10
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD APR
PY 2020
VL 58
IS 4
BP 2720
EP 2731
DI 10.1109/TGRS.2019.2953879
PG 12
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA LV9FL
UT WOS:000538748900035
OA Green Accepted
DA 2022-01-04
ER

PT J
AU Chen, HRX
   Wu, C
   Du, B
   Zhang, LP
   Wang, L
AF Chen, Hongruixuan
   Wu, Chen
   Du, Bo
   Zhang, Liangpei
   Wang, Le
TI Change Detection in Multisource VHR Images via Deep Siamese
   Convolutional Multiple-Layers Recurrent Neural Network
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection (CD); deep siamese convolutional multiple-layers
   recurrent neural network; deep siamese convolutional neural network
   (DSCNN); heterogeneous images; long-short term memory (LSTM);
   multiple-layers recurrent neural network (MRNN); very-high-resolution
   (VHR) images
ID CHANGE VECTOR ANALYSIS; SLOW FEATURE ANALYSIS; MAD
AB With the rapid development of Earth observation technology, very-high-resolution (VHR) images from various satellite sensors are more available, which greatly enrich the data source of change detection (CD). Multisource multitemporal images can provide abundant information on observed landscapes with various physical and material views, and it is exigent to develop efficient techniques to utilize these multisource data for CD. In this article, we propose a novel and general deep siamese convolutional multiple-layers recurrent neural network (RNN) (SiamCRNN) for CD in multitemporal VHR images. Superior to most VHR image CD methods, SiamCRNN can be used for both homogeneous and heterogeneous images. Integrating the merits of both convolutional neural network (CNN) and RNN, SiamCRNN consists of three subnetworks: deep siamese convolutional neural network (DSCNN), multiple-layers RNN (MRNN), and fully connected (FC) layers. The DSCNN has a flexible structure for multisource image and is able to extract spatial-spectral features from homogeneous or heterogeneous VHR image patches. The MRNN stacked by long-short term memory (LSTM) units is responsible for mapping the spatial-spectral features extracted by DSCNN into a new latent feature space and mining the change information between them. In addition, FC, the last part of SiamCRNN, is adopted to predict change probability. The experimental results in two homogeneous data sets and one challenging heterogeneous VHR images data set demonstrate that the promising performances of the proposed network outperform several state-of-the-art approaches.
C1 [Chen, Hongruixuan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
   [Wu, Chen] Wuhan Univ, Sch Comp Sci, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
   [Du, Bo] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Remote Sensing Grp, Wuhan 430072, Peoples R China.
   [Wang, Le] Univ Buffalo State Univ New York, Dept Geog, Buffalo, NY 14261 USA.
RP Wu, C (corresponding author), Wuhan Univ, Sch Comp Sci, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
EM qschrx@whu.edu.cn; chen.wu@whu.edu.cn; gunspace@163.com;
   zlp62@whu.edu.cn; lewang@buffalo.edu
OI Wu, Chen/0000-0001-6461-8377; Chen, Hongruixuan/0000-0003-0100-4786
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61971317, 41801285, 61822113, 41871243]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61971317, 41801285, 61822113, and
   41871243.
CR Andrew G., 2013, P 30 INT C MACH LEAR, P2284
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Huang X, 2017, IEEE J-STARS, V10, P654, DOI 10.1109/JSTARS.2016.2587324
   Kingma D., 2014, 14126980 ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Luo H., 2018, REMOTE SENS, V10, P20
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tang YQ, 2013, IEEE GEOSCI REMOTE S, V10, P1060, DOI 10.1109/LGRS.2012.2228626
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Wang S, 2015, INT CONF MACH LEARN, P883, DOI 10.1109/ICMLC.2015.7340670
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Yang H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111768
   Zelinski ME, 2014, IEEE J-STARS, V7, P3453, DOI 10.1109/JSTARS.2013.2294322
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang LP, 2014, IEEE T GEOSCI REMOTE, V52, P6141, DOI 10.1109/TGRS.2013.2295263
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 41
TC 45
Z9 48
U1 28
U2 85
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD APR
PY 2020
VL 58
IS 4
BP 2848
EP 2864
DI 10.1109/TGRS.2019.2956756
PG 17
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA LV9FL
UT WOS:000538748900045
DA 2022-01-04
ER

PT J
AU Song, A
   Kim, Y
AF Song, Ahram
   Kim, Yongil
TI Transfer Change Rules from Recurrent Fully Convolutional Networks for
   Hyperspectral Unmanned Aerial Vehicle Images without Ground Truth Data
SO REMOTE SENSING
LA English
DT Article
DE change detection; hyperspectral unmanned aerial vehicle; spectral
   similarity measures
ID UNSUPERVISED CHANGE DETECTION; SPECTRAL SIMILARITY; DISCRIMINATION
AB Change detection (CD) networks based on supervised learning have been used in diverse CD tasks. However, such supervised CD networks require a large amount of data and only use information from current images. In addition, it is time consuming to manually acquire the ground truth data for newly obtained images. Here, we proposed a novel method for CD in case of a lack of training data in an area near by another one with the available ground truth data. The proposed method automatically entails generating training data and fine-tuning the CD network. To detect changes in target images without ground truth data, the difference images were generated using spectral similarity measure, and the training data were selected via fuzzy c-means clustering. Recurrent fully convolutional networks with multiscale three-dimensional filters were used to extract objects of various sizes from unmanned aerial vehicle (UAV) images. The CD network was pre-trained on labeled source domain data; then, the network was fine-tuned on target images using generated training data. Two further CD networks were trained with a combined weighted loss function. The training data in the target domain were iteratively updated using he prediction map of the CD network. Experiments on two hyperspectral UAV datasets confirmed that the proposed method is capable of transferring change rules and improving CD results based on training data extracted in an unsupervised way.
C1 [Song, Ahram; Kim, Yongil] Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
RP Kim, Y (corresponding author), Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
EM aram200@snu.ac.kr; yik@snu.ac.kr
OI song, ahram/0000-0002-9190-2848
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2019R1A6A3A0109230211,
   NRF-2019R1I1A2A01058144]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (NRF-2019R1A6A3A0109230211 and
   NRF-2019R1I1A2A01058144)
CR Acquarelli J, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071156
   Adao T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111110
   Adep R. N., 2016, PERSPECT SCI, V8, P722, DOI [10.1016/j.pisc.2016.06.070, DOI 10.1016/J.PISC.2016.06.070, DOI 10.1016/j.pisc.2016.06.070]
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Camacho A, 2019, INT J REMOTE SENS, V40, P7603, DOI 10.1080/01431161.2019.1595210
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Chang CI, 2000, IEEE T INFORM THEORY, V46, P1927, DOI 10.1109/18.857802
   Chen B, 2013, IEEE J-STARS, V6, P1376, DOI 10.1109/JSTARS.2013.2254702
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Dellinger F, 2014, INT GEOSCI REMOTE SE, P1281, DOI 10.1109/IGARSS.2014.6946667
   Mai DS, 2015, IEEE INT FUZZY SYST
   Du YZ, 2004, OPT ENG, V43, P1777, DOI 10.1117/1.1766301
   Dunn JC, 1973, FUZZY RELATIVE ISODA, DOI [10.1080/01969727308546046, DOI 10.1080/01969727308546046]
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Jong K.L.D., UNSUPERVISED CHANGE
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   Kumar MN, 2011, INT J REMOTE SENS, V32, P4041, DOI 10.1080/01431161.2010.484431
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liu JF, 2020, IEEE GEOSCI REMOTE S, V17, P127, DOI 10.1109/LGRS.2019.2916601
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Padma S, 2014, INT J APPL EARTH OBS, V32, P138, DOI 10.1016/j.jag.2014.04.001
   Park S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030354
   Peng DF, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.024512
   Ramos Jeisson Fabián, 2018, Dyna rev.fac.nac.minas, V85, P117, DOI 10.15446/dyna.v85n204.68355
   ROBILA SA, 2005, P IEEE INT S SIGN CI, V1, P165
   Schultz M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111850
   Shanmugam S, 2014, INT J REMOTE SENS, V35, P8217, DOI 10.1080/01431161.2014.980922
   Song A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12050799
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Thomson AG, 1998, INT J REMOTE SENS, V19, P3423, DOI 10.1080/014311698214091
   Wang SM, 2018, RESOUR CONSERV RECY, V128, P526, DOI 10.1016/j.resconrec.2016.05.011
   Washaya P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071026
   Wulder MA, 2008, J SPAT SCI, V53, P49, DOI 10.1080/14498596.2008.9635135
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
NR 41
TC 4
Z9 4
U1 3
U2 6
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD APR
PY 2020
VL 12
IS 7
AR 1099
DI 10.3390/rs12071099
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA LU4EF
UT WOS:000537709600049
OA gold
DA 2022-01-04
ER

PT J
AU Kennedy, B
   Pouliot, D
   Manseau, M
   Fraser, R
   Duffe, J
   Pasher, J
   Chen, WJ
   Olthof, I
AF Kennedy, Blair
   Pouliot, Darren
   Manseau, Micheline
   Fraser, Robert
   Duffe, Jason
   Pasher, Jon
   Chen, Wenjun
   Olthof, Ian
TI Assessment of Landsat-based terricolous macrolichen cover retrieval and
   change analysis over caribou ranges in northern Canada and Alaska
SO REMOTE SENSING OF ENVIRONMENT
LA English
DT Article
DE Machine learning; Lichen; Landsat; North; Canada; Alaska
ID REFLECTANCE SPECTRA; LICHEN ABUNDANCE; VEGETATION; TUNDRA; HABITAT;
   SELECTION; RECOVERY; FOREST; FIRES
AB Terricolous macrolichens are an important food source for caribou (Rangifer tarandus) and can greatly influence their movement, distribution and demography over time. Mapping the spatial distribution and cover of macrolichens with remote sensing can serve as an important approach for assessing the impact of disturbances (e.g. fire, grazing, trampling) on lichen cover at the landscape scale and for monitoring post-disturbance rates of recovery. Previous remote sensing-based efforts to retrieve the distribution and abundance of lichen have been restricted to particular regions and thus are not indicative of the potential for large extent mapping and monitoring. In this study, we assessed the effectiveness of machine learning methods for retrieving lichen cover and change across different regions in northern Canada and Alaska using Landsat-5 images, topographic and climate data. Global and regional-scale models were evaluated to assess whether regionally specific analyses would improve performance. Of the models tested, the deep neural network was the most accurate for predicting lichen cover (model efficiency (ME) = 0.58, mean absolute error (MAE) < 7%). For the regional analysis, the performance was the best in north-central Canada (ME = 0.56, MAE = 8%) and the worst in north-eastern Canada (ME = 0.22, MAE < 4%) due to lower lichen cover, more exposed ground, and reduced sample quality and distribution. Analysis of trend-based change detection from 1984 to 2011 in the three regional test areas showed the expected directional response with declining lichen cover in north-western Canada in response to climate-induced shrub expansion, slow recovery to wildfire in north-central Canada, and declining lichen cover in north-eastern Canada related to caribou foraging/trampling and shrub expansion.
C1 [Kennedy, Blair; Pouliot, Darren; Manseau, Micheline; Duffe, Jason; Pasher, Jon] Environm & Climate Change Canada, Landscape Sci & Technol Div, 1125 Colonel By Dr, Ottawa, ON K1A 0H3, Canada.
   [Fraser, Robert; Chen, Wenjun; Olthof, Ian] Nat Resources Canada, Canada Ctr Mapping & Earth Observat, 560 Rochester St, Ottawa, ON K1S 5K2, Canada.
RP Kennedy, B (corresponding author), Environm & Climate Change Canada, Landscape Sci & Technol Div, 1125 Colonel By Dr, Ottawa, ON K1A 0H3, Canada.
EM blair.kennedy3@canada.ca
FU Canadian Space AgencyCanadian Space Agency
FX This research was supported through a Canadian Space Agency grant for
   the project "Integrated Earth Observation Monitoring for Essential
   Ecosystem Information: Resilience to Ecosystem Stress and Climate
   Change". The authors also wish to acknowledge the organizations and
   individuals that provided data to support this research. Finally, the
   authors would like to thank the anonymous reviewers for their in depth
   and insightful comments on this research.
CR Allard M., 2012, NUNAVIK NUNATSIAVUT
   Bland J., 2011, BMJ-BRIT MED J, V2011, P342
   Bojesen M, 2018, ArcticDEM, Harvard Dataverse, DOI [10.7910/DVN/OHHUKH, DOI 10.7910/DVN/OHHUKH]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Brook RK, 2002, INT J REMOTE SENS, V23, P4761, DOI 10.1080/01431160110113917
   Campeau AB, 2019, POLAR BIOL, V42, P1005, DOI 10.1007/s00300-019-02492-6
   Canadian Forest Service, 2019, CAN NAT FIR DAT AG F
   Chapin FS, 2005, SCIENCE, V310, P657, DOI 10.1126/science.1117368
   Chen WenJun, 2017, Journal of Environmental Protection, V8, P258, DOI 10.4236/jep.2017.83020
   Colpaert A, 2003, ARCTIC, V56, P147
   COSEWIC, 2016, COSEWIC ASS STAT REP
   COSEWIC, 2017, ASS STAT REP CAR RAN
   Crete M., 1996, EVOL ECOL, V9, P1
   Dahlberg A, 2013, ARCTIC BIODIVERSITY, P354
   Epstein HE, 2008, J GEOPHYS RES-BIOGEO, V113, DOI 10.1029/2007JG000555
   Falldorf T, 2014, REMOTE SENS ENVIRON, V140, P573, DOI 10.1016/j.rse.2013.09.027
   Fauchald P, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1601365
   Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086
   Fraser RH, 2016, ARCT SCI, V2, P79, DOI 10.1139/as-2016-0008
   Fraser RH, 2014, REMOTE SENS-BASEL, V6, P11533, DOI 10.3390/rs61111533
   Fraser RH, 2014, ECOSYSTEMS, V17, P1151, DOI 10.1007/s10021-014-9783-3
   Gilichinsky M, 2011, INT J REMOTE SENS, V32, P455, DOI 10.1080/01431160903474962
   Goodwin NR, 2008, REMOTE SENS ENVIRON, V112, P3680, DOI 10.1016/j.rse.2008.05.005
   Gould WA, 2003, J GEOPHYS RES-ATMOS, V108, DOI 10.1029/2001JD000948
   Granlund L, 2018, REMOTE SENS ENVIRON, V216, P301, DOI 10.1016/j.rse.2018.06.041
   Heggenes Jan, 2018, Rangifer, V38, P1, DOI 10.7557/2.38.1.4121
   Heggenes J, 2017, ECOL EVOL, V7, P6423, DOI 10.1002/ece3.3130
   Hu FS, 2015, FRONT ECOL ENVIRON, V13, P369, DOI 10.1890/150063
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jandt R, 2008, ARCT ANTARCT ALP RES, V40, P89, DOI 10.1657/1523-0430(06-122)[JANDT]2.0.CO;2
   Joly K, 2003, CAN J ZOOL, V81, P1192, DOI 10.1139/Z03-109
   Joly Kyle, 2018, Rangifer, V38, P27, DOI 10.7557/2.38.1.4107
   Joly K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127586
   Joly K, 2010, ECOSCIENCE, V17, P321, DOI 10.2980/17-3-3337
   Joly K, 2009, POLAR RES-SWEDEN, V28, P433, DOI 10.1111/j.1751-8369.2009.00113.x
   Ju JC, 2016, REMOTE SENS ENVIRON, V176, P1, DOI 10.1016/j.rse.2016.01.001
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   KASISCHKE ES, 2006, ALASKAS CHANGING BOR, P285
   Kendall M. G., 1975, RANK CORRELATION MET
   Key C., 1999, NORMALIZED BURN RATI
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LLANO G. A., 1956, ECON BOT, V10, P367, DOI 10.1007/BF02859767
   Macander M.J., 2018, LICHEN COVER MAPPING
   Macander M.J., 2017, REMOTE SENS, V9, P4
   Manseau M, 1996, J ECOL, V84, P503, DOI 10.2307/2261473
   MAYER DG, 1993, ECOL MODEL, V68, P21, DOI 10.1016/0304-3800(93)90105-2
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Moffat ND, 2016, ARCT ANTARCT ALP RES, V48, P581, DOI 10.1657/AAAR0015-063
   MORNEAU C, 1989, CAN J BOT, V67, P2770, DOI 10.1139/b89-357
   Myneni RB, 1997, NATURE, V386, P698, DOI 10.1038/386698a0
   Nash J.E., 1970, J HYDROL, V10, P282, DOI DOI 10.1016/0022-1694(70)90255-6
   Nelson PR, 2013, REMOTE SENS ENVIRON, V137, P43, DOI 10.1016/j.rse.2013.05.026
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP
   Nordberg ML, 2002, CAN J REMOTE SENS, V28, P262, DOI 10.5589/m02-026
   Nordberg ML, 1998, 27TH INTERNATIONAL SYMPOSIUM ON REMOTE SENSING OF ENVIRONMENT, PROCEEDINGS, P431
   Parlee BL, 2018, SCI ADV, V4, DOI 10.1126/sciadv.1701611
   PETZOLD DE, 1988, REMOTE SENS ENVIRON, V24, P481, DOI 10.1016/0034-4257(88)90020-X
   Pouliot D, 2009, INT J REMOTE SENS, V30, P149, DOI 10.1080/01431160802302090
   Pouliot D, 2011, REMOTE SENS ENVIRON, V115, P158, DOI 10.1016/j.rse.2010.08.014
   Qiu S, 2019, REMOTE SENS ENVIRON, V231, DOI 10.1016/j.rse.2019.05.024
   Rees WG, 2004, REMOTE SENS ENVIRON, V90, P281, DOI 10.1016/j.rse.2003.12.009
   Rickbeil G.J.M., 2017, PLOS ONE, V12, P1
   Riggs G., 2015, VIIRS SNOW COVER ALG
   Rouse J.W.J., 1973, P 3 EARTH RESOUR TEC, V1, P309, DOI DOI 10.1002/MRM.26868
   Ruder, 2016, ARXIV160904747
   Saulquin B, 2013, J GEOPHYS RES-OCEANS, V118, P3752, DOI 10.1002/jgrc.20264
   Scikit-learn, 2018, 1 11 ENS METH
   SEN PK, 1968, J AM STAT ASSOC, V63, P1379
   Skatter H. G., 2014, CANADIAN WILDLIFE BI, V3, P1
   Sun LX, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9100972
   Theau J, 2004, CAN J REMOTE SENS, V30, P867, DOI 10.5589/m04-047
   Theau J, 2005, REMOTE SENS ENVIRON, V94, P232, DOI 10.1016/j.rse.2004.10.008
   Theau Jerome, 2004, Rangifer, V24, P31
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tommervik H, 2003, REMOTE SENS ENVIRON, V85, P370, DOI 10.1016/S0034-4257(03)00014-2
   Tremblay B, 2012, ENVIRON RES LETT, V7, DOI 10.1088/1748-9326/7/3/035501
   Tsuyuzaki S, 2018, POLAR BIOL, V41, P753, DOI 10.1007/s00300-017-2236-7
   Virtanen T, 2002, ENVIRON POLLUT, V120, P647, DOI 10.1016/S0269-7491(02)00186-0
   Vors LS, 2009, GLOBAL CHANGE BIOL, V15, P2626, DOI 10.1111/j.1365-2486.2009.01974.x
NR 79
TC 7
Z9 7
U1 2
U2 11
PU ELSEVIER SCIENCE INC
PI NEW YORK
PA STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA
SN 0034-4257
EI 1879-0704
J9 REMOTE SENS ENVIRON
JI Remote Sens. Environ.
PD APR
PY 2020
VL 240
AR 111694
DI 10.1016/j.rse.2020.111694
PG 14
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA LA4YZ
UT WOS:000523955300009
OA hybrid
DA 2022-01-04
ER

PT J
AU Song, A
   Choi, J
AF Song, Ahram
   Choi, Jaewan
TI Fully Convolutional Networks with Multiscale 3D Filters and Transfer
   Learning for Change Detection in High Spatial Resolution Satellite
   Images
SO REMOTE SENSING
LA English
DT Article
DE multiscale three-dimensional filters; transfer learning; change
   detection; high spatial resolution satellite image; fully convolutional
   network; convolutional long short-term memory
ID CNN; ACCURACY
AB Remote sensing images having high spatial resolution are acquired, and large amounts of data are extracted from their region of interest. For processing these images, objects of various sizes, from very small neighborhoods to large regions composed of thousands of pixels, should be considered. To this end, this study proposes change detection method using transfer learning and recurrent fully convolutional networks with multiscale three-dimensional (3D) filters. The initial convolutional layer of the change detection network with multiscale 3D filters was designed to extract spatial and spectral features of materials having different sizes; the layer exploits pre-trained weights and biases of semantic segmentation network trained on an open benchmark dataset. The 3D filter sizes were defined in a specialized way to extract spatial and spectral information, and the optimal size of the filter was determined using highly accurate semantic segmentation results. To demonstrate the effectiveness of the proposed method, binary change detection was performed on images obtained from multi-temporal Korea multipurpose satellite-3A. Results revealed that the proposed method outperformed the traditional deep learning-based change detection methods and the change detection accuracy improved using multiscale 3D filters and transfer learning.
C1 [Song, Ahram] Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Choi, Jaewan] Chungbuk Natl Univ, Sch Civil Engn, 1 Chungdae Ro, Cheongju 28644, Chungbuk, South Korea.
RP Choi, J (corresponding author), Chungbuk Natl Univ, Sch Civil Engn, 1 Chungdae Ro, Cheongju 28644, Chungbuk, South Korea.
EM aram200@snu.ac.kr; jaewanchoi@chungbuk.ac.kr
OI song, ahram/0000-0002-9190-2848
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2019R1A6A3A0109230211];
   Satellite Information Utilization Center Establishment Program of the
   Ministry of Land, Infrastructure, and Transport of Korean government
   [20SIUE-B148326-03]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2019R1A6A3A0109230211) and by the Satellite
   Information Utilization Center Establishment Program of the Ministry of
   Land, Infrastructure, and Transport of Korean government, grant number
   20SIUE-B148326-03.
CR Acharya TD, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6110371
   Aguirre-Gutierrez J, 2012, APPL GEOGR, V34, P29, DOI 10.1016/j.apgeog.2011.10.010
   Bindschadler RA, 2010, REMOTE SENS ENVIRON, V114, P1353, DOI 10.1016/j.rse.2010.01.014
   Brisco B, 2013, INT J DIGIT EARTH, V6, P103, DOI 10.1080/17538947.2011.608813
   Chen HRX, 2020, IEEE T GEOSCI REMOTE, V58, P2848, DOI 10.1109/TGRS.2019.2956756
   Choi J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9100976
   Dellinger F, 2014, INT GEOSCI REMOTE SE, P1281, DOI 10.1109/IGARSS.2014.6946667
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Deng JS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101230
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Geng J, 2017, INT GEOSCI REMOTE SE, P612, DOI 10.1109/IGARSS.2017.8127028
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong ZQ, 2019, IEEE T GEOSCI REMOTE, V57, P3599, DOI 10.1109/TGRS.2018.2886022
   Guirado E, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121220
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Ji CY, 2001, INT J REMOTE SENS, V22, P1441, DOI 10.1080/01431160117207
   Khanal N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11192296
   Kong YL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030452
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li Y, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1264
   Liang J, 2019, J NONLINEAR FUNCT AN, DOI 10.23952/jnfa.2019.18
   Liang MM, 2018, IEEE J-STARS, V11, P2911, DOI 10.1109/JSTARS.2018.2836671
   Liao WX, 2019, 2019 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P157, DOI 10.1109/HPBDIS.2019.8735457
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Malila W.A, 1980, P LARS S, P385
   MANAVALAN P, 1995, INT J REMOTE SENS, V16, P633, DOI 10.1080/01431169508954430
   Moller M, 2007, INT J APPL EARTH OBS, V9, P311, DOI 10.1016/j.jag.2006.10.002
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Muro J, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100795
   Niemeyer I., 2008, OBJECT BASED IMAGE A, P185, DOI DOI 10.1007/978-3-540-77058-9_10
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Papadomanolaki M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060684
   Schultz M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111850
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A., 2019, THESIS
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Washaya P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071026
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Wulder MA, 2008, J SPAT SCI, V53, P49, DOI 10.1080/14498596.2008.9635135
   Xingjian S., 2015, ADV NEURAL INFORM PR, P802
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   정재준, 2005, [The Geographical Journal of Korea, 국토지리학회지], V39, P161
NR 48
TC 9
Z9 9
U1 10
U2 22
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2020
VL 12
IS 5
AR 799
DI 10.3390/rs12050799
PG 17
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA LL4XB
UT WOS:000531559300054
OA gold
DA 2022-01-04
ER

PT J
AU Adarme, MO
   Feitosa, RQ
   Happ, PN
   De Almeida, CA
   Gomes, AR
AF Adarme, Mabel Ortega
   Feitosa, Raul Queiroz
   Happ, Patrick Nigri
   De Almeida, Claudio Aparecido
   Gomes, Alessandra Rodrigues
TI Evaluation of Deep Learning Techniques for Deforestation Detection in
   the Brazilian Amazon and Cerrado Biomes From Remote Sensing Imagery
SO REMOTE SENSING
LA English
DT Article
DE deforestation detection; Brazilian biomes; deep learning; optical
   imagery
ID LAND-USE; CARBON EMISSIONS
AB Deforestation is one of the major threats to natural ecosystems. This process has a substantial contribution to climate change and biodiversity reduction. Therefore, the monitoring and early detection of deforestation is an essential process for preservation. Techniques based on satellite images are among the most attractive options for this application. However, many approaches involve some human intervention or are dependent on a manually selected threshold to identify regions that suffer deforestation. Motivated by this scenario, the present work evaluates Deep Learning-based strategies for automatic deforestation detection, namely, Early Fusion (EF), Siamese Network (SN), and Convolutional Support Vector Machine (CSVM) as well as Support Vector Machine (SVM), used as the baseline. The target areas are two regions with different deforestation patterns: the Amazon and Cerrado biomes in Brazil. The experiments used two co-registered Landsat 8 images acquired at different dates. The strategies based on Deep Learning achieved the best performance in our analysis in comparison with the baseline, with SN and EF superior to CSVM and SVM. In the same way, a reduction of the salt-and-pepper effect in the generated probabilistic change maps was noticed as the number of training samples increased. Finally, the work assesses how the methods can reduce the time invested in the visual inspection of deforested areas.
C1 [Adarme, Mabel Ortega; Feitosa, Raul Queiroz; Happ, Patrick Nigri] Pontificia Catolica Univ Rio de Janeiro, Dept Elect Engn, BR-22451900 Rio De Janeiro, Brazil.
   [De Almeida, Claudio Aparecido; Gomes, Alessandra Rodrigues] Natl Inst Space Res INPE, BR-12227010 Sao Jose Dos Campos, SP, Brazil.
RP Adarme, MO (corresponding author), Pontificia Catolica Univ Rio de Janeiro, Dept Elect Engn, BR-22451900 Rio De Janeiro, Brazil.
EM mortega@ele.puc-rio.br; raul@ele.puc-rio.br; patrick@ele.puc-rio.br;
   claudio.almeida@inpe.br; alessandra.gomes@inpe.br
RI Feitosa, Raul Queiroz/D-6570-2017
OI Feitosa, Raul Queiroz/0000-0001-8344-5096; Ortega Adarme,
   Mabel/0000-0002-4106-0291; Almeida, Claudio/0000-0002-1032-6966; Nigri
   Happ, Patrick/0000-0003-3280-5471
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq)Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPQ); Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES)Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES)
FX This research was supported by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq), by Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES).
CR Aide TM, 2013, BIOTROPICA, V45, P262, DOI 10.1111/j.1744-7429.2012.00908.x
   Amin A, 2019, J ENVIRON ECON MANAG, V93, P272, DOI 10.1016/j.jeem.2018.11.006
   Picoli MCA, 2018, ISPRS J PHOTOGRAMM, V145, P328, DOI 10.1016/j.isprsjprs.2018.08.007
   Assis LFFG, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8110513
   Barreto P, 2006, HUMAN PRESSURE BRAZI
   Bazi Y, 2018, IEEE T GEOSCI REMOTE, V56, P3107, DOI 10.1109/TGRS.2018.2790926
   Beuchle R, 2015, APPL GEOGR, V58, P116, DOI 10.1016/j.apgeog.2015.01.017
   Bonanomi J, 2019, PERSPECT ECOL CONSER, V17, P26, DOI 10.1016/j.pecon.2018.12.002
   Bueno IT, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050570
   Casseb A.R., 2012, REV PAN AMAZ SAUDE, V3, P43, DOI DOI 10.5123/S2176-62232012000400005
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   de Almeida CA, 2016, ACTA AMAZON, V46, P291, DOI 10.1590/1809-4392201505504
   De Sy V, 2015, ENVIRON RES LETT, V10, DOI 10.1088/1748-9326/10/12/124004
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Goodman RC, 2019, FOREST ECOL MANAG, V439, P18, DOI 10.1016/j.foreco.2019.02.037
   Gunn, 1998, ISIS TECH REP, V14, P5
   Howarth P, 1981, INT J REMOTE SENS, V2, P277, DOI DOI 10.1080/01431168108948362
   IBGE-Instituto Brasileiro de Geografia e Estatistica, 2004, MAP BIOM VEG
   Kintisch E, 2007, SCIENCE, V316, P536, DOI 10.1126/science.316.5824.536
   Kranjcic N, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060655
   Kumar D., 2019, INT J ELECT COMPUT E, V9, P1720, DOI [10.11591/ijece.v9i3, DOI 10.11591/IJECE.V9I3.PP1720-1731]
   Lovett GM, 2007, FRONT ECOL ENVIRON, V5, P253, DOI 10.1890/1540-9295(2007)5[253:WNEM]2.0.CO;2
   LUDEKE AK, 1990, J ENVIRON MANAGE, V31, P247, DOI 10.1016/S0301-4797(05)80038-6
   MacDicken K., 2015, GLOBAL FOREST RESOUR
   Machado R.B., 2004, ESTIMATIVAS PERDA AR, P1
   Malingreau JP, 2012, AMBIO, V41, P309, DOI 10.1007/s13280-011-0196-7
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   MMA & IBAMA, 2011, MON DESM NOS BIOM BR
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nackaerts K, 2005, INT J REMOTE SENS, V26, P839, DOI 10.1080/0143116032000160462
   National Institute for Space Research (INPE), 1988, MON BRAZ AM FOR SAT
   National Institute for Space Research (INPE), 1982, DET RES LAND US DEV
   National Institute for Space Research (INPE), MET UT NOS PROJ PROD
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Sano EE, 2008, PESQUI AGROPECU BRAS, V43, P153, DOI 10.1590/S0100-204X2008000100020
   Sathler D, 2018, ECOL SOC, V23, DOI [10.5751/ES-10062-230230, 10.5751/es-10062-230230]
   Sestini A, 2018, METODOLOGIA DETECCAO
   Shimabukuro Y., 2007, REVISTAAMBI AGUA, V1, P37, DOI DOI 10.4136/ambi-agua.4
   Song XL, 2011, PROCEDIA ENVIRON SCI, V11, P238, DOI 10.1016/j.proenv.2011.12.037
   Soterroni AC, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav7336
   Souza C., 2017, MAPBIOMAS GEN HDB, P1
   Steinweg T., 2018, CARGILL ZERO DEFORES, P1
   Valeriano D.M., 2004, INT ARCH PHOTOGRAMM, P272
   World Wildlife Fund (WWF), 1988, AM DEF
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang Z., 2018, ARXIV180709562
NR 50
TC 12
Z9 12
U1 9
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2020
VL 12
IS 6
AR 910
DI 10.3390/rs12060910
PG 28
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA LE6FX
UT WOS:000526820600012
OA gold
DA 2022-01-04
ER

PT J
AU de Bem, PP
   de Carvalho, OA
   Guimaraes, RF
   Gomes, RAT
AF de Bem, Pablo Pozzobon
   de Carvalho Junior, Osmar Abilio
   Guimaraes, Renato Fontes
   Trancoso Gomes, Roberto Arnaldo
TI Change Detection of Deforestation in the Brazilian Amazon Using Landsat
   Data and Convolutional Neural Networks
SO REMOTE SENSING
LA English
DT Article
DE deep learning; CNN; classification; change detection; deforestation
ID SUPPORT VECTOR MACHINE; FOREST FRAGMENTATION; PROTECTED AREAS; COVER;
   DYNAMICS; ALGORITHMS; HIGHWAY; IMAGES; CLASSIFICATION; SPACE
AB Mapping deforestation is an essential step in the process of managing tropical rainforests. It lets us understand and monitor both legal and illegal deforestation and its implications, which include the effect deforestation may have on climate change through greenhouse gas emissions. Given that there is ample room for improvements when it comes to mapping deforestation using satellite imagery, in this study, we aimed to test and evaluate the use of algorithms belonging to the growing field of deep learning (DL), particularly convolutional neural networks (CNNs), to this end. Although studies have been using DL algorithms for a variety of remote sensing tasks for the past few years, they are still relatively unexplored for deforestation mapping. We attempted to map the deforestation between images approximately one year apart, specifically between 2017 and 2018 and between 2018 and 2019. Three CNN architectures that are available in the literature-SharpMask, U-Net, and ResUnet-were used to classify the change between years and were then compared to two classic machine learning (ML) algorithms-random forest (RF) and multilayer perceptron (MLP)-as points of reference. After validation, we found that the DL models were better in most performance metrics including the Kappa index, F1 score, and mean intersection over union (mIoU) measure, while the ResUnet model achieved the best overall results with a value of 0.94 in all three measures in both time sequences. Visually, the DL models also provided classifications with better defined deforestation patches and did not need any sort of post-processing to remove noise, unlike the ML models, which needed some noise removal to improve results.
C1 [de Bem, Pablo Pozzobon; de Carvalho Junior, Osmar Abilio; Guimaraes, Renato Fontes; Trancoso Gomes, Roberto Arnaldo] Univ Brasilia, Dept Geog, Campus Univ Darcy Ribeiro, BR-70910900 Brasilia, DF, Brazil.
RP de Carvalho, OA (corresponding author), Univ Brasilia, Dept Geog, Campus Univ Darcy Ribeiro, BR-70910900 Brasilia, DF, Brazil.
EM pablo.bem@aluno.unb.br; osmarjr@unb.br; renatofg@unb.br;
   robertogomes@unb.br
RI De+Carvalho+Junior, Osmar/AAK-4880-2021; de, Pablo/AAW-5619-2020; Gomes,
   Roberto Arnaldo Trancoso/F-5843-2014; Guimaraes, Renato/C-4601-2013
OI De+Carvalho+Junior, Osmar/0000-0002-0346-1684; de,
   Pablo/0000-0003-3868-8704; Guimaraes, Renato/0000-0002-9555-043X
FU National Council for Scientific and Technological DevelopmentConselho
   Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)
   [434838/2018-7]; Coordination for the Improvement of Higher Education
   PersonnelCoordenacao de Aperfeicoamento de Pessoal de Nivel Superior
   (CAPES); Union Heritage Secretariat of the Ministry of Economy
FX This research was funded by the following institutions: National Council
   for Scientific and Technological Development (434838/2018-7),
   Coordination for the Improvement of Higher Education Personnel and the
   Union Heritage Secretariat of the Ministry of Economy.
CR Abadi M., 2016, ARXIV160304467
   Ajami A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111282
   Alves DS, 2002, INT J REMOTE SENS, V23, P2903, DOI 10.1080/01431160110096791
   Aragao LEOC, 2014, BIOL REV, V89, P913, DOI 10.1111/brv.12088
   Arima EY, 2008, PHOTOGRAMM ENG REM S, V74, P699, DOI 10.14358/PERS.74.6.699
   Arima EY, 2016, J LAND USE SCI, V11, P257, DOI 10.1080/1747423X.2015.1027797
   Arima EY, 2005, ANN ASSOC AM GEOGR, V95, P525, DOI 10.1111/j.1467-8306.2005.00473.x
   Asner GP, 2006, P NATL ACAD SCI USA, V103, P12947, DOI 10.1073/pnas.0604093103
   Barber CP, 2014, BIOL CONSERV, V177, P203, DOI 10.1016/j.biocon.2014.07.004
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Boisier JP, 2015, NAT CLIM CHANGE, V5, P656, DOI [10.1038/nclimate2658, 10.1038/NCLIMATE2658]
   Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Cabral AIR, 2018, APPL GEOGR, V100, P101, DOI 10.1016/j.apgeog.2018.10.003
   Cao C, 2019, ENVIRONMENTS, V6, DOI 10.3390/environments6020025
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Carranza-Garcia M, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030274
   CARRERO GC, 2011, ECOL SOC, V16, pNI385
   CHEN F, 2018, REMOTE SENS-BASEL, V10, DOI DOI 10.3390/rs10030443
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt R.C., 2018, ARXIV181008452V1
   Fearnside PM, 2015, HANDBOOK OF ROAD ECOLOGY, P414
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Ghorbanzadeh O, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020196
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Godar J, 2012, FOREST ECOL MANAG, V267, P58, DOI 10.1016/j.foreco.2011.11.046
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Guo E., 2018, ARXIV181009111
   Hecheltjen A, 2014, REMOTE SENS DIGIT IM, V18, P145, DOI 10.1007/978-94-007-7969-3_10
   Helber P, 2019, IEEE J-STARS, V12, P2217, DOI 10.1109/JSTARS.2019.2918242
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hughes LH, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101552
   Kang M, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080860
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kingma D., 2014, 14126980 ARXIV
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Le Quere C, 2018, EARTH SYST SCI DATA, V10, P2141, DOI 10.5194/essd-10-2141-2018
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li GY, 2019, GISCI REMOTE SENS, V56, P161, DOI 10.1080/15481603.2018.1497438
   Li L, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091350
   Li MY, 2020, J APPL REMOTE SENS, V14, DOI 10.1117/1.JRS.14.016501
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu CC, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020119
   Liu RY, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232844
   Liu T, 2018, GISCI REMOTE SENS, V55, P243, DOI 10.1080/15481603.2018.1426091
   Liu XY, 2020, INFORM FUSION, V55, P1, DOI 10.1016/j.inffus.2019.07.010
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Ma WP, 2019, IEEE T GEOSCI REMOTE, V57, P4834, DOI 10.1109/TGRS.2019.2893310
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mahmon NA, 2014, 2014 IEEE 5TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P153, DOI 10.1109/ICSGRC.2014.6908713
   Malambo L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11242939
   Mboga N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111106
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Merkle N, 2018, IEEE J-STARS, V11, P1811, DOI 10.1109/JSTARS.2018.2803212
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Muller H, 2016, INT J APPL EARTH OBS, V44, P61, DOI 10.1016/j.jag.2015.07.005
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Ortega M, 2019, CRIT PHILOS RACE, V7, P124
   Pearson TRH, 2017, CARBON BAL MANAGE, V12, DOI 10.1186/s13021-017-0072-2
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Pfaff A, 2007, J REGIONAL SCI, V47, P109, DOI 10.1111/j.1467-9787.2007.00502.x
   Pinheiro P. O., 2016, ARXIV160308695
   Qian XL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010143
   Quantum GIS Geographic Information System, QUANT GIS GEOGR INF
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rakshit S., 2018, ARXIV180900340
   Rosa IMD, 2016, CURR BIOL, V26, P2161, DOI 10.1016/j.cub.2016.06.013
   Scarpa G, 2018, IEEE T GEOSCI REMOTE, V56, P5443, DOI 10.1109/TGRS.2018.2817393
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Shimabukuro YE, 2019, INT J REMOTE SENS, V40, P5475, DOI 10.1080/01431161.2019.1579943
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Soares B, 2004, GLOBAL CHANGE BIOL, V10, P745, DOI 10.1111/j.1529-8817.2003.00769.x
   Spracklen DV, 2015, GEOPHYS RES LETT, V42, P9546, DOI 10.1002/2015GL066063
   Stehman SV, 2009, INT J REMOTE SENS, V30, P5243, DOI 10.1080/01431160903131000
   Stehman SV, 2005, REMOTE SENS ENVIRON, V96, P466, DOI 10.1016/j.rse.2005.04.002
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   USGS, LANDS COLL LANDS COL
   Vedovato LB, 2016, REG ENVIRON CHANGE, V16, P2485, DOI 10.1007/s10113-016-1067-3
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang S, 2018, ISPRS J PHOTOGRAMM, V145, P148, DOI 10.1016/j.isprsjprs.2017.12.012
   Warner T., 2009, SAGE HDB REMOTE SENS, P459
   Wei SS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010068
   Xiao XW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212506
   Xing HF, 2018, ISPRS J PHOTOGRAMM, V141, P237, DOI 10.1016/j.isprsjprs.2018.04.025
   Yu L, 2017, INT J COMPUT INTELL, V16, DOI 10.1142/S1469026817500018
   Yuan QQ, 2018, IEEE J-STARS, V11, P978, DOI 10.1109/JSTARS.2018.2794888
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang XK, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232787
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
   Zhuo XY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040624
NR 99
TC 22
Z9 23
U1 14
U2 24
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2020
VL 12
IS 6
AR 901
DI 10.3390/rs12060901
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA LE6FX
UT WOS:000526820600003
OA gold
DA 2022-01-04
ER

PT J
AU Pereira-Pires, JE
   Aubard, V
   Ribeiro, RA
   Fonseca, JM
   Silva, JMN
   Mora, A
AF Pereira-Pires, Joao E.
   Aubard, Valentine
   Ribeiro, Rita A.
   Fonseca, Jose M.
   Silva, Joao M. N.
   Mora, Andre
TI Semi-Automatic Methodology for Fire Break Maintenance Operations
   Detection with Sentinel-2 Imagery and Artificial Neural Network
SO REMOTE SENSING
LA English
DT Article
DE remote sensing; fire break; object-based classification; change
   detection; wildfires; artificial neural networks; sentinel-2
ID LANDSAT TIME-SERIES; VEGETATION; CLASSIFICATION; GENERATION
AB The difficult job of fighting fires and the nearly impossible task to stop a wildfire without great casualties requires an imperative implementation of proactive strategies. These strategies must decrease the number of fires, the burnt area and create better conditions for the firefighting. In this line of action, the Portuguese Institute of Nature and Forest Conservation defined a fire break network (FBN), which helps controlling wildfires. However, these fire breaks are efficient only if they are correctly maintained, which should be ensured by the local authorities and requires verification from the national authorities. This is a fastidious task since they have a large network of thousands of hectares to monitor over a full year. With the increasing quality and frequency of the Earth Observation Satellite imagery with Sentinel-2 and the definition of the FBN, a semi-automatic remote sensing methodology is proposed in this article for the detection of maintenance operations in a fire break. The proposed methodology is based on a time-series analysis, an object-based classification and a change detection process. The change detection is ensured by an artificial neural network, with reflectance bands and spectral indices as features. Additionally, an analysis of several bands and spectral indices is presented to show the behaviour of the data during a full year and in the presence of a maintenance operation. The proposed methodology achieved a relative error lower than 4% and a recall higher than 75% on the detection of maintenance operations.
C1 [Pereira-Pires, Joao E.; Ribeiro, Rita A.; Fonseca, Jose M.; Mora, Andre] NOVA Univ Lisbon, Ctr Technol & Syst, UNINOVA, Sch Sci & Technol, P-2829516 Caparica, Portugal.
   [Aubard, Valentine; Silva, Joao M. N.] Univ Lisbon, Forest Res Ctr, Sch Agr, P-1349017 Lisbon, Portugal.
RP Pereira-Pires, JE (corresponding author), NOVA Univ Lisbon, Ctr Technol & Syst, UNINOVA, Sch Sci & Technol, P-2829516 Caparica, Portugal.
EM je.pires@campus.fct.unl.pt; vaubard@isa.ulisboa.pt; rar@uninova.pt;
   jmf@uninova.pt; joaosilva@isa.ulisboa.pt; atm@uninova.pt
RI Fonseca, Jose MMR/C-9497-2013; Pereira-Pires, Joao E./ABC-4145-2020;
   Varela, M.L.R./M-7580-2013; Mora, Andre/A-7912-2012; Silva,
   Joao/C-5673-2013; Ribeiro, Rita/A-5372-2012
OI Fonseca, Jose MMR/0000-0001-7173-7374; Pereira-Pires, Joao
   E./0000-0003-2957-6372; Varela, M.L.R./0000-0002-2299-1859; Mora,
   Andre/0000-0003-1354-4739; Aubard, Valentine/0000-0001-9786-5374; Silva,
   Joao/0000-0001-5201-9836; Ribeiro, Rita/0000-0002-3849-0151
FU Fundacao de Ciencias e Tecnologia (FCT) [PTDC/CCI-COM/30344/2017,
   PCIF/SSI/0102/2017, UID/EEA/00066/2019]; FCTPortuguese Foundation for
   Science and TechnologyEuropean Commission [UIDB/00239/2020]
FX This research was funded by Fundacao de Ciencias e Tecnologia (FCT)
   under the framework of projects FUELMON (PTDC/CCI-COM/30344/2017),
   foRESTER (PCIF/SSI/0102/2017) and PEST (UID/EEA/00066/2019). The Forest
   Research Centre is a research unit funded by FCT (UIDB/00239/2020).
CR [Anonymous], 2014, DPFVAP ICNF PRIMARY
   Barbero R, 2015, INT J WILDLAND FIRE, V24, P892, DOI 10.1071/WF15083
   Bowman DMJS, 2017, NAT ECOL EVOL, V1, DOI 10.1038/s41559-016-0058
   Casquilho J.P., 2015, INTRO STAT PHYS
   Cheng L, 2014, PHOTOGRAMM ENG REM S, V80, P839, DOI 10.14358/PERS.80.9.839
   Chowdhury EH, 2015, REMOTE SENS-BASEL, V7, P2431, DOI 10.3390/rs70302431
   Chuvieco E, 2019, REMOTE SENS ENVIRON, V225, P45, DOI 10.1016/j.rse.2019.02.013
   Clerc S., 2020, MPC TEAM S2 MP CL1C
   De Luca G, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101238
   Dechoz C, 2015, PROC SPIE, V9643, DOI 10.1117/12.2195046
   Dong Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11131623
   Guizar-Sicairos M, 2008, OPT LETT, V33, P156, DOI 10.1364/OL.33.000156
   Guo W, 2013, COMPUT ELECTRON AGR, V96, P58, DOI 10.1016/j.compag.2013.04.010
   Hamunyela E, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060515
   Hao YZ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030478
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V158, P220, DOI 10.1016/j.rse.2014.11.005
   Immitzer M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030166
   Johansen K, 2007, REMOTE SENS ENVIRON, V110, P29, DOI 10.1016/j.rse.2007.02.014
   Li XL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010148
   Mallinis G, 2008, ISPRS J PHOTOGRAMM, V63, P237, DOI 10.1016/j.isprsjprs.2007.08.007
   Mora A, 2017, INFORMATION, V8, DOI 10.3390/info8040147
   Perez AJ, 2000, COMPUT ELECTRON AGR, V25, P197, DOI 10.1016/S0168-1699(99)00068-X
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   San-Miguel-Ayanz J., 2019, FOREST FIRES EUROPE
   Schultz M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111850
   Schultz M, 2016, INT J APPL EARTH OBS, V52, P318, DOI 10.1016/j.jag.2016.06.020
   Temudo MP, 2012, J LAND USE SCI, V7, P425, DOI 10.1080/1747423X.2011.595834
   Tymstra C., 2020, PROGR DISASTER SCI, V5, DOI [10.1016/j.pdisas.2019.100045, DOI 10.1016/J.PDISAS.2019.100045]
   Wang WX, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.035006
   Xue JR, 2017, J SENSORS, V2017, DOI 10.1155/2017/1353691
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
NR 31
TC 5
Z9 5
U1 3
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2020
VL 12
IS 6
AR 909
DI 10.3390/rs12060909
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA LE6FX
UT WOS:000526820600011
OA Green Published, gold
DA 2022-01-04
ER

PT J
AU Hou, B
   Liu, QJ
   Wang, H
   Wang, YH
AF Hou, Bin
   Liu, Qingjie
   Wang, Heng
   Wang, Yunhong
TI From W-Net to CDGAN: Bitemporal Change Detection via Deep Learning
   Techniques
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; change detection generative adversarial network
   (CDGAN); convolutional neural network (CNN); remote sensing; W-Net
ID UNSUPERVISED CHANGE DETECTION; LAND-USE CHANGE; IMAGE; CLASSIFICATION
AB Traditional change detection methods usually follow the image differencing, change feature extraction, and classification framework, and their performance is limited by such simple image domain differencing and also the hand-crafted features. Recently, the success of deep convolutional neural networks (CNNs) has widely spread across the whole field of computer vision for their powerful representation abilities. Therefore, in this article, we address the remote sensing image change detection problem with deep learning techniques. We first propose an end-to-end dual-branch architecture, termed the W-Net, with each branch taking as input one of the two bitemporal images as in the traditional change detection models. In this way, CNN features with more powerful representative abilities can be obtained to boost the final detection performance. In addition, W-Net performs differencing in the feature domain rather than in the traditional image domain, which greatly alleviates loss of useful information for determining the changes. Furthermore, by reformulating change detection as an image translation problem, we apply the recently popular generative adversarial network (GAN) in which our W-Net serves as the generator, leading to a new GAN architecture for change detection which we call CDGAN. To train our networks and also facilitate future research, we construct a large scale data set by collecting images from Google Earth and provide carefully manually annotated ground truths. Experiments show that our proposed methods can provide fine-grained change detection results superior to the existing state-of-the-art baselines.
C1 [Hou, Bin; Liu, Qingjie; Wang, Heng; Wang, Yunhong] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Hou, Bin] Coordinat Ctr China, Natl Comp Network Emergency Response Tech Team, Beijing 100029, Peoples R China.
RP Liu, QJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM houbin@buaa.edu.cn; qingjie.liu@buaa.edu.cn; hengwang@buaa.edu.cn;
   yhwang@buaa.edu.cn
FU Natural Science Foundation of China (NSFC)National Natural Science
   Foundation of China (NSFC) [61601011, 41871283]
FX This work was supported by the Natural Science Foundation of China
   (NSFC) under Grant 61601011 and Grant 41871283.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Acosta A., 2017, P IEEE C COMP VIS PA, P4681
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2011, INT GEOSCI REMOTE SE, P233, DOI 10.1109/IGARSS.2011.6048935
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bruzzone L, 2000, INT J REMOTE SENS, V21, P3539, DOI 10.1080/014311600750037552
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen JY, 2013, INT J REMOTE SENS, V34, P2454, DOI 10.1080/01431161.2012.743691
   CHEN Q, 2016, REMOTE SENS-BASEL, V8, P549, DOI DOI 10.3390/rs8070549
   Chintala S., 2016, ARXIV151106434
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Fan YD, 2017, INT J DISAST RISK SC, V8, P471, DOI 10.1007/s13753-017-0143-8
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu W, 2017, MULTIMED TOOLS APPL, V76, P17719, DOI 10.1007/s11042-015-2960-3
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu Q, 2013, REMOTE SENS-BASEL, V5, P6026, DOI 10.3390/rs5116026
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kingma D., 2014, 14126980 ARXIV
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Liu XY, 2018, IEEE IMAGE PROC, P873, DOI 10.1109/ICIP.2018.8451049
   Liu XY, 2018, LECT NOTES COMPUT SC, V10704, P428, DOI 10.1007/978-3-319-73603-7_35
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Malila W. A., 1980, Sixth Annual Symposium on Machine Processing of Remotely Sensed Data and Soil Information Systems and Remote Sensing and Soil Survey, P326
   Mucher CA, 2000, INT J REMOTE SENS, V21, P1159, DOI 10.1080/014311600210128
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Robertson LD, 2011, INT J REMOTE SENS, V32, P1505, DOI 10.1080/01431160903571791
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Xiao JY, 2006, LANDSCAPE URBAN PLAN, V75, P69, DOI 10.1016/j.landurbplan.2004.12.005
   Xiong BL, 2012, IEEE GEOSCI REMOTE S, V9, P287, DOI 10.1109/LGRS.2011.2166149
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 57
TC 24
Z9 24
U1 11
U2 43
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAR
PY 2020
VL 58
IS 3
BP 1790
EP 1802
DI 10.1109/TGRS.2019.2948659
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA KU3GZ
UT WOS:000519598700020
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Venugopal, N
AF Venugopal, N.
TI Automatic Semantic Segmentation with DeepLab Dilated Learning Network
   for Change Detection in Remote Sensing Images
SO NEURAL PROCESSING LETTERS
LA English
DT Article
DE Deep neural network; Change detection; Synthetic aperture radar images;
   Convolutional neural network; Multi-temporal detection techniques
ID CLASSIFICATION; REPRESENTATION; MODEL
AB Automatic change detection is an interesting research area in remote sensing (RS) technology aims to detect the changes in synthetic aperture radar (SAR) and multi-temporal hyperspectral images acquired at different time intervals. This method identifies the differences between the images and accomplishes the classification result into changed and unchanged areas. However, the existing algorithms are degraded due to noises present in the RS images. The main aim of the proposed method is the automatic semantic segmentation based change detection that produces a final change between the two input images. This paper proposes a feature learning method named deep lab dilated convolutional neural network (DL-DCNN) for the detection of changes from the images. The proposed approach consists of three stages: (i) pre-processing, (ii) semantic segmentation based change detection and (iii) accuracy assessment. Initially, preprocessing is performed to correct the errors and to obtain detailed information from the scene. Then, map the changes between the two images with the help of a trained network. The DCNN network performs fine-tuning and determines the relationship between two images as changed and unchanged pixel areas. The experimental analysis conducted on various datasets and compared with several existing algorithms. The experimental analysis is performed in terms of F-score, percentage correct classification, kappa coefficient, and overall error rate measures to show a better performance measure than the other state-of-art approaches.
C1 [Venugopal, N.] PES Univ, Dept Elect & Elect Engn, Bengaluru 560085, Karnataka, India.
RP Venugopal, N (corresponding author), PES Univ, Dept Elect & Elect Engn, Bengaluru 560085, Karnataka, India.
EM venugopaln@pes.edu
CR Alqurashi A F, 2013, ADV REMOTE SENS, V2, P193, DOI DOI 10.4236/ARS.2013.22022
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Canty MJ, 2008, REMOTE SENS ENVIRON, V112, P1025, DOI 10.1016/j.rse.2007.07.013
   Celik T, 2010, SIGNAL PROCESS, V90, P1471, DOI 10.1016/j.sigpro.2009.10.018
   de Morsier F, 2013, IEEE T GEOSCI REMOTE, V51, P1939, DOI 10.1109/TGRS.2012.2236683
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Huang L, 2015, EEE INT C MULT EXP 2, V2015, P1, DOI DOI 10.1016/J.OBHDP.2015.07.001
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jia L, 2015, IEEE T GEOSCI REMOTE, V53, P3960, DOI 10.1109/TGRS.2015.2388495
   Jiao Y, 2018, INT J NEURAL SYST, V28, DOI 10.1142/S0129065717500393
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li N, 2014, IEEE J-STARS, V7, P3200, DOI 10.1109/JSTARS.2014.2345417
   Li P, 2018, IEEE T IND INFORM, V14, P790, DOI 10.1109/TII.2017.2739340
   Lin ML, 2013, IEEE T NEUR NET LEAR, V24, P647, DOI 10.1109/TNNLS.2012.2228231
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Maas A. L., 2013, P ICML, V30, P3
   Pham MT, 2016, IEEE T GEOSCI REMOTE, V54, P2020, DOI 10.1109/TGRS.2015.2493730
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Qi Zhixin, 2012, ADV GEOGRAPHIC INFOR, P107
   Shang R, 2018, SIGNAL PROCESS, V142, P375, DOI 10.1016/j.sigpro.2017.07.023
   Tian DY, 2018, INFORM SCIENCES, V467, P415, DOI 10.1016/j.ins.2018.08.015
   Vu VT, 2019, IEEE T GEOSCI REMOTE, V57, P473, DOI 10.1109/TGRS.2018.2856926
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Yang G, 2019, IEEE GEOSCI REMOTE S, V16, P826, DOI 10.1109/LGRS.2018.2879969
   Zhan YJ, 2017, IEEE GEOSCI REMOTE S, V14, P1785, DOI 10.1109/LGRS.2017.2735801
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang Y, 2019, PATTERN RECOGN, V88, P421, DOI 10.1016/j.patcog.2018.12.001
   Zhang Y, 2018, EXPERT SYST APPL, V96, P302, DOI 10.1016/j.eswa.2017.12.015
   Zhang YX, 2015, IEEE T GEOSCI REMOTE, V53, P1346, DOI 10.1109/TGRS.2014.2337883
   Zhou GX, 2016, IEEE T NEUR NET LEAR, V27, P2426, DOI 10.1109/TNNLS.2015.2487364
NR 45
TC 9
Z9 9
U1 10
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1370-4621
EI 1573-773X
J9 NEURAL PROCESS LETT
JI Neural Process. Lett.
PD JUN
PY 2020
VL 51
IS 3
SI SI
BP 2355
EP 2377
DI 10.1007/s11063-019-10174-x
EA FEB 2020
PG 23
WC Computer Science, Artificial Intelligence
SC Computer Science
GA LV2PH
UT WOS:000516067200001
DA 2022-01-04
ER

PT J
AU Jiang, HW
   Hu, XY
   Li, K
   Zhang, JM
   Gong, JQ
   Zhang, M
AF Jiang, Huiwei
   Hu, Xiangyun
   Li, Kun
   Zhang, Jinming
   Gong, Jinqi
   Zhang, Mi
TI PGA-SiamNet: Pyramid Feature-Based Attention-Guided Siamese Network for
   Remote Sensing Orthoimagery Building Change Detection
SO REMOTE SENSING
LA English
DT Article
DE building change detection; remote sensing orthoimagery; attention
   mechanism; Siamese convolutional neural network
ID IMAGE-ANALYSIS; SENSED IMAGES
AB In recent years, building change detection has made remarkable progress through using deep learning. The core problems of this technique are the need for additional data (e.g., Lidar or semantic labels) and the difficulty in extracting sufficient features. In this paper, we propose an end-to-end network, called the pyramid feature-based attention-guided Siamese network (PGA-SiamNet), to solve these problems. The network is trained to capture possible changes using a convolutional neural network in a pyramid. It emphasizes the importance of correlation among the input feature pairs by introducing a global co-attention mechanism. Furthermore, we effectively improved the long-range dependencies of the features by utilizing various attention mechanisms and then aggregating the features of the low-level and co-attention level; this helps to obtain richer object information. Finally, we evaluated our method with a publicly available dataset (WHU) building dataset and a new dataset (EV-CD) building dataset. The experiments demonstrate that the proposed method is effective for building change detection and outperforms the existing state-of-the-art methods on high-resolution remote sensing orthoimages in various metrics.
C1 [Jiang, Huiwei; Hu, Xiangyun; Li, Kun; Zhang, Jinming; Gong, Jinqi; Zhang, Mi] Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
   [Hu, Xiangyun] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
RP Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.; Hu, XY (corresponding author), Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM huiwei_jiang@whu.edu.cn; huxy@whu.edu.cn; petrick_lee@whu.edu.cn;
   nicnyzjm@whu.edu.cn; jinqigong@whu.edu.cn; mizhang@whu.edu.cn
OI Li, Kun/0000-0001-8501-3916
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41771363]; Guangzhou Science, Technology and
   Innovation Commission [201802030008]
FX This research was partially supported by National Natural Science
   Foundation of China, grant number 41771363; the research funding was
   from Guangzhou Science, Technology and Innovation Commission
   (201802030008).
CR Aleksandrowicz S, 2014, REMOTE SENS-BASEL, V6, P5976, DOI 10.3390/rs6075976
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Cao Y., 2019, IEEE ICC
   Champion N., 2007, INT ARCH PHOTOGRAMME, V36, P197
   Chen H., DEEP SIAMESE MULTISC
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen Y.-C., SHOW MATCH SEGMENT J
   Choy Christopher B, 2016, ADV NEURAL INFORM PR
   Cleve C, 2008, COMPUT ENVIRON URBAN, V32, P317, DOI 10.1016/j.compenvurbsys.2007.10.001
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dalal N., 2005, P IEEE C COMP VIS PA, P886, DOI DOI 10.1109/CVPR.2005.177
   Daudt R. Caye, 2019, P C COMP VIS PATT RE
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Fu J., 2018, ARXIV180902983, P3146
   Hu J., 2018, P NIPS
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SY, 2019, IEEE I CONF COMP VIS, P2010, DOI 10.1109/ICCV.2019.00210
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Huvanandana J, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BME-HUST), P18, DOI 10.1109/BME-HUST.2016.7782086
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Jong K.L.D., UNSUPERVISED CHANGE
   Kanazawa A., WARPNET WEAKLY SUPER
   Khan S.H., 2016, WEAKLY SUPERVISED CH
   Khan S.H., 2016, P 26 INT JOINT C ART
   Kingma D., 2014, 14126980 ARXIV
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Li H., PYRAMID ATTENTION NE
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Liu Y., BUILDING CHANGE DETE
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J, 2016, SPRINGER COMPLEX, P1, DOI 10.1007/978-3-662-47824-0
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ma JL, 2019, NONLINEAR DYNAM, V97, P2533, DOI [10.1007/s11071-019-05146-8, 10.1080/03610926.2019.1586938]
   Malpica JA, 2013, INT J REMOTE SENS, V34, P1652, DOI 10.1080/01431161.2012.725483
   Moo Yi K., 2017, P C COMP VIS PATT RE
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng DF, 2016, INT ARCH PHOTOGRAMM, V41, P669, DOI 10.5194/isprsarchives-XLI-B3-669-2016
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Remondino F, 2014, PHOTOGRAMM REC, V29, P144, DOI 10.1111/phor.12063
   Rocco I, 2018, ADV NEUR IN, V31
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sakurada K., WEAKLY SUPERVISED SI
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Tian J, 2016, ISPRS ANN PHOTO REM, V3, P149, DOI 10.5194/isprsannals-III-7-149-2016
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Varghese A., 2018, P EUR C COMP VIS ECC
   Wang F., SURVEY ATTENTION BAS
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang WL, 2019, WOODHEAD PUBL FOOD S, P23, DOI 10.1016/B978-0-12-814217-2.00003-2
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Xiong C., 2016, ARXIV161101604
   Yan GL, 2019, MICRO NANO TECHNOL, P219, DOI 10.1016/B978-0-323-51270-1.00007-8
   Yang J, 2016, CVPR
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Yu Chen, 2018, Pattern Recognition and Computer Vision. First Chinese Conference, PRCV 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11256), P347, DOI 10.1007/978-3-030-03398-9_30
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, IEEE IMAGE PROC, P2941
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang Z., 2018, ARXIV PREPRINT ARXIV
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 68
TC 32
Z9 34
U1 18
U2 32
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB
PY 2020
VL 12
IS 3
AR 484
DI 10.3390/rs12030484
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KO2QH
UT WOS:000515393800143
OA gold
DA 2022-01-04
ER

PT J
AU Zhang, XZ
   Liu, G
   Zhang, C
   Atkinson, PM
   Tan, XH
   Jian, X
   Zhou, XC
   Li, YM
AF Zhang, Xinzheng
   Liu, Guo
   Zhang, Ce
   Atkinson, Peter M.
   Tan, Xiaoheng
   Jian, Xin
   Zhou, Xichuan
   Li, Yongming
TI Two-Phase Object-Based Deep Learning for Multi-Temporal SAR Image Change
   Detection
SO REMOTE SENSING
LA English
DT Article
DE synthetic aperture radar (SAR); change detection; deep learning;
   superpixel
ID PCANET
AB Change detection is one of the fundamental applications of synthetic aperture radar (SAR) images. However, speckle noise presented in SAR images has a negative effect on change detection, leading to frequent false alarms in the mapping products. In this research, a novel two-phase object-based deep learning approach is proposed for multi-temporal SAR image change detection. Compared with traditional methods, the proposed approach brings two main innovations. One is to classify all pixels into three categories rather than two categories: unchanged pixels, changed pixels caused by strong speckle (false changes), and changed pixels formed by real terrain variation (real changes). The other is to group neighbouring pixels into superpixel objects such as to exploit local spatial context. Two phases are designed in the methodology: (1) Generate objects based on the simple linear iterative clustering (SLIC) algorithm, and discriminate these objects into changed and unchanged classes using fuzzy c-means (FCM) clustering and a deep PCANet. The prediction of this Phase is the set of changed and unchanged superpixels. (2) Deep learning on the pixel sets over the changed superpixels only, obtained in the first phase, to discriminate real changes from false changes. SLIC is employed again to achieve new superpixels in the second phase. Low rank and sparse decomposition are applied to these new superpixels to suppress speckle noise significantly. A further clustering step is applied to these new superpixels via FCM. A new PCANet is then trained to classify two kinds of changed superpixels to achieve the final change maps. Numerical experiments demonstrate that, compared with benchmark methods, the proposed approach can distinguish real changes from false changes effectively with significantly reduced false alarm rates, and achieve up to 99.71% change detection accuracy using multi-temporal SAR imagery.
C1 [Zhang, Xinzheng; Liu, Guo; Tan, Xiaoheng; Jian, Xin; Zhou, Xichuan; Li, Yongming] Chongqing Univ, Coll Microelect & Commun Engn, Chongqing 400044, Peoples R China.
   [Zhang, Xinzheng; Tan, Xiaoheng; Jian, Xin] Chongqing Key Lab Space Informat Network & Intell, Chongqing 400044, Peoples R China.
   [Zhang, Ce; Atkinson, Peter M.] Univ Lancaster, Lancaster Environm Ctr, Lancaster LA1 4YQ, England.
   [Zhang, Ce] UK Ctr Ecol & Hydrol, Lib Ave, Lancaster LA1 4AP, England.
RP Zhang, XZ (corresponding author), Chongqing Univ, Coll Microelect & Commun Engn, Chongqing 400044, Peoples R China.; Zhang, XZ (corresponding author), Chongqing Key Lab Space Informat Network & Intell, Chongqing 400044, Peoples R China.
EM zhangxinzheng@cqu.edu.cn; 20114898@cqu.edu.cn; c.zhang9@lancaster.ac.uk;
   pma@lancaster.ac.uk; txh@cqu.edu.cn; jianxin@cqu.edu.cn; zxc@cqu.edu.cn;
   yongmingli@cqu.edu.cn
RI Li, Yongming/AAP-2697-2020
OI Li, Yongming/0000-0002-7542-4356; Zhang, Xinzheng/0000-0003-0170-992X;
   Atkinson, Peter/0000-0002-5489-6880; Zhang, Ce/0000-0001-5100-3584
FU National Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61301224]; Basic and Advanced Research Project in
   Chongqing [cstc2017jcyjA1378, cstc2016jcyjA0457]
FX This research was funded by the National Science Foundation of China
   under Grants No. 61301224. This research was also partly supported by
   the Basic and Advanced Research Project in Chongqing under Grants No.
   cstc2017jcyjA1378 and No. cstc2016jcyjA0457.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bengio Y., DEEP LEARNING REPRES
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   CHAVEZ PS, 1994, PHOTOGRAMM ENG REM S, V60, P571
   De S., 2017, P GEOSC REM SENS IGA
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao P, 2019, IEEE GEOSCI REMOTE S, V16, P1240, DOI 10.1109/LGRS.2019.2895656
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hou B, 2016, IEEE J-STARS, V9, P3072, DOI 10.1109/JSTARS.2016.2553104
   Li C., 2016, P INT JOINT C NEUR N
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li Y., 2018, P GEOSC REM SENS IGA
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu T., DUAL CHANNEL CONVOLU
   Luo FL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080790
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Neagoe VE, 2014, IEEE J-STARS, V7, P3525, DOI 10.1109/JSTARS.2014.2330808
   Sun J., 2016, PROC CVPR IEEE, P770, DOI DOI 10.1109/CVPR.2016.90
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Zhang C, 2019, REMOTE SENS ENVIRON, V221, P173, DOI 10.1016/j.rse.2018.11.014
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang XZ, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151831
   Zhao YQ, 2015, IEEE T GEOSCI REMOTE, V53, P296, DOI 10.1109/TGRS.2014.2321557
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   Zou HX, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071107
NR 36
TC 11
Z9 11
U1 11
U2 18
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB
PY 2020
VL 12
IS 3
AR 548
DI 10.3390/rs12030548
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KO2QH
UT WOS:000515393800207
OA Green Submitted, Green Accepted, gold, Green Published
DA 2022-01-04
ER

PT J
AU Li, HC
   Yang, G
   Yang, W
   Du, Q
   Emery, WJ
AF Li, Heng-Chao
   Yang, Gang
   Yang, Wen
   Du, Qian
   Emery, William J.
TI Deep nonsmooth nonnegative matrix factorization network with
   semi-supervised learning for SAR image change detection
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE SAR image change detection; Nonsmooth nonnegative matrix factorization;
   Deep learning; Extreme learning machine; Semi-supervised learning
ID UNSUPERVISED CHANGE DETECTION; INTENSITY; MODELS; PCANET; RATIO
AB In the paper, we propose a deep nonsmooth nonnegative matrix factorization (nsNMF) network with semi-supervised learning for synthetic aperture radar (SAR) image change detection. In most of the existing deep-NMF-based models, the nonnegative matrix is linearly decomposed layer by layer, which may fail to characterize the nonlinearities in complex data. As such, a nonlinear deep nsNMF model is first built for learning hierarchical, nonlinear, and localized data representations. Meanwhile, in view of its good generalization performance and low computational complexity, extreme learning machine (ELM) is integrated into the nonlinear deep nsNMF model to construct a deep nsNMF network for satisfactory classification. More importantly, since it is difficult to acquire more labeled samples in practice, semi-supervised learning strategy is proposed to make use of partially labeled data for training. The learning process of the proposed network consists of pretraining stage and fine-toning stage, in which the former pretrains all decomposed matrices layer by layer and the latter aims to reduce the total reconstruction error by using the mini-batch gradient descent algorithm. The experimental results on four pairs of SAR images demonstrate the effectiveness of the proposed method.
C1 [Li, Heng-Chao; Yang, Gang] Southwest Jiaotong Univ, Sichuan Prov Key Lab Informat Coding & Transmiss, Chengdu 610031, Peoples R China.
   [Yang, Wen] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Emery, William J.] Univ Colorado, Dept Aerosp Engn Sci, Boulder, CO 80309 USA.
RP Yang, G (corresponding author), Southwest Jiaotong Univ, Sichuan Prov Key Lab Informat Coding & Transmiss, Chengdu 610031, Peoples R China.
EM ygfxr@my.swjtu.edu.cn
RI Yang, Wen/AAM-8352-2020
OI Yang, Wen/0000-0002-3263-8768; Yang, Gang/0000-0001-6944-0483
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61871335, 61771351]; Frontier Intersection
   Basic Research Project for the Central Universities [A0920502051814-5];
   Doctoral Innovation Fund Program of Southwest Jiaotong University
   [D-CX201925]
FX The authors would like to thank European Space Agency for providing some
   experimental data sets. They would also like to thank the
   Editor-in-Chief, the Associate Editor, and the anonymous reviewers for
   their careful reading and valuable comments, which have greatly improved
   the technical quality and presentation of this paper. This work was
   supported in part by the National Natural Science Foundation of China
   (Grant Nos. 61871335 and 61771351), in part by the Frontier Intersection
   Basic Research Project for the Central Universities (Grant No.
   A0920502051814-5), and in part by the Doctoral Innovation Fund Program
   of Southwest Jiaotong University (Grant No. D-CX201925).
CR Bazi Y, 2009, INT J REMOTE SENS, V30, P6591, DOI 10.1080/01431160902882538
   Benedek C, 2015, ISPRS J PHOTOGRAMM, V107, P22, DOI 10.1016/j.isprsjprs.2015.02.006
   Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Celik T, 2011, PATTERN RECOGN LETT, V32, P1635, DOI 10.1016/j.patrec.2011.05.008
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Feng XR, 2018, IEEE T GEOSCI REMOTE, V56, P6245, DOI 10.1109/TGRS.2018.2834567
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, ISPRS J PHOTOGRAMM, V93, P123, DOI 10.1016/j.isprsjprs.2014.04.010
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee H, 2010, IEEE SIGNAL PROC LET, V17, P4, DOI 10.1109/LSP.2009.2027163
   Li HC, 2018, ELECTRON LETT, V54, P892, DOI 10.1049/el.2018.1269
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li HC, 2014, INT GEOSCI REMOTE SE, P1289, DOI 10.1109/IGARSS.2014.6946669
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Li ZX, 2017, IEEE GEOSCI REMOTE S, V14, P783, DOI 10.1109/LGRS.2017.2681198
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Mel BW, 1999, NATURE, V401, P759, DOI 10.1038/44507
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60
   Patra S, 2011, INT J REMOTE SENS, V32, P6071, DOI 10.1080/01431161.2010.507793
   Qian B, 2016, LECT NOTES COMPUT SC, V9967, P583, DOI 10.1007/978-3-319-46654-5_64
   Rajabi R, 2015, IEEE GEOSCI REMOTE S, V12, P38, DOI 10.1109/LGRS.2014.2325874
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Tong M, 2019, NEURAL COMPUT APPL, V31, P7447, DOI 10.1007/s00521-018-3554-6
   Trigeorgis G, 2017, IEEE T PATTERN ANAL, V39, P417, DOI 10.1109/TPAMI.2016.2554555
   Volpi M, 2012, IEEE GEOSCI REMOTE S, V9, P1026, DOI 10.1109/LGRS.2012.2189092
   Wang F, 2013, IEEE GEOSCI REMOTE S, V10, P697, DOI 10.1109/LGRS.2012.2219494
   Wu C, 2018, ISPRS J PHOTOGRAMM, V146, P137, DOI 10.1016/j.isprsjprs.2018.09.005
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xiong BL, 2012, REMOTE SENS LETT, V3, P267, DOI 10.1080/01431161.2011.572093
   Yang G, 2018, INT GEOSCI REMOTE SE, P4917, DOI 10.1109/IGARSS.2018.8519082
   Yu JS, 2018, IEEE ACCESS, V6, P58096, DOI 10.1109/ACCESS.2018.2873385
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 51
TC 13
Z9 14
U1 8
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD FEB
PY 2020
VL 160
BP 167
EP 179
DI 10.1016/j.isprsjprs.2019.12.002
PG 13
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA KH3DA
UT WOS:000510525500012
DA 2022-01-04
ER

PT J
AU Lv, ZY
   Liu, TF
   Kong, XB
   Shi, C
   Benediktsson, JA
AF Lv, ZhiYong
   Liu, TongFei
   Kong, XiangBing
   Shi, Cheng
   Benediktsson, Jon Atli
TI Landslide Inventory Mapping With Bitemporal Aerial Remote Sensing Images
   Based on the Dual-Path Fully Convolutional Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Terrain factors; Remote sensing; Feature extraction; Convolution; Deep
   learning; Three-dimensional displays; Sun; Change detection (CD);
   landslide inventory map (LIM); natural disaster; remote sensing images
ID SATELLITE IMAGES; CLASSIFICATION
AB This article presents a novel dual-path full convolutional network (DP-FCN) model for constructing a landslide inventory map (LIM) with bitemporal very high-resolution (VHR) remote sensing images. Unlike traditional methods for drawing LIM, the proposed DP-FCN directly draws LIMs from the bitemporal aerial images with VHR through a trained deep neural network without generating the change magnitude map. Thus, the proposed approach can effectively reduce the effects of pseudo changes caused by phenological differences rather than landslide events. The proposed DP-FCN model contains two modules, namely, deep feature extraction, and joint feature learning networks. Deep feature extraction aims to reduce redundancy while extracting the high-level deep features from bitemporal images. Joint feature learning establishes the relationship between the deep features of bitemporal images and the ground reference map. Experiments on the real datasets of the landslide sites in Lantau Island of Hong Kong, China, demonstrate the feasibility and superiority of the proposed approach in drawing LIM with VHR remote sensing images. Moreover, compared with the results obtained by the state-of-the-art algorithms, the proposed DP-FCN method achieves the best performance in terms of accuracy for landslide inventory mapping.
C1 [Lv, ZhiYong; Liu, TongFei; Shi, Cheng] XiAn Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Kong, XiangBing] Yellow River Inst Hydraul Res, Zhengzhou 450003, Henan, Peoples R China.
   [Benediktsson, Jon Atli] Univ Iceland, Fac Elect & Comp Engn, IS-107 Reykjavik, Iceland.
RP Kong, XB (corresponding author), Yellow River Inst Hydraul Res, Zhengzhou 450003, Henan, Peoples R China.
EM lvzhiyong_fly@hotmail.com; liutongfei_home@hotmail.com;
   kongxb@foxmail.com; chengc_s@163.com; benedikt@hi.is
RI Tongfei, Liu/AAH-3686-2021; Benediktsson, Jon Atli/F-2861-2010
OI Tongfei, Liu/0000-0003-1394-4724; Benediktsson, Jon
   Atli/0000-0003-0621-9647; Shi, Cheng/0000-0001-8530-2005; ZhiYong,
   Lv/0000-0003-2595-4794
FU National Key Research and Development Program of China [2017YFC0504501];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61501200, 61701396, 61902313]; Natural
   Science Foundation of Shaan Xi ProvinceNatural Science Foundation of
   Shaanxi Province [2017JQ4006]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFC0504501, in part by the
   National Natural Science Foundation of China under Grants 61501200,
   61701396, and 61902313, and in part by the Natural Science Foundation of
   Shaan Xi Province under Grant 2017JQ4006.
CR Aamir T, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P508, DOI 10.1109/ICWS.2017.59
   Chapella H., 2019, IAEG AEG ANN M P SAN, V1, P217, DOI [10.1007/978-3-319-93124-1_26, DOI 10.1007/978-3-319-93124-1_26]
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Choi KY, 2013, J ROCK MECH GEOTECH, V5, P354, DOI 10.1016/j.jrmge.2013.07.007
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Du Y, 2002, REMOTE SENS ENVIRON, V82, P123, DOI 10.1016/S0034-4257(02)00029-9
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Herold M, 2003, IEEE T GEOSCI REMOTE, V41, P1907, DOI 10.1109/TGRS.2003.815238
   Huang X, 2014, ISPRS J PHOTOGRAMM, V90, P36, DOI 10.1016/j.isprsjprs.2014.01.008
   Iglovikov V, 2018, 180105746 ARXIV
   Im J, 2007, REMOTE SENS ENVIRON, V106, P89, DOI 10.1016/j.rse.2006.07.019
   Iwamoto M. K., 2018, P TRANSP RES BOARD 9, P3918
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Li ZB, 2016, REMOTE SENS ENVIRON, V187, P76, DOI 10.1016/j.rse.2016.10.008
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Livne M, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00097
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2005, INT J REMOTE SENS, V26, P101, DOI 10.1080/01431160410001720748
   Lu M, 2016, REMOTE SENS ENVIRON, V184, P374, DOI 10.1016/j.rse.2016.07.028
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Lv ZY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111112
   Ma HR, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.016008
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Niethammer U, 2011, INT ARCH PHOTOGRAMM, V38-1, P161
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shahabi H, 2015, SCI REP-UK, V5, DOI 10.1038/srep09899
   Si A, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7100394
   Stumpf A, 2017, REMOTE SENS ENVIRON, V189, P40, DOI 10.1016/j.rse.2016.11.007
   Wang CS, 2017, SCI REP-UK, V7, DOI 10.1038/srep43351
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wills CJ, 2002, ENVIRON ENG GEOSCI, V8, P279, DOI 10.2113/8.4.279
   Zhang LP, 2006, IEEE T GEOSCI REMOTE, V44, P2950, DOI 10.1109/TGRS.2006.876704
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang XK, 2017, REMOTE SENS LETT, V8, P811, DOI 10.1080/2150704X.2017.1317929
   Zhao CY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020279
   Zhao W, 2017, IEEE J-STARS, V10, P1758, DOI 10.1109/JSTARS.2017.2661802
   Zhong SP, 2019, MITOCHONDRIAL DNA B, V4, P189, DOI 10.1080/23802359.2018.1545545
NR 50
TC 4
Z9 4
U1 14
U2 24
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 4575
EP 4584
DI 10.1109/JSTARS.2020.2980895
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA NG7TR
UT WOS:000564184200006
OA gold
DA 2022-01-04
ER

PT J
AU Hedjam, R
   Abdesselam, A
   Melgani, F
AF Hedjam, Rachid
   Abdesselam, Abdelhamid
   Melgani, Farid
TI Change Detection in Unlabeled Optical Remote Sensing Data Using Siamese
   CNN
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Remote sensing; Training; Optical imaging; Optical
   sensors; Convolutional neural networks; Remote sensing change detection
   (CD); semisupervised CD; Siamese convolutional neural network (CNN)
ID IMAGES
AB In this article, we propose a new semisupervised method to detect the changes occurring in a geographical area after a major damage. We detect the changes by processing a pair of optical remote sensing images. The proposed method adopts a patch-based approach, whereby we use a Siamese convolutional neural network (S-CNN), trained with augmented data, to compare successive pairs of patches obtained from the input images. The main contribution of this work lies in developing an S-CNN training phase without resorting to class labels that are actually not available from the input images. We train the S-CNN using genuine and impostor patch-pairs defined in a semisupervised way from the input images. We tested the proposed change detection model on four real datasets and compared its performance to those of two existing models. The obtained results were very promising.
C1 [Hedjam, Rachid; Abdesselam, Abdelhamid] Sultan Qaboos Univ, Dept Comp Sci, Muscat 123, Oman.
   [Melgani, Farid] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
RP Hedjam, R (corresponding author), Sultan Qaboos Univ, Dept Comp Sci, Muscat 123, Oman.
EM rachid.hedjam@squ.edu.om; ahamid@squ.edu.om; melgani@disi.unitn.it
CR Al Rahhal MM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10121890
   Argyridis A, 2016, INT J IMAGE DATA FUS, V7, P148, DOI 10.1080/19479832.2016.1158211
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen Y., 2019, P 3 ACM SIGSPATIAL I, P24
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   De S, 2017, INT GEOSCI REMOTE SE, P5193, DOI 10.1109/IGARSS.2017.8128171
   Demir B, 2013, IEEE T IMAGE PROCESS, V22, P3219, DOI 10.1109/TIP.2013.2259838
   El Amin A. M., 2016, P INT WORKSH PATT RE
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Hedjam R, 2019, INT GEOSCI REMOTE SE, P1530, DOI 10.1109/IGARSS.2019.8898672
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 1995, HDB BRAIN THEORY NEU, V336-1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2018, INT GEOSCI REMOTE SE, P3627, DOI 10.1109/IGARSS.2018.8519419
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Minu S, 2015, AQUAT PR, V4, P1366, DOI 10.1016/j.aqpro.2015.02.177
   Pan ZK, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12101574
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang Z., 2018, ARXIV180709562
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 36
TC 2
Z9 2
U1 13
U2 16
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 4178
EP 4187
DI 10.1109/JSTARS.2020.3009116
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA MW9LC
UT WOS:000557351700001
OA gold
DA 2022-01-04
ER

PT J
AU Khelifi, L
   Mignotte, M
AF Khelifi, Lazhar
   Mignotte, Max
TI Deep Learning for Change Detection in Remote Sensing Images:
   Comprehensive Review and Meta-Analysis
SO IEEE ACCESS
LA English
DT Review
DE Change detection; remote sensing images; deep learning; feature
   learning; weakly supervised learning; review
ID UNSUPERVISED CHANGE DETECTION; LAND-COVER; NETWORK; CLASSIFICATION;
   REPRESENTATION; FEATURES
AB Deep learning (DL) algorithms are considered as a methodology of choice for remote-sensing image analysis over the past few years. Due to its effective applications, deep learning has also been introduced for automatic change detection and achieved great success. The present study attempts to provide a comprehensive review and a meta-analysis of the recent progress in this subfield. Specifically, we first introduce the fundamentals of deep learning methods which are frequently adopted for change detection. Secondly, we present the details of the meta-analysis conducted to examine the status of change detection DL studies. Then, we focus on deep learning-based change detection methodologies for remote sensing images by giving a general overview of the existing methods. Specifically, these deep learning-based methods were classified into three groups; fully supervised learning-based methods, fully unsupervised learning-based methods and transfer learning-based techniques. As a result of these investigations, promising new directions were identified for future research. This study will contribute in several ways to our understanding of deep learning for change detection and will provide a basis for further research. Some source codes of the methods discussed in this paper are available from: https://github.com/lazharkhelifi/deeplearning_changedetection_remotesensing_review.
C1 [Khelifi, Lazhar; Mignotte, Max] Univ Montreal, Dept Comp Sci & Operat Res, Vis Lab, Montreal, PQ H3C 3J7, Canada.
RP Khelifi, L (corresponding author), Univ Montreal, Dept Comp Sci & Operat Res, Vis Lab, Montreal, PQ H3C 3J7, Canada.
EM khelifil@iro.umontreal.ca
FU Natural Sciences and Engineering Research Council of Canada
   (NSERC)Natural Sciences and Engineering Research Council of Canada
   (NSERC)
FX This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC) for having supported this research work via
   the individual discovery grant program.
CR Abdalla A, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105091
   Anastassiou GA, 2011, MATH COMPUT MODEL, V53, P1111, DOI 10.1016/j.mcm.2010.11.072
   Bengio, 2014, CORR
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Bengio Y., 2007, LARGE SCALE KERNEL M
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao C, 2019, ENVIRONMENTS, V6, DOI 10.3390/environments6020025
   Cao XH, 2019, IET IMAGE PROCESS, V13, P1509, DOI 10.1049/iet-ipr.2018.5172
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409
   CHEN LC, 2016, ARXIV 1606 00915 CS, V1606, P915, DOI DOI 10.1109/TPAMI.2017.2699184
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Chung Y.-A., 2018, NAACL HLT, V1, P1585, DOI DOI 10.18653/V1/N18-1143
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Dai YY, 2020, IEEE T VEH TECHNOL, V69, P4312, DOI 10.1109/TVT.2020.2973705
   Daudt RC, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.07.003
   de Jong K. L., 2018, ARXIV181205815
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Feranec J, 2007, LAND USE POLICY, V24, P234, DOI 10.1016/j.landusepol.2006.02.002
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Fu K., 2018, REMOTE SENS, V10, P1
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Gao YH, 2019, IEEE GEOSCI REMOTE S, V16, P1655, DOI 10.1109/LGRS.2019.2906279
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Geva AB, 1999, IEEE T FUZZY SYST, V7, P723, DOI 10.1109/91.811242
   Gislason PO, 2006, PATTERN RECOGN LETT, V27, P294, DOI 10.1016/j.patrec.2005.08.011
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hamdi ZM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171976
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HEBB DO, 2005, ORG BEHAV NEUROPSYCH
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Hoel C.-J., 2019, IEEE T INTELL VEH, V5, P294
   Hoffman M., 2014, ABS14126830 CORR
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang FH, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102585
   ITO Y, 1991, NEURAL NETWORKS, V4, P385, DOI 10.1016/0893-6080(91)90075-G
   Jaturapitpornchai R., 2019, REMOTE SENS, V11, P1
   Jiang HW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030484
   Jordan J., 2018, COMMON ARCHITECTURES
   Kadhim N, 2016, EURO-MEDITERR J ENVI, V1, DOI 10.1007/s41207-016-0007-4
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kolos M, 2019, LECT NOTES COMPUT SC, V11555, P371, DOI 10.1007/978-3-030-22808-8_37
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lewis D. D., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P4
   Li D, 2019, PROC INT CONF DATA, P1226, DOI 10.1109/ICDE.2019.00112
   Li ST, 2019, IEEE T GEOSCI REMOTE, V57, P6690, DOI 10.1109/TGRS.2019.2907932
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Li Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020243
   Li YF, 2021, IEEE T PATTERN ANAL, V43, P334, DOI 10.1109/TPAMI.2019.2922396
   Lipton Z., 2015, COMPUT SCI, DOI DOI 10.1145/2647868.2654889
   Liu R., 2019, IEEE ACCESS, V7
   Liu RC, 2020, IEEE J-STARS, V13, P1109, DOI 10.1109/JSTARS.2020.2974276
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Luo WH, 2020, IEEE T PATTERN ANAL, V42, P1317, DOI 10.1109/TPAMI.2019.2899570
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Malila W.A, 1980, P LARS S, P385
   McCulloch Warren S., 1943, B MATH BIOPHYS, V5, P115, DOI [10.1007/BF02478259, DOI 10.1007/BF02478259]
   Mnih V., 2016, P INT C LEARN REPR, P1928, DOI DOI 10.5555/3045390.3045594
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mohamed AR, 2011, INT CONF ACOUST SPEE, P5060
   Mohamed AR, 2012, IEEE T AUDIO SPEECH, V20, P14, DOI 10.1109/TASL.2011.2109382
   Nguyen TT, 2020, IEEE T CYBERNETICS, V50, P3826, DOI 10.1109/TCYB.2020.2977374
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paoletti ME, 2019, ISPRS J PHOTOGRAMM, V158, P279, DOI 10.1016/j.isprsjprs.2019.09.006
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng J., 1994, MACH LEARN P 1994, DOI DOI 10.1016/B978-1-55860-335-6.50035-0
   Reed R., 1999, NEURAL SMITHING SUPE
   Rikiya Y., 2018, INSIGHTS IMAGING, V9, P115
   Rish I., 2001, IJCAI 2001 WORKSHOP, P41, DOI DOI 10.1039/B104835J
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Simonyan K., 2015, P INT C LEARN REPR, P1129
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Suresh S, 2009, APPL SOFT COMPUT, V9, P541, DOI 10.1016/j.asoc.2008.07.005
   Suykens J. A. K., 1999, Proceedings of the European Conference on Circuit Theory and Design. ECCTD'99, P839
   Teng Z., 2020, PATTERN RECOGN, V101, P1
   Venugopal N, 2019, SENS IMAGING, V20, DOI 10.1007/s11220-019-0252-0
   Viana CM, 2019, SPATIAL MODELING IN GIS AND R FOR EARTH AND ENVIRONMENTAL SCIENCES, P621, DOI 10.1016/B978-0-12-815226-3.00029-6
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Witten IH, 2011, MOR KAUF D, P3, DOI 10.1016/B978-0-12-374856-0.00001-8
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu B., 2015, ARXIV150500853
   Xue J, 2013, INTERSPEECH, P2364
   Yang G, 2019, IEEE T GEOSCI REMOTE, V57, P8890, DOI 10.1109/TGRS.2019.2923643
   Yang MJ, 2019, IEEE T GEOSCI REMOTE, V57, P6960, DOI 10.1109/TGRS.2019.2909781
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zalta E. N., 2019, STANFORD ENCY PHILOS
   Zhang C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8040189
   Zhang DJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081308
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang L, 2016, IEEE IMAGE PROC, P3708, DOI 10.1109/ICIP.2016.7533052
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang W, 2019, IEEE T NEUR NET LEAR, V30, P3847, DOI 10.1109/TNNLS.2019.2899588
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang Z., 2018, CNN
   Zhao Z, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1156
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou PC, 2016, MULTIDIM SYST SIGN P, V27, P925, DOI 10.1007/s11045-015-0370-3
   Zhou PC, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P318, DOI 10.1109/BigMM.2015.13
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu YK, 2017, INT CONF ACOUST SPEE, P5335, DOI 10.1109/ICASSP.2017.7953175
NR 129
TC 27
Z9 27
U1 74
U2 116
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 126385
EP 126400
DI 10.1109/ACCESS.2020.3008036
PG 16
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA MS8HX
UT WOS:000554515900001
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Kalinicheva, E
   Ienco, D
   Sublime, J
   Trocan, M
AF Kalinicheva, Ekaterina
   Ienco, Dino
   Sublime, Jeremie
   Trocan, Maria
TI Unsupervised Change Detection Analysis in Satellite Image Time Series
   Using Deep Learning Combined With Graph-Based Approaches
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Autoencoder (AE); change detection; gated recurrent unit (GRU);
   object-oriented image analysis; pattern recognition; satellite image
   time series (SITS); time-series clustering; unsupervised learning
ID NEURAL-NETWORK; CLASSIFICATION; FOREST
AB Nowadays, huge volume of satellite images, via the different Earth Observation missions, are constantly acquired and they constitute a valuable source of information for the analysis of spatiotemporal phenomena. However, it can be challenging to obtain reference data associated to such images to deal with land use or land cover changes as often the nature of the phenomena under study is not known a priori. With the aim to deal with satellite image analysis, considering a real-world scenario, where reference data cannot be available, in this article, we present a novel end-to-end unsupervised approach for change detection and clustering for satellite image time series (SITS). In the proposed framework, we first create bitemporal change masks for every couple of consecutive images using neural network autoencoders (AEs). Then, we associate the extracted changes to different spatial objects. The objects sharing the same geographical location are combined in spatiotemporal evolution graphs that are finally clustered accordingly to the type of change process with gated recurrent unit (GRU) AE-based model. The proposed approach was assessed on two real-world SITS data supplying promising results.
C1 [Kalinicheva, Ekaterina; Sublime, Jeremie; Trocan, Maria] DaSSIP Team, ISEP LISITE Lab, F-92130 Issy Les Moulineaux, France.
   [Ienco, Dino] Univ Montpellier, INRAE, UMR TETIS, F-34093 Montpellier 5, France.
   [Ienco, Dino] Univ Montpellier, LIRMM, F-34095 Montpellier 5, France.
   [Sublime, Jeremie] Univ Paris 13, UMR 7030, CNRS, LIPN, Paris, France.
RP Kalinicheva, E (corresponding author), DaSSIP Team, ISEP LISITE Lab, F-92130 Issy Les Moulineaux, France.
EM ekaterina.kalinicheva@isep.fr; dino.ienco@irstea.fr;
   jeremie.sublime@isep.fr; maria.trocan@isep.fr
RI Sublime, Jeremie/I-2438-2019; Kalinicheva, Ekaterina/ABB-9659-2020;
   Ienco, Dino/ABB-5260-2021
OI Sublime, Jeremie/0000-0003-0508-8550; Kalinicheva,
   Ekaterina/0000-0001-8332-2491; Ienco, Dino/0000-0002-8736-3132
FU EDITE Ph.D. Scholarship
FX This work was supported by the EDITE Ph.D. Scholarship.
CR Alqurashi AE, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100838
   Bengio, 2014, ARXIV14061078, DOI DOI 10.3115/V1/D14-1179
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cai SS, 2015, REMOTE SENS-BASEL, V7, P8705, DOI 10.3390/rs70708705
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dutrieux LP, 2015, ISPRS J PHOTOGRAMM, V107, P112, DOI 10.1016/j.isprsjprs.2015.03.015
   El Hajj M, 2008, SENSORS-BASEL, V8, P2774, DOI 10.3390/s8042774
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goldstein M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152173
   Guo X., 2017, P 26 INT JOINT C ART, DOI [10.24963/ijcai.2017/243, DOI 10.24963/IJCAI.2017/243]
   Guttler F, 2017, ISPRS J PHOTOGRAMM, V130, P92, DOI 10.1016/j.isprsjprs.2017.05.013
   Ienco D, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133361
   Interdonato R, 2019, ISPRS J PHOTOGRAMM, V149, P91, DOI 10.1016/j.isprsjprs.2019.01.011
   Kalinicheva E, 2019, LECT NOTES COMPUT SC, V11729, P637, DOI 10.1007/978-3-030-30508-6_50
   Kanjir U, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7100405
   Khiali L, 2019, INT J APPL EARTH OBS, V74, P103, DOI 10.1016/j.jag.2018.07.014
   Kong YL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030452
   Lei T, 2019, INT CONF ACOUST SPEE, P3027, DOI 10.1109/ICASSP.2019.8682802
   Lopes M, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9100993
   Luo H., 2018, ARXIV181012563
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Ndikumana E, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081217
   Olen S, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081272
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pareeth S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050601
   Pelletier C, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050523
   Prechelt L., 2012, EARLY STOPPING, DOI [DOI 10.1007/978-3-642-35289-8_5, 10.1007/978-3-642-35289-8_5]
   Rakthanmanon T, 2013, ACM T KNOWL DISCOV D, V7, DOI 10.1145/2500489
   Song X.-P., 2011, REMOTE SENS, V6, P8878
   Sublime J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091123
   Sutskever I, 2014, ADV NEUR IN, V27
   Tavenard R., 2017, TSLEARN MACHINE LEAR
   Vaduva C, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091436
   van Hoek M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8050422
   Verbesselt J, 2010, REMOTE SENS ENVIRON, V114, P106, DOI 10.1016/j.rse.2009.08.014
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Zhang Y., 2011, INT J MACH LEARN CYB, V1, P43
   Zhu Z, 2012, REMOTE SENS ENVIRON, V122, P75, DOI 10.1016/j.rse.2011.10.030
NR 38
TC 7
Z9 7
U1 9
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 1450
EP 1466
DI 10.1109/JSTARS.2020.2982631
PG 17
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA LL2IX
UT WOS:000531380500004
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Liu, RC
   Jiang, DW
   Zhang, LL
   Zhang, ZT
AF Liu, Ruochen
   Jiang, Dawei
   Zhang, Langlang
   Zhang, Zetong
TI Deep Depthwise Separable Convolutional Network for Change Detection in
   Optical Aerial Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Convolution; Feature extraction; Image segmentation; Training; Remote
   sensing; Optical imaging; Deep learning; Change detection; depthwise
   separable convolution; image segmentation; optical aerial images
AB In this article, a remote sensing image change detection method based on depthwise separable convolution with U-Net is proposed, which omits the tedious steps of generating and analyzing the difference map in the traditional remote sensing image change detection method. First, two images having c-channel each can be specifically stacked into a 2c-channel image, and the change detection can be converted to an image segmentation problem, an improved full convolution network (FCN) called U-Net is exploited to directly separate the changing regions. Because the capability of the deep convolution network is proportional to the depth of the network and a deeper convolution network means the increase of the training parameters, we then replace the original convolution in FCN by the depthwise separable convolution, making the entire network lighter, while the model performs slightly better than the traditional convolution operation. Besides that, another innovation in our proposed method is to use a preference control loss function to meet the different needs of precision and recall rate. Experimental results validate the effectiveness and robustness of the proposed method.
C1 [Liu, Ruochen; Jiang, Dawei; Zhang, Langlang; Zhang, Zetong] Xidian Univ, Minist Educ, Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
RP Liu, RC (corresponding author), Xidian Univ, Minist Educ, Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM ruochenliu@xidian.edu.cn; 1656556479@qq.com; 984195898@qq.com;
   503202358@qq.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61876141, 61373111]; Provincial Natural
   Science Foundation of Shaanxi of China [2019JZ-26]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61876141 and 61373111 and in part by
   the Provincial Natural Science Foundation of Shaanxi of China under
   Grant 2019JZ-26.
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Chinchor N, 1993, PROC 5 MESSAGE UNDER, P69, DOI DOI 10.3115/1072017.1072026
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   KING DB, 2015, P INT C LEARN REPR, V1214, P1
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu M, 2016, REMOTE SENS ENVIRON, V184, P374, DOI 10.1016/j.rse.2016.07.028
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Lyu H., 2016, REMOTE SENSING, V8, P1
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 23
TC 14
Z9 14
U1 10
U2 15
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 1109
EP 1118
DI 10.1109/JSTARS.2020.2974276
PG 10
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA LH6ZP
UT WOS:000528935500001
OA gold
DA 2022-01-04
ER

PT J
AU Wiratama, W
   Lee, J
   Sim, D
AF Wiratama, Wahyu
   Lee, Jongseok
   Sim, Donggyu
TI Change Detection on Multi-Spectral Images Based on Feature-level U-Net
SO IEEE ACCESS
LA English
DT Article
DE Convolutional neural network; deep learning; remote sensing; satellite
   images; change detection
ID FUZZY C-MEANS; FUSION TECHNIQUE
AB This paper proposes a change detection algorithm on multi-spectral images based on feature-level U-Net. A low-complexity pan-sharpening method is proposed to employ not only panchromatic images, but also multi-spectral images for enhancing the performance of the deep neural network. The high-resolution multi-spectral (HRMS) images are then fed into the proposed feature-level U-Net. The proposed feature-level U-Net consists of two-stages: a feature-level subtracting network and U-Net. The feature-level subtracting network is used to extract dynamic difference images (DI) for the use of low-level and high-level features. By employing this network, the performance of change detection algorithms can be improved with a smaller number of layers for U-Net with a low computational complexity. Furthermore, the proposed algorithm detects small changes by taking benefits of both geometrical and spectral resolution enhancement and adopting an intensity-hue-saturation (IHS) pan-sharpening method. A modified of IHS pan-sharpening algorithm is introduced to solve spectral distortion problem by applying mean filtering in high frequency. We found that the proposed change detection on HRMS images gives a better performance compared to existing change detection algorithms by achieving an average F-1 score of 0.62, a percentage correct classification (PCC) of 98.78%, and a kappa of 61.60 for test datasets.
C1 [Wiratama, Wahyu; Lee, Jongseok; Sim, Donggyu] Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
RP Sim, D (corresponding author), Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
EM dgsim@kw.ac.kr
OI Wiratama, Wahyu/0000-0002-8069-4633; Lee, Jongseok/0000-0001-8045-0244
FU MSIT (Ministry of Science and ICT), South Korea, through the ITRC
   (Information Technology Research Center) support program
   [IITP-2019-2016-0-00288]; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT,
   and Future Planning [NRF-2018R1A2B2008238]
FX This work was supported in part by the MSIT (Ministry of Science and
   ICT), South Korea, through the ITRC (Information Technology Research
   Center) support program under Grant IITP-2019-2016-0-00288 supervised by
   the IITP (Institute for Information and Communications Technology
   Planning and Evaluation), and in part by the Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Science, ICT, and Future Planning under Grant
   NRF-2018R1A2B2008238.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bi CJ, 2014, INT CONF CLOUD COMPU, P327, DOI 10.1109/CCIS.2014.7175753
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   Choi M. J., 2000, INT J REMOTE SENS, V13, P1
   Choi M, 2006, IEEE T GEOSCI REMOTE, V44, P1672, DOI 10.1109/TGRS.2006.869923
   Darrell, 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.1109/CVPR.2015.7298965
   De Jong K. L., 2018, ARXIV181205815, V14
   Gao F., 2015, P INT C CIRC SYS CAS, P9
   Garzelli A, 2008, IEEE T GEOSCI REMOTE, V46, P228, DOI 10.1109/TGRS.2007.907604
   Goh Yeh-Huann, 2019, IEIE Transactions on Smart Processing & Computing, V8, P171, DOI 10.5573/IEIESPC.2019.8.3.171
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo E., 2018, ARXIV181009111, V22
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hao M, 2017, MULTIMED TOOLS APPL, V76, P20081, DOI 10.1007/s11042-017-4354-1
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Laben C.A., 2000, PROCESS ENHANCING SP
   Li YS, 2018, NEUROCOMPUTING, V315, P371, DOI 10.1016/j.neucom.2018.07.030
   Lim K, 2018, ASIAPAC SIGN INFO PR, P509, DOI 10.23919/APSIPA.2018.8659603
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mohammed El Amin A., 2016, P 1 INT WORKSH PATT, P11
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarp G, 2014, EUR J REMOTE SENS, V47, P19, DOI 10.5721/EuJRS20144702
   Seydi ST, 2018, APPL GEOMAT, V10, P65, DOI 10.1007/s12518-018-0206-6
   SHETTIGARA VK, 1992, PHOTOGRAMM ENG REM S, V58, P561
   Singh K.K., 2013, 2013 STUD C ENG SYST, P1
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Vrabel J, 1996, PHOTOGRAMM ENG REM S, V62, P1075
   Wiratama W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9071441
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Yoo H.-J., 2015, IEIE T SMART PROCESS, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang Z., 2018, ARXIV180709562
NR 41
TC 7
Z9 7
U1 2
U2 9
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2020
VL 8
BP 12279
EP 12289
DI 10.1109/ACCESS.2020.2964798
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA LC5ZA
UT WOS:000525409100035
OA gold
DA 2022-01-04
ER

PT J
AU Touati, R
   Mignotte, M
   Dahmane, M
AF Touati, Redha
   Mignotte, Max
   Dahmane, Mohamed
TI Anomaly Feature Learning for Unsupervised Change Detection in
   Heterogeneous Images: A Deep Sparse Residual Model
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Anomalous patterns; change detection (CD); deep learning; feature space
   reconstruction; heterogeneous remote sensing; multimodal anomaly
   detector; reconstruction error; sparse autoencoder
ID REMOTE-SENSING IMAGES; REPRESENTATION; ALGORITHM
AB In this article, we propose a novel and simple automatic model based on multimodal anomaly feature learning in a residual space, aiming at solving the binary classification problem of temporal change detection (CD) between pairs of heterogeneous remote sensing images. The model starts by learning from image pairs the normal existing patterns in the before and after images to come up with a suitable representation of the normal (nonchange) class. To achieve this, we employ a stacked sparse autoencoder trained on a large number of temporal image features (training data) in an unsupervised manner. To classify pixels of new unseen image-pairs, the built anomaly detection model reconstructs the input from its representation in the latent space. First, the probe (new) image (i.e., the bitemporal heterogeneous image pair as the input request) is encoded in this compact normal space from a stacked hidden representation. The reconstruction error is computed using the L2 norm in what we call the residual normal space. In which, the nonchange patterns are characterized by small reconstruction errors as a normal class while the change patterns are quantified by high reconstruction errors categorizing the abnormal class. The dichotomic (changed/unchanged) classification map is generated in the residual space by clustering the reconstructed errors using a Gaussian mixture model. Experimental results on different real heterogeneous images, reflecting a mixture of imaging and land surface CD conditions, confirm the robustness of the proposed anomaly detection model.
C1 [Touati, Redha; Mignotte, Max] Univ Montreal, Fac Arts & Sci, DIRO, Vis Lab, Montreal, PQ H3C 3J7, Canada.
   [Touati, Redha; Dahmane, Mohamed] CRIM, R&D Vis Dept, Montreal, PQ H3N 1M3, Canada.
RP Touati, R (corresponding author), Univ Montreal, Fac Arts & Sci, DIRO, Vis Lab, Montreal, PQ H3C 3J7, Canada.
EM touatire@iro.umontreal.ca; mignotte@iro.umontreal.ca;
   mohamed.dahmane@crim.ca
OI Dahmane, Mohamed/0000-0002-2670-1433
FU Computer Research Institute of Montreal (CRIM); Ministry of Economic
   Science and Innovation (MESI) of the Government of Quebec
FX This work was supported in part by the Computer Research Institute of
   Montreal (CRIM) and in part by the Ministry of Economic Science and
   Innovation (MESI) of the Government of Quebec.
CR Alberga V, 2009, REMOTE SENS-BASEL, V1, P122, DOI 10.3390/rs1030122
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chalapathy R., 2018, ARXIV PREPRINT ARXIV
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Daehyung Park, 2018, IEEE Robotics and Automation Letters, V3, P1544, DOI 10.1109/LRA.2018.2801475
   Droniou A, 2015, ROBOT AUTON SYST, V71, P83, DOI 10.1016/j.robot.2014.11.005
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Hedjam R, 2016, IEEE T GEOSCI REMOTE, V54, P6997, DOI 10.1109/TGRS.2016.2593982
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hsu Wei-Ning, 2017, ARXIV170404222
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Jaques N, 2017, INT CONF AFFECT, P202, DOI 10.1109/ACII.2017.8273601
   Kim Y, 2013, INT CONF ACOUST SPEE, P3687, DOI 10.1109/ICASSP.2013.6638346
   Laxhammar R, 2014, IEEE T PATTERN ANAL, V36, P1158, DOI 10.1109/TPAMI.2013.172
   Leidal K, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P424, DOI 10.1109/ASRU.2017.8268967
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu W, 2016, LECT NOTES COMPUT SC, V9948, P521, DOI 10.1007/978-3-319-46672-9_58
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lu HT, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P140
   Mercier G., 2008, TECH REP
   Mercier G, 2007, INT GEOSCI REMOTE SE, P2394, DOI 10.1109/IGARSS.2007.4423324
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Merkle N., 2017, P IGARSS 2017 IGARSS, P1
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Ng A. Y, 2011, IEEE INT C MACH LEAR, P689
   Nielsen AA, 2015, IEEE J-STARS, V8, P4041, DOI 10.1109/JSTARS.2015.2416434
   O. D. Team, 2014, ORF TOOLB SOFTW GUID
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Prendes J., 2015, REV FRANCAISE PHOTOG, V209, P23
   Prendes J., 2015, THESIS
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Ranzato M., 2007, ADV NEURAL INFORM PR, V20, P1185
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   Tang YQ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030252
   Touati R., 2017, P 7 IEEE INT C IM PR, P1
   Touati R, 2018, IEEE IMAGE PROC, P3998, DOI 10.1109/ICIP.2018.8451184
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   van Tulder G, 2019, IEEE T MED IMAGING, V38, P638, DOI 10.1109/TMI.2018.2868977
   Wang W, 2014, PROC VLDB ENDOW, V7, P649, DOI 10.14778/2732296.2732301
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xie Junyuan, 2012, P ADV NEUR INF PROC, P341
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Yu Qi, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6716, DOI 10.1109/ICASSP.2014.6854900
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang YJ, 2013, 2013 10TH CHINA INTERNATIONAL FORUM ON SOLID STATE LIGHTING (CHINASSL), P158, DOI 10.1109/SSLCHINA.2013.7177338
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
NR 54
TC 12
Z9 12
U1 5
U2 14
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PY 2020
VL 13
BP 588
EP 600
DI 10.1109/JSTARS.2020.2964409
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA LE3QM
UT WOS:000526635300002
OA gold
DA 2022-01-04
ER

PT J
AU Wang, MY
   Tan, K
   Jia, XP
   Wang, X
   Chen, Y
AF Wang, Moyang
   Tan, Kun
   Jia, Xiuping
   Wang, Xue
   Chen, Yu
TI A Deep Siamese Network with Hybrid Convolutional Feature Extraction
   Module for Change Detection Based on Multi-sensor Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE multi-sensor image; change detection; siamese neural network; dilated
   convolution; object-based image analysis
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION; SELECTION; MACHINE
AB Information extraction from multi-sensor remote sensing images has increasingly attracted attention with the development of remote sensing sensors. In this study, a supervised change detection method, based on the deep Siamese convolutional network with hybrid convolutional feature extraction module (OB-DSCNH), has been proposed using multi-sensor images. The proposed architecture, which is based on dilated convolution, can extract the deep change features effectively, and the character of "network in network" increases the depth and width of the network while keeping the computational budget constant. The change decision model is utilized to detect changes through the difference of extracted features. Finally, a change detection map is obtained via an uncertainty analysis, which combines the multi-resolution segmentation, with the output from the Siamese network. To validate the effectiveness of the proposed approach, we conducted experiments on multispectral images collected by the ZY-3 and GF-2 satellites. Experimental results demonstrate that our proposed method achieves comparable and better performance than mainstream methods in multi-sensor images change detection.
C1 [Wang, Moyang; Tan, Kun; Wang, Xue; Chen, Yu] China Univ Min & Technol, NASG Key Lab Land Environm & Disaster Monitoring, Xuzhou 221116, Jiangsu, Peoples R China.
   [Tan, Kun; Wang, Xue] East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, Shanghai 200241, Peoples R China.
   [Jia, Xiuping] Univ New South Wales, Sch Engn & Informat Technol, Canberra, ACT 2600, Australia.
RP Tan, K (corresponding author), China Univ Min & Technol, NASG Key Lab Land Environm & Disaster Monitoring, Xuzhou 221116, Jiangsu, Peoples R China.; Tan, K (corresponding author), East China Normal Univ, Minist Educ, Key Lab Geog Informat Sci, Shanghai 200241, Peoples R China.
EM ts18160045a31@cumt.edu.cn; tankun@geo.ecnu.edu.cn; x.jia@adfa.edu.au;
   wx_cumt@yeah.net; chenyu@cumt.edu.cn
RI Tan, Kun/AAA-6254-2019; Tan, Kun/V-1487-2019
OI Tan, Kun/0000-0001-6353-0146; Tan, Kun/0000-0001-6353-0146; Wang,
   Xue/0000-0002-6999-1362; Jia, Xiuping/0000-0001-9916-6382
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [41871337]; Priority Academic Program Development of
   Jiangsu Higher Education Institutions
FX `This research is supported in part by Natural Science Foundation of
   China (No. 41871337) and Priority Academic Program Development of
   Jiangsu Higher Education Institutions.
CR Bachtiar LR, 2013, NEURAL COMPUT, V25, P259, DOI 10.1162/NECO_a_00386
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chen H, 2006, INT C COMP SUPP COOP, P199
   Chen L.-C., 2017, RETHINKING ATROUS CO
   CHEN Q, 2016, REMOTE SENS-BASEL, V8, P549, DOI DOI 10.3390/rs8070549
   Chen YY, 2014, REMOTE SENS-BASEL, V6, P12575, DOI 10.3390/rs61212575
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Espindola GM, 2006, INT J REMOTE SENS, V27, P3035, DOI 10.1080/01431160600617194
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Hay GJ, 2003, ISPRS J PHOTOGRAMM, V57, P327, DOI 10.1016/S0924-2716(02)00162-4
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holschneider M., 1989, WAVELETS TIME FREQUE, P286
   Hu BT, 2014, ADV NEUR IN, V27
   Huang GB, 2004, IEEE IJCNN, P985
   Huang X, 2017, REMOTE SENS ENVIRON, V196, P56, DOI 10.1016/j.rse.2017.05.001
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu QK, 2017, REMOTE SENS LETT, V8, P1210, DOI 10.1080/2150704X.2017.1375610
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Rahman F, 2018, IEEE GLOB CONF SIG, P958, DOI 10.1109/GlobalSIP.2018.8646512
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song XL, 2011, PROCEDIA ENVIRON SCI, V11, P238, DOI 10.1016/j.proenv.2011.12.037
   Srivastava N, 2014, J MACH LEARN RES, V15, P2949
   Tan K, 2019, IEEE J-STARS, V12, P627, DOI 10.1109/JSTARS.2019.2892975
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Tang YQ, 2011, INT J REMOTE SENS, V32, P5719, DOI 10.1080/01431161.2010.507263
   Touati R, 2019, IEEE J-STARS, V12, P3588, DOI 10.1109/JSTARS.2019.2934602
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang X, 2019, IEEE T GEOSCI REMOTE, V57, P7232, DOI 10.1109/TGRS.2019.2912468
   Wu XD, 2014, IEEE T KNOWL DATA EN, V26, P97, DOI 10.1109/TKDE.2013.109
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang XY, 2016, REMOTE SENS ENVIRON, V178, P172, DOI 10.1016/j.rse.2016.03.015
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 48
TC 22
Z9 23
U1 12
U2 27
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JAN
PY 2020
VL 12
IS 2
AR 205
DI 10.3390/rs12020205
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KO5DK
UT WOS:000515569800004
OA gold
DA 2022-01-04
ER

PT J
AU Liu, JF
   Chen, KM
   Xu, GL
   Sun, X
   Yan, ML
   Diao, WH
   Han, HZ
AF Liu, Junfu
   Chen, Keming
   Xu, Guangluan
   Sun, Xian
   Yan, Menglong
   Diao, Wenhui
   Han, Hongzhe
TI Convolutional Neural Network-Based Transfer Learning for Optical Aerial
   Images Change Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Feature extraction; Semantics; Data models; Training; Remote sensing;
   Optical imaging; Training data; Change detection; convolutional neural
   network 20 (CNN); deep learning; optical aerial image; transfer learning
AB Considering the lack of labeled training data sets for the supervised change detection task, in this letter, we try to relieve this problem by proposing a convolutional neural network (CNN)-based change detection method with a newly designed loss function to achieve transfer learning among different data sets. To reach this goal, we first pretrain a U-Net model on an open source data set by taking advantages of the relatively sufficient training data used for the supervised semantic segmentation task. Then, we minimize a skillfully designed loss function to combine the high-level features extracted from the pretrained model and the semantic information contained in the change detection data set, by which a transfer learning is achieved. Third, we compute the distance between the feature vectors obtained from the above step and produce a difference map. Finally, a simple clustering method used on the difference map can even obtain satisfied change map. Experiments carried out on typical optical aerial image data sets validate that the proposed approach compares favorably to the state-of-the-art unsupervised methods.
C1 [Liu, Junfu] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing 100049, Peoples R China.
   [Liu, Junfu; Chen, Keming; Xu, Guangluan; Sun, Xian; Yan, Menglong; Diao, Wenhui] Chinese Acad Sci, Inst Elect, Key Lab Technol Geospatial Informat Proc & Applic, Beijing 100190, Peoples R China.
   [Han, Hongzhe] Chinese Acad Sci, Inst Elect, Beijing 100190, Peoples R China.
   [Han, Hongzhe] Chinese Acad Sci, Cloud Comp Ctr, Dongguan 523008, Peoples R China.
RP Chen, KM (corresponding author), Chinese Acad Sci, Inst Elect, Key Lab Technol Geospatial Informat Proc & Applic, Beijing 100190, Peoples R China.
EM kmchen.ie@gmail.com
OI Liu, Junfu/0000-0002-7316-4562; Sun, Xian/0000-0002-0038-9816
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61302170]; Dongguan Science and Technology
   Fund [2016108101008]
FX The work of K. Chen was supported by the National Natural Science
   Foundation of China under Grant 61302170, and the work of H. Han was
   supported by the Dongguan Science and Technology Fund under Grant
   2016108101008.
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Lin JZ, 2018, IEEE J-STARS, V11, P4048, DOI 10.1109/JSTARS.2018.2874225
   Lin JZ, 2017, IEEE GEOSCI REMOTE S, V14, P1656, DOI 10.1109/LGRS.2017.2723763
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Singh P, 2014, INT C PATT RECOG, P924, DOI 10.1109/ICPR.2014.169
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
NR 16
TC 20
Z9 21
U1 8
U2 45
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD JAN
PY 2020
VL 17
IS 1
BP 127
EP 131
DI 10.1109/LGRS.2019.2916601
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA KA0ZF
UT WOS:000505528400026
DA 2022-01-04
ER

PT J
AU Guo, QZ
   Wu, XX
   Sang, X
   Fu, Y
   Zang, YC
   Gong, XM
AF Guo, Qiaozhen
   Wu, Xiaoxu
   Sang, Xiao
   Fu, Ying
   Zang, Yuchen
   Gong, Xuemei
TI An integrated study on change detection and environment evaluation of
   surface water
SO APPLIED WATER SCIENCE
LA English
DT Article
DE Surface water; Extraction; Change detection; Environment evaluation;
   Landsat
ID QUALITY ASSESSMENT; INDEX NDWI; CHINA
AB Surface water pollution is one of the serious environment pollution problems, posing threat to human and other creatures. Extraction, change detection and environment evaluation of surface water are prerequisite for water resource management. Undoubtedly, remote sensing data play an important role in these researches because of its large geographic coverage and high temporal frequency. In this study, the Tianjin Binhai New Area was chosen as the study area and the surface water extraction method Modified Normalized Difference Water Index (MNDWI) was used by combining with adaptive dynamic threshold to extract surface water and detect its change. Comparing with single-band threshold, model of multi-band spectral relationship, Iterative Self-organizing Data Analysis Technique Algorithm and MNDWI, MNDWI-based adaptive dynamic threshold method performed better, which considered the influence of background. Analysis on dynamic change of water showed the area of lake and river had increased and the area of seawater had decreased. Meanwhile, the correlation analysis between area change of surface water and impact factors indicated both climatic and anthropogenic factors made positive contribution to the present water environment situation. Finally, an improved model of surface water environment evaluation was established to evaluate water quality by combining genetic algorithm (GA) and backpropagation (BP) neural network model. And the test results proved that the optimized GA-BP neural network is better than the single BP neural network. The environment evaluation indicated that water quality of the Haihe River section in the study area was poor. Therefore, water environment protection should be strengthened in this area. Some suggestions on practical management were given accordingly.
C1 [Guo, Qiaozhen; Sang, Xiao; Fu, Ying; Zang, Yuchen] Tianjin Chengjian Univ, Sch Geol & Geomat, Tianjin 300384, Peoples R China.
   [Wu, Xiaoxu] Beijing Normal Univ, Coll Global Change & Earth Syst Sci, State Key Lab Remote Sensing Sci, Beijing 100875, Peoples R China.
   [Gong, Xuemei] Beijing Inst Technol, Sch Opt & Photon, Beijing 100081, Peoples R China.
RP Guo, QZ (corresponding author), Tianjin Chengjian Univ, Sch Geol & Geomat, Tianjin 300384, Peoples R China.
EM gqiaozhen@tcu.edu.cn; wuxx@bnu.edu.cn; sangxiao1993@126.com;
   fuying19900707@163.com; m15822289627@163.com; gxmgxm201303@163.com
FU Natural Science Foundation of Tianjin, ChinaNatural Science Foundation
   of Tianjin [18JCYBJC90900]; Scientific Research Project of Tianjin
   municipal Education Commission, China [2018KJ164]
FX This work was financially supported by the Natural Science Foundation of
   Tianjin, China (Grant No. 18JCYBJC90900) and the Scientific Research
   Project of Tianjin municipal Education Commission, China (Grant No.
   2018KJ164).
CR An Y, 2014, INT J ENV RES PUB HE, V11, P3507, DOI 10.3390/ijerph110403507
   Bukata RP, 2013, J GREAT LAKES RES, V39, P2, DOI 10.1016/j.jglr.2013.04.001
   Chen J, 2013, ENVIRON EARTH SCI, V69, P2709, DOI 10.1007/s12665-012-2093-1
   Chow MF, 2016, ENVIRON EARTH SCI, V75, DOI 10.1007/s12665-015-4922-5
   El Din ES, 2017, INT J REMOTE SENS, V38, P1023, DOI 10.1080/01431161.2016.1275056
   Li WB, 2013, REMOTE SENS-BASEL, V5, P5530, DOI 10.3390/rs5115530
   McFeeters SK, 2013, REMOTE SENS-BASEL, V5, P3544, DOI 10.3390/rs5073544
   Meng XJ, 2015, SUSTAINABILITY-BASEL, V7, P2000, DOI 10.3390/su7022000
   Nechad B, 2010, REMOTE SENS ENVIRON, V114, P854, DOI 10.1016/j.rse.2009.11.022
   Oh J, 2017, INT CONF UBIQ ROBOT, P331
   Palmer SCJ, 2015, REMOTE SENS ENVIRON, V157, P1, DOI 10.1016/j.rse.2014.09.021
   Perrin JL, 2014, J HYDROL, V510, P26, DOI 10.1016/j.jhydrol.2013.12.002
   Rokni K, 2014, REMOTE SENS-BASEL, V6, P4173, DOI 10.3390/rs6054173
   Sun FD, 2012, INT J REMOTE SENS, V33, P6854, DOI 10.1080/01431161.2012.692829
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yu F, 2014, APPL ENERG, V134, P102, DOI 10.1016/j.apenergy.2014.07.104
NR 16
TC 2
Z9 2
U1 3
U2 9
PU SPRINGER HEIDELBERG
PI HEIDELBERG
PA TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY
SN 2190-5487
EI 2190-5495
J9 APPL WATER SCI
JI Appl. Water Sci.
PD DEC 5
PY 2019
VL 10
IS 1
AR 28
DI 10.1007/s13201-019-1109-3
PG 15
WC Water Resources
SC Water Resources
GA KQ2OX
UT WOS:000516769100002
OA gold
DA 2022-01-04
ER

PT J
AU Liu, RY
   Kuffer, M
   Persello, C
AF Liu, Ruoyun
   Kuffer, Monika
   Persello, Claudio
TI The Temporal Dynamics of Slums Employing a CNN-Based Change Detection
   Approach
SO REMOTE SENSING
LA English
DT Article
DE slum; informal settlement; deprivation; India; machine learning; fully
   convolutional networks; urban dynamics; change detection
ID FULLY CONVOLUTIONAL NETWORKS; LAND-COVER CHANGE; SEMANTIC SEGMENTATION;
   TRANSFERABILITY; ACCURACY; AREAS
AB Along with rapid urbanization, the growth and persistence of slums is a global challenge. While remote sensing imagery is increasingly used for producing slum maps, only a few studies have analyzed their temporal dynamics. This study explores the potential of fully convolutional networks (FCNs) to analyze the temporal dynamics of small clusters of temporary slums using very high resolution (VHR) imagery in Bangalore, India. The study develops two approaches based on FCNs. The first approach uses a post-classification change detection, and the second trains FCNs to directly classify the dynamics of slums. For both approaches, the performances of 3 x 3 kernels and 5 x 5 kernels of the networks were compared. While classification results of individual years exhibit a relatively high F1-score (3 x 3 kernel) of 88.4% on average, the change accuracies are lower. The post-classification results obtained an F1-score of 53.8% and the change-detection networks obtained an F1-score of 53.7%. According to the trajectory error matrix (TEM), the post-classification results scored higher for the overall accuracy but lower for the accuracy difference of change trajectories than the change-detection networks. Although the two methods did not have significant differences in terms of accuracy, the change-detection network was less noisy. Within our study area, the areas of slums show a small overall decrease; the annual growth of slums (between 2012 and 2016) was 7173 m(2), in contrast to an annual decline of 8390 m(2). However, these numbers hid the spatial dynamics, which were much larger. Interestingly, areas where slums disappeared commonly changed into green areas, not into built-up areas. The proposed change-detection network provides a robust map of the locations of changes with lower confidence about the exact boundaries. This shows the potential of FCNs for detecting the dynamics of slums in VHR imagery.
C1 [Liu, Ruoyun; Kuffer, Monika; Persello, Claudio] Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7514 AE Enschede, Netherlands.
RP Kuffer, M (corresponding author), Univ Twente, Fac Geoinformat Sci & Earth Observat ITC, NL-7514 AE Enschede, Netherlands.
EM liu37039@alumni.itc.nl; M.Kuffer@utwente.nl; C.Persello@utwente.nl
RI Persello, Claudio/AAN-2070-2020; Kuffer, Monika/R-6199-2017
OI Persello, Claudio/0000-0003-3742-5398; Kuffer,
   Monika/0000-0002-1915-2069
FU  [:27015G05]
FX The authors greatly appreciate the support provided by the project
   Dynaslum (Data Driven Modelling and Decision Support for Slums) project
   (contract number:27015G05), which are managed by the Dutch national
   research council (NWO), for providing the data for this research.
CR Ajami A, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111282
   [Anonymous], 2015, TRANSF OUR WORLD 203
   Bachofer F., 2018, REMOTE SENSING MEASU
   Badmos OS, 2019, COMPUT ENVIRON URBAN, V77, DOI 10.1016/j.compenvurbsys.2019.101369
   Bergado JR, 2018, IEEE T GEOSCI REMOTE, V56, P6361, DOI 10.1109/TGRS.2018.2837357
   Bergado JR, 2016, INT GEOSCI REMOTE SE, P1516, DOI 10.1109/IGARSS.2016.7729387
   Duque JC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090895
   Foody GM, 2010, REMOTE SENS ENVIRON, V114, P2271, DOI 10.1016/j.rse.2010.05.003
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Government of India, 2015, SLUMS IND STAT COMP
   Kit O, 2013, ISPRS J PHOTOGRAMM, V83, P130, DOI 10.1016/j.isprsjprs.2013.06.009
   Kohli D, 2016, COMPUT ENVIRON URBAN, V60, P37, DOI 10.1016/j.compenvurbsys.2016.07.010
   Kohli D, 2013, REMOTE SENS-BASEL, V5, P4209, DOI 10.3390/rs5094209
   Kohli D, 2012, COMPUT ENVIRON URBAN, V36, P154, DOI 10.1016/j.compenvurbsys.2011.11.001
   Koltun, 2015, 1511 ARXIV, DOI DOI 10.16373/J.CNKI.AHR.150049.ISSN
   Krishna A, 2014, ENVIRON URBAN, V26, P568, DOI 10.1177/0956247814537958
   Kuffer M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7110428
   Kuffer M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060455
   Kuffer M, 2016, IEEE J-STARS, V9, P1830, DOI 10.1109/JSTARS.2016.2538563
   Kux H., 2008, OBJECT BASED IMAGE A, P531, DOI DOI 10.1007/978-3-540-77058-9_29
   Li BL, 2009, INT J REMOTE SENS, V30, P1283, DOI 10.1080/01431160802474022
   Liu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040365
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mahabir R, 2016, REG STUD REG SCI, V3, P399, DOI 10.1080/21681376.2016.1229130
   Mboga N, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111106
   Molenaar M, 2000, INT ARCH PHOTOGRAMM, VXXXIII, P670
   Ng A. Y., 2013, P 30 INT C MACH LEAR, P3
   Paisitkriangkrai S, 2016, IEEE J-STARS, V9, P2868, DOI 10.1109/JSTARS.2016.2582921
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Pratomo J, 2018, EUR J REMOTE SENS, V51, P838, DOI 10.1080/22797254.2018.1496798
   Radoux J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070646
   Ranguelova E, 2019, EUR J REMOTE SENS, V52, P40, DOI 10.1080/22797254.2018.1535838
   Roy D, 2018, CITIES, V74, P269, DOI 10.1016/j.cities.2017.12.014
   Sun WW, 2018, IEEE GEOSCI REMOTE S, V15, P474, DOI 10.1109/LGRS.2018.2795531
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   UN-HABITAT, 2006, STAT WORLDS CIT 2006
   United Nations, 2018, UN DESA WORLD URB PR
   Veljanovski T., 2012, REMOTE SENSING APPL, P407
   Verma D, 2019, HABITAT INT, V88, DOI 10.1016/j.habitatint.2019.04.008
   Wang J, 2019, REMOTE SENS ENVIRON, V234, DOI 10.1016/j.rse.2019.111448
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wurm M, 2019, ISPRS J PHOTOGRAMM, V150, P59, DOI 10.1016/j.isprsjprs.2019.02.006
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 43
TC 16
Z9 16
U1 5
U2 10
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 1
PY 2019
VL 11
IS 23
AR 2844
DI 10.3390/rs11232844
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KE2IO
UT WOS:000508382100125
OA Green Published, gold
DA 2022-01-04
ER

PT J
AU Luo, B
   Hu, CD
   Su, X
   Wang, YJ
AF Luo, Bin
   Hu, Chudi
   Su, Xin
   Wang, Yajun
TI Differentially Deep Subspace Representation for Unsupervised Change
   Detection of SAR Images
SO REMOTE SENSING
LA English
DT Article
DE Differentially Deep Subspace Representation (DDSR); AutoEncoder-like
   (AE-like) network; SAR; Unsupervised Change Detection
ID AUTOMATIC CHANGE DETECTION; CHANGE VECTOR ANALYSIS
AB Temporal analysis of synthetic aperture radar (SAR) time series is a basic and significant issue in the remote sensing field. Change detection as well as other interpretation tasks of SAR images always involves non-linear/non-convex problems. Complex (non-linear) change criteria or models have thus been proposed for SAR images, instead of direct difference (e.g., change vector analysis) with/without linear transform (e.g., Principal Component Analysis, Slow Feature Analysis) used in optical image change detection. In this paper, inspired by the powerful deep learning techniques, we present a deep autoencoder (AE) based non-linear subspace representation for unsupervised change detection with multi-temporal SAR images. The proposed architecture is built upon an autoencoder-like (AE-like) network, which non-linearly maps the input SAR data into a latent space. Unlike normal AE networks, a self-expressive layer performing like principal component analysis (PCA) is added between the encoder and the decoder, which further transforms the mapped SAR data to mutually orthogonal subspaces. To make the proposed architecture more efficient at change detection tasks, the parameters are trained to minimize the representation difference of unchanged pixels in the deep subspace. Thus, the proposed architecture is namely the Differentially Deep Subspace Representation (DDSR) network for multi-temporal SAR images change detection. Experimental results on real datasets validate the effectiveness and superiority of the proposed architecture.
C1 [Luo, Bin; Hu, Chudi; Wang, Yajun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Su, Xin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
RP Su, X (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM lluob@whu.edu.cn; chudihu@whu.edu.cn; xinsu.rs@whu.edu.cn;
   yjwangisu@whu.edu.cn
FU National Science Foundation of China (NSFC)National Natural Science
   Foundation of China (NSFC) [61801332]
FX This research was funded by National Science Foundation of China (NSFC)
   (grant number 61801332).
CR Atasever UH, 2016, NEURAL NETW WORLD, V26, P141, DOI 10.14311/NNW.2016.26.008
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Chen YP, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.045018
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P9976, DOI 10.1109/TGRS.2019.2930682
   Fang B, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111292
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Ji SP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111343
   LEVIEN LM, 1999, P ASPRS ANN C 17 21, V1, P22
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liwicki S, 2015, IEEE T IMAGE PROCESS, V24, P2955, DOI 10.1109/TIP.2015.2428052
   Lombardo P, 2001, IEE P-RADAR SON NAV, V148, P200, DOI 10.1049/ip-rsn:20010114
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Noordermeer L, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182145
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Peng X, 2018, IEEE T IMAGE PROCESS, V27, P5076, DOI 10.1109/TIP.2018.2848470
   Preiss Mark, 2006, COHERENT CHANGE DETE
   Quin G, 2014, IEEE T GEOSCI REMOTE, V52, P5349, DOI 10.1109/TGRS.2013.2288271
   Reid, 2017, ADV NEURAL INFORM PR, P24
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Rosa RAS, 2015, INT GEOSCI REMOTE SE, P2797, DOI 10.1109/IGARSS.2015.7326395
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Su X, 2015, ISPRS J PHOTOGRAMM, V101, P247, DOI 10.1016/j.isprsjprs.2014.12.012
   Taubenbock H, 2012, REMOTE SENS ENVIRON, V117, P162, DOI 10.1016/j.rse.2011.09.015
   Wang C., 2019, ADV MULTIMEDIA UBIQU, P28
   Wessels KJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8110888
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xu R, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101578
   Xv J., 2019, J APPL REMOTE SENS, V13
   Zhang HY, 2017, IEEE ACCESS, V5, P2696, DOI 10.1109/ACCESS.2017.2672780
NR 37
TC 7
Z9 7
U1 8
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 1
PY 2019
VL 11
IS 23
AR 2740
DI 10.3390/rs11232740
PG 18
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KE2IO
UT WOS:000508382100021
OA gold
DA 2022-01-04
ER

PT J
AU Zhang, XK
   Shi, WZ
   Lv, ZY
   Peng, FF
AF Zhang, Xiaokang
   Shi, Wenzhong
   Lv, Zhiyong
   Peng, Feifei
TI Land Cover Change Detection from High-Resolution Remote Sensing Imagery
   Using Multitemporal Deep Feature Collaborative Learning and a
   Semi-supervised Chan-Vese Model
SO REMOTE SENSING
LA English
DT Article
DE change detection; deep feature learning; Chan-Vese model;
   high-resolution remote sensing imagery; semi-supervised learning;
   uncertainty analysis
ID UNSUPERVISED CHANGE DETECTION; LEVEL SET EVOLUTION; SATELLITE IMAGES;
   CLASSIFICATION; TREES
AB This paper presents a novel approach for automatically detecting land cover changes from multitemporal high-resolution remote sensing images in the deep feature space. This is accomplished by using multitemporal deep feature collaborative learning and a semi-supervised Chan-Vese (SCV) model. The multitemporal deep feature collaborative learning model is developed to obtain the multitemporal deep feature representations in the same high-level feature space and to improve the separability between changed and unchanged patterns. The deep difference feature map at the object-level is then extracted through a feature similarity measure. Based on the deep difference feature map, the SCV model is proposed to detect changes in which labeled patterns automatically derived from uncertainty analysis are integrated into the energy functional to efficiently drive the contour towards accurate boundaries of changed objects. The experimental results obtained on the four data sets acquired by different high-resolution sensors corroborate the effectiveness of the proposed approach.
C1 [Zhang, Xiaokang; Shi, Wenzhong] Hong Kong Polytech Univ, Dept Land Survey & Geoinformat, Hong Kong, Peoples R China.
   [Zhang, Xiaokang] Hubei Water Resources Res Inst, Hubei Soil & Water Conservat Engn Res Ctr, Wuhan 430070, Peoples R China.
   [Lv, Zhiyong] XiAn Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
   [Peng, Feifei] Cent China Normal Univ, Coll Urban & Environm Sci, Wuhan 430079, Peoples R China.
RP Shi, WZ (corresponding author), Hong Kong Polytech Univ, Dept Land Survey & Geoinformat, Hong Kong, Peoples R China.
EM xiazhang@polyu.edu.hk; lswzshi@polyu.edu.hk; zhiyonglyu@xaut.edu.cn;
   feifpeng@mail.ccnu.edu.cn
OI Zhang, Xiaokang/0000-0002-6127-4801
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801323,41701511]
FX This research was funded by the National Natural Science Foundation of
   China under grants 41801323,41701511.
CR Ardila JP, 2012, REMOTE SENS ENVIRON, V124, P413, DOI 10.1016/j.rse.2012.05.027
   Bischke B, 2019, IEEE IMAGE PROC, P1480, DOI 10.1109/ICIP.2019.8803050
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Blaschke T, 2011, REMOTE SENS-BASEL, V3, P1743, DOI 10.3390/rs3081743
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cai LP, 2016, INT J REMOTE SENS, V37, P5457, DOI 10.1080/01431161.2016.1232871
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Foley JA, 2005, SCIENCE, V309, P570, DOI 10.1126/science.1111772
   Ghosh S, 2014, APPL SOFT COMPUT, V15, P1, DOI 10.1016/j.asoc.2013.09.010
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gu HY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040590
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Homer C, 2015, PHOTOGRAMM ENG REM S, V81, P345, DOI 10.14358/PERS.81.5.345
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Im J, 2007, REMOTE SENS ENVIRON, V106, P89, DOI 10.1016/j.rse.2006.07.019
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei T, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091381
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Li H, 2015, IEEE GEOSCI REMOTE S, V12, P582, DOI 10.1109/LGRS.2014.2352264
   Li ZB, 2016, REMOTE SENS ENVIRON, V175, P215, DOI 10.1016/j.rse.2016.01.003
   Liu W, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010049
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lv ZY, 2019, IEEE T GEOSCI REMOTE, V57, P9554, DOI 10.1109/TGRS.2019.2927659
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Lv ZY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111809
   Lv ZY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030472
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Mahdianpari M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071119
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Neagoe VE, 2014, IEEE J-STARS, V7, P3525, DOI 10.1109/JSTARS.2014.2330808
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   Sesnie SE, 2008, REMOTE SENS ENVIRON, V112, P2145, DOI 10.1016/j.rse.2007.08.025
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   Shi WZ, 2015, REMOTE SENS-BASEL, V7, P7846, DOI 10.3390/rs70607846
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Vincent P., 2008, P 25 INT C MACH LEAR, V10, P1096
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030298
   Xie J., 2012, P ANN C NEUR INF PRO, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang XD, 2017, IEEE J-STARS, V10, P3373, DOI 10.1109/JSTARS.2017.2672736
   Zhang XK, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212509
   Zhang XK, 2017, EUR J REMOTE SENS, V50, P202, DOI 10.1080/22797254.2017.1308236
   Zhang XK, 2017, REMOTE SENS LETT, V8, P811, DOI 10.1080/2150704X.2017.1317929
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
NR 64
TC 6
Z9 6
U1 12
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD DEC 1
PY 2019
VL 11
IS 23
AR 2787
DI 10.3390/rs11232787
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA KE2IO
UT WOS:000508382100068
OA gold
DA 2022-01-04
ER

PT J
AU Du, B
   Ru, LX
   Wu, C
   Zhang, LP
AF Du, Bo
   Ru, Lixiang
   Wu, Chen
   Zhang, Liangpei
TI Unsupervised Deep Slow Feature Analysis for Change Detection in
   Multi-Temporal Remote Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Feature extraction; Remote sensing; Change detection algorithms;
   Detection algorithms; Eigenvalues and eigenfunctions; Artificial neural
   networks; Training; Change detection; deep network; remote sensing
   images; slow feature analysis (SFA)
ID CLASSIFICATION; LANDSCAPE; PCANET; MAD
AB Change detection has been a hotspot in the remote sensing technology for a long time. With the increasing availability of multi-temporal remote sensing images, numerous change detection algorithms have been proposed. Among these methods, image transformation methods with feature extraction and mapping could effectively highlight the changed information and thus has a better change detection performance. However, the changes of multi-temporal images are usually complex, and the existing methods are not effective enough. In recent years, the deep network has shown its brilliant performance in many fields, including feature extraction and projection. Therefore, in this paper, based on the deep network and slow feature analysis (SFA) theory, we proposed a new change detection algorithm for multi-temporal remotes sensing images called deep SFA (DSFA). In the DSFA model, two symmetric deep networks are utilized for projecting the input data of bi-temporal imagery. Then, the SFA module is deployed to suppress the unchanged components and highlight the changed components of the transformed features. The change vector analysis pre-detection is employed to find unchanged pixels with high confidence as training samples. Finally, the change intensity is calculated with chi-square distance and the changes are determined by threshold algorithms. The experiments are performed on two real-world data sets and a public hyperspectral data set. The visual comparison and the quantitative evaluation have shown that DSFA could outperform the other state-of-the-art algorithms, including other SFA-based and deep learning methods.
C1 [Du, Bo; Ru, Lixiang; Wu, Chen; Zhang, Liangpei] Wuhan Univ, Sch Comp Sci, Wuhan, Peoples R China.
   [Du, Bo] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430072, Peoples R China.
   [Wu, Chen; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
RP Wu, C (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430072, Peoples R China.
EM gunspace@163.com; rulixiang@whu.edu.cn; chen.wu@whu.edu.cn;
   zlp62@whu.edu.cn
RI Ru, Lixiang/AAR-3320-2020
OI Ru, Lixiang/0000-0002-9129-2453; Wu, Chen/0000-0001-6461-8377
FU National Key R&D Program of China [2018YFA0605500]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61601333, 61822113, 41801285, 41871243]; Natural Science
   Foundation of Hubei ProvinceNatural Science Foundation of Hubei Province
   [2018CFA050]; National Key Research and Development Program
   [2017YFC1502505]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018YFA0605500, in part by the National Natural Science
   Foundation of China under Grant 61601333, Grant 61822113, Grant
   41801285, and Grant 41871243, in part by the Natural Science Foundation
   of Hubei Province under Grant 2018CFA050, and in part by the National
   Key Research and Development Program under Grant 2017YFC1502505.
   (Corresponding author: Chen Wu.)
CR Ahlqvist O, 2008, REMOTE SENS ENVIRON, V112, P1226, DOI 10.1016/j.rse.2007.08.012
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Demir B, 2012, IEEE T GEOSCI REMOTE, V50, P1930, DOI 10.1109/TGRS.2011.2168534
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du B, 2013, NEUROCOMPUTING, V120, P72, DOI 10.1016/j.neucom.2012.08.056
   Du B, 2012, INT J FUZZY SYST, V14, P272
   Franzius M., 2008, P INT C ART NEUR NET
   Franzius M, 2011, NEURAL COMPUT, V23, P2289, DOI 10.1162/NECO_a_00171
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gueguen L, 2011, IEEE T GEOSCI REMOTE, V49, P4503, DOI 10.1109/TGRS.2011.2141999
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Huang Z, 2010, INT J REMOTE SENS, V31, P1543, DOI 10.1080/01431160903475399
   Kennedy RE, 2009, REMOTE SENS ENVIRON, V113, P1382, DOI 10.1016/j.rse.2008.07.018
   Li MK, 2019, IEEE GEOSCI REMOTE S, V16, P402, DOI 10.1109/LGRS.2018.2876616
   Liu DS, 2008, REMOTE SENS ENVIRON, V112, P2222, DOI 10.1016/j.rse.2007.10.002
   Livescu K, 2013, INT C MACH LEARN, P1247
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Luo H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10070980
   Marchesi S, 2009, INT GEOSCI REMOTE SE, P1231, DOI 10.1109/IGARSS.2009.5418265
   Nielsen A. A., 1997, 199711 TU DENM DEP M
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Pedersen, 2012, MATRIX COOKBOOK
   Ren SQ, 2015, ADV NEUR IN, V28
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Wiskott, 2011, SCHOLARPEDIA, V6, P5282, DOI [10.4249/scholarpedia.5282, DOI 10.4249/scholarpedia.5282]
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2017, IEEE T GEOSCI REMOTE, V55, P2367, DOI 10.1109/TGRS.2016.2642125
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wulder MA, 2008, REMOTE SENS ENVIRON, V112, P796, DOI 10.1016/j.rse.2007.06.013
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhang LP, 2013, IEEE T GEOSCI REMOTE, V51, P242, DOI [10.1109/TGRS.2012.2197860, 10.1109/TGRS.2011.2180392]
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
NR 49
TC 87
Z9 87
U1 44
U2 97
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD DEC
PY 2019
VL 57
IS 12
BP 9976
EP 9992
DI 10.1109/TGRS.2019.2930682
PG 17
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA KA3MB
UT WOS:000505701800036
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Larabi, ME
   Chaib, S
   Bakhti, K
   Hasni, K
   Bouhlala, MA
AF Larabi, Mohammed El Amin
   Chaib, Souleyman
   Bakhti, Khadidja
   Hasni, Kamel
   Bouhlala, Mohammed Amine
TI High-resolution optical remote sensing imagery change detection through
   deep transfer learning
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; deep learning; convolutional neural network; remote
   sensing; hyperfeatures; hypervectors
ID BUILDING CHANGE DETECTION; SENSED IMAGES; MAP
AB Change detection is a challenging task that has received much attention in the remote sensing field. Whereas numerous remote sensing change detection methods have been developed, the efficiency of these approaches is insufficient to meet the real-world applications' requirements. Recently, deep learning methods have been largely used for remote sensing imagery change detection, most of these approaches are limited by their training dataset. However, adapting a pretrained convolutional neural network (CNN) on an image classification task to change detection is extremely challenging. An automatic land cover/use change detection approach based on fast and accurate frameworks for optical high-resolution remote sensing imagery is proposed. The fast framework is designed for applications that require immediate results with less complexity. The accurate framework is designed for applications that require high levels of precision, it decomposes large images into small processing blocks and forwards them into CNN. The proposed frameworks can learn transferable features from one task to another and escape the use of the expensive and inaccurate handcrafted features and the requirements of the big training dataset. A number of experiments were carried out to validate the proposed approach on three real bitemporal images. The experimental results illustrate the superiority of the proposed approach over other state-of-the-art methods. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Larabi, Mohammed El Amin; Bakhti, Khadidja; Hasni, Kamel; Bouhlala, Mohammed Amine] Algerian Space Agcy, Ctr Tech Spatiales, Ave Palestine, Arzew, Algeria.
   [Larabi, Mohammed El Amin] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Chaib, Souleyman] Harbin Inst Technol, Sch Comp Sci, Harbin, Peoples R China.
   [Bakhti, Khadidja] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing, Peoples R China.
RP Larabi, ME (corresponding author), Algerian Space Agcy, Ctr Tech Spatiales, Ave Palestine, Arzew, Algeria.; Larabi, ME (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
EM arabi.mohamed.lamine@gmail.com
RI CHAIB, SOULEYMAN/AAZ-2826-2020
CR Bayarjargal Y, 2006, REMOTE SENS ENVIRON, V105, P9, DOI 10.1016/j.rse.2006.06.003
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2003, IEEE T GEOSCI REMOTE, V41, P2455, DOI 10.1109/TGRS.2003.817268
   Bruzzone L, 2011, INT GEOSCI REMOTE SE, P229, DOI 10.1109/IGARSS.2011.6048934
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dimyati M, 1996, INT J REMOTE SENS, V17, P931, DOI 10.1080/01431169608949056
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Donahue J, 2014, PR MACH LEARN RES, V32
   Gamanya R, 2009, EXPERT SYST APPL, V36, P571, DOI 10.1016/j.eswa.2007.09.067
   GIRSHICK R, 2014, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   GONG P, 1992, INT J REMOTE SENS, V13, P773, DOI 10.1080/01431169208904151
   Farji-Brener AG, 2015, ECOLOGY, V96, P510, DOI 10.1890/14-0220.1
   Hall O, 2003, INT J APPL EARTH OBS, V4, P311, DOI [DOI 10.1016/S0303-2434(03)00010-, DOI 10.1016/S0303-2434(03)00010-2]
   Hecheltjen A, 2014, REMOTE SENS DIGIT IM, V18, P145, DOI 10.1007/978-94-007-7969-3_10
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton G. E., 2012, ARXIV PREPRINT ARXIV
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang X, 2014, REMOTE SENS LETT, V5, P713, DOI 10.1080/2150704X.2014.963732
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   McDermid GJ, 2008, CAN J REMOTE SENS, V34, P462, DOI 10.5589/m08-061
   Niemeyer I, 2006, VERIFYING TREATY COMPLIANCE: LIMITING WEAPONS OF MASS DESTRUCTION AND MONITORING KYOTO PROTOCOL PROVISIONS, P335, DOI 10.1007/3-540-33854-3_15
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Oliva, 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Prabhu K.M.M, 2013, WINDOW FUNCTIONS THE
   Ranzato Marc'Aurelio, 2007, P IEEE COMP SOC C CO
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang T., 2012, P 21 INT C PATT REC
   Yan S., 2013, ARXIV13124400, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 51
TC 5
Z9 5
U1 12
U2 33
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD NOV 26
PY 2019
VL 13
IS 4
AR 046512
DI 10.1117/1.JRS.13.046512
PG 18
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA KB0FR
UT WOS:000506175100001
DA 2022-01-04
ER

PT J
AU Gao, YH
   Gao, F
   Dong, JY
   Wang, SK
AF Gao, Yunhao
   Gao, Feng
   Dong, Junyu
   Wang, Shengke
TI Change Detection From Synthetic Aperture Radar Images Based on Channel
   Weighting-Based Deep Cascade Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Feature extraction; Synthetic aperture radar; Radar polarimetry;
   Speckle; Training; Deep learning; Reliability; Change detection; deep
   cascade network (DCNet); deep learning; residual learning; synthetic
   aperture radar (SAR)
ID UNSUPERVISED CHANGE DETECTION; CONVOLUTIONAL NETWORK; NEURAL-NETWORKS;
   FEATURE FUSION
AB Deep learning methods have recently demonstrated their significant capability for synthetic aperture radar (SAR) image change detection. However, with the increase of network depth, convolutional neural networks often encounter some negative effects, such as overfitting and exploding gradients. In addition, the existing deep networks employed in SAR change detection tend to produce a lot of redundant features that affect the performance of the network. To solve the aforementioned problems, this article proposed a deep cascade network (DCNet) for SAR image change detection. On the one hand, a very DCNet is established to exploit discriminative features, and residual learning is introduced to solve the exploding gradients problem. In addition, a fusion mechanism is employed to combine the outputs of different hierarchical layers to further alleviate the exploding gradient problem. Moreover, a simple yet effective channel weighting-based module is designed for SAR change detection. Average pooling and max pooling are used to aggregate channel-wise information. Meaningful channel-wise features are emphasized and unnecessary ones are suppressed. Therefore, the similarity in feature maps can be reduced, and then, the classification performance of the DCNet is improved. Experimental results on four real SAR datasets demonstrated that the proposed DCNet can obtain better change detection performance than several competitive methods. Our codes are available at https://github.com/summitgao/SAR_CD_DCNet.
C1 [Gao, Yunhao; Gao, Feng; Dong, Junyu; Wang, Shengke] Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Peoples R China.
EM 914283361@qq.com; gaofeng@ouc.edu.cn; dongjunyu@ouc.edu.cn;
   neverme@ouc.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Key R&D Program of China [2018AAA0100602]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [41606198, 41576011]; Key R&D Program of Shandong Province
   [2019GHY11204]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018AAA0100602, in part by the National Natural Science
   Foundation of China under Grants 41606198 and 41576011, and in part by
   the Key R&D Program of Shandong Province under Grant 2019GHY11204.
CR Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   G-Michael T, 2016, IEEE J OCEANIC ENG, V41, P592, DOI 10.1109/JOE.2015.2465631
   Gao F, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.016010
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   GIRSHICK R, 2014, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jia L, 2016, IEEE GEOSCI REMOTE S, V13, P856, DOI 10.1109/LGRS.2016.2550666
   John V, 2015, IEEE T COMPUT IMAG, V1, P159, DOI 10.1109/TCI.2015.2480006
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li F, 2016, INT J REMOTE SENS, V37, P3232, DOI 10.1080/01431161.2016.1196838
   Lin HN, 2017, IEEE GEOSCI REMOTE S, V14, P1665, DOI 10.1109/LGRS.2017.2727515
   Liu F., 2019, IEEE T NEUR NET LEAR, V30, P1
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu QS, 2018, IEEE T GEOSCI REMOTE, V56, P117, DOI 10.1109/TGRS.2017.2743243
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Quan SN, 2018, IEEE J-STARS, V11, P458, DOI 10.1109/JSTARS.2017.2787591
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Su LZ, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.035014
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang RF, 2019, IEEE GEOSCI REMOTE S, V16, P554, DOI 10.1109/LGRS.2018.2878420
   Wang SN, 2016, REMOTE SENS LETT, V7, P1043, DOI 10.1080/2150704X.2016.1212417
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhao WT, 2017, COMM COM INF SC, V772, P566, DOI 10.1007/978-981-10-7302-1_47
NR 48
TC 12
Z9 12
U1 10
U2 20
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD NOV
PY 2019
VL 12
IS 11
BP 4517
EP 4529
DI 10.1109/JSTARS.2019.2953128
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA KE3CT
UT WOS:000508437700030
DA 2022-01-04
ER

PT J
AU Keshk, HM
   Yin, XC
AF Keshk, Hatem Magdy
   Yin, Xu-Cheng
TI Change Detection in SAR Images Based on Deep Learning
SO INTERNATIONAL JOURNAL OF AERONAUTICAL AND SPACE SCIENCES
LA English
DT Article
DE Change detection; SAR; Remote sensing; Deep learning
ID UNSUPERVISED CHANGE DETECTION; ALGORITHM; MODEL
AB Change detection in remote-sensing images is used to detect changes during different time periods on the surface of the Earth. Because of the advantages of synthetic aperture radar (SAR), which is not affected by time, weather or other conditions, change-detection technology based on SAR images has important research value. At present, this technology has attracted the attention of increasingly more researchers, and has also been used extensively in diverse fields, such as urban planning, disaster assessment, and forest early warning systems. Our objective in this paper is to combine both the change detection of SAR images with the deep neural networks to compare its efficiency with fuzzy clustering method and deep belief network. Our experiments, conducted on real data sets and theoretical analysis, indicates the advantages of the proposed method. Our results appear that proposed deep-learning algorithms can further improve the change-detection process.
C1 [Keshk, Hatem Magdy; Yin, Xu-Cheng] Univ Sci & Technol Beijing, Beijing, Peoples R China.
   [Keshk, Hatem Magdy] Natl Author Remote Sensing & Space Sci, Cairo, Egypt.
RP Keshk, HM (corresponding author), Univ Sci & Technol Beijing, Beijing, Peoples R China.; Keshk, HM (corresponding author), Natl Author Remote Sensing & Space Sci, Cairo, Egypt.
EM Hatem.magdy@narss.sci.eg
OI Keshk, Hatem/0000-0002-8043-1227
FU University of Science and Technology Beijing
FX This study was partially supported by University of Science and
   Technology Beijing.
CR Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chen Y, 2012, SCI CHINA INFORM SCI, V55, P1888, DOI 10.1007/s11432-012-4612-9
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Gong MG, 2014, INT J REMOTE SENS, V35, P4009, DOI 10.1080/01431161.2014.916054
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jiao L. C., 2017, DEEP LEARNING OPTIMI
   KESHK H, 2019, INT J SENS WIREL COM, V9, P1, DOI DOI 10.2174/2210327909666190207153858
   Kim SB, 2009, ANN REHABIL MED-ARM, V33, P333
   Lange S., 2010, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2010.5596468
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Lunetta RS, 1999, REMOTE SENSING CHANG
   Manonmani R., 2010, INT J GEOMAT GEOSCI, V4, P339
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Rathore N., 2013, INT J ADV RES COMPUT, V2, P243
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Su LZ, 2014, INT J REMOTE SENS, V35, P621, DOI 10.1080/01431161.2013.871596
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zeiler MD, 2013, ARXIV201313013557
   Zhang JF, 2003, INT GEOSCI REMOTE SE, P2436
   [张景发 Zhang Jingfa], 2002, [自然灾害学报, Journal of Natural Disasters], V11, P59
NR 30
TC 9
Z9 9
U1 8
U2 46
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 2093-274X
EI 2093-2480
J9 INT J AERONAUT SPACE
JI Int. J. Aeronaut. Space Sci.
PD JUN
PY 2020
VL 21
IS 2
BP 549
EP 559
DI 10.1007/s42405-019-00222-0
EA OCT 2019
PG 11
WC Engineering, Aerospace
SC Engineering
GA LR1KJ
UT WOS:000490629200001
DA 2022-01-04
ER

PT J
AU Kerner, HR
   Wagstaff, KL
   Bue, BD
   Gray, PC
   Bell, JF
   Ben Amor, H
AF Kerner, Hannah Rae
   Wagstaff, Kiri L.
   Bue, Brian D.
   Gray, Patrick C.
   Bell, James F., III
   Ben Amor, Heni
TI Toward Generalized Change Detection on Planetary Surfaces With
   Convolutional Autoencoders and Transfer Learning
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection algorithms; earth; machine learning; mars; moon; neural
   networks; remote sensing; supervised learning; unsupervised learning
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS; REMOTE-SENSING
   DATA; LAND-USE; NEURAL-NETWORKS; IMAGE-ANALYSIS; CLASSIFICATION; COVER;
   SYSTEM; INFORMATION
AB Ongoing planetary exploration missions are returning large volumes of image data. Identifying surface changes in these images, e.g., new impact craters, is critical for investigating many scientific hypotheses. Traditional approaches to change detection rely on image differencing and manual feature engineering. These methods can be sensitive to irrelevant variations in illumination or image quality and typically require before and after images to be coregistered, which itself is a major challenge. Additionally, most prior change detection studies have been limited to remote sensing images of earth. We propose a new deep learning approach for binary patch-level change detection involving transfer learning and nonlinear dimensionality reduction using convolutional autoencoders. Our experiments on diverse remote sensing datasets of Mars, the moon, and earth show that our methods can detect meaningful changes with high accuracy using a relatively small training dataset despite significant differences in illumination, image quality, imaging sensors, coregistration, and surface properties. We show that the latent representations learned by a convolutional autoencoder yield the most general representations for detecting change across surface feature types, scales, sensors, and planetary bodies.
C1 [Kerner, Hannah Rae] Univ Maryland, Dept Geog Sci, College Pk, MD 20742 USA.
   [Wagstaff, Kiri L.; Bue, Brian D.] CALTECH, Jet Prop Lab, 4800 Oak Grove Dr, Pasadena, CA 91109 USA.
   [Gray, Patrick C.] Duke Univ, Nicholas Sch Environm, Durham, NC 27710 USA.
   [Bell, James F., III] Arizona State Univ, Sch Earth & Space Explorat, Tempe, AZ 85282 USA.
   [Ben Amor, Heni] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85282 USA.
RP Kerner, HR (corresponding author), Univ Maryland, Dept Geog Sci, College Pk, MD 20742 USA.
EM hkerner@umd.edu; kiri.l.wagstaff@jpl.nasa.gov; bbue@jpl.nasa.gov;
   patrick.c.gray@duke.edu; Jim.Bell@asu.edu; hbenamor@asu.edu
RI ; Bell, James/D-3014-2016
OI Gray, Patrick/0000-0002-8997-5255; Wagstaff, Kiri/0000-0003-4401-5506;
   Bell, James/0000-0002-2006-4074
FU Jet Propulsion Laboratory, California Institute of Technology, Internal
   Strategic University Research Partnerships (SURP) program; National
   Aeronautics and Space AdministrationNational Aeronautics & Space
   Administration (NASA)
FX This work was supported by the Jet Propulsion Laboratory, California
   Institute of Technology, Internal Strategic University Research
   Partnerships (SURP) program under a contract with the National
   Aeronautics and Space Administration.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abd El-Kawy OR, 2011, APPL GEOGR, V31, P483, DOI 10.1016/j.apgeog.2010.10.012
   Alesheikh AA, 2007, INT J ENVIRON SCI TE, V4, P61, DOI 10.1007/BF03325962
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Camps-Valls G., 2009, KERNEL METHODS REMOT
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Castelluccio M., 2015, LAND USE CLASSIFICAT
   Castilla G., 2008, OBJECT BASED IMAGE A, P91, DOI DOI 10.1007/978-3-540-77058-9_5
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Dai XL, 1998, IEEE T GEOSCI REMOTE, V36, P1566, DOI 10.1109/36.718860
   Daubar IJ, 2013, ICARUS, V225, P506, DOI 10.1016/j.icarus.2013.04.009
   Daudt R. C., 2018, P IEEE INT C IM PROC
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Doran G., 2016, P 25 INT JOINT C ART, P3352
   Ge Y, 2018, MULTIMED TOOLS APPL, V77, P17489, DOI 10.1007/s11042-017-5314-5
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gray PC, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081257
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   Heyer T, 2018, PLANET SPACE SCI, V159, P56, DOI 10.1016/j.pss.2018.04.015
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Houborg R, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090768
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ip WH, 2014, RES ASTRON ASTROPHYS, V14, P1511, DOI 10.1088/1674-4527/14/12/001
   Kerner HR, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P9484
   Kerner HR, 2018, COMPUT GEOSCI-UK, V118, P109, DOI 10.1016/j.cageo.2018.06.001
   Klaric MN, 2013, IEEE T GEOSCI REMOTE, V51, P2067, DOI 10.1109/TGRS.2013.2243840
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lefevre S, 2017, P IEEE, V105, P1884, DOI 10.1109/JPROC.2017.2684300
   Liu N, 2018, IEEE ACCESS, V6, P11215, DOI 10.1109/ACCESS.2018.2798799
   Lyu HB, 2017, INT GEOSCI REMOTE SE, P1958, DOI 10.1109/IGARSS.2017.8127363
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Malin MC, 2007, J GEOPHYS RES-PLANET, V112, DOI 10.1029/2006JE002808
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   MCEWEN AS, 2007, J GEOPHYS RES-PLANET, V112, DOI DOI 10.1029/2005JE002605
   Mohnier M, 2007, IEEE T GEOSCI REMOTE, V45, P861, DOI 10.1109/TGRS.2006.890580
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Munyati C, 2000, INT J REMOTE SENS, V21, P1787, DOI 10.1080/014311600209742
   Nichol J, 2005, INT J REMOTE SENS, V26, P1913, DOI 10.1080/01431160512331314047
   Peiman R, 2011, INT J REMOTE SENS, V32, P4365, DOI 10.1080/01431161.2010.486806
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Peters J, 2017, ADAPT COMPUT MACH LE
   Planet Team, 2018, PLANT APPL PROGR INT
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Robinson MS, 2010, SPACE SCI REV, V150, P81, DOI 10.1007/s11214-010-9634-2
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Shalaby A, 2007, APPL GEOGR, V27, P28, DOI 10.1016/j.apgeog.2006.09.004
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Speyerer EJ, 2016, NATURE, V538, P215, DOI 10.1038/nature19829
   Stillman DE, 2018, DYNAMIC MARS, P51, DOI 10.1016/B978-0-12-813018-6.00002-9
   Stillman DE, 2014, ICARUS, V233, P328, DOI 10.1016/j.icarus.2014.01.017
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Torres-Vera MA, 2009, INT J REMOTE SENS, V30, P117, DOI 10.1080/01431160802261163
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xu Y, 2013, PROC SPIE, V8919, DOI 10.1117/12.2031104
   Yosinski J, 2014, ADV NEUR IN, V27
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H., 2004, P FLOR ART INT RES S
   Zhang PZ, 2019, IEEE T GEOSCI REMOTE, V57, P2277, DOI 10.1109/TGRS.2018.2872509
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zuiderveld K., 1994, GRAPHICS GEMS, P474, DOI [10.1016/b978-0-12-336156-1.50061-6, DOI 10.1016/B978-0-12-336156-1.50061-6]
NR 82
TC 9
Z9 9
U1 7
U2 21
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD OCT
PY 2019
VL 12
IS 10
SI SI
BP 3900
EP 3918
DI 10.1109/JSTARS.2019.2936771
PG 19
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA JW6TN
UT WOS:000503182000018
DA 2022-01-04
ER

PT J
AU Zhang, ZC
   Vosselman, G
   Gerke, M
   Persello, C
   Tuia, D
   Yang, MY
AF Zhang, Zhenchao
   Vosselman, George
   Gerke, Markus
   Persello, Claudio
   Tuia, Devis
   Yang, Michael Ying
TI Detecting Building Changes between Airborne Laser Scanning and
   Photogrammetric Data
SO REMOTE SENSING
LA English
DT Article
DE change detection; multimodal data; convolutional neural networks;
   Siamese networks; airborne laser scanning; dense image matching
ID IMAGERY
AB Detecting topographic changes in an urban environment and keeping city-level point clouds up-to-date are important tasks for urban planning and monitoring. In practice, remote sensing data are often available only in different modalities for two epochs. Change detection between airborne laser scanning data and photogrammetric data is challenging due to the multi-modality of the input data and dense matching errors. This paper proposes a method to detect building changes between multimodal acquisitions. The multimodal inputs are converted and fed into a light-weighted pseudo-Siamese convolutional neural network (PSI-CNN) for change detection. Different network configurations and fusion strategies are compared. Our experiments on a large urban data set demonstrate the effectiveness of the proposed method. Our change map achieves a recall rate of 86.17%, a precision rate of 68.16%, and an F-1-score of 76.13%. The comparison between Siamese architecture and feed-forward architecture brings many interesting findings and suggestions to the design of networks for multimodal data processing.
C1 [Zhang, Zhenchao; Vosselman, George; Persello, Claudio; Yang, Michael Ying] Univ Twente, Fac ITC, Dept Earth Observat Sci, NL-7514 AE Enschede, Netherlands.
   [Gerke, Markus] Tech Univ Carolo Wilhelmina Braunschweig, Inst Geodesy & Photogrammetry, DE-38106 Braunschweig, Germany.
   [Tuia, Devis] Wageningen Univ, Lab Geoinformat Sci & Remote Sensing, NL-6700 AA Wageningen, Netherlands.
RP Yang, MY (corresponding author), Univ Twente, Fac ITC, Dept Earth Observat Sci, NL-7514 AE Enschede, Netherlands.
EM z.zhang-1@utwente.nl; george.vosselman@utwente.nl; m.gerke@tu-bs.de;
   c.persello@utwente.nl; devis.tuia@wur.nl; michael.yang@utwente.nl
RI Tuia, Devis/AAE-9339-2019; Persello, Claudio/AAN-2070-2020; Yang,
   Michael/AAC-6698-2019; /D-3985-2009
OI Tuia, Devis/0000-0003-0374-2459; Persello, Claudio/0000-0003-3742-5398;
   Yang, Michael/0000-0002-0649-9987; Gerke, Markus/0000-0002-2221-6182;
   /0000-0001-8813-8028
FU China Scholarship Council (CSC)China Scholarship Council
FX This research was funded by the China Scholarship Council (CSC).
CR Akaike K, 2015, ADV MATER INTERFACES, V2, DOI 10.1002/admi.201500232
   Basgall PL, 2014, PROC SPIE, V9080, DOI 10.1117/12.2049856
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chen LC, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3525560
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Daudt R.C., 2018, P INT GEOSC REM SENS
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow Ian, 2016, DEEP LEARNING, V1
   He HQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020355
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]
   Hu XY, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090730
   Kim S., 2009, LASERSCANNING09, V18, P259
   Lefevre S, 2017, P IEEE, V105, P1884, DOI 10.1109/JPROC.2017.2684300
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   Malpica JA, 2013, INT J REMOTE SENS, V34, P1652, DOI 10.1080/01431161.2012.725483
   Mandlburger G., 2017, ISPRS ANN PHOTOGRAMM, P259
   Matikainen L., 2004, INT ARCH PHOTOGRAMME, V35, P434
   Mou L., 2017, P 2017 JOINT URB REM, P1
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nex F, 2015, ISPRS ANN PHOTO REM, V2-3, P135, DOI 10.5194/isprsannals-II-3-W4-135-2015
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qin RJ, 2014, ISPRS J PHOTOGRAMM, V90, P23, DOI 10.1016/j.isprsjprs.2014.01.006
   Remondino F, 2014, PHOTOGRAMM REC, V29, P144, DOI 10.1111/phor.12063
   Ren SQ, 2015, ADV NEUR IN, V28
   Ressl C, 2016, PHOTOGRAMM FERNERKUN, P57, DOI 10.1127/pfg/2016/0288
   Rothermel M., 2012, P LC3D WORKSH BERL, P2
   Sherrah J., 2016, ARXIV160602585
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tran THG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020448
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Vosselman G., 2004, INT ARCH PHOTOGRAMM, V35, P207
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xu S, 2015, REMOTE SENS-BASEL, V7, P17051, DOI 10.3390/rs71215867
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang Z., 2019, ISPRS ANN PHOTOGRAMM, VIV-2/W5, P453, DOI [10.5194/isprs-annals-IV-2-W5-453-2019, DOI 10.5194/ISPRS-ANNALS-IV-2-W5-453-2019]
   Zhang ZC, 2018, INT J APPL EARTH OBS, V70, P25, DOI 10.1016/j.jag.2018.04.002
NR 46
TC 11
Z9 12
U1 3
U2 8
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD OCT
PY 2019
VL 11
IS 20
AR 2417
DI 10.3390/rs11202417
PG 17
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA JP6TN
UT WOS:000498395800085
OA gold, Green Published
DA 2022-01-04
ER

PT J
AU Gao, YH
   Gao, F
   Dong, JY
   Wang, SK
AF Gao, Yunhao
   Gao, Feng
   Dong, Junyu
   Wang, Shengke
TI Transferred Deep Learning for Sea Ice Change Detection From
   Synthetic-Aperture Radar Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; deep learning; fine-tune; neural network;
   synthetic-aperture radar (SAR)
AB High-quality sea ice monitoring is crucial to navigation safety and climate research in the polar regions. In this letter, a transferred multilevel fusion network (MLFN) is proposed for sea ice change detection from synthetic-aperture radar (SAR) images. Considering the fact that training data are limited in the task of sea ice change detection, a large data set was used to train the MLFN, and the deep knowledge can be transferred to sea ice analysis. In addition, cascade dense blocks are employed to optimize the convolutional layers. Multilayer feature fusion is introduced to exploit the complementary information among low-, mid-, and high-level feature representations. Therefore, more discriminative feature extraction can be achieved by the MLFN. Furthermore, the fine-tune strategy is utilized to optimize the network parameters. The experimental results on two real sea ice data sets demonstrated that the proposed method achieved better performance than other competitive methods.
C1 [Gao, Yunhao; Gao, Feng; Dong, Junyu; Wang, Shengke] Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Shandong, Peoples R China.
RP Gao, F (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Shandong, Peoples R China.
EM gaofeng@ouc.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41606198, 41576011, U1706218]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41606198, Grant 41576011, and Grant
   U1706218.
CR Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chaib S, 2017, IEEE T GEOSCI REMOTE, V55, P4775, DOI 10.1109/TGRS.2017.2700322
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Wang L, 2016, IEEE T GEOSCI REMOTE, V54, P4524, DOI 10.1109/TGRS.2016.2543660
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Xiong BL, 2012, IEEE GEOSCI REMOTE S, V9, P287, DOI 10.1109/LGRS.2011.2166149
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
NR 17
TC 20
Z9 20
U1 6
U2 30
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2019
VL 16
IS 10
BP 1655
EP 1659
DI 10.1109/LGRS.2019.2906279
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA JD1SU
UT WOS:000489756100030
DA 2022-01-04
ER

PT J
AU Geng, J
   Ma, XR
   Zhou, XJ
   Wang, HY
AF Geng, Jie
   Ma, Xiaorui
   Zhou, Xiaojun
   Wang, Hongyu
TI Saliency-Guided Deep Neural Networks for SAR Image Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; deep neural networks (DNNs); synthetic aperture radar
   (SAR) image; unsupervised learning
ID RADAR IMAGES; ALGORITHM; CLASSIFICATION; FUSION; MODEL
AB Change detection is an important task to identify land-cover changes between the acquisitions at different times. For synthetic aperture radar (SAR) images, inherent speckle noise of the images can lead to false changed points, which affects the change detection performance. Besides, the supervised classifier in change detection framework requires numerous training samples, which are generally obtained by manual labeling. In this paper, a novel unsupervised method named saliency-guided deep neural networks (SGDNNs) is proposed for SAR image change detection. In the proposed method, to weaken the influence of speckle noise, a salient region that probably belongs to the changed object is extracted from the difference image. To obtain pseudotraining samples automatically, hierarchical fuzzy C-means (HFCM) clustering is developed to select samples with higher probabilities to be changed and unchanged. Moreover, to enhance the discrimination of sample features, DNNs based on the nonnegative- and Fisher-constrained autoencoder are applied for final detection. Experimental results on five real SAR data sets demonstrate the effectiveness of the proposed approach.
C1 [Geng, Jie] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
   [Ma, Xiaorui; Zhou, Xiaojun; Wang, Hongyu] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
RP Geng, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
EM gengjie@nwpu.edu.cn
FU Fundamental Research Funds for the Central UniversitiesFundamental
   Research Funds for the Central Universities; National Natural Science
   Foundation of ChinaNational Natural Science Foundation of China (NSFC)
   [61671103, 61801078]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities and in part by the National Natural Science
   Foundation of China under Grant 61671103 and Grant 61801078.
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bengio, 2007, P 24 INT C MACH LEAR, P473, DOI [10.1145/1273496.1273556, DOI 10.1145/1273496.1273556]
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen FB, 2017, RES J BIOTECHNOL, V12, P1
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Dominguez EM, 2018, IEEE T GEOSCI REMOTE, V56, P3611, DOI 10.1109/TGRS.2018.2805471
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Geng J, 2018, IEEE T GEOSCI REMOTE, V56, P2255, DOI 10.1109/TGRS.2017.2777868
   Geng J, 2017, IEEE T GEOSCI REMOTE, V55, P2442, DOI 10.1109/TGRS.2016.2645226
   Geng L, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACVW.2017.8
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hosseini-Asl E, 2016, IEEE T NEUR NET LEAR, V27, P2486, DOI 10.1109/TNNLS.2015.2479223
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee J.-S., 1986, P SOC PHOTO-OPT INS, V25
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li L, 2018, IEEE T GEOSCI REMOTE, V56, P4605, DOI 10.1109/TGRS.2018.2829630
   Li Y, 2015, IEEE T GEOSCI REMOTE, V53, P4712, DOI 10.1109/TGRS.2015.2407953
   Liu F, 2019, IEEE T NEUR NET LEAR, V30, P818, DOI 10.1109/TNNLS.2018.2847309
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Moreira A, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2248301
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Mura MD, 2015, P IEEE, V103, P1585, DOI 10.1109/JPROC.2015.2462751
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Reigber A, 2013, P IEEE, V101, P759, DOI 10.1109/JPROC.2012.2220511
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Zhan T, 2018, IEEE GEOSCI REMOTE S, V15, P1352, DOI 10.1109/LGRS.2018.2843385
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang XR, 2017, IEEE GEOSCI REMOTE S, V14, P1928, DOI 10.1109/LGRS.2017.2737823
   Zheng YG, 2017, PATTERN RECOGN, V61, P309, DOI 10.1016/j.patcog.2016.07.040
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 51
TC 35
Z9 35
U1 15
U2 59
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD OCT
PY 2019
VL 57
IS 10
BP 7365
EP 7377
DI 10.1109/TGRS.2019.2913095
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA JD2UB
UT WOS:000489829200006
DA 2022-01-04
ER

PT J
AU Daudt, RC
   Le Saux, B
   Boulch, A
   Gousseau, Y
AF Daudt, Rodrigo Caye
   Le Saux, Bertrand
   Boulch, Alexandre
   Gousseau, Yann
TI Multitask learning for large-scale semantic change detection
SO COMPUTER VISION AND IMAGE UNDERSTANDING
LA English
DT Article
DE Semantic change detection; High resolution Earth observation; Fully
   convolutional networks; Remote sensing; Multitask learning
ID CHANGE-VECTOR ANALYSIS; IMAGES; FRAMEWORK
AB Change detection is one of the main problems in remote sensing, and is essential to the accurate processing and understanding of the large scale Earth observation data available. Most of the recently proposed change detection methods bring deep learning to this context, but change detection labelled datasets which are openly available are still very scarce, which limits the methods that can be proposed and tested. In this paper we present the first large scale very high resolution semantic change detection dataset, which enables the usage of deep supervised learning methods for semantic change detection with very high resolution images. The dataset contains coregistered RGB image pairs, pixel-wise change information and land cover information. We then propose several supervised learning methods using fully convolutional neural networks to perform semantic change detection. Most notably, we present a network architecture that performs change detection and land cover mapping simultaneously, while using the predicted land cover information to help to predict changes. We also describe a sequential training scheme that allows this network to be trained without setting a hyperparameter that balances different loss functions and achieves the best overall results.
C1 [Daudt, Rodrigo Caye; Le Saux, Bertrand; Boulch, Alexandre] Univ Paris Saclay, ONERA, DTIS, FR-91123 Palaiseau, France.
   [Daudt, Rodrigo Caye; Gousseau, Yann] Telecom ParisTech, LTCI, FR-75013 Paris, France.
RP Daudt, RC (corresponding author), Univ Paris Saclay, ONERA, DTIS, FR-91123 Palaiseau, France.
EM rodrigo.daudt@onera.fr
RI Le Saux, Bertrand/AAA-2534-2020
FU ONERA's project DELTA
FX This work was funded by ONERA's project DELTA. We thank X. Zhu and L.
   Mou (DLR) for the Eppalock Lake images.
CR Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bourdis N, 2011, INT GEOSCI REMOTE SE, P4176, DOI 10.1109/IGARSS.2011.6050150
   Bovolo F, 2005, 2005 INTERNATIONAL WORKSHOP ON THE ANALYSIS ON MULTI-TEMPORAL REMOTE SENSING IMAGES, P85
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen Y, 2018, IEEE IMAGE PROC, P4008, DOI 10.1109/ICIP.2018.8451392
   Cheng Y, 2018, J IND INF INTEGR, V9, P1, DOI 10.1016/j.jii.2017.08.001
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Daudt RC, 2018, INT GEOSCI REMOTE SE, P2115, DOI 10.1109/IGARSS.2018.8518015
   Demir I., 2018, ABS180506561 CORR
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Le Saux B, 2013, INT GEOSCI REMOTE SE, P3990, DOI 10.1109/IGARSS.2013.6723707
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu G., 2019, IEEE T GEOSCI REMOTE
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maggiolo L., 2018, INT GEOSC REM SENS S, P2103
   Maggiori E, 2017, INT GEOSCI REMOTE SE, P5157, DOI 10.1109/IGARSS.2017.8128163
   Mnih V, 2010, LECT NOTES COMPUT SC, V6316, P210, DOI 10.1007/978-3-642-15567-3_16
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Rolnick D., 2017, ABS170510694 CORR
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Sesnie SE, 2008, REMOTE SENS ENVIRON, V112, P2145, DOI 10.1016/j.rse.2007.08.025
   Simonyan K, 2014, ArXiv:1409.1556
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stent S., 2015, BRIT MACH VIS C
   Vakalopoulou Maria, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P61, DOI 10.1109/CVPRW.2015.7301384
   Volpi M., 2009, 2009 IEEE INT WORKSH, P1
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
NR 48
TC 26
Z9 26
U1 21
U2 56
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1077-3142
EI 1090-235X
J9 COMPUT VIS IMAGE UND
JI Comput. Vis. Image Underst.
PD OCT
PY 2019
VL 187
AR 102783
DI 10.1016/j.cviu.2019.07.003
PG 10
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA IY4JY
UT WOS:000486358500002
OA Green Submitted, Bronze
DA 2022-01-04
ER

PT J
AU Panigrahi, S
   Verma, K
   Tripathi, P
AF Panigrahi, Sangram
   Verma, Kesari
   Tripathi, Priyanka
TI Land cover change detection using focused time delay neural network
SO SOFT COMPUTING
LA English
DT Article
DE Data mining; Land cover change detection; FTDNN; EVI time series data
ID SERIES; RECOGNITION; NDVI
AB The development of improved satellite technology generates a huge amount of remote sensing data, these data play the crucial role in natural resource management. The land use and land cover (LULC) change intensely affects local environment, as well as the global environment. Therefore, the quantifiable knowledge about LULC changes occur in global scale is important to make effective planning for conservation and precise use of natural resources, that has motivated the scientists to develop the various land cover change detection techniques. In this paper, we have proposed neural network-based approach, i.e., focused time delay neural network (FTDNN)-based approach for land cover change detection, which is a time series prediction-based approach and detect the sudden change in the enhanced vegetation index (EVI) time series. The performance of the proposed method has been addressed by using quantitative and qualitative analysis techniques. For the quantitative evaluation, the proposed algorithm is applied to the standard synthetic data set, which are analogous to EVI time series data set. The performance result of the proposed method compares with the four previously existing data mining-based benchmark techniques. The analysis was shown that the FTDNN-based method significantly outperforms than other techniques. For qualitative analysis, the San Francisco Bay Area data set has been used, which comprises real EVI time series. The proposed FTDNN-based method is applied to the San Francisco Bay Area data set and observe the interesting land cover changes. These outcomes indicate the effectiveness of data mining techniques for the land cover change detection problem.
C1 [Panigrahi, Sangram; Verma, Kesari] NIT Raipur, Dept Comp Applicat, Raipur 492010, Madhya Pradesh, India.
   [Tripathi, Priyanka] NITTTR Bhopal, Dept Comp Engn & Applicat, Bhopal 462002, India.
RP Panigrahi, S (corresponding author), NIT Raipur, Dept Comp Applicat, Raipur 492010, Madhya Pradesh, India.
EM sangrampanigrahi.sp@gmail.com; keshriverma@gmail.com;
   ptripathi@nitttrbpl.ac.in
RI Verma, Kesari/AAT-3000-2020
OI Verma, Kesari/0000-0002-5755-3111
CR Alcock R. J., 1999, 7 HELL C INF P 7 HELL C INF IOANN, P27
   Amato F, 2013, J APPL BIOMED, V11, P47, DOI 10.2478/v10136-012-0031-x
   Anava O., 2013, C LEARN THEOR, P172
   [Anonymous], 2016, CTR CONTINUING STUDY, P1
   [Anonymous], 2017, SYNTHETIC CONTROL CH
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P305, DOI 10.1109/36.377930
   Bogorny V, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), DOI 10.1109/ICDM.2010.166
   Boriah S., 2008, P ACM SIGKDD INT C K, P857, DOI DOI 10.1145/1401890
   Boriah S, 2010, THESIS, P1
   Boriah S, 2008, TECHNICAL REPORT
   Boriah S, 2009, CH CRC DATA MIN KNOW, P29
   Boriah Shyam, 2010, P 2010 C INT DAT UND, P175
   Box G.E.P., 1994, TIME SERIES ANAL FOR, VThird
   BOX GEP, 1968, ROY STAT SOC C-APP, V17, P91
   Briassoulis H, 2004, LAND USE LAND COVER
   Chamber Y., 2011, C INT DAT UND, P248
   Chan KY, 2011, EXPERT SYST APPL, V38, P9799, DOI 10.1016/j.eswa.2011.02.020
   Charaniya N. A., 2012, 2012 4th International Conference on Computational Intelligence and Communication Networks (CICN 2012), P851, DOI 10.1109/CICN.2012.116
   Chau KW, 2010, J HYDROINFORM, V12, P458, DOI 10.2166/hydro.2010.032
   Chellasamy M, 2015, INT J GEOMAT GEOSCI, V5, P459
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   De Vries B., 1990, P NIPS, P162
   Demuth H, 1993, NEURAL NETWORK TOOLB
   Fkirin M A, 2009, American Journal of Environmental Sciences, V5, P706, DOI 10.3844/ajessp.2009.706.713
   Garg A, 2011, INT GEOSCI REMOTE SE, P1449, DOI 10.1109/IGARSS.2011.6049339
   Gillanders SN, 2008, PROG PHYS GEOG, V32, P503, DOI 10.1177/0309133308098363
   Grekousis G, 2013, CITIES, V30, P193, DOI 10.1016/j.cities.2012.03.006
   Han J., 2011, MORGAN KAUFMANN SERI, V3, P744
   Helmy A. K., 2010, American Journal of Engineering and Applied Sciences, V3, P604, DOI 10.3844/ajeassp.2010.604.610
   Houghton RA, 2012, BIOGEOSCIENCES, V9, P5125, DOI 10.5194/bg-9-5125-2012
   Htike K., 2010, INT C COMP COMM ENG, P1
   Huete A., 1999, MODIS VEGETATION IND
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Karpatne A, 2016, IEEE GEOSC REM SEN M, V4, P8, DOI 10.1109/MGRS.2016.2528038
   Kucera J., 2007, P INT WORKSH AN MULT, P1
   LIU HQ, 1995, IEEE T GEOSCI REMOTE, V33, P457, DOI 10.1109/36.377946
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   LUCAS JM, 1990, TECHNOMETRICS, V32, P1, DOI 10.2307/1269835
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Mahmood R, 2014, INT J CLIMATOL, V34, P929, DOI 10.1002/joc.3736
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   Meher-Homji VM, 1988, EFFECTS FORESTS PREC
   Mithal V, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1989734.1989740
   Mukherjee P, 2001, PHYSCHEMCOMM, part. no.
   Ngai EWT, 2011, DECIS SUPPORT SYST, V50, P559, DOI 10.1016/j.dss.2010.08.006
   PAGE ES, 1954, BIOMETRIKA, V41, P100, DOI 10.1093/biomet/41.1-2.100
   Panigrahi S, 2016, IAJIT, V16, P1
   Panigrahi S, 2016, REV MODIS EVI NDVI D
   Panigrahi S, 2017, SADHANA-ACAD P ENG S, V42, P2081, DOI 10.1007/s12046-017-0751-4
   Panigrahi S, 2016, IETE TECH REV, V33, P539, DOI 10.1080/02564602.2015.1119663
   Pham DT, 1998, P I MECH ENG I-J SYS, V212, P115, DOI 10.1243/0959651981539343
   Qiu F, 2004, INT J REMOTE SENS, V25, P1749, DOI 10.1080/01431160310001618798
   Running SW, 1999, REMOTE SENS ENVIRON, V70, P108, DOI 10.1016/S0034-4257(99)00061-9
   Salmon BP, 2011, IEEE J-STARS, V4, P327, DOI 10.1109/JSTARS.2010.2053918
   Shekhar S, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P837, DOI 10.1007/978-0-387-09823-4_43
   Shumway R.H., 2006, TIME SERIES ANAL ITS
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   STEINBACH M, 2001, P 4 KDD WORKSH MIN S, P1
   Tan P., 2001, EARTH SCI, P1
   Tan P. -N., 2006, INTRO DATA MINING, P1
   Taormina R, 2015, J HYDROL, V529, P1617, DOI 10.1016/j.jhydrol.2015.08.022
   Taylor W A, 2000, CHANGE POINT ANAL PO
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Turkson R. E., 2016, 3 INT C ART INT PATT, P1, DOI DOI 10.1109/ICAIPR.2016.7585216
   Verburg PH, 2015, ANTHROPOCENE, V12, P29, DOI 10.1016/j.ancene.2015.09.004
   Wang WC, 2015, ENVIRON RES, V139, P46, DOI 10.1016/j.envres.2015.02.002
   Weigend AS, 1994, C P ED P NATO ADV RE
   Wu CL, 2010, J HYDROL, V389, P146, DOI 10.1016/j.jhydrol.2010.05.040
   Zhang SW, 2009, LECT NOTES COMPUT SC, V5754, P948
   Zhang WJ, 2007, ENVIRON MONIT ASSESS, V130, P415, DOI 10.1007/s10661-006-9432-1
NR 70
TC 3
Z9 3
U1 3
U2 14
PU SPRINGER
PI NEW YORK
PA 233 SPRING ST, NEW YORK, NY 10013 USA
SN 1432-7643
EI 1433-7479
J9 SOFT COMPUT
JI Soft Comput.
PD SEP
PY 2019
VL 23
IS 17
BP 7699
EP 7713
DI 10.1007/s00500-018-3395-3
PG 15
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
SC Computer Science
GA IZ2KE
UT WOS:000486914400013
DA 2022-01-04
ER

PT J
AU Yang, MJ
   Jiao, LC
   Liu, F
   Hou, B
   Yang, SY
AF Yang, Meijuan
   Jiao, Licheng
   Liu, Fang
   Hou, Biao
   Yang, Shuyuan
TI Transferred Deep Learning-Based Change Detection in Remote Sensing
   Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Adaptation; change detection; deep neural networks (DNNs);
   reconstruction; remote sensing
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION; LAND-COVER
   TRANSITIONS; CHANGE VECTOR ANALYSIS; DIFFERENCE IMAGE; NEURAL-NETWORK;
   SAR IMAGES; INFORMATION; FRAMEWORK
AB Supervised deep neural networks (DNNs) have been extensively used in diverse tasks. Generally, training such DNNs with superior performance requires a large amount of labeled data. However, it is time-consuming and expensive to manually label the data, especially for tasks in remote sensing, e.g., change detection. The situation motivates us to resort to the existing related images with labels, from which the concept of change can be adapted to new images. However, the distributions of the related labeled images (source domain) and unlabeled new images (target domain) are similar but not identical. It impedes a change detection model learned from source domains being well applied to the target domain. In this paper, we propose a transferred deep learning-based change detection framework to solve this problem. It consists of pretraining and fine-tuning stages. In the pretraining process, we propose two tasks to be learned simultaneously, namely, change detection for the source domain with labels and reconstruction of the unlabeled target data. The auxiliary task aims to reconstruct the difference image (DI) for the target domain. DI is an effective feature, such that the auxiliary task is of much relevance to change detection. The lower layers are shared between these two tasks in the training process. It mitigates the distribution discrepancy between the source and target domains and makes the concept of change from the source domain adapt to the target domain. In addition, we evaluate three modes of the U-net architecture to merge the information for a pair of patches. To fine-tune the change detection network (CDN) for the target domain, two strategies are exploited to select the pixels that have a high possibility of being correctly classified by an unsupervised approach. The proposed method demonstrates an excellent capacity for adapting the concept of change from the source domain to the target domain. It outperforms the state-of-the-art change detection methods via experimental results on real remote sensing data sets.
C1 [Yang, Meijuan; Jiao, Licheng; Liu, Fang; Hou, Biao; Yang, Shuyuan] Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Yang, Meijuan; Jiao, Licheng; Liu, Fang; Hou, Biao; Yang, Shuyuan] Xidian Univ, Sch Artificial Intelligence, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Xian 710071, Peoples R China.
RP Jiao, LC (corresponding author), Xidian Univ, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.; Jiao, LC (corresponding author), Xidian Univ, Sch Artificial Intelligence, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Xian 710071, Peoples R China.
EM mjuanyang@gmail.com; lchjiao@mail.xidian.edu.cn
OI Yang, Meijuan/0000-0002-9277-7751; Jiao, Licheng/0000-0003-3354-9617
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1701267]; State Key Program of National
   Natural Science of ChinaNational Natural Science Foundation of China
   (NSFC) [61836009]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1701267 and in part by the State Key
   Program of National Natural Science of China under Grant 61836009.
CR Ban YF, 2016, REMOTE SENS DIGIT IM, V20, P19, DOI 10.1007/978-3-319-47037-5_2
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bianchini M, 2014, IEEE T NEUR NET LEAR, V25, P1553, DOI 10.1109/TNNLS.2013.2293637
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Castellana L, 2007, PATTERN RECOGN LETT, V28, P405, DOI 10.1016/j.patrec.2006.08.010
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2014, ISPRS J PHOTOGRAMM, V87, P19, DOI 10.1016/j.isprsjprs.2013.10.007
   Demir B, 2012, IEEE T GEOSCI REMOTE, V50, P1930, DOI 10.1109/TGRS.2011.2168534
   El Amin A. M., 2016, P INT WORKSH PATT RE
   Gadhiraju S.V., 2014, GEOMATICA, V68, P5
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Haboudane D, 2007, INT GEOSCI REMOTE SE, P4327
   Hao M, 2016, J SENSORS, V2016, DOI 10.1155/2016/9078364
   Janalipour M, 2017, INT J REMOTE SENS, V38, P82, DOI 10.1080/01431161.2016.1259673
   Jiao L. C., 2017, DEEP LEARNING OPTIMI
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LEE JS, 1986, OPT ENG, V25, P636, DOI 10.1117/12.7973877
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li YY, 2017, INT GEOSCI REMOTE SE, P3090, DOI 10.1109/IGARSS.2017.8127652
   Lin S., 2017, IEEE T NEUR NET LEAR, V29, P4709
   Liu GC, 2015, PATTERN RECOGN, V48, P685, DOI 10.1016/j.patcog.2014.09.027
   Long M., 2015, INT C MACH LEARN PML, V1, P97
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Paolini L, 2006, INT J REMOTE SENS, V27, P685, DOI 10.1080/01431160500183057
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820
   Shang RH, 2014, ENG APPL ARTIF INTEL, V31, P53, DOI 10.1016/j.engappai.2014.02.004
   Song, 2016, ADV NEURAL INFORM PR, P2110
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Tzeng E., 2017, P IEEE C COMP VIS PA, P7167
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang S, 2018, ISPRS J PHOTOGRAMM, V145, P148, DOI 10.1016/j.isprsjprs.2017.12.012
   Ye S, 2016, ISPRS J PHOTOGRAMM, V114, P115, DOI 10.1016/j.isprsjprs.2016.01.018
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
NR 47
TC 27
Z9 27
U1 18
U2 97
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2019
VL 57
IS 9
BP 6960
EP 6973
DI 10.1109/TGRS.2019.2909781
PG 14
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA IV3YB
UT WOS:000484209000051
DA 2022-01-04
ER

PT J
AU Maurya, AK
   Varade, DM
   Dikshit, O
AF Maurya, Ajay K.
   Varade, Divyesh M.
   Dikshit, Onkar
TI Effect of Pansharpening in Fusion Based Change Detection of Snow Cover
   Using Convolutional Neural Networks
SO IETE TECHNICAL REVIEW
LA English
DT Article
DE Change detection; Classification; Convolutional neural network;
   Pansharpening; Snow
ID FOCUS IMAGE FUSION; POLARIMETRIC SAR; SEASONAL SNOW; RIVER; ENHANCEMENT;
   MULTISENSOR; CLIMATE
AB Seasonal dynamics of snow cover is an essential area of research for hydrological modelling and water resource management. With the increased availability of remote sensing data, the timely information of the spatiotemporal distribution of snow cover is feasible at regular intervals. The primary objective of this study is to assess the effect of pansharpening in the accuracy of snow cover change detection in mountainous regions using freely available Landsat-8 multispectral data. In mountainous regions at the medium resolution, the changes at the mountain ridges are seldom identified. The incorporation of pansharpening in the change detection framework facilitates an improvement in the snow cover change detection at the ridges. For pansharpening, the PanNet architecture based on convolutional neural networks was adopted. A study area around Dhundi in the state of Himachal Pradesh in India was selected for the analysis. The experiments were carried out using a subset of Landsat-8 multispectral data acquired in the autumn and the winter seasons of 2017 and 2018, respectively. An improvement of 0.184 and 0.267 in the kappa coefficient was observed for the overall changes in the snow cover and at the ridges, respectively, based on the results from the proposed approach.
C1 [Maurya, Ajay K.] Indian Meteorol Dept, Reg Meteorol Ctr, Gauhati 781015, Assam, India.
   [Varade, Divyesh M.; Dikshit, Onkar] Indian Inst Technol Kanpur, Dept Civil Engn, Kanpur 208016, Uttar Pradesh, India.
RP Maurya, AK (corresponding author), Indian Meteorol Dept, Reg Meteorol Ctr, Gauhati 781015, Assam, India.
EM ajayk@iitk.ac.in; varadi@iitk.ac.in; onkar@iitk.ac.in
OI MAURYA, AJAY/0000-0003-0855-3868; Varade, Divyesh/0000-0003-0283-8387
FU Department of Science and Technology, Ministry of Science and
   TechnologyDepartment of Science & Technology (DOST), Philippines
   [DST/CE/2016056]
FX This work was supported by Department of Science and Technology,
   Ministry of Science and Technology: [Grant Number Project Number
   DST/CE/2016056].
CR Amolins K, 2007, ISPRS J PHOTOGRAMM, V62, P249, DOI 10.1016/j.isprsjprs.2007.05.009
   Armstrong RL, 2019, REG ENVIRON CHANGE, V19, P1249, DOI 10.1007/s10113-018-1429-0
   Bishop C. M., 2003, NEURAL NETWORKS PATT
   Butenuth M, 2011, INT J REMOTE SENS, V32, P8575, DOI 10.1080/01431161.2010.542204
   Chaabouni-Chouayakh H, 2013, INT J IMAGE DATA FUS, V4, P89, DOI 10.1080/19479832.2012.739577
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Congalton R.G., 2009, ASSESSING ACCURACY R
   Du CB, 2018, OPTOELECTRON LETT, V14, P71, DOI 10.1007/s11801-018-7207-x
   Ehlers M, 2010, INT J IMAGE DATA FUS, V1, P25, DOI 10.1080/19479830903561985
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   GILLESPIE AR, 1987, REMOTE SENS ENVIRON, V22, P343, DOI 10.1016/0034-4257(87)90088-5
   Gurung D.R., 2011, CRYOSPHERE DISCUSSIO, V5, P755, DOI 10.5194/tcd-5-755-2011
   Hall D. K., 2014, ENCY SNOW ICE GLACIE, P779
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Karathanassi V, 2007, INT J REMOTE SENS, V28, P2309, DOI 10.1080/01431160600606890
   Karim M. R., 2018, PRACTICAL CONVOLUTIO
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Lu L, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-42999-1
   Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594
   Muhuri A, 2017, IEEE GEOSCI REMOTE S, V14, P2340, DOI 10.1109/LGRS.2017.2764123
   Peng X, 2010, INT GEOSCI REMOTE SE, P496, DOI 10.1109/IGARSS.2010.5654172
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh DK, 2018, ARAB J GEOSCI, V11, DOI 10.1007/s12517-018-3926-3
   Singh P, 1997, MT RES DEV, V17, P49, DOI 10.2307/3673913
   Singh SK, 2014, INT J CLIMATOL, V34, P446, DOI 10.1002/joc.3697
   Trivedi MR, 2007, ARCT ANTARCT ALP RES, V39, P488, DOI 10.1657/1523-0430(06-006)[TRIVEDI]2.0.CO;2
   Varade D, 2019, WATER RESOUR RES, V55, P462, DOI 10.1029/2018WR023806
   Varade D, 2017, 2017 INT C EM TRENDS, P1
   Varade D, 2019, J MT SCI-ENGL, V16, P1435, DOI 10.1007/s11629-019-5373-3
   Varade D, 2014, INT ARCH PHOTOGRAMM, V40-8, P543, DOI 10.5194/isprsarchives-XL-8-543-2014
   Varade DM, 2019, IETE TECH REV, V36, P475, DOI 10.1080/02564602.2018.1503569
   Venkateswaran, 2017, NEURAL NETWORKS R SM
   Wang B, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9080804
   Yang JF, 2017, IEEE I CONF COMP VIS, P1753, DOI 10.1109/ICCV.2017.193
   Zeng Y, 2010, INT J IMAGE DATA FUS, V1, P193, DOI 10.1080/19479831003802832
   Zhang W, 2017, J MT SCI-ENGL, V14, P2295, DOI 10.1007/s11629-017-4556-z
NR 40
TC 1
Z9 1
U1 0
U2 11
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0256-4602
EI 0974-5971
J9 IETE TECH REV
JI IETE Tech. Rev.
PD SEP 2
PY 2020
VL 37
IS 5
BP 465
EP 475
DI 10.1080/02564602.2019.1657043
EA AUG 2019
PG 11
WC Engineering, Electrical & Electronic; Telecommunications
SC Engineering; Telecommunications
GA OU3DH
UT WOS:000484768200001
DA 2022-01-04
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Automatic building change image quality assessment in high resolution
   remote sensing based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep belief network; Building change detection; Morphological building
   index; Morphological shadow index; Extreme learning machine; Quality
   Assessment
ID URBAN-AREA
AB The multi-temporal high-resolution remote sensing (HRRS) images are usually acquired at different imaging angles, with serious noise interferences and obvious building shadows, so that detecting the changes of urban buildings is a problem. In order to address this challenge, a deep learning-based algorithm called ABCDHIDL is proposed to automatically detect the building changes from multi-temporal HRRS images. Firstly, an automatic selection method of labeled samples of building changes based on morphology (ASLSBCM) is proposed. Secondly, a deep learning model (DBN-ELM) for building changes detection based on deep belief network (DBN) and extreme learning machine (ELM) is proposed. A convolution operation is employed to extract the spectral, texture and spatial features and generate a combined low-level features vector for each pixel in the multi-temporal HRRS images. The unlabeled samples are introduced to pre-train the DBN, and the parameters of DBN-ELM are globally optimized by jointly using the ELM classifier and the labeled samples are offered by ASLSBCM to further improve the detection accuracy. In order to evaluate the performance of ABCDHIDL, four groups of double-temporal WorldView2 HRRS images in four different experimental regions are selected respectively as the test datasets, and five other representative methods are used and compared with ABCDHIDL in the experiments of buildings change detection. The results show that ABCDHIDL has higher accuracy and automation level than the other five methods despite its relatively higher time consumption. (C) 2019 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
RP Huang, FH (corresponding author), Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.; Huang, FH (corresponding author), Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
EM huang_fenghua@126.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41501451]; Natural Science Foundation of
   Fujian Province in ChinaNatural Science Foundation of Fujian Province
   [2019J01088]; Program for Outstanding Youth Scientific Research Talents
   in Fujian Province Universities [MinJiaoKe [2015]54]; Program for New
   Century Excellent Talents in Fujian Province UniversitiesProgram for New
   Century Excellent Talents in University (NCET) [MinJiaoKe [2016]23]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), Natural Science Foundation of Fujian Province in China
   (No. 2019J01088), Program for Outstanding Youth Scientific Research
   Talents in Fujian Province Universities (MinJiaoKe [2015]54), and
   Program for New Century Excellent Talents in Fujian Province
   Universities (MinJiaoKe [2016]23). The authors would like to thank
   Wenzao Shi and Zhengyuan Mao in the Spatial Information Research Center
   (SIRC) of Fujian Province (China) for their assistance, suggestions, and
   discussions.
CR Argialas DP, 2013, SURV REV, V45, P441, DOI 10.1179/1752270613Y.0000000058
   Argyridis A, 2016, INT J IMAGE DATA FUS, V7, P148, DOI 10.1080/19479832.2016.1158211
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Chen H, 2014, IEEE SENS J, V14, DOI 10.1109/JSEN.2014.2316798
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   GAO C, 2014, ACTA GEODAET CARTOGR, P107
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   [胡荣明 Hu Rongming], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P514
   HU Xiaowen, 2012, J NANJING U INFORM S, V4, P420
   Huang F., 2016, INT J EARTH SCI ENG, V9, P2172
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang X. Q., 2009, THESIS
   Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721, DOI 10.14358/PERS.77.7.721
   [季顺平 JI Shunping], 2007, [遥感学报, Journal of Remote Sensing], V11, P323
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   [靳珍怡 Jin Zhenyi], 2016, [中国医学物理学杂志, Chinese Journal of Medical Physics], V33, P445
   Kang Yan, 2015, Instrument Technique and Sensor, P73
   Li Xiaolong, 2014, Journal of Frontiers of Computer Science and Technology, V8, P305, DOI 10.3778/j.issn.1673-9418.1306023
   Liu D. W., 2016, ACTA OPT SINICA, V36, P298
   Lu DS, 2011, INT J REMOTE SENS, V32, P2519, DOI 10.1080/01431161003698393
   [吕刚 Lu Gang], 2014, [计算机应用与软件, Computer Applications and Software], V31, P182
   [吕启 Lu Qi], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1911
   Lv G., 2014, COMPUT APPL SOFTW, V31, P213
   Matias T, 2014, NEUROCOMPUTING, V129, P428, DOI 10.1016/j.neucom.2013.09.016
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Paulose A., 2014, INT J SCI RES, V3, P1220
   Peng Gang, 2015, Computer Engineering and Design, V36, P1581, DOI 10.16208/j.issn1000-7024.2015.06.034
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   [施文灶 Shi Wenzao], 2016, [地球信息科学学报, Journal of Geo-Information Science], V18, P423
   Sirmacek B, 2010, IEEE GEOSCI REMOTE S, V7, P146, DOI 10.1109/LGRS.2009.2028744
   Sirmacek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   [谭勇 Tan Yong], 2012, [计算机仿真, Computer Simulation], V29, P245
   Tao C., 2012, THESIS
   [王宇红 Wang Yuhong], 2016, [化工学报, CIESC Journal], V67, P5163
   [徐涵秋 Xu Hanqiu], 2005, [遥感学报, Journal of Remote Sensing], V9, P589
NR 36
TC 7
Z9 7
U1 5
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102585
DI 10.1016/j.jvcir.2019.102585
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
SC Computer Science
GA IU3AD
UT WOS:000483450200017
DA 2022-01-04
ER

PT J
AU Gao, P
   Wang, X
   Gao, YH
   Dong, JY
   Wang, SK
AF Gao, Peng
   Wang, Xiao
   Gao, Yunhao
   Dong, Junyu
   Wang, Shengke
TI Sea Ice Change Detection in SAR Images Based on Convolutional-Wavelet
   Neural Networks
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; convolutional-wavelet neural network (CWNN); sea ice;
   synthetic aperture radar (SAR) images
AB Sea ice change detection from synthetic aperture radar (SAR) images can be regarded as a classification procedure, in which pixels are classified into changed and unchanged classes. However, existing methods usually suffer from the intrinsic speckle noise of multitemporal SAR images. To solve the problem, this letter presents a change detection method based On convolutional-wavelet neural networks (CWNNs). In CWNN, dual-tree complex wavelet transform is introduced into convolutional neural networks for changed and unchanged pixels' classification, and then, the effect of speckle noise is effectively reduced. In addition, a virtual sample generation scheme is employed to create samples for CWNN training, and the problem of limited samples is alleviated. Experimental results on two real SAR image data sets demonstrate the effectiveness and robustness of the proposed method.
C1 [Gao, Peng; Wang, Xiao; Gao, Yunhao; Dong, Junyu; Wang, Shengke] Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Shandong, Peoples R China.
RP Dong, JY (corresponding author), Ocean Univ China, Sch Informat Sci & Engn, Qingdao Key Lab Mixed Real & Virtual Ocean, Qingdao 266100, Shandong, Peoples R China.
EM dongjunyu@ouc.edu.cn
OI Dong, Junyu/0000-0001-7012-2087; Gao, Feng/0000-0002-1825-328X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41606198, 41576011, U1706218]; Natural
   Science Foundation of Shandong ProvinceNatural Science Foundation of
   Shandong Province [ZR2016FB02]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41606198, Grant 41576011, and Grant
   U1706218, and in part by the Natural Science Foundation of Shandong
   Province under Grant ZR2016FB02. (Corresponding author: Junyu Dong.)
CR Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bazi Y, 2009, INT J REMOTE SENS, V30, P6591, DOI 10.1080/01431160902882538
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Gao F., 2016, J APPL REMOTE SENS, V10
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Wang L, 2016, IEEE T GEOSCI REMOTE, V54, P4524, DOI 10.1109/TGRS.2016.2543660
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wang Q, 2017, IEEE GEOSCI REMOTE S, V14, P2077, DOI 10.1109/LGRS.2017.2751559
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
NR 18
TC 41
Z9 41
U1 7
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD AUG
PY 2019
VL 16
IS 8
BP 1240
EP 1244
DI 10.1109/LGRS.2019.2895656
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA IK8AF
UT WOS:000476814300014
DA 2022-01-04
ER

PT J
AU Li, YY
   Peng, C
   Chen, YQ
   Jiao, LC
   Zhou, LH
   Shang, RH
AF Li, Yangyang
   Peng, Cheng
   Chen, Yanqiao
   Jiao, Licheng
   Zhou, Linhao
   Shang, Ronghua
TI A Deep Learning Method for Change Detection in Synthetic Aperture Radar
   Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; convolutional neural network (CNN); spatial fuzzy
   clustering; synthetic aperture radar (SAR) images
ID UNSUPERVISED CHANGE DETECTION; MULTITEMPORAL SAR IMAGES; CLASSIFICATION;
   SEGMENTATION
AB With the rapid development of various technologies of satellite sensor, synthetic aperture radar (SAR) image has been an import source of data in the application of change detection. In this paper, a novel method based on a convolutional neural network (CNN) for SAR image change detection is proposed. The main idea of our method is to generate the classification results directly from the original two SAR images through a CNN without any preprocessing operations, which also eliminate the process of generating the difference image (DI), thus reducing the influence of the DI on the final classification result. In CNN, the spatial characteristics of the raw image can be extracted and captured by automatic learning and the results with stronger robustness can be obtained. The basic idea of the proposed method includes three steps: it first produces false labels through unsupervised spatial fuzzy clustering. Then we train the CNN through proper samples that are selected from the samples with false labels. Finally, the final detection results are obtained by the trained convolutional network. Although training the convolutional network is a supervised learning fashion, the whole process of the algorithm is an unsupervised process without priori knowledge. The theoretical analysis and experimental results demonstrate the validity, robustness, and potential of our algorithm in simulated and real data sets. In addition, we try to apply our algorithm to the change detection of heterogeneous images, which also achieves satisfactory results.
C1 [Li, Yangyang; Peng, Cheng; Chen, Yanqiao; Jiao, Licheng; Zhou, Linhao; Shang, Ronghua] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence,Joint Int Res Lab Int, Minist Educ,Int Res Ctr Intelligent Percept & Com, Xian 710071, Shaanxi, Peoples R China.
RP Peng, C; Chen, YQ (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence,Joint Int Res Lab Int, Minist Educ,Int Res Ctr Intelligent Percept & Com, Xian 710071, Shaanxi, Peoples R China.
EM pengchengmaster@163.com; chenyanqiao2016@163.com
OI Jiao, Licheng/0000-0003-3354-9617; Peng, Cheng/0000-0002-1994-893X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772399, U1701267, 61773304, 61672405,
   61772400]; Program for Cheung Kong Scholars and Innovative Research Team
   in UniversityProgram for Changjiang Scholars & Innovative Research Team
   in University (PCSIRT) [IRT_ 15R53]; Fund for Foreign Scholars in
   University Research and Teaching Programs (the 111 Project)Ministry of
   Education, China - 111 Project [B07048]; Major Research Plan of the
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [91438201]; Technology Foundation for
   Selected Overseas Chinese Scholar in Shaanxi [2017021, 2018021]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61772399, Grant U1701267, Grant 61773304, Grant
   61672405, and Grant 61772400, in part by the Program for Cheung Kong
   Scholars and Innovative Research Team in University under Grant IRT_
   15R53, in part by the Fund for Foreign Scholars in University Research
   and Teaching Programs (the 111 Project) under Grant B07048, in part by
   the Major Research Plan of the National Natural Science Foundation of
   China under Grant 91438201, and in part by the Technology Foundation for
   Selected Overseas Chinese Scholar in Shaanxi under Grant 2017021 and
   Grant 2018021.
CR Bezdek JC, 1981, PATTERN RECOGN, DOI DOI 10.1007/978-1-4757-0450-1
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Chen YQ, 2017, IEEE T GEOSCI REMOTE, V55, P6683, DOI 10.1109/TGRS.2017.2727067
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Dunn JC, 1973, FUZZY RELATIVE ISODA, DOI [10.1080/01969727308546046, DOI 10.1080/01969727308546046]
   Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lange S., 2010, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2010.5596468
   Lee JS, 2009, OPT SCI ENG-CRC, P1
   Lunetta R.S., 1999, REMOTE SENSING CHANG, V310
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Manonmani R, 2010, International Journal of Geomatics and Geosciences, V1, P60
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Rakshit S, 2007, PATTERN RECOGN, V40, P890, DOI 10.1016/j.patcog.2006.02.008
   Rathore N., 2013, INT J ADV RES COMPUT, V2, P243
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Su LZ, 2014, INT J REMOTE SENS, V35, P621, DOI 10.1080/01431161.2013.871596
   Tripathy B K, 2015, PROJECT DECISION MAK, P1
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang F, 2016, IEEE T GEOSCI REMOTE, V54, P1793, DOI 10.1109/TGRS.2015.2488681
   Zhang JF, 2003, INT GEOSCI REMOTE SE, P2436
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
NR 41
TC 45
Z9 46
U1 11
U2 48
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD AUG
PY 2019
VL 57
IS 8
BP 5751
EP 5763
DI 10.1109/TGRS.2019.2901945
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA IK7XA
UT WOS:000476805800041
DA 2022-01-04
ER

PT J
AU Song, F
   Dan, TT
   Yu, R
   Yang, K
   Yang, Y
   Chen, WY
   Gao, XY
   Ong, SH
AF Song, Fei
   Dan, Tingting
   Yu, Rui
   Yang, Kun
   Yang, Yang
   Chen, Weiyang
   Gao, Xueyan
   Ong, Sim-Heng
TI Small UAV-based multi-temporal change detection for monitoring
   cultivated land cover changes in mountainous terrain
SO REMOTE SENSING LETTERS
LA English
DT Article
DE cultivated land; small UAV; multi-temporal; image registration; change
   detection
AB Land degradation, soil erosion and illegal occupation in mountainous terrain of southern China have led to an ever-decreasing stock of cultivated land. Small unmanned aerial vehicles (UAVs) are used to collect images with very fine spatial and temporal resolutions. However, acquired image pairs of the same scene often contain scale changes, noises and rotated changes at different temporal scales. To address these problems, we propose a small UAV-based multi-temporal change detection for cultivated land cover in mountainous terrain which contains the following contributions. First, the multi-scale feature description includes convolutional neural network (CNN)-based feature descriptor (CFD) and neighbouring structure descriptor (NSD), where CFD is generated using layers formed via a pretrained Visual Geometry Group (VGG)-16 architecture. Second, a gradually increasing selection of inliers is defined for improving the robustness of feature point registration. Finally, intuitionistic fuzzy C-Means (IFCM) classifier is adopted to generate a similarity matrix between image pair of geometric correction process. The performance of proposed method is validated on multi-temporal image pairs taken by the small UAV. Experimental results show that the proposed method can detect cultivated land cover change at small size and scattered distribution landscapes, obtain satisfactory change detection results.
C1 [Song, Fei; Dan, Tingting; Yu, Rui; Yang, Kun; Yang, Yang; Chen, Weiyang; Gao, Xueyan] Yunnan Normal Univ, Sch Informat Sci & Technol, Kunming, Yunnan, Peoples R China.
   [Song, Fei; Dan, Tingting; Yu, Rui; Yang, Kun; Yang, Yang; Chen, Weiyang; Gao, Xueyan] Minist Educ, Engn Res Ctr GIS Technol, Kunming, Yunnan, Peoples R China.
   [Ong, Sim-Heng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.
RP Yang, K; Yang, Y (corresponding author), Yunnan Normal Univ, Sch Informat Sci & Technol, Kunming, Yunnan, Peoples R China.
EM kmdcynu@163.com; yyang_ynu@163.com
RI Ong, Sim-Heng/R-9244-2019
OI Ong, Sim-Heng/0000-0003-2766-8150; song, fei/0000-0003-0636-8343
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41661080]; Yunnan Ten-thousand Talents
   Program
FX This work were supported by the National Natural Science Foundation of
   China [Grant No: 41661080] and Yunnan Ten-thousand Talents Program.
CR Aredehey G, 2018, INT J REMOTE SENS, V39, P810, DOI 10.1080/01431161.2017.1392639
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Pan J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010083
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   Simonyan K, 2014, ArXiv:1409.1556
   Verma H, 2016, APPL SOFT COMPUT, V46, P543, DOI 10.1016/j.asoc.2015.12.022
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wei ZQ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090904
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yang Y, 2015, PATTERN RECOGN, V48, P156, DOI 10.1016/j.patcog.2014.06.017
   Yang ZQ, 2019, IEEE T IMAGE PROCESS, V28, P2584, DOI 10.1109/TIP.2018.2887204
   Zhang S, 2018, PATTERN RECOGN, V80, P183, DOI 10.1016/j.patcog.2018.03.004
NR 15
TC 9
Z9 11
U1 4
U2 130
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PD JUN 3
PY 2019
VL 10
IS 6
BP 573
EP 582
DI 10.1080/2150704X.2019.1576949
PG 10
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA HN0LH
UT WOS:000459879100001
DA 2022-01-04
ER

PT J
AU Jaturapitpornchai, R
   Matsuoka, M
   Kanemoto, N
   Kuzuoka, S
   Ito, R
   Nakamura, R
AF Jaturapitpornchai, Raveerat
   Matsuoka, Masashi
   Kanemoto, Naruo
   Kuzuoka, Shigeki
   Ito, Riho
   Nakamura, Ryosuke
TI Newly Built Construction Detection in SAR Images Using Deep Learning
SO REMOTE SENSING
LA English
DT Article
DE satellite imagery; SAR; deep learning; U-net; urban change
AB Remote sensing data can be utilized to help developing countries monitor the use of land. However, the problem of constant cloud coverage prevents us from taking full advantage of satellite optical images. Therefore, we instead opt to use data from synthetic-aperture radar (SAR), which can capture images of the Earth's surface regardless of the weather conditions. In this study, we use SAR data to identify newly built constructions. Most studies on change detection tend to detect all of the changes that have a similar temporal change characteristic occurring on two occasions, while we want to identify only the constructions and avoid detecting other changes such as the seasonal change of vegetation. To do so, we study various deep learning network techniques and have decided to propose the fully convolutional network with a skip connection. We train this network with pairs of SAR data acquired on two different occasions from Bangkok and the ground truth, which we manually create from optical images available from Google Earth for all of the SAR pairs. Experiments to assign the most suitable patch size, loss weighting, and epoch number to the network are discussed in this paper. The trained model can be used to generate a binary map that indicates the position of these newly built constructions precisely with the Bangkok dataset, as well as with the Hanoi and Xiamen datasets with acceptable results. The proposed model can even be used with SAR images of the same specific satellite from another orbit direction and still give promising results.
C1 [Jaturapitpornchai, Raveerat; Matsuoka, Masashi] Tokyo Inst Technol, Dept Architecture & Bldg Engn, Yokohama, Kanagawa 2268502, Japan.
   [Kanemoto, Naruo; Ito, Riho; Nakamura, Ryosuke] Natl Inst Adv Ind Sci & Technol, Tokyo 1350064, Japan.
   [Kuzuoka, Shigeki] Space Shift, Tokyo 1050013, Japan.
RP Jaturapitpornchai, R (corresponding author), Tokyo Inst Technol, Dept Architecture & Bldg Engn, Yokohama, Kanagawa 2268502, Japan.
EM jaturapitpornchai.r.aa@m.titech.ac.jp; matsuoka.m.ab@m.titech.ac.jp;
   naruo.kanemoto@aist.go.jp; kuzuoka@spcsft.com; pscrh.itou@aist.go.jp;
   r.nakamura@aist.go.jp
RI Matsuoka, Masashi/D-9882-2017
OI Matsuoka, Masashi/0000-0003-3061-5754
CR Aitken A.P., 2017, 170702937 ARXIV
   Ajadi OA, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060482
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Badrinarayanan Vijay, 2015, 151100561 ARXIV
   Bai YB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101626
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   De Jong K.L., 2018, 181205815 ARXIV
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Iino S, 2018, INT J IMAGE DATA FUS, V9, P302, DOI 10.1080/19479832.2018.1491897
   Ioffe S., 2015, 150203167 ARXIV
   Isola P., 2016, 161107004 ARXIV
   LEE JS, 1981, COMPUT VISION GRAPH, V17, P24, DOI 10.1016/S0146-664X(81)80005-6
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Mu CH, 2017, IEEE C EVOL COMPUTAT, P1150, DOI 10.1109/CEC.2017.7969436
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pacifici F, 2010, IEEE GEOSCI REMOTE S, V7, P58, DOI 10.1109/LGRS.2009.2021780
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Xu YY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010144
   Xu ZE, 2017, REMOTE SENS LETT, V8, P888, DOI 10.1080/2150704X.2017.1335906
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
NR 29
TC 11
Z9 11
U1 3
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 2
PY 2019
VL 11
IS 12
AR 1444
DI 10.3390/rs11121444
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IG4SY
UT WOS:000473794600050
OA gold
DA 2022-01-04
ER

PT J
AU Song, A
   Kim, Y
   Kim, Y
AF Song, Ahram
   Kim, Yeji
   Kim, Yongil
TI Change Detection of Surface Water in Remote Sensing Images Based on
   Fully Convolutional Network
SO JOURNAL OF COASTAL RESEARCH
LA English
DT Article; Proceedings Paper
CT 3rd International Water Safety Symposium (IWSS)
CY JUN 19-23, 2018
CL Incheon, SOUTH KOREA
DE Deep learning; surface water; change detection; fully convolutional
   network; CRMS dataset
ID CLASSIFICATION
AB This study presents a new approach based on fully convolutional networks (FCN) to detect changes in surface water. The proposed method can be divided into three steps: (1) training the FCN using color-infrared (CIR) images from the Coastwide Reference Monitoring System (CRMS) dataset with two classes, such as water and land; (2) passing the multitemporal images respectively through the pre-trained FCN and generating a difference image (DI) from score maps of the last prediction layers; and (3) determining optimal threshold values using fuzzy entropy and discriminating between changed and unchanged pixels in the DI. This method has the advantage of effectively learning the spatial and spectral characteristics of water bodies from large remote-sensing datasets, and it would be helpful to analyze and monitor changes in newly obtained images without ground truth. The experimental results obtained using the multitemporal CRMS data demonstrated the effectiveness of this deep-learning approach for detecting changes in remote-sensing images, as compared other traditional methods for change detection.
C1 [Song, Ahram; Kim, Yeji; Kim, Yongil] Seoul Natl Univ, Dept Civil Environm Engn, Seoul, South Korea.
   [Kim, Yeji] Korea Aerosp Res Inst, Satellite Operat & Applicat Ctr, Daejeon, South Korea.
RP Kim, Y (corresponding author), Seoul Natl Univ, Dept Civil Environm Engn, Seoul, South Korea.
EM yik@snu.ac.kr
OI song, ahram/0000-0002-9190-2848
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2016R1A2B4016301]; Satellite Information Utilization Center
   Establishment program - Ministry of Land, Infrastructure and Transport
   of the Korean government [18SIUE-B148326-01]
FX This work was supported by the National Research Foundation of Korea
   (NRF) funded by the Korean government (MSIT) (grant no.
   NRF-2016R1A2B4016301) and by the Satellite Information Utilization
   Center Establishment program funded by Ministry of Land, Infrastructure
   and Transport of the Korean government (grant no. 18SIUE-B148326-01).
CR Audebert N, 2017, LECT NOTES COMPUT SC, V10111, P180, DOI 10.1007/978-3-319-54181-5_12
   Frattini F, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS (ISSREW), P383, DOI 10.1109/ISSREW.2014.57
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Huang C, 2016, INT GEOSCI REMOTE SE, P2834, DOI 10.1109/IGARSS.2016.7729732
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Li JJ, 2018, IEEE GEOSCI REMOTE S, V15, P292, DOI 10.1109/LGRS.2017.2786272
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Rokni K, 2015, INT J APPL EARTH OBS, V34, P226, DOI 10.1016/j.jag.2014.08.014
   Sarp G, 2017, J TAIBAH UNIV SCI, V11, P381, DOI 10.1016/j.jtusci.2016.04.005
   Xu Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070709
NR 12
TC 3
Z9 3
U1 3
U2 24
PU COASTAL EDUCATION & RESEARCH FOUNDATION
PI COCONUT CREEK
PA 5130 NW 54TH STREET, COCONUT CREEK, FL 33073 USA
SN 0749-0208
EI 1551-5036
J9 J COASTAL RES
JI J. Coast. Res.
PD SUM
PY 2019
SI 91
BP 426
EP 430
DI 10.2112/SI91-086.1
PG 5
WC Environmental Sciences; Geography, Physical; Geosciences,
   Multidisciplinary
SC Environmental Sciences & Ecology; Physical Geography; Geology
GA IX5KZ
UT WOS:000485724400086
DA 2022-01-04
ER

PT J
AU Cui, B
   Zhang, YH
   Yan, L
   Wei, JJ
   Wu, HA
AF Cui, Bin
   Zhang, Yonghong
   Yan, Li
   Wei, Jujie
   Wu, Hong'an
TI An Unsupervised SAR Change Detection Method Based on Stochastic Subspace
   Ensemble Learning
SO REMOTE SENSING
LA English
DT Article
DE change detection; synthetic aperture radar; two-channel network;
   stochastic subspace ensemble learning
ID FLOOD DETECTION; IMAGE FUSION; DIFFERENCE; CNN
AB As synthetic aperture radar (SAR) is playing an increasingly important role in Earth observations, many new methods and technologies have been proposed for change detection using multi-temporal SAR images. Especially with the development of deep learning, numerous methods have been proposed in recent years. However, the requirement to have a certain number of high-quality samples has become one of the main reasons for the limited development of these methods. Thus, in this paper, we propose an unsupervised SAR change detection method that is based on stochastic subspace ensemble learning. The proposed method consists of two stages: The first stage involves the automatic determination of high-confidence samples, which includes a fusion strategy and a refinement process; and the second stage entails using the stochastic subspace ensemble learning module, which contains three steps: obtaining the subsample sets, establishing and training a two-channel network, and applying the prediction results and an ensemble strategy. The subsample sets are used to solve the problem of imbalanced samples. The two-channel networks are used to extract high-dimensional features and learn the relationship between the neighborhood of the pixels in the original images and the labels. Finally, by using an ensemble strategy, the results predicted by all patches reclassified in each network are integrated as the detection result. The experimental results of different SAR datasets prove the effectiveness and the feasibility of the proposed method.
C1 [Cui, Bin; Yan, Li] Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430072, Hubei, Peoples R China.
   [Cui, Bin; Zhang, Yonghong; Wei, Jujie; Wu, Hong'an] Chinese Acad Surveying & Mapping, Beijing 100830, Peoples R China.
RP Yan, L (corresponding author), Wuhan Univ, Sch Geodesy & Geomat, Wuhan 430072, Hubei, Peoples R China.
EM 2015102140032@whu.edu.cn; yhzhang@casm.ac.cn; lyan@sgg.whu.edu.cn;
   weijj@casm.ac.cn; wuha@casm.ac.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41271430, 41801284]; National Key Research
   and Development Program of China [2017YFE0107100]
FX This research was funded by the National Natural Science Foundation of
   China [No. 41271430, No. 41801284], and the National Key Research and
   Development Program of China [No. 2017YFE0107100].
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Cui B, 2019, REMOTE SENS LETT, V10, P488, DOI 10.1080/2150704X.2018.1562256
   CUI ZY, 2018, REMOTE SENS-BASEL, V10, P776, DOI DOI 10.3390/rs10050776
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Dietterich G., 2000, MULT CLASS SYST 10 I, V1875
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao G, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083583
   Garcia-Pedrajas N, 2008, NEURAL NETWORKS, V21, P1344, DOI 10.1016/j.neunet.2007.12.046
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Liu T, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042615
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Lu J, 2014, REMOTE SENS LETT, V5, P240, DOI 10.1080/2150704X.2014.898190
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Pantze A, 2014, REMOTE SENS ENVIRON, V155, P120, DOI 10.1016/j.rse.2013.08.050
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Schlaffer S, 2015, INT J APPL EARTH OBS, V38, P15, DOI 10.1016/j.jag.2014.12.001
   Song SL, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080683
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
   Zhang C, 2018, ISPRS J PHOTOGRAMM, V140, P133, DOI 10.1016/j.isprsjprs.2017.07.014
   Zhang YH, 2016, PHOTOGRAMM ENG REM S, V82, P719, DOI 10.14358/PERS.82.9.719
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
   Zhou Z-H, 2012, ENSEMBLE METHODS FDN, DOI [10.1201/b12207, DOI 10.1201/B12207]
NR 37
TC 14
Z9 14
U1 6
U2 16
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 1
PY 2019
VL 11
IS 11
AR 1314
DI 10.3390/rs11111314
PG 21
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IE8UC
UT WOS:000472648000057
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Fang, B
   Pan, L
   Kou, R
AF Fang, Bo
   Pan, Li
   Kou, Rong
TI Dual Learning-Based Siamese Framework for Change Detection Using
   Bi-Temporal VHR Optical Remote Sensing Images
SO REMOTE SENSING
LA English
DT Article
DE VHR optical remote sensing images; change detection; deep learning
   technology; dual learning framework; Siamese network
ID TIME-SERIES; CLASSIFICATION; ALGORITHMS; NETWORKS; DESIGN; MAD
AB As a fundamental and profound task in remote sensing, change detection from very-high-resolution (VHR) images plays a vital role in a wide range of applications and attracts considerable attention. Current methods generally focus on the research of simultaneously modeling and discriminating the changed and unchanged features. In practice, for bi-temporal VHR optical remote sensing images, the temporal spectral variability tends to exist in all bands throughout the entire paired images, making it difficult to distinguish none-changes and changes with a single model. In this paper, motivated by this observation, we propose a novel hybrid end-to-end framework named dual learning-based Siamese framework (DLSF) for change detection. The framework comprises two parallel streams which are dual learning-based domain transfer and Siamese-based change decision. The former stream is aimed at reducing the domain differences of two paired images and retaining the intrinsic information by translating them into each other's domain. While the latter stream is aimed at learning a decision strategy to decide the changes in two domains, respectively. By training our proposed framework with certain change map references, this method learns a cross-domain translation in order to suppress the differences of unchanged regions and highlight the differences of changed regions in two domains, respectively, then focus on the detection of changed regions. To the best of our knowledge, the idea of incorporating dual learning framework and Siamese network for change detection is novel. The experimental results on two datasets and the comparison with other state-of-the-art methods verify the efficiency and superiority of our proposed DLSF.
C1 [Fang, Bo; Pan, Li; Kou, Rong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
RP Fang, B (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM lavender.fangbo@whu.edu.cn; panli@whu.edu.cn; kourong@whu.edu.cn
CR Awad M, 2014, ECOL INFORM, V24, P60, DOI 10.1016/j.ecoinf.2014.07.004
   Benedek C., 2008, INT C PATT REC, V12, P8, DOI DOI 10.1109/ICPR.2008.4761658
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Bueno IT, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11050570
   Daudt R.C., 2018, P IEEE INT GEOSC REM, P22
   Daudt R.C., 2018, ARXIV181008462
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Feng WQ, 2018, INT J REMOTE SENS, V39, P7998, DOI 10.1080/01431161.2018.1479794
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hadsell R., 2006, PROCEEDINGS OF THE I, P100
   Hu T, 2018, REMOTE SENS ENVIRON, V217, P144, DOI 10.1016/j.rse.2018.08.017
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Isola P., 2017, P IEEE C COMP VIS PA, P632
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kennedy RE, 2009, REMOTE SENS ENVIRON, V113, P1382, DOI 10.1016/j.rse.2008.07.018
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D., 2014, 14126980 ARXIV
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Malila W.A., 1980, LARS S, V385
   Malmir M, 2015, ENVIRON MONIT ASSESS, V187, DOI 10.1007/s10661-015-4295-y
   Mao BX, 2014, INT CONF CLOUD COMPU, P656, DOI 10.1109/CCIS.2014.7175816
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Rokni K, 2014, REMOTE SENS-BASEL, V6, P4173, DOI 10.3390/rs6054173
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh D, 2008, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN MICROWAVE THEORY AND APPLICATIONS, PROCEEDINGS, P419, DOI 10.1109/AMTA.2008.4763244
   Tan K, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030359
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang X, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020276
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Xia Yingce, 2016, ARXIV161100179
   Yang W, 2016, IEEE T GEOSCI REMOTE, V54, P6746, DOI 10.1109/TGRS.2016.2590145
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu L, 2016, FRONT COMPUT SCI-CHI, V10, P292, DOI 10.1007/s11704-015-4103-4
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 18
Z9 19
U1 11
U2 30
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 1
PY 2019
VL 11
IS 11
AR 1292
DI 10.3390/rs11111292
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IE8UC
UT WOS:000472648000035
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Ji, SP
   Shen, YY
   Lu, M
   Zhang, YJ
AF Ji, Shunping
   Shen, Yanyun
   Lu, Meng
   Zhang, Yongjun
TI Building Instance Change Detection from Large-Scale Aerial Images using
   Convolutional Neural Networks and Simulated Samples
SO REMOTE SENSING
LA English
DT Article
DE building change detection; deep learning; CNN; aerial images
ID UNSUPERVISED CHANGE DETECTION; SUPPORT VECTOR MACHINES; REMOTELY-SENSED
   IMAGES; COVER CHANGE DETECTION; MONITOR LAND-COVER; SATELLITE IMAGES;
   FOREST; CLASSIFICATION; DEFORESTATION; LANDSCAPE
AB We present a novel convolutional neural network (CNN)-based change detection framework for locating changed building instances as well as changed building pixels from very high resolution (VHR) aerial images. The distinctive advantage of the framework is the self-training ability, which is highly important in deep-learning-based change detection in practice, as high-quality samples of changes are always lacking for training a successful deep learning model. The framework consists two parts: a building extraction network to produce a binary building map and a building change detection network to produce a building change map. The building extraction network is implemented with two widely used structures: a Mask R-CNN for object-based instance segmentation, and a multi-scale full convolutional network for pixel-based semantic segmentation. The building change detection network takes bi-temporal building maps produced from the building extraction network as input and outputs a building change map at the object and pixel levels. By simulating arbitrary building changes and various building parallaxes in the binary building map, the building change detection network is well trained without real-life samples. This greatly lowers the requirements of labeled changed buildings, and guarantees the algorithm's robustness to registration errors caused by parallaxes. To evaluate the proposed method, we chose a wide range of urban areas from an open-source dataset as training and testing areas, and both pixel-based and object-based model evaluation measures were used. Experiments demonstrated our approach was vastly superior: without using any real change samples, it reached 63% average precision (AP) at the object (building instance) level. In contrast, with adequate training samples, other methodsincluding the most recent CNN-based and generative adversarial network (GAN)-based oneshave only reached 25% AP in their best cases.
C1 [Ji, Shunping; Shen, Yanyun; Zhang, Yongjun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
   [Lu, Meng] Univ Utrecht, Fac Geosci, Dept Phys Geog, Princetonlaan 8, NL-3584 CB Utrecht, Netherlands.
RP Ji, SP (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM jishunping@whu.edu.cn; shenyanyun@whu.edu.cn; m.lu@uu.nl;
   zhangyj@whu.edu.cn
RI Lu, Meng/AAF-1711-2019
OI Lu, Meng/0000-0002-6850-581X; Ji, Shunping/0000-0002-3088-1481
FU National Key Research and Development Program of China [2018YFB0505003]
FX This work was supported by the National Key Research and Development
   Program of China, Grant No. 2018YFB0505003.
CR Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen L, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P833, DOI 10.1145/3269206.3271759
   Chen XX, 2005, REMOTE SENS ENVIRON, V98, P63, DOI 10.1016/j.rse.2005.05.021
   Conchedda G, 2008, ISPRS J PHOTOGRAMM, V63, P578, DOI 10.1016/j.isprsjprs.2008.04.002
   Coops N. C., 2006, FOREST DISTURBANCE S, P33
   Coops NC, 2010, FOREST ECOL MANAG, V259, P2355, DOI 10.1016/j.foreco.2010.03.008
   Dalal N, 2006, FINDING PEOPLE IMAGE
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   De Chant T, 2009, PHOTOGRAMM ENG REM S, V75, P1005, DOI 10.14358/PERS.75.8.1005
   Deer P., 1995, DIGITAL CHANGE DETEC
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding AZ, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P444, DOI 10.1109/YAC.2016.7804935
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   Du Y, 2002, REMOTE SENS ENVIRON, V82, P123, DOI 10.1016/S0034-4257(02)00029-9
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Erener A, 2009, RIV ITAL TELERILEVAM, V41, P47
   Fisher P, 1997, INT J REMOTE SENS, V18, P679, DOI 10.1080/014311697219015
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   GREEN K, 1994, PHOTOGRAMM ENG REM S, V60, P331
   Hall O, 2003, INT J APPL EARTH OBS, V4, P311, DOI [DOI 10.1016/S0303-2434(03)00010-, DOI 10.1016/S0303-2434(03)00010-2]
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Howarth P, 1981, INT J REMOTE SENS, V2, P277, DOI DOI 10.1080/01431168108948362
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Jensen J. R., 1983, Manual of remote sensing. Volume 2. Interpretation and applications, P1571
   JENSEN JR, 1982, PHOTOGRAMM ENG REM S, V48, P629
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Kauth R.J., 1976, LARS S, P159
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Koltunov A, 2007, REMOTE SENS ENVIRON, V110, P18, DOI 10.1016/j.rse.2007.02.010
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lefebvre A., 2008, P IGARSS 2008 2008 I
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu HF, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7100410
   Liu X, 2002, INT J REMOTE SENS, V23, P2513, DOI 10.1080/01431160110097240
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   LUDEKE AK, 1990, J ENVIRON MANAGE, V31, P247, DOI 10.1016/S0301-4797(05)80038-6
   Lunetta R.S., 1999, REMOTE SENSING CHANG, V310
   Lunetta RS, 2004, REMOTE SENS ENVIRON, V89, P444, DOI 10.1016/j.rse.2003.10.022
   Melgani F, 2006, IEEE GEOSCI REMOTE S, V3, P457, DOI 10.1109/LGRS.2006.875773
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nemoto K., 2017, REMOTE SENS TECH APP, V10431, P23
   Ochoa-Gaona S, 2000, APPL GEOGR, V20, P17, DOI 10.1016/S0143-6228(99)00017-X
   Peiman R, 2011, INT J REMOTE SENS, V32, P4365, DOI 10.1080/01431161.2010.486806
   Pijanowski BC, 2005, INT J GEOGR INF SCI, V19, P197, DOI 10.1080/13658810410001713416
   QUARMBY NA, 1989, INT J REMOTE SENS, V10, P953, DOI 10.1080/01431168908903937
   Ren SQ, 2015, ADV NEUR IN, V28
   RICHARDS JA, 1984, REMOTE SENS ENVIRON, V16, P35, DOI 10.1016/0034-4257(84)90025-7
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Serpico SB, 2006, IEEE T GEOSCI REMOTE, V44, P3695, DOI 10.1109/TGRS.2006.881118
   Shalaby A, 2007, APPL GEOGR, V27, P28, DOI 10.1016/j.apgeog.2006.09.004
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tomowski D, 2011, 2011 Proceedings of Joint Urban Remote Sensing Event (JURSE 2011), P329, DOI 10.1109/JURSE.2011.5764786
   Torres-Vera MA, 2009, INT J REMOTE SENS, V30, P117, DOI 10.1080/01431160802261163
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wiemker R., 1997, LECT NOTES COMPUTER, P263, DOI [10.1007/3-540-63460-6_126, DOI 10.1007/3-540-63460-6_126]
   Wulder MA, 2008, REMOTE SENS ENVIRON, V112, P796, DOI 10.1016/j.rse.2007.06.013
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Yuan F, 2005, REMOTE SENS ENVIRON, V98, P317, DOI 10.1016/j.rse.2005.08.006
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang Z., 2018, ARXIV180709562
NR 74
TC 34
Z9 34
U1 20
U2 33
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 1
PY 2019
VL 11
IS 11
AR 1343
DI 10.3390/rs11111343
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IE8UC
UT WOS:000472648000086
OA Green Published, gold
DA 2022-01-04
ER

PT J
AU Peng, DF
   Zhang, YJ
   Guan, HY
AF Peng, Daifeng
   Zhang, Yongjun
   Guan, Haiyan
TI End-to-End Change Detection for High Resolution Satellite Images Using
   Improved UNet plus
SO REMOTE SENSING
LA English
DT Article
DE change detection; deep learning; end-to-end; encoder-decoder
   architecture; feature maps; multiple side-outputs fusion
ID UNSUPERVISED CHANGE DETECTION; REMOTE-SENSING IMAGES; SET;
   CLASSIFICATION; NETWORKS; FEATURES
AB Change detection (CD) is essential to the accurate understanding of land surface changes using available Earth observation data. Due to the great advantages in deep feature representation and nonlinear problem modeling, deep learning is becoming increasingly popular to solve CD tasks in remote-sensing community. However, most existing deep learning-based CD methods are implemented by either generating difference images using deep features or learning change relations between pixel patches, which leads to error accumulation problems since many intermediate processing steps are needed to obtain final change maps. To address the above-mentioned issues, a novel end-to-end CD method is proposed based on an effective encoder-decoder architecture for semantic segmentation named UNet++, where change maps could be learned from scratch using available annotated datasets. Firstly, co-registered image pairs are concatenated as an input for the improved UNet++ network, where both global and fine-grained information can be utilized to generate feature maps with high spatial accuracy. Then, the fusion strategy of multiple side outputs is adopted to combine change maps from different semantic levels, thereby generating a final change map with high accuracy. The effectiveness and reliability of our proposed CD method are verified on very-high-resolution (VHR) satellite image datasets. Extensive experimental results have shown that our proposed approach outperforms the other state-of-the-art CD methods.
C1 [Peng, Daifeng; Guan, Haiyan] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhang, Yongjun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
RP Peng, DF (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing 210044, Jiangsu, Peoples R China.
EM daifeng@nuist.edu.cn; zhangyj@whu.edu.cn; guanhy.nj@nuist.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801386, 41671454]; Natural Science
   Foundation of Jiangsu ProvinceNatural Science Foundation of Jiangsu
   Province [BK20180797]; Startup Project for Introducing Talent of NUIST
   [2018r029]
FX This work was supported in part by the National Natural Science
   Foundation of China (under grant numbers: 41801386 and 41671454), in
   part by the Natural Science Foundation of Jiangsu Province (under grant
   number: BK20180797), and in part by the Startup Project for Introducing
   Talent of NUIST (under grant number: 2018r029).
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Arabi ME, 2018, INT GEOSCI REMOTE SE, P5041, DOI 10.1109/IGARSS.2018.8518178
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen ST, 2018, ACM TRANS MODELING P, V3, DOI 10.1145/3199675
   Daudt R.C., 2018, ARXIV181008452V1
   Daudt R.C., 2018, ARXIV181008468
   Daudt RC, 2018, IEEE IMAGE PROC, P4063, DOI 10.1109/ICIP.2018.8451652
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Dong HH, 2019, IEEE ACCESS, V7, P15389, DOI 10.1109/ACCESS.2018.2889326
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2019, IEEE J-STARS, V12, P321, DOI 10.1109/JSTARS.2018.2887108
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Guo E., 2018, ARXIV181009111
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI 10.1007/978-3-319-10578-9_23
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jian P, 2016, INT J REMOTE SENS, V37, P1814, DOI 10.1080/2150704X.2016.1163744
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Khan SH, 2017, IEEE T GEOSCI REMOTE, V55, P5407, DOI 10.1109/TGRS.2017.2707528
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Klambauer G., 2017, P 31 INT C NEUR INF, DOI DOI 10.5555/3294771.3294864
   Koltun V., 2015, ARXIV151107122
   Langkvist M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040329
   Le Hegarat-Mascle S, 2005, REMOTE SENS ENVIRON, V95, P464, DOI 10.1016/j.rse.2005.01.011
   Lebedev M. A., 2018, INT ARCH PHOTOGRAMM, V42, P565, DOI [10.5194/isprs-archives-XLII-2-565-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-565-2018]
   Lee C.Y., 2015, ARXIV14095185
   Lei T, 2019, IEEE GEOSCI REMOTE S, V16, P982, DOI 10.1109/LGRS.2018.2889307
   Lei Y, 2019, IEEE ACCESS, V7, P36600, DOI 10.1109/ACCESS.2019.2902613
   Li XL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030258
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Niu XD, 2019, IEEE GEOSCI REMOTE S, V16, P45, DOI 10.1109/LGRS.2018.2868704
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K., 2015, P BRIT MACH VIS C BM
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI 10.1109/ICCV.2015.164
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhang Z., 2018, ARXIV180709562
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 70
TC 111
Z9 115
U1 59
U2 102
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN 1
PY 2019
VL 11
IS 11
AR 1382
DI 10.3390/rs11111382
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IE8UC
UT WOS:000472648000125
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Saha, S
   Bovolo, F
   Bruzzone, L
AF Saha, Sudipan
   Bovolo, Francesca
   Bruzzone, Lorenzo
TI Unsupervised Deep Change Vector Analysis for Multiple-Change Detection
   in VHR Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection (CD); deep change vector analysis (DCVA); deep
   features; multitemporal images; remote sensing; very high-resolution
   images
ID RANDOM-FIELD MODEL; MULTISENSOR; MULTIDATE; RADAR
AB Change detection (CD) in multitemporal images is an important application of remote sensing. Recent technological evolution provided very high spatial resolution (VHR) multitemporal optical satellite images showing high spatial correlation among pixels and requiring an effective modeling of spatial context to accurately capture change information. Here, we propose a novel unsupervised context-sensitive framework-deep change vector analysis (DCVA)-for CD in multitemporal VHR images that exploit convolutional neural network (CNN) features. To have an unsupervised system, DCVA starts from a suboptimal pretrained multilayered CNN for obtaining deep features that can model spatial relationship among neighboring pixels and thus complex objects. An automatic feature selection strategy is employed layerwise to select features emphasizing both high and low prior probability change information. Selected features from multiple layers are combined into a deep feature hypervector providing a multiscale scene representation. The use of the same pretrained CNN for semantic segmentation of single images enables us to obtain coherent multitemporal deep feature hypervectors that can be compared pixelwise to obtain deep change vectors that also model spatial context information. Deep change vectors are analyzed based on their magnitude to identify changed pixels. Then, deep change vectors corresponding to identified changed pixels are binarized to obtain a compressed binary deep change vectors that preserve information about the direction (kind) of change. Changed pixels are analyzed for multiple CD based on the binary features, thus implicitly using the spatial information. Experimental results on multitemporal data sets ofWorldview-2, Pleiades, and Quickbird images confirm the effectiveness of the proposed method.
C1 [Saha, Sudipan; Bovolo, Francesca] Fdn Bruno Kessler, I-38123 Trento, Italy.
   [Saha, Sudipan; Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38123 Trento, Italy.
RP Bovolo, F (corresponding author), Fdn Bruno Kessler, I-38123 Trento, Italy.
EM saha@fbk.eu; bovolo@fbk.eu
RI Bovolo, Francesca/R-7491-2017; Bruzzone, Lorenzo/A-2076-2012
OI Bovolo, Francesca/0000-0003-3104-7656; Bruzzone,
   Lorenzo/0000-0002-6036-459X; Saha, Sudipan/0000-0002-9440-0720
CR Auffarth B, 2010, LECT NOTES ARTIF INT, V6171, P248, DOI 10.1007/978-3-642-14400-4_20
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bishop C.M., 2006, PATTERN RECOGN
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2010, INT GEOSCI REMOTE SE, P3074, DOI 10.1109/IGARSS.2010.5652646
   Bovolo F, 2010, IEEE GEOSCI REMOTE S, V7, P53, DOI 10.1109/LGRS.2009.2029248
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruzzone L, 2000, INT J REMOTE SENS, V21, P3539, DOI 10.1080/014311600750037552
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1350, DOI 10.1109/36.763299
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Correa YTS, 2014, PROC SPIE, V9244, DOI 10.1117/12.2068171
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   Falco N, 2016, INT GEOSCI REMOTE SE, P3374, DOI 10.1109/IGARSS.2016.7729872
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Fawcett T., 2004, MACH LEARN, V31, P1, DOI DOI 10.1016/J.PATREC.2005.10.010
   Fischer P., 2014, DESCRIPTOR MATCHING
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Geng L, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACVW.2017.8
   Guo QL, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030698
   HALL FG, 1991, REMOTE SENS ENVIRON, V35, P11, DOI 10.1016/0034-4257(91)90062-B
   Han Y, 2015, IEEE T GEOSCI REMOTE, V53, P6650, DOI 10.1109/TGRS.2015.2445632
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kieri  A., 2012, F12036 UPTEC UPPS U
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JA, 2007, INFORM SCI STAT, P1
   Li L, 2016, INT GEOSCI REMOTE SE, P2873, DOI 10.1109/IGARSS.2016.7729742
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu DS, 2011, ISPRS J PHOTOGRAMM, V66, P298, DOI 10.1016/j.isprsjprs.2010.10.010
   Lv PY, 2018, IEEE T GEOSCI REMOTE, V56, P4002, DOI 10.1109/TGRS.2018.2819367
   Lv PY, 2016, IEEE GEOSCI REMOTE S, V13, P1965, DOI 10.1109/LGRS.2016.2619163
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma XR, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0071-8
   Maggiori E, 2016, HIGH RESOLUTION SEMA
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Malila W.A, 1980, P LARS S, P385
   Marinelli  D., 2017, P 9 INT WORKSH AN MU, P1
   Nogueira K, 2017, PATTERN RECOGN, V61, P539, DOI 10.1016/j.patcog.2016.07.001
   Oliva, 2014, ADV NEURAL INFORM PR, P487, DOI DOI 10.1162/153244303322533223
   Pacifici F, 2014, IEEE T GEOSCI REMOTE, V52, P6241, DOI 10.1109/TGRS.2013.2295819
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sermanet P., 2013, COMPUT VIS PATTERN R, V1312, P6229, DOI DOI 10.1109/CVPR.2015.7299176
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Subudhi BN, 2014, OPT LASER TECHNOL, V57, P284, DOI 10.1016/j.optlastec.2013.10.003
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Vetrivel  A., 2016, AUTOMATED SATELLITE
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wang SL, 2014, CHIN CONT DECIS CONF, P1016, DOI 10.1109/CCDC.2014.6852313
   Wellner P. D., 1993, EPC1993110 XER, P1
   Xu Y, 2013, PROC SPIE, V8919, DOI 10.1117/12.2031104
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhong YF, 2018, APPL SOFT COMPUT, V64, P75, DOI 10.1016/j.asoc.2017.11.045
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 71
TC 107
Z9 107
U1 34
U2 104
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JUN
PY 2019
VL 57
IS 6
BP 3677
EP 3693
DI 10.1109/TGRS.2018.2886643
PG 17
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA IB1IV
UT WOS:000470019800047
DA 2022-01-04
ER

PT J
AU Peng, DF
   Guan, HY
AF Peng, Daifeng
   Guan, Haiyan
TI Unsupervised change detection method based on saliency analysis and
   convolutional neural network
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; deep feature representation; saliency detection;
   convolutional neural network; multiscale fusion
ID IMAGE; SET; FEATURES
AB Due to great advantages in deep features representation and classification for image data, deep learning is becoming increasingly popular for change detection (CD) in the remote-sensing community. An unsupervised CD method is proposed by combining deep features representation, saliency detection, and convolutional neural network (CNN). First, bitemporal images are fed into the pretrained CNN model for deep features extraction and difference image generation. Second, multiscale saliency detection is adopted to implement the uncertainty analysis for the difference image, where image pixels can be categorized into three classes: changed, unchanged, and uncertain. Then, a flexible CNN model is constructed and trained using the interested changed and unchanged pixels, and the change type of the uncertain pixels can be determined by the CNN model. Finally, object-based refinement and multiscale fusion strategies are utilized to generate the final change map. The effectiveness and reliability of our CD method are verified on three very high-resolution datasets, and the experimental results show that our proposed approach outperforms the other state-of-the-art CD methods in terms of five quantitative metrics. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Peng, Daifeng; Guan, Haiyan] Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing, Jiangsu, Peoples R China.
RP Peng, DF (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Remote Sensing & Geomat Engn, Nanjing, Jiangsu, Peoples R China.
EM daifeng@nuist.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41801386, 41671454]; Startup Project for
   Introducing Talent of NUIST [2018r029]; Natural Science Foundation of
   Jiangsu ProvinceNatural Science Foundation of Jiangsu Province
   [BK20180797]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grants Nos. 41801386 and 41671454), in part by the
   Startup Project for Introducing Talent of NUIST (Grant No. 2018r029),
   and in part by the Natural Science Foundation of Jiangsu Province under
   Grant No. BK20180797.
CR Bao NS, 2012, J APPL REMOTE SENS, V6, DOI 10.1117/1.JRS.6.063578
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chang NB, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3518096
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen Q, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081204
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Guo E., 2018, ARXIV181009111
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Jian P, 2016, INT J REMOTE SENS, V37, P1814, DOI 10.1080/2150704X.2016.1163744
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Simonyan K, 2014, ArXiv:1409.1556
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Wang C, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073696
   Wang SN, 2016, REMOTE SENS LETT, V7, P1043, DOI 10.1080/2150704X.2016.1212417
   Wu C, 2017, REMOTE SENS ENVIRON, V199, P241, DOI 10.1016/j.rse.2017.07.009
   Wu C, 2016, SIGNAL PROCESS, V124, P184, DOI 10.1016/j.sigpro.2015.09.020
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Yousif O, 2017, INT J REMOTE SENS, V38, P1765, DOI 10.1080/01431161.2016.1217442
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang JY, 2011, MULTIMED TOOLS APPL, V52, P175, DOI 10.1007/s11042-010-0471-9
   Zhang MY, 2019, IEEE GEOSCI REMOTE S, V16, P266, DOI 10.1109/LGRS.2018.2869608
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 32
TC 9
Z9 9
U1 7
U2 27
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD MAY 8
PY 2019
VL 13
IS 2
AR 024512
DI 10.1117/1.JRS.13.024512
PG 12
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA HY3PT
UT WOS:000468039500002
DA 2022-01-04
ER

PT J
AU Gong, MG
   Niu, XD
   Zhan, T
   Zhang, MY
AF Gong, Maoguo
   Niu, Xudong
   Zhan, Tao
   Zhang, Mingyang
TI A coupling translation network for change detection in heterogeneous
   images
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID UNSUPERVISED CHANGE DETECTION; RADAR IMAGES; SAR IMAGES; FRAMEWORK;
   CLASSIFICATION; ALGORITHMS; FUSION; MODEL
AB Based on the images acquired through different sensors, change detection is much more challenging than those based on homogeneous images. The main reason behind it is that the heterogeneous image-pair cannot be directly compared in original observation space due to their distinct statistical properties. In order to detect the changes, we establish a coupling variational autoencoder (VAE) to transform the heterogeneous images into a shared-latent space, where they have more consistent representations and hence the prior changed regions can be highlighted by direct comparison. And based on the shared space, we build coupled generative adversarial networks (GANs) associated with the coupling VAE to translate the heterogeneous images into homogeneous, from which more accurate change detection results can be obtained in their common observation spaces. The proposed framework is totally unsupervised, and the experimental results on real heterogeneous data sets demonstrate its superiority over some other existing algorithms.
C1 [Gong, Maoguo; Niu, Xudong; Zhan, Tao; Zhang, Mingyang] Xidian Univ, Minist Educ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Xian, Shaanxi, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Minist Educ, Sch Elect Engn, Key Lab Intelligent Percept & Image Understanding, Xian, Shaanxi, Peoples R China.
EM gong@ieee.org
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National key research and
   development program of China [2017YFB0802200]; Key research and
   development program of Shaanxi Province [2018ZDXM-GY-045]
FX This work was supported by the National Natural Science Foundation of
   China (Grant no. 61772393), the National key research and development
   program of China (Grant no. 2017YFB0802200), and the Key research and
   development program of Shaanxi Province (Grant no. 2018ZDXM-GY-045).
CR Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Coates A., 2011, P 14 INT C ART INT S, P215, DOI DOI 10.1109/ICDAR.2011.95
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gokaraju B., APPL IM PATT REC WOR, P1
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Isola P., 2016, P IEEE C COMP VIS PA
   Jensen J. R., 1987, INLAND WETLAND CHANG
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   LEE JS, 1986, OPT ENG, V25, P636, DOI 10.1117/12.7973877
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Liu J., 2016, IEEE T NEURAL NETWOR, V29, P545, DOI DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu L., 2008, P INT WORKSH ED TECH, V1, P353
   Liu M.-Y., 2017, ARXIV170300848
   Liu ZG, 2014, IEEE GEOSCI REMOTE S, V11, P168, DOI 10.1109/LGRS.2013.2250908
   Ma JJ, 2012, IEEE GEOSCI REMOTE S, V9, P1122, DOI 10.1109/LGRS.2012.2191387
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Oliver C., 1998, UNDERSTANDING SYNTHE
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Qin Y, 2013, INT J REMOTE SENS, V34, P6723, DOI 10.1080/01431161.2013.805282
   Quin G, 2014, IEEE T GEOSCI REMOTE, V52, P5349, DOI 10.1109/TGRS.2013.2288271
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Robin A, 2010, IEEE T PATTERN ANAL, V32, P1977, DOI 10.1109/TPAMI.2010.37
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Welling, 2013, ARXIV13126114, DOI DOI 10.1007/S11042-018-6187-Y
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhu Jun-Yan, 2017, ARXIV170310593
NR 51
TC 7
Z9 7
U1 4
U2 23
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD MAY 3
PY 2019
VL 40
IS 9
BP 3647
EP 3672
DI 10.1080/01431161.2018.1547934
PG 26
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA HS0GC
UT WOS:000463538000020
DA 2022-01-04
ER

PT J
AU Li, L
   Wang, C
   Zhang, H
   Zhang, B
   Wu, F
AF Li, Lu
   Wang, Chao
   Zhang, Hong
   Zhang, Bo
   Wu, Fan
TI Urban Building Change Detection in SAR Images Using Combined
   Differential Image and Residual U-Net Network
SO REMOTE SENSING
LA English
DT Article
DE weighted function; color difference image; urban building change
   detection; synthetic aperture radar (SAR); residual U-Net
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION; MODEL
AB With the rapid development of urbanization in China, monitoring urban changes is of great significance to city management, urban planning, and cadastral map updating. Spaceborne synthetic aperture radar (SAR) sensors can capture a large area of radar images quickly with fine spatiotemporal resolution and are not affected by weather conditions, making multi-temporal SAR images suitable for change detection. In this paper, a new urban building change detection method based on an improved difference image and residual U-Net network is proposed. In order to overcome the intensity compression problem of the traditional log-ratio method, the spatial distance and intensity similarity are combined to generate a weighting function to obtain a weighted difference image. By fusing the weighted difference image and the bitemporal original images, the three-channel color difference image is generated for building change detection. Due to the complexity of urban environments and the small scale of building changes, the residual U-Net network is used instead of fixed statistical models and the construction and classifier of the network are modified to distinguish between different building changes. Three scenes of Sentinel-1 interferometric wide swath data are used to validate the proposed method. The experimental results and comparative analysis show that our proposed method is effective for urban building change detection and is superior to the original U-Net and SVM method.
C1 [Li, Lu; Wang, Chao; Zhang, Hong; Zhang, Bo; Wu, Fan] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
   [Li, Lu; Wang, Chao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP Zhang, H (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth Sci, Beijing 100094, Peoples R China.
EM lilushhf@sina.com; wangchao@radi.ac.cn; zhanghong@radi.ac.cn;
   zhangbo@radi.ac.cn; wufan@radi.ac.cn
RI Wang, Chao/N-9848-2019
OI Wang, Chao/0000-0003-4887-923X; wu, fan/0000-0002-9280-8378; Lu,
   Li/0000-0002-1398-7196; zhang, hong/0000-0002-0088-8148
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41331176, 41371352]; National Key Research
   and Development Program of China [2016YFB0501501]
FX This research was funded by the National Natural Science Foundation of
   China (41331176 and 41371352) and the National Key Research and
   Development Program of China (2016YFB0501501).
CR Argenti F, 2002, IEEE T GEOSCI REMOTE, V40, P2363, DOI 10.1109/TGRS.2002.805083
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Cao H, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060874
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chini M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111833
   Cui B., 2017, ISPRS PHOTOGRAMM REM, V4, P439, DOI [10.5194/isprs-annals-IV-2-W4-439-2017, DOI 10.5194/ISPRS-ANNALS-IV-2-W4-439-2017]
   Dabboor M, 2014, INT J REMOTE SENS, V35, P6859, DOI 10.1080/01431161.2014.960614
   De Grandi EC, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8080641
   Dekker RJ, 1998, INT J REMOTE SENS, V19, P1133, DOI 10.1080/014311698215649
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Ghanbari M, 2015, INT GEOSCI REMOTE SE, P1853, DOI 10.1109/IGARSS.2015.7326153
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   [韩晶 Han Jing], 2012, [大地测量与地球动力学, Journal of Geodesy and Geodynamics], V32, P94
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   [胡召玲 Hu Zhaoling], 2013, [测绘学报, Acta Geodetica et Cartographica Sinica], V42, P116
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Li YQ, 2018, IMMS 2019: 2019 2ND INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND MANAGEMENT SCIENCES, P123, DOI [10.1016/j.jag.2018.05.023, 10.1145/3357292.3357320]
   Liu WS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020559
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Nielsen A.A., 2015, P 8 INT WORKSH AN MU, P1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Su LZ, 2014, INT J REMOTE SENS, V35, P621, DOI 10.1080/01431161.2013.871596
   Tanase R, 2016, INT GEOSCI REMOTE SE, P7545, DOI 10.1109/IGARSS.2016.7730968
   Tang Hao, 2016, Journal of Computer Applications, V36, P3436, DOI 10.11772/j.issn.1001-9081.2016.12.3436
   United Nations, 2017, TECHNICAL REPORT
   Wang Y., 2018, P 2017 INT WORKSH RE, P1
   Wang Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020342
   Wang YJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081193
   Wei SS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11010068
   [徐真 Xu Zhen], 2017, [雷达学报, Journal of Radars], V6, P483
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang Y, 2018, IEEE J-STARS, V11, P4701, DOI 10.1109/JSTARS.2018.2866540
   Zhang Y, 2017, INT GEOSCI REMOTE SE, P3078, DOI 10.1109/IGARSS.2017.8127649
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhuang HF, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081295
   Zhuang HF, 2018, EUR J REMOTE SENS, V51, P723, DOI 10.1080/22797254.2018.1482523
NR 43
TC 14
Z9 15
U1 12
U2 32
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 1
PY 2019
VL 11
IS 9
AR 1091
DI 10.3390/rs11091091
PG 19
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IA7US
UT WOS:000469763600099
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Sublime, J
   Kalinicheva, E
AF Sublime, Jeremie
   Kalinicheva, Ekaterina
TI Automatic Post-Disaster Damage Mapping Using Deep-Learning Techniques
   for Change Detection: Case Study of the Tohoku Tsunami
SO REMOTE SENSING
LA English
DT Article
DE change detection; deep learning; Tsunami; damage mapping; remote sensing
ID NETWORK
AB Post-disaster damage mapping is an essential task following tragic events such as hurricanes, earthquakes, and tsunamis. It is also a time-consuming and risky task that still often requires the sending of experts on the ground to meticulously map and assess the damages. Presently, the increasing number of remote-sensing satellites taking pictures of Earth on a regular basis with programs such as Sentinel, ASTER, or Landsat makes it easy to acquire almost in real time images from areas struck by a disaster before and after it hits. While the manual study of such images is also a tedious task, progress in artificial intelligence and in particular deep-learning techniques makes it possible to analyze such images to quickly detect areas that have been flooded or destroyed. From there, it is possible to evaluate both the extent and the severity of the damages. In this paper, we present a state-of-the-art deep-learning approach for change detection applied to satellite images taken before and after the Tohoku tsunami of 2011. We compare our approach with other machine-learning methods and show that our approach is superior to existing techniques due to its unsupervised nature, good performance, and relative speed of analysis.
C1 [Sublime, Jeremie; Kalinicheva, Ekaterina] ISEP, DaSSIP Team, LISITE, 28 Rue Notre Dame Champs, F-75006 Paris, France.
   [Sublime, Jeremie] Univ Paris 13, Sorbonne Paris Cite, CNRS, UMR 7030,LIPN, 99 Ave JB Clement, F-93430 Villetaneuse, France.
RP Sublime, J; Kalinicheva, E (corresponding author), ISEP, DaSSIP Team, LISITE, 28 Rue Notre Dame Champs, F-75006 Paris, France.; Sublime, J (corresponding author), Univ Paris 13, Sorbonne Paris Cite, CNRS, UMR 7030,LIPN, 99 Ave JB Clement, F-93430 Villetaneuse, France.
EM jeremie.sublime@isep.fr; ekaterina.kalinicheva@isep.fr
RI Kalinicheva, Ekaterina/ABB-9659-2020; Sublime, Jeremie/I-2438-2019
OI Kalinicheva, Ekaterina/0000-0001-8332-2491; Sublime,
   Jeremie/0000-0003-0508-8550
CR Bai YB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101626
   Bukenya F., 2012, INT J SCI ENG RES, V3, P1
   Chahdi H., 2016, P IEEE INT C DAT SCI
   Chahdi H, 2016, LECT NOTES COMPUT SC, V9949, P156, DOI 10.1007/978-3-319-46675-0_18
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dong L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1235, DOI 10.1145/2733373.2806325
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   El Hajj M, 2008, SENSORS-BASEL, V8, P2774, DOI 10.3390/s8042774
   Guan QJ, 2017, INT C INTEL HUM MACH, P373, DOI 10.1109/IHMSC.2017.91
   Hinton G.E., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Ji YQ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10071088
   Kalinicheva E, 2018, IEEE I C ELECT CIRC, P641, DOI 10.1109/ICECS.2018.8617850
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Karimzadeh S, 2018, GEOSCIENCES, V8, DOI 10.3390/geosciences8120487
   Khiali L, 2019, INT J APPL EARTH OBS, V74, P103, DOI 10.1016/j.jag.2018.07.014
   LeCun Yann, 1998, CONVOLUTIONAL NETWOR, P255
   Lei T, 2019, INT CONF ACOUST SPEE, P3027, DOI 10.1109/ICASSP.2019.8682802
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281, DOI DOI 10.1007/S11665-016-2173-6
   Mori N, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL049210
   Nagi J., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P342, DOI 10.1109/ICSIPA.2011.6144164
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Patel A, 2016, J CLIN EXP HEPATOL, V6, P311, DOI 10.1016/j.jceh.2016.10.001
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Sublime J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050495
   Tan K, 2016, IEEE J-STARS, V9, P3439, DOI 10.1109/JSTARS.2016.2541678
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Woods, 2006, DIGITAL IMAGE PROCES
   Xu Y, 2013, PROC SPIE, V8919, DOI 10.1117/12.2031104
NR 33
TC 27
Z9 27
U1 5
U2 22
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY 1
PY 2019
VL 11
IS 9
AR 1123
DI 10.3390/rs11091123
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA IA7US
UT WOS:000469763600131
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Xu, JF
   Zhang, BM
   Guo, HT
   Lu, J
   Lin, YZ
AF Xu, Junfeng
   Zhang, Baoming
   Guo, Haitao
   Lu, Jun
   Lin, Yuzhun
TI Combining iterative slow feature analysis and deep feature learning for
   change detection in high-resolution remote sensing images
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; high-resolution remote sensing image; deep learning;
   slow feature analysis; stacked denoising autoencoder
ID CHANGE VECTOR ANALYSIS; NETWORK; RADAR; MAD
AB In order to make full use of local neighborhood information for high-resolution remote sensing images, this study combined iterative slow feature analysis (ISFA) and stacked denoising autoencoder (SDAE) to improve the change detection precision. First, this approach introduced ISFA for initial change detection in an unsupervised way, which enlarged the separability of changed and unchanged areas. Then, by setting different membership degrees, the changed and unchanged samples were obtained through fuzzy-means clustering. Finally, the change model was built by SDAE to represent the local neighborhood features deeply, and the change detection result can be obtained after all the samples were fed into the model. Experiments were performed on three real datasets, and the results validated the effectiveness and superiority of the proposed approach. (C) 2019 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Xu, Junfeng; Zhang, Baoming; Guo, Haitao; Lu, Jun; Lin, Yuzhun] Informat Engn Univ, Inst Geospatial Informat, Zhengzhou, Henan, Peoples R China.
RP Xu, JF (corresponding author), Informat Engn Univ, Inst Geospatial Informat, Zhengzhou, Henan, Peoples R China.
EM xjf4606@foxmail.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41601507]
FX This study was supported by the National Natural Science Foundation of
   China (No. 41601507).
CR Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bezdek JC, 1974, J CYBERNETICS, V3, P58, DOI [10.1080/01869727308548047, DOI 10.1080/01969727308546047]
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Feng W., 2018, REM SENS, V10, P1
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Fu XG, 2015, IEEE T NEUR NET LEAR, V26, P1900, DOI 10.1109/TNNLS.2014.2361267
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li L., 2016, IEEE GEOSC REM SENS
   [李亮 Li Liang], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P945
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Lv ZY, 2018, IEEE J-STARS, V11, P1520, DOI 10.1109/JSTARS.2018.2803784
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang C, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073696
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yang H, 2006, INT J REMOTE SENS, V27, P4199, DOI 10.1080/01431160600754609
   Zhan T, 2018, ISPRS J PHOTOGRAMM, V146, P38, DOI 10.1016/j.isprsjprs.2018.09.002
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   [张鑫龙 Zhang Xinlong], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P999
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
NR 35
TC 5
Z9 5
U1 5
U2 39
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD APR 23
PY 2019
VL 13
IS 2
AR 024506
DI 10.1117/1.JRS.13.024506
PG 16
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA HU5KT
UT WOS:000465317600001
DA 2022-01-04
ER

PT J
AU Wiratama, W
   Sim, D
AF Wiratama, Wahyu
   Sim, Donggyu
TI Fusion Network for Change Detection of High-Resolution Panchromatic
   Imagery
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE change detection; convolutional network; deep learning; panchromatic;
   remote sensing
ID FUZZY C-MEANS; LAND-COVER; REPRESENTATION; INFORMATION
AB This paper proposes a fusion network for detecting changes between two high-resolution panchromatic images. The proposed fusion network consists of front- and back-end neural network architectures to generate dual outputs for change detection. Two networks for change detection were applied to handle image- and high-level changes of information, respectively. The fusion network employs single-path and dual-path networks to accomplish low-level and high-level differential detection, respectively. Based on two dual outputs, a two-stage decision algorithm was proposed to efficiently yield the final change detection results. The dual outputs were incorporated into the two-stage decision by operating logical operations. The proposed algorithm was designed to incorporate not only dual network outputs but also neighboring information. In this paper, a new fused loss function was presented to estimate the errors and optimize the proposed network during the learning stage. Based on our experimental evaluation, the proposed method yields a better detection performance than conventional neural network algorithms, with an average area under the curve of 0.9709, percentage correct classification of 99%, and Kappa of 75 for many test datasets.
C1 [Wiratama, Wahyu; Sim, Donggyu] Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
RP Sim, D (corresponding author), Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
EM wiratama@kw.ac.kr; dgsim@kw.ac.kr
OI Sim, Donggyu/0000-0002-2794-9932
FU Ministry of Science and ICT (MSIT), Korea, under the Information
   Technology Research Center (ITRC) support program
   [IITP-2018-2016-0-00288]; Basic Science Research Program through the
   National Research Foundation of Korea (NRF) - Ministry of Science, ICT &
   Future Planning [NRF-2018R1A2B2008238]
FX This research was supported by the Ministry of Science and ICT (MSIT),
   Korea, under the Information Technology Research Center (ITRC) support
   program (IITP-2018-2016-0-00288) supervised by the Institute for
   Information & communications Technology Promotion (IITP) and Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Science, ICT & Future Planning
   (NRF-2018R1A2B2008238).
CR Bagnell J. A., 2018, ARXIV171100002
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bi CJ, 2014, INT CONF CLOUD COMPU, P327, DOI 10.1109/CCIS.2014.7175753
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Ciuonzo D, 2018, INT J GEN SYST, V47, P529, DOI 10.1080/03081079.2018.1455192
   Ciuonzo D, 2017, IEEE T SIGNAL PROCES, V65, P5078, DOI 10.1109/TSP.2017.2712124
   De S, 2017, INT GEOSCI REMOTE SE, P5193, DOI 10.1109/IGARSS.2017.8128171
   El Amin A.M., 2016, P 1 INT WORKSH PATT
   El Amin A.M., 2016, CONVOLUTIONAL NEURAL, V10011
   Gao F., 2015, P INT C CIRC SYST CA
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo Z, 2017, GISCI REMOTE SENS, V54, P38, DOI 10.1080/15481603.2016.1250328
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hadsell R., 2006, P 2006 IEEE COMP SOC
   Hao M, 2017, MULTIMED TOOLS APPL, V76, P20081, DOI 10.1007/s11042-017-4354-1
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SL, 2017, GISCI REMOTE SENS, V54, P495, DOI 10.1080/15481603.2017.1286727
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Singh K.K., 2013, P IEEE PIMRC, P1
   VISWANATHAN R, 1989, IEEE T ACOUST SPEECH, V37, P772, DOI 10.1109/29.17574
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wahl DE, 2016, IEEE T GEOSCI REMOTE, V54, P2460, DOI 10.1109/TGRS.2015.2502219
   Wang Q, 2018, REMOTE SENS LETT, V9, P923, DOI 10.1080/2150704X.2018.1492172
   Wiratama W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101785
   Yoo H.-J., 2015, IEIE T SMART PROCESS, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang WX, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030240
   Zhang Z., 2018, ARXIV180709562
NR 38
TC 8
Z9 8
U1 4
U2 9
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD APR 1
PY 2019
VL 9
IS 7
AR 1441
DI 10.3390/app9071441
PG 17
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA HW2VN
UT WOS:000466547500176
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Gong, JQ
   Hu, XY
   Pang, SY
   Li, K
AF Gong, Jinqi
   Hu, Xiangyun
   Pang, Shiyan
   Li, Kun
TI Patch Matching and Dense CRF-Based Co-Refinement for Building Change
   Detection from Bi-Temporal Aerial Images
SO SENSORS
LA English
DT Article
DE building change detection; patch matching; phase consistency; semantic
   segmentation; relief displacement
ID REMOTELY-SENSED IMAGES; CLASSIFICATION
AB The identification and monitoring of buildings from remotely sensed imagery are of considerable value for urbanization monitoring. Two outstanding issues in the detection of changes in buildings with composite structures and relief displacements are heterogeneous appearances and positional inconsistencies. In this paper, a novel patch-based matching approach is developed using densely connected conditional random field (CRF) optimization to detect building changes from bi-temporal aerial images. First, the bi-temporal aerial images are combined to obtain change information using an object-oriented technique, and then semantic segmentation based on a deep convolutional neural network is used to extract building areas. With the change information and extracted buildings, a graph-cuts-based segmentation algorithm is applied to generate the bi-temporal changed building proposals. Next, in the bi-temporal changed building proposals, corner and edge information are integrated for feature detection through a phase congruency (PC) model, and the structural feature descriptor, called the histogram of orientated PC, is used to perform patch-based roof matching. We determined the final change in buildings by gathering matched roof and bi-temporal changed building proposals using co-refinement based on CRF, which were further classified as newly built, demolished, or changed. Experiments were conducted with two typical datasets covering complex urban scenes with diverse building types. The results confirm the effectiveness and generality of the proposed algorithm, with more than 85% and 90% in overall accuracy and completeness, respectively.
C1 [Gong, Jinqi; Hu, Xiangyun; Li, Kun] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Xiangyun] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
   [Pang, Shiyan] Cent China Normal Univ, Sch Educ Informat Technol, Wuhan 430079, Hubei, Peoples R China.
RP Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.; Hu, XY (corresponding author), Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
EM jinqigong@whu.edu.cn; huxy@whu.edu.cn; psy@whu.edu.cn;
   petrick_Lee@whu.edu.cn
OI Li, Kun/0000-0001-8501-3916
FU National Key Research and Development Program of China [2016YFB0501403];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41771363, 41701389]
FX This work was partially supported by the National Key Research and
   Development Program of China (Project No. 2016YFB0501403) and National
   Natural Science Foundation of China (Project No. 41771363 and 41701389).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Akcay HG, 2010, INT GEOSCI REMOTE SE, P1932, DOI 10.1109/IGARSS.2010.5652842
   Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Beucher S, 1991, SCANNING MICROSCOPY, P299
   Blaschke T, 2014, ISPRS J PHOTOGRAMM, V87, P180, DOI 10.1016/j.isprsjprs.2013.09.014
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Canty M.J., 2007, P INT SOC OPT ENG BE, P8
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Cheng MM, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12758
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Daudt R.C., 2018, ARXIV181008462
   Daudt R. Caye, 2018, ARXIV181008452
   Devi S., 2014, INT J SCI ENG TECHNO, V3, P2800
   Feng J., 2017, ARXIV170208835
   Feng T., 2017, SCI SURV MAPP, V5, P237
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gong JQ, 2017, MAR GEOD, V40, P87, DOI 10.1080/01490419.2017.1304472
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Hecheltjen A, 2014, REMOTE SENS DIGIT IM, V18, P145, DOI 10.1007/978-94-007-7969-3_10
   HORN BKP, 1986, ROBOT VISION
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Huang X, 2014, REMOTE SENS LETT, V5, P713, DOI 10.1080/2150704X.2014.963732
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Huang X, 2012, IEEE J-STARS, V5, P161, DOI 10.1109/JSTARS.2011.2168195
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Kovesi P, 2000, PSYCHOL RES-PSYCH FO, V64, P136, DOI 10.1007/s004260000024
   Kovesi P., 2003, P DIG IM COMP TECHN, V1, P309, DOI DOI 10.1177/0734242X0302100404
   Krahenbuhl P., 2012, ARXIV12105644
   Li J., 2018, ARXIV180409493
   Liu HF, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7100410
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   Myint SW, 2011, REMOTE SENS ENVIRON, V115, P1145, DOI 10.1016/j.rse.2010.12.017
   Nielsen A.A., 2005, PERSPEKTIVER MANGE I, P69
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ok AO, 2013, IEEE T GEOSCI REMOTE, V51, P1701, DOI 10.1109/TGRS.2012.2207123
   Ozdemir B, 2010, PATTERN RECOGN LETT, V31, P1128, DOI 10.1016/j.patrec.2009.10.016
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saito S, 2016, J IMAGING SCI TECHN, V60, DOI 10.2352/J.ImagingSci.Technol.2016.60.1.010402
   Sellaouti A, 2014, IEEE GEOSCI REMOTE S, V11, P706, DOI 10.1109/LGRS.2013.2276936
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Tang YQ, 2013, IEEE GEOSCI REMOTE S, V10, P1060, DOI 10.1109/LGRS.2012.2228626
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Ye YX, 2017, IEEE T GEOSCI REMOTE, V55, P2941, DOI 10.1109/TGRS.2017.2656380
   Yuan D, 1998, REMOTE SENSING CHANG, P21, DOI DOI 10.1234/12345678
   Zhang M., 2017, REMOTE SENS-BASEL, V9, DOI DOI 10.3390/rs9050500
   [张鑫龙 Zhang Xinlong], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P999
   Zhou GQ, 2005, IEEE T GEOSCI REMOTE, V43, P2138, DOI 10.1109/TGRS.2005.848417
   Zhou WQ, 2008, SENSORS-BASEL, V8, P1613, DOI 10.3390/s8031613
NR 57
TC 5
Z9 6
U1 6
U2 14
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD APR 1
PY 2019
VL 19
IS 7
AR 1557
DI 10.3390/s19071557
PG 29
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA HU8WA
UT WOS:000465570700076
PM 30935129
OA gold, Green Published, Green Submitted
DA 2022-01-04
ER

PT J
AU Zhang, C
   Wei, SQ
   Ji, SP
   Lu, M
AF Zhang, Chi
   Wei, Shiqing
   Ji, Shunping
   Lu, Meng
TI Detecting Large-Scale Urban Land Cover Changes from Very High Resolution
   Remote Sensing Images Using CNN-Based Classification
SO ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION
LA English
DT Article
DE classification; change detection; convolutional neural networks; Atrous
   convolution; very-high-resolution remote sensing images
ID CROP CLASSIFICATION; TIME-SERIES; SEGMENTATION
AB The study investigates land use/cover classification and change detection of urban areas from very high resolution (VHR) remote sensing images using deep learning-based methods. Firstly, we introduce a fully Atrous convolutional neural network (FACNN) to learn the land cover classification. In the FACNN an encoder, consisting of full Atrous convolution layers, is proposed for extracting scale robust features from VHR images. Then, a pixel-based change map is produced based on the classification map of current images and an outdated land cover geographical information system (GIS) map. Both polygon-based and object-based change detection accuracy is investigated, where a polygon is the unit of the GIS map and an object consists of those adjacent changed pixels on the pixel-based change map. The test data covers a rapidly developing city of Wuhan (8000 km(2)), China, consisting of 0.5 m ground resolution aerial images acquired in 2014, and 1 m ground resolution Beijing-2 satellite images in 2017, and their land cover GIS maps. Testing results showed that our FACNN greatly exceeded several recent convolutional neural networks in land cover classification. Second, the object-based change detection could achieve much better results than a pixel-based method, and provide accurate change maps to facilitate manual urban land cover updating.
C1 [Zhang, Chi; Wei, Shiqing; Ji, Shunping] Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
   [Lu, Meng] Univ Utrecht, Fac Geosci, Dept Phys Geog, Princetonlaan 8, NL-3584 CB Utrecht, Netherlands.
RP Ji, SP (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, 129 Luoyu Rd, Wuhan 430079, Hubei, Peoples R China.
EM whuzhangchi@whu.edu.cn; wei_sq@whu.edu.cn; jishunping@whu.edu.cn;
   m.lu@uu.nl
RI Lu, Meng/AAF-1711-2019
OI Lu, Meng/0000-0002-6850-581X; Ji, Shunping/0000-0002-3088-1481
FU project of Land Cover Change Detection of Wuhan City from the Wuhan
   Institute of Surveying and Mapping
FX This work was supported by the project of Land Cover Change Detection of
   Wuhan City from theWuhan Institute of Surveying and Mapping. The
   algorithm has been successfully applied to the 2018 annual GIS map
   updating ofWuhan city.
CR Chen L.-C., 2017, ARXIV170605587
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Conrad C, 2011, INT J REMOTE SENS, V32, P8763, DOI 10.1080/01431161.2010.550647
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Du Y, 2002, REMOTE SENS ENVIRON, V82, P123, DOI 10.1016/S0034-4257(02)00029-9
   Gamanya R, 2009, EXPERT SYST APPL, V36, P571, DOI 10.1016/j.eswa.2007.09.067
   Garzelli A, 2018, INT GEOSCI REMOTE SE, P6083, DOI 10.1109/IGARSS.2018.8518976
   Guo R, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030110
   Hinton G.E., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji SP, 2019, INT J REMOTE SENS, V40, P3308, DOI 10.1080/01431161.2018.1528024
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Kemker R, 2018, ISPRS J PHOTOGRAMM, V145, P60, DOI 10.1016/j.isprsjprs.2018.04.014
   Koltun V., 2015, ARXIV151107122
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin T.Y., 2017, ARXIV161203144
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Paris C, 2019, IEEE T GEOSCI REMOTE, V57, P4259, DOI 10.1109/TGRS.2018.2890404
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruiz L, 2004, INT ARCH PHOTOGRA B4, VXXXV, P1682
   Shackelford AK, 2003, IEEE T GEOSCI REMOTE, V41, P2354, DOI 10.1109/TGRS.2003.815972
   Stow D., 2010, HDB APPL SPATIAL STA, VVolume 4, P565
   Szegedy C., 2015, ARXIV150203167, P448
   TODD WJ, 1977, J RES US GEOL SURV, V5, P529
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wardlow BD, 2007, REMOTE SENS ENVIRON, V108, P290, DOI 10.1016/j.rse.2006.11.021
   Zhang C, 2018, REMOTE SENS ENVIRON, V216, P57, DOI 10.1016/j.rse.2018.06.034
NR 31
TC 39
Z9 39
U1 23
U2 45
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2220-9964
J9 ISPRS INT J GEO-INF
JI ISPRS Int. Geo-Inf.
PD APR
PY 2019
VL 8
IS 4
AR 189
DI 10.3390/ijgi8040189
PG 16
WC Computer Science, Information Systems; Geography, Physical; Remote
   Sensing
SC Computer Science; Physical Geography; Remote Sensing
GA HX6FK
UT WOS:000467499300030
OA gold, Green Published, Green Submitted
DA 2022-01-04
ER

PT J
AU Zhang, PZ
   Gong, MG
   Zhang, H
   Liu, J
   Ban, YF
AF Zhang, Puzhao
   Gong, Maoguo
   Zhang, Hui
   Liu, Jia
   Ban, Yifang
TI Unsupervised Difference Representation Learning for Detecting Multiple
   Types of Changes in Multitemporal Remote Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection (CD); deep neural networks (DNNs); difference
   representation (DR); multiclass changes; multitemporal image analysis;
   remote sensing
ID DEEP; CLASSIFICATION; LANDSAT
AB With the rapid increase of remote sensing images in temporal, spectral, and spatial resolutions, it is urgent to develop effective techniques for joint interpretation of spatial-temporal images. Multitype change detection (CD) is a significant research topic in multitemporal remote sensing image analysis, and its core is to effectively measure the difference degree and represent the difference among the multitemporal images. In this paper, we propose a novel difference representation learning (DRL) network and present an unsupervised learning framework for multitype CD task. Deep neural networks work well in representation learning but rely too much on labeled data, while clustering is a widely used classification technique free from supervision. However, the distribution of real remote sensing data is often not very friendly for clustering. To better highlight the changes and distinguish different types of changes, we combine difference measurement, DRL, and unsupervised clustering into a unified model, which can be driven to learn Gaussian-distributed and discriminative difference representations for nonchange and different types of changes. Furthermore, the proposed model is extended into an iterative framework to imitate the bottom-up aggregative clustering procedure, in which similar change types are gradually merged into the same classes. At the same time, the training samples are updated and reused to ensure that it converges to a stable solution. The experimental studies on four pairs of multispectral data sets demonstrate the effectiveness and superiority of the proposed model on multitype CD.
C1 [Zhang, Puzhao; Gong, Maoguo; Zhang, Hui; Liu, Jia] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Joint Int Res Lab Intelligent Percept & Computat, Int Res Ctr Intelligent Percept & Computat,Minist, Xian 710071, Shaanxi, Peoples R China.
   [Zhang, Puzhao; Ban, Yifang] KTH Royal Inst Technol, Div Geoinformat, S-10044 Stockholm, Sweden.
RP Gong, MG (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Joint Int Res Lab Intelligent Percept & Computat, Int Res Ctr Intelligent Percept & Computat,Minist, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org
RI Liu, Jia/P-9706-2018
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Program for Support of
   Top-Notch Young Professionals of China; National Key Research and
   Development Program of China [2017YFB0802200]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]; China
   Scholarship CouncilChina Scholarship Council
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393, in part by the National
   Program for Support of Top-Notch Young Professionals of China, in part
   by the National Key Research and Development Program of China under
   Grant 2017YFB0802200, in part by the Key Research and Development
   Program of Shaanxi Province under Grant 2018ZDXM-GY-045, and in part by
   China Scholarship Council.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alphan H, 2009, ENVIRON MONIT ASSESS, V151, P327, DOI 10.1007/s10661-008-0274-x
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2011, INT GEOSCI REMOTE SE, P233, DOI 10.1109/IGARSS.2011.6048935
   Brahma PP, 2016, IEEE T NEUR NET LEAR, V27, P1997, DOI 10.1109/TNNLS.2015.2496947
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hong M., 2016, K MEANS FRIENDLY SPA
   Hong S, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487982
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jiang Z, 2016, INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2015, VOL 2B
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Liu F., 2012, P 2012 IEEE PES GEN, V2, P1
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P4363, DOI 10.1109/TGRS.2015.2396686
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Malila W.A, 1980, P LARS S, P385
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ortiz-Rivera V, 2006, PROC SPIE, V6233, DOI 10.1117/12.667961
   Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Vedaldi A., 2008, P 18 ACM INT C MULT, P1469
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xie JY, 2016, PR MACH LEARN RES, V48
   Xu J, 2017, IEEE T NEUR NET LEAR, V28, P1974, DOI 10.1109/TNNLS.2016.2562670
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   [张伟 Zhang Wei], 2013, [地震, Earthquake], V33, P87
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3111, DOI 10.1109/TNNLS.2017.2712801
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
NR 43
TC 17
Z9 17
U1 4
U2 41
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD APR
PY 2019
VL 57
IS 4
BP 2277
EP 2289
DI 10.1109/TGRS.2018.2872509
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HR3EH
UT WOS:000463019000034
DA 2022-01-04
ER

PT J
AU Wang, RF
   Zhang, J
   Chen, JW
   Jiao, LC
   Wang, M
AF Wang, Rongfang
   Zhang, Jie
   Chen, Jiawei
   Jiao, Licheng
   Wang, Mi
TI Imbalanced Learning-Based Automatic SAR Images Change Detection by
   Morphologically Supervised PCA-Net
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; imbalance learning; PCA network (PCA-Net); synthetic
   aperture radar (SAR) images
ID UNSUPERVISED CHANGE DETECTION; REPRESENTATION
AB Change detection is a quite challenging task due to the imbalance between unchanged and changed class. In addition, the traditional difference map generated by log-ratio is subject to the speckle, which will reduce the accuracy. In this letter, an imbalanced learning-based change detection is proposed based on PCA network (PCA-Net), where a supervised PCA-Net is designed to obtain the robust features directly from given multitemporal synthetic aperture radar (SAR) images instead of a difference map. Furthermore, to tackle with the imbalance between changed and unchanged classes, we propose a morphologically supervised learning method, where the knowledge in the pixels near the boundary between two classes is exploited to guide network training. Finally, our proposed PCA-Net can be trained by the data sets with available reference maps and applied to a new data set, which is quite practical in change detection projects. Our proposed method is verified on five sets of multiple temporal SAR images. It is demonstrated from the experiment results that with the knowledge in training samples from the boundary, the learned features benefit change detection and make the proposed method outperform than supervised methods trained by randomly drawing samples.
C1 [Wang, Rongfang; Zhang, Jie; Chen, Jiawei; Jiao, Licheng] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Mi] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
RP Chen, JW (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM rfwang@xidian.edu.cn; jawaechan@gmail.com
OI WANG, RONGFANG/0000-0002-7253-7750; Jiao, Licheng/0000-0003-3354-9617;
   Chen, Jia-Wei/0000-0002-8195-1582
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61701361]; Open Fund of State Laboratory of
   Information Engineering in Surveying, Mapping and Remote Sensing, Wuhan
   University [17E02]; Key R&D Program, The Key Industry Innovation Chain
   of Shaanxi [2018JM6083]; Fundamental Research Funds for the Central
   University [JB181701]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61701361, in part by the Open Fund of
   State Laboratory of Information Engineering in Surveying, Mapping and
   Remote Sensing, Wuhan University, under Grant 17E02, in part by the Key
   R&D Program, The Key Industry Innovation Chain of Shaanxi, under Grant
   2018JM6083, and in part by the Fundamental Research Funds for the
   Central University under Grant JB181701.
CR Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 2000, INT GEOSCI REMOTE SE, P2441, DOI 10.1109/IGARSS.2000.859602
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Haibo He, 2009, IEEE Transactions on Knowledge and Data Engineering, V21, P1263, DOI 10.1109/TKDE.2008.239
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li W, 2012, INT GEOSCI REMOTE SE, P6165, DOI 10.1109/IGARSS.2012.6352664
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Theau J., 2012, CHANGE DETECTION, P75
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 18
TC 21
Z9 23
U1 5
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD APR
PY 2019
VL 16
IS 4
BP 554
EP 558
DI 10.1109/LGRS.2018.2878420
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HQ5IK
UT WOS:000462443300012
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Ma, WP
   Xiong, YT
   Wu, Y
   Yang, H
   Zhang, XR
   Jiao, LC
AF Ma, Wenping
   Xiong, Yunta
   Wu, Yue
   Yang, Hui
   Zhang, Xiangrong
   Jiao, Licheng
TI Change Detection in Remote Sensing Images Based on Image Mapping and a
   Deep Capsule Network
SO REMOTE SENSING
LA English
DT Article
DE change detection; capsule network; image mapping; synthetic aperture
   radar image; optical image; heterogeneous image
ID UNSUPERVISED CHANGE DETECTION; CHANGE-VECTOR ANALYSIS; SAR IMAGES;
   LAND-COVER; FUSION; MODEL
AB Homogeneous image change detection research has been well developed, and many methods have been proposed. However, change detection between heterogeneous images is challenging since heterogeneous images are in different domains. Therefore, direct heterogeneous image comparison in the way that we do it is difficult. In this paper, a method for heterogeneous synthetic aperture radar (SAR) image and optical image change detection is proposed, which is based on a pixel-level mapping method and a capsule network with a deep structure. The mapping method proposed transforms an image from one feature space to another feature space. Then, the images can be compared directly in a similarly transformed space. In the mapping process, some image blocks in unchanged areas are selected, and these blocks are only a small part of the image. Then, the weighted parameters are acquired by calculating the Euclidean distances between the pixel to be transformed and the pixels in these blocks. The Euclidean distance calculated according to the weighted coordinates is taken as the pixel gray value in another feature space. The other image is transformed in a similar manner. In the transformed feature space, these images are compared, and the fusion of the two different images is achieved. The two experimental images are input to a capsule network, which has a deep structure. The image fusion result is taken as the training labels. The training samples are selected according to the ratio of the center pixel label and its neighboring pixels' labels. The capsule network can improve the detection result and suppress noise. Experiments on remote sensing datasets show the final detection results, and the proposed method obtains a satisfactory performance.
C1 [Ma, Wenping; Xiong, Yunta; Yang, Hui; Zhang, Xiangrong; Jiao, Licheng] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence,Joint Int Res Lab Int, Minist Educ,Int Res Ctr Intelligent Percept & Com, Xian 710071, Shaanxi, Peoples R China.
   [Wu, Yue] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
RP Wu, Y (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM wpma@mail.xidian.edu.cn; tataerchenyingxue@163.com; ywu@xidian.edu.cn;
   hyangstu@163.com; xrzhang@mail.xidian.edu.cn; lchjiao@mail.xidian.edu.cn
OI Zhang, Xiangrong/0000-0003-0379-2042; Wu, Yue/0000-0002-3459-5079
FU National Natural Science Foundations of ChinaNational Natural Science
   Foundation of China (NSFC) [61702392, 61671350, 61772400]; China
   Postdoctoral Science FoundationChina Postdoctoral Science Foundation
   [2018T111022, 2017M623127]
FX The research was jointly supported by the National Natural Science
   Foundations of China (No. 61702392, 61671350, 61772400), and the China
   Postdoctoral Science Foundation (No. 2018T111022, 2017M623127).
CR Ayush J., 2018, ARXIV180206167V7, P526
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Cohen TS, 2016, PR MACH LEARN RES, V48
   Conradsen K, 2003, IEEE T GEOSCI REMOTE, V41, P4, DOI 10.1109/TGRS.2002.808066
   Dawn S, 2010, LECT NOTES COMPUT SC, V6134, P103, DOI 10.1007/978-3-642-13681-8_13
   Mai DS, 2015, IEEE INT FUZZY SYST
   Garcia-Laencina PJ, 2010, NEURAL COMPUT APPL, V19, P263, DOI 10.1007/s00521-009-0295-6
   Gens R., 2014, P NIPS, P2537
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   JENSEN JR, 1987, PHOTOGRAMM ENG REM S, V53, P521
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Kit O, 2013, ISPRS J PHOTOGRAMM, V83, P130, DOI 10.1016/j.isprsjprs.2013.06.009
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kuruoglu EE, 2004, IEEE T IMAGE PROCESS, V13, P527, DOI 10.1109/TIP.2003.818017
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Le Roux N, 2008, NEURAL COMPUT, V20, P1631, DOI 10.1162/neco.2008.04-07-510
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Liu WS, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111135
   Liu ZG, 2016, PATTERN RECOGN, V52, P85, DOI 10.1016/j.patcog.2015.10.001
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lv ZY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030472
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma WP, 2019, INT J REMOTE SENS, V40, P1066, DOI 10.1080/01431161.2018.1524172
   Marchesi S, 2010, IEEE T IMAGE PROCESS, V19, P1877, DOI 10.1109/TIP.2010.2045070
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Mhaskar HN, 2016, ANAL APPL, V14, P829, DOI 10.1142/S0219530516400042
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Sabour S., 2017, P ADV NEURAL INF PRO, P3859, DOI DOI 10.1371/JOURNAL.PONE.0035195
   Santos MDL, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW GENERATIONS, P662, DOI 10.1109/ITNG.2015.111
   Sermanet P, 2012, INT C PATT RECOG, P3288
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Vesanto J, 2000, IEEE T NEURAL NETWOR, V11, P586, DOI 10.1109/72.846731
   Wang D., 2018, P 6 INT C LEARN REPR
   Wu F, 1996, INT J ROBUST NONLIN, V6, P983
   Wu K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030284
   Yan L, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060841
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zheng YG, 2014, IEEE GEOSCI REMOTE S, V11, P691, DOI 10.1109/LGRS.2013.2275738
NR 56
TC 24
Z9 24
U1 7
U2 15
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 2
PY 2019
VL 11
IS 6
AR 626
DI 10.3390/rs11060626
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA HU9LG
UT WOS:000465615300025
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Pang, SY
   Hu, XY
   Zhang, M
   Cai, ZL
   Liu, FZ
AF Pang, Shiyan
   Hu, Xiangyun
   Zhang, Mi
   Cai, Zhongliang
   Liu, Fengzhu
TI Co-Segmentation and Superpixel-Based Graph Cuts for Building Change
   Detection from Bi-Temporal Digital Surface Models and Aerial Images
SO REMOTE SENSING
LA English
DT Article
DE building change detection; co-segmentation; graph cuts; digital surface
   models; aerial images
ID SATELLITE STEREO IMAGERY
AB Thanks to the recent development of laser scanner hardware and the technology of dense image matching (DIM), the acquisition of three-dimensional (3D) point cloud data has become increasingly convenient. However, how to effectively combine 3D point cloud data and images to realize accurate building change detection is still a hotspot in the field of photogrammetry and remote sensing. Therefore, with the bi-temporal aerial images and point cloud data obtained by airborne laser scanner (ALS) or DIM as the data source, a novel building change detection method combining co-segmentation and superpixel-based graph cuts is proposed in this paper. In this method, the bi-temporal point cloud data are firstly combined to achieve a co-segmentation to obtain bi-temporal superpixels with the simple linear iterative clustering (SLIC) algorithm. Secondly, for each period of aerial images, semantic segmentation based on a deep convolutional neural network is used to extract building areas, and this is the basis for subsequent superpixel feature extraction. Again, with the bi-temporal superpixel as the processing unit, a graph-cuts-based building change detection algorithm is proposed to extract the changed buildings. In this step, the building change detection problem is modeled as two binary classifications, and acquisition of each period's changed buildings is a binary classification, in which the changed building is regarded as foreground and the other area as background. Then, the graph cuts algorithm is used to obtain the optimal solution. Next, by combining the bi-temporal changed buildings and digital surface models (DSMs), these changed buildings are further classified as newly built, taller, demolished, and lower. Finally, two typical datasets composed of bi-temporal aerial images and point cloud data obtained by ALS or DIM are used to validate the proposed method, and the experiments demonstrate the effectiveness and generality of the proposed algorithm.
C1 [Pang, Shiyan] Cent China Normal Univ, Sch Educ Informat Technol, Wuhan 430079, Hubei, Peoples R China.
   [Pang, Shiyan; Hu, Xiangyun] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.
   [Pang, Shiyan; Cai, Zhongliang] Wuhan Univ, Sch Resource & Environm Sci, Wuhan 430079, Hubei, Peoples R China.
   [Hu, Xiangyun; Zhang, Mi] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
   [Liu, Fengzhu] Beijing Insititute Surveying & Mapping, Beijing 100038, Peoples R China.
   [Liu, Fengzhu] Beijing Key Lab Urban Spatial Informat Engn, Beijing 100038, Peoples R China.
RP Hu, XY (corresponding author), Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Hubei, Peoples R China.; Hu, XY (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
EM psy@whu.edu.cn; huxy@whu.edu.cn; mizhang@whu.edu.cn; zlcai@whu.edu.cn;
   fengzhuliu@whu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41701389, 41771363]; Guangzhou Science,
   Technology and Innovation Commission [201802030008]; China Postdoctoral
   Science FoundationChina Postdoctoral Science Foundation [2016M602363];
   Beijing Postdoctoral Research FoundationChina Postdoctoral Science
   Foundation [2018046]; Beijing Key Laboratory of Urban Spatial
   Information Engineering [2019208]
FX This study was partially supported by National Natural Science
   Foundation of China (Project No. 41701389 and 41771363), the research
   funding by Guangzhou Science, Technology and Innovation Commission
   (Project No. 201802030008), China Postdoctoral Science Foundation funded
   project (Project No. 2016M602363), Beijing Postdoctoral Research
   Foundation (Project No. 2018046) and Funded by Beijing Key Laboratory of
   Urban Spatial Information Engineering (Project No. 2019208).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Argialas DP, 2013, SURV REV, V45, P441, DOI 10.1179/1752270613Y.0000000058
   Awrangjeb M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101512
   Axelsson P., 2000, INT ARCH PHOTOGRAMME, V33, P110, DOI DOI 10.1016/J.ISPRSJPRS.2005.10.005
   Beucher S, 1991, SCANNING MICROSCOPY, P299
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chen BH, 2016, NEUROCOMPUTING, V208, P350, DOI 10.1016/j.neucom.2015.11.118
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Du SJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121030
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Jung F, 2004, ISPRS J PHOTOGRAMM, V58, P187, DOI 10.1016/j.isprsjprs.2003.09.005
   Li PJ, 2010, INT J REMOTE SENS, V31, P3393, DOI 10.1080/01431161003727705
   Li WZ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060625
   Malpica JA, 2013, INT J REMOTE SENS, V34, P1652, DOI 10.1080/01431161.2012.725483
   Murakami H, 1999, ISPRS J PHOTOGRAMM, V54, P148, DOI 10.1016/S0924-2716(99)00006-4
   Pang SY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040966
   Pang SY, 2014, REMOTE SENS-BASEL, V6, P10733, DOI 10.3390/rs61110733
   Qin R, 2016, ISPRS J PHOTOGRAMM, V122, P41, DOI 10.1016/j.isprsjprs.2016.09.013
   Qin RJ, 2016, INT J REMOTE SENS, V37, P3455, DOI 10.1080/01431161.2015.1066527
   Qin RJ, 2015, IEEE J-STARS, V8, P2125, DOI 10.1109/JSTARS.2015.2424275
   Qin RJ, 2014, REMOTE SENS-BASEL, V6, P7911, DOI 10.3390/rs6097911
   Qin RJ, 2014, ISPRS J PHOTOGRAMM, V96, P179, DOI 10.1016/j.isprsjprs.2014.07.007
   Sofina N, 2016, IEEE J-STARS, V9, P3430, DOI 10.1109/JSTARS.2016.2542074
   Tang YQ, 2013, IEEE GEOSCI REMOTE S, V10, P1060, DOI 10.1109/LGRS.2012.2228626
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tian J, 2013, ISPRS J PHOTOGRAMM, V79, P226, DOI 10.1016/j.isprsjprs.2013.02.017
   Tian J., 2011, INT WORKSH MULT MULT, P1
   Tian J, 2015, INT J IMAGE DATA FUS, V6, P155, DOI 10.1080/19479832.2014.1001879
   Tian JJ, 2014, IEEE T GEOSCI REMOTE, V52, P406, DOI 10.1109/TGRS.2013.2240692
   Vu TT, 2010, INT J REMOTE SENS, V31, P3411, DOI 10.1080/01431161003727697
   Zhang M., 2017, REMOTE SENS-BASEL, V9, DOI DOI 10.3390/rs9050500
NR 36
TC 5
Z9 5
U1 6
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR 2
PY 2019
VL 11
IS 6
AR 729
DI 10.3390/rs11060729
PG 24
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA HU9LG
UT WOS:000465615300087
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Li, MK
   Li, M
   Zhang, P
   Wu, Y
   Song, WY
   An, L
AF Li, Mengke
   Li, Ming
   Zhang, Peng
   Wu, Yan
   Song, Wanying
   An, Lin
TI SAR Image Change Detection Using PCANet Guided by Saliency Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; PCANet; saliency detection; synthetic aperture radar
   (SAR) image
AB The selection of training samples is important for the accuracy and efficiency of the synthetic aperture radar (SAR) image change detection task. However, training samples are traditionally extracted from the whole image, which leads to longer training time and an unbalanced number of pixels in the changed and unchanged classes. To overcome this problem, we propose a novel change detection method combining saliency detection with a principal component analysis network, named SDPCANet. To enhance the reliability of the training samples and reduce the amount of training samples, the SDPCANet uses context-aware saliency detection to obtain the salient region, from which the training samples are extracted. In addition, to alleviate the gap between the numbers of training samples in two classes, we regulate the candidate samples using the uniform-selecting strategy to enhance the reliability of the training samples for the SDPCANet. Then, the SDPCANet is trained with the extracted training samples and the remaining pixels are classified in the salient region to obtain the final change map. The experimental results on four sets of multitemporal SAR images demonstrate that the SDPCANet outperforms the reference methods proposed recently.
C1 [Li, Mengke; Li, Ming; Zhang, Peng; Wu, Yan; Song, Wanying; An, Lin] Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Shaanxi, Peoples R China.
RP Li, M (corresponding author), Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Shaanxi, Peoples R China.
EM liming@xidian.edu.cn
OI Zhang, Peng/0000-0002-8065-0948
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61772390, 61871312]; Aeronautical Science Foundation of
   China [2016081011]; Natural Science Basic Research Plan in Shaanxi
   Province of China [2017JM4022]; Shanghai Aerospace Science and
   Technology Innovation Fund [SAST2016092]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61772390 and Grant 61871312, in part by the
   Aeronautical Science Foundation of China under Grant 2016081011, in part
   by the Natural Science Basic Research Plan in Shaanxi Province of China
   under Grant 2017JM4022, and in part by the Shanghai Aerospace Science
   and Technology Innovation Fund under Grant SAST2016092.
CR Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Fernandez-Prieto D, 2011, IEEE T GEOSCI REMOTE, V49, P5016, DOI 10.1109/TGRS.2011.2154336
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Mu CH, 2017, IEEE C EVOL COMPUTAT, P1150, DOI 10.1109/CEC.2017.7969436
   Ren WL, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P143
   Roy M, 2014, IEEE J-STARS, V7, P1200, DOI 10.1109/JSTARS.2013.2293175
   Shang R, 2018, SIGNAL PROCESS, V142, P375, DOI 10.1016/j.sigpro.2017.07.023
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
NR 14
TC 27
Z9 28
U1 5
U2 41
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAR
PY 2019
VL 16
IS 3
BP 402
EP 406
DI 10.1109/LGRS.2018.2876616
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HN8EK
UT WOS:000460427600016
DA 2022-01-04
ER

PT J
AU Fan, JC
   Lin, K
   Han, M
AF Fan, Jianchao
   Lin, Kai
   Han, Min
TI A Novel Joint Change Detection Approach Based on Weight-Clustering
   Sparse Autoencoders
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Difference images (DIs); joint change detection; object-oriented
   classification; weight-clustering sparse autoencoders (WCSAE)
ID UNSUPERVISED CHANGE DETECTION; BUILDING CHANGE DETECTION; CHANGE VECTOR
   ANALYSIS; IMAGE CHANGE DETECTION; NEURAL-NETWORKS; CLASSIFICATION;
   REPRESENTATION; DESIGN; COVER
AB With the rapid development of earth observation technology, the number of available remote sensing data has soared dramatically. It becomes a significant problem that how to use remote sensing images and how to improve the accuracy of change detection effectively. In this paper, a novel approach for change detection using weight-clustering sparse autoencoders (WCSAE) combined object-oriented classification with difference images (DIs) is proposed. First, bi-phase images are segmented as patches through the density-based spatial clustering of applications with noise algorithm. Afterward, the average and variance of superpixels are stacked as the input of WCSAE. To reduce the redundant information of extracted features, similar weights in the hidden layer of WCSAE are clustered layer-wise under termination conditions by using the hierarchical agglomerative clustering algorithm. For the improvement of the classification accuracy, L1/2 regularization is introduced in the objective function to extract more sparse features and avoid over-fitting. Next, the post-classification change detection map is obtained by means of comparing with classification results of two phase images. Then, by using the change vector analysis technology, the difference map is yielded and also classified under WCSAE to acquire the DI classification map. Finally, the joint probability judgment is implemented on the joint scopes to determine changed and unchanged areas. The effectiveness and superiority of the proposed method are verified in accordance with the experimental results on standard datasets and actual remote sensing images.
C1 [Fan, Jianchao] Natl Marine Environm Monitoring Ctr, Dept Ocean Remote Sensing, Key Lab Sea Area Management Technol, Dalian 116023, Peoples R China.
   [Lin, Kai; Han, Min] Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
RP Han, M (corresponding author), Dalian Univ Technol, Sch Control Sci & Engn, Dalian 116024, Peoples R China.
EM jcfan@nmemc.org.cn; linkai522@mail.dlut.edu.cn; minhan@dlut.edu.cn
RI lin, kai/W-1445-2019
OI lin, kai/0000-0003-3345-8889
FU National Key R&D Program of China [2017YFC1404902, 2016YFC1401007];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41706195, 61773087]; National High
   Resolution Special Research [41-Y30B12-9001-14/16]; Key Laboratory of
   Sea-Area Management Technology Foundation [201701]
FX This work was supported in part by the National Key R&D Program of China
   under Grants 2017YFC1404902 and 2016YFC1401007, in part by the National
   Natural Science Foundation of China under Grants 41706195 and 61773087,
   in part by the National High Resolution Special Research
   (41-Y30B12-9001-14/16), and in part by the Key Laboratory of Sea-Area
   Management Technology Foundation (201701).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ayinde B. O., 2017, IEEE T NEURAL NETWOR, V29, P3969
   Ayinde BO, 2017, NEURAL NETWORKS, V93, P99, DOI 10.1016/j.neunet.2017.04.012
   Bengio, 2011, P 28 INT C MACH LEAR, P833
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2013, IEEE T GEOSCI REMOTE, V51, P2042, DOI 10.1109/TGRS.2012.2223219
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Cai D., 2017, P 26 INT JOINT C ART, P1561
   Cao G, 2017, INT J REMOTE SENS, V38, P7161, DOI 10.1080/01431161.2017.1371861
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen Q, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070549
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   De S, 2018, IEEE J-STARS, V11, P154, DOI 10.1109/JSTARS.2017.2752282
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Doersch C., 2016, ARXIV160605908
   Elshamli A, 2017, IEEE J-STARS, V10, P4198, DOI 10.1109/JSTARS.2017.2711360
   Fan JC, 2017, INT GEOSCI REMOTE SE, P1974, DOI 10.1109/IGARSS.2017.8127367
   Friedl MA, 1997, REMOTE SENS ENVIRON, V61, P399, DOI 10.1016/S0034-4257(97)00049-7
   Garcia S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Geng J, 2017, IEEE T GEOSCI REMOTE, V55, P2442, DOI 10.1109/TGRS.2016.2645226
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Griffiths P, 2013, IEEE J-STARS, V6, P2088, DOI 10.1109/JSTARS.2012.2228167
   Han M, 2018, GISCI REMOTE SENS, V55, P265, DOI 10.1080/15481603.2018.1430100
   Han M, 2015, NEUROCOMPUTING, V149, P65, DOI 10.1016/j.neucom.2013.09.070
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hosseini-Asl E, 2016, IEEE T NEUR NET LEAR, V27, P2486, DOI 10.1109/TNNLS.2015.2479223
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Kusetogullari H, 2015, IEEE J-STARS, V8, P2151, DOI 10.1109/JSTARS.2015.2427274
   Li L, 2018, IEEE T GEOSCI REMOTE, V56, P4605, DOI 10.1109/TGRS.2018.2829630
   Li XJ, 2010, J MARINE SYST, V82, pS54, DOI 10.1016/j.jmarsys.2010.02.005
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Makhzani A., 2015, ARXIV PREPRINT ARXIV
   Makhzani A., 2015, ADV NEURAL INFORM PR, P2791
   Marin C, 2015, IEEE T GEOSCI REMOTE, V53, P2664, DOI 10.1109/TGRS.2014.2363548
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   NG A., 2011, CS294A LECT NOTES
   Rastner P, 2014, IEEE J-STARS, V7, P853, DOI 10.1109/JSTARS.2013.2274668
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Simoudis E., 1997, SISTEMA REV CIENCIAS, V11, P41
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tan K, 2016, IEEE J-STARS, V9, P3439, DOI 10.1109/JSTARS.2016.2541678
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Walter V, 2004, ISPRS J PHOTOGRAMM, V58, P225, DOI 10.1016/j.isprsjprs.2003.09.007
   Xiao PF, 2017, IEEE T GEOSCI REMOTE, V55, P1587, DOI 10.1109/TGRS.2016.2627638
   Zhang CS, 2018, IEEE J-STARS, V11, P2440, DOI 10.1109/JSTARS.2018.2817121
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang YJ, 2018, IEEE GEOSCI REMOTE S, V15, P13, DOI 10.1109/LGRS.2017.2763182
   Zhao W, 2017, IEEE J-STARS, V10, P1758, DOI 10.1109/JSTARS.2017.2661802
NR 57
TC 9
Z9 9
U1 5
U2 27
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD FEB
PY 2019
VL 12
IS 2
SI SI
BP 685
EP 699
DI 10.1109/JSTARS.2019.2892951
PG 15
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA HO1KG
UT WOS:000460663600026
DA 2022-01-04
ER

PT J
AU Li, XL
   Yuan, ZH
   Wang, Q
AF Li, Xuelong
   Yuan, Zhenghang
   Wang, Qi
TI Unsupervised Deep Noise Modeling for Hyperspectral Image Change
   Detection
SO REMOTE SENSING
LA English
DT Article
DE hyperspectral images (HSI); change detection; deep learning;
   convolutional neural networks (CNN); noise modeling
ID CHANGE VECTOR ANALYSIS; COVER CHANGE DETECTION; EO-1 HYPERION; SUPPORT;
   DESIGN; MAD
AB Hyperspectral image (HSI) change detection plays an important role in remote sensing applications, and considerable research has been done focused on improving change detection performance. However, the high dimension of hyperspectral data makes it hard to extract discriminative features for hyperspectral processing tasks. Though deep convolutional neural networks (CNN) have superior capability in high-level semantic feature learning, it is difficult to employ CNN for change detection tasks. As a ground truth map is usually used for the evaluation of change detection algorithms, it cannot be directly used for supervised learning. In order to better extract discriminative CNN features, a novel noise modeling-based unsupervised fully convolutional network (FCN) framework is presented for HSI change detection in this paper. Specifically, the proposed method utilizes the change detection maps of existing unsupervised change detection methods to train the deep CNN, and then removes the noise during the end-to-end training process. The main contributions of this paper are threefold: (1) A new end-to-end FCN-based deep network architecture for HSI change detection is presented with powerful learning features; (2) An unsupervised noise modeling method is introduced for the robust training of the proposed deep network; (3) Experimental results on three datasets confirm the effectiveness of the proposed method.
C1 [Wang, Qi] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
RP Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM li@nwpu.edu.cn; zhenghangyuan@mail.nwpu.edu.cn; crabwq@gmail.com
RI Li, Xuelong/Z-3785-2019; Li, Xuelong/ABF-3381-2020
OI Wang, Qi/0000-0002-7028-4956
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [U1864204, 61773316]; Natural Science
   Foundation of Shaanxi ProvinceNatural Science Foundation of Shaanxi
   Province [2018KJXX-024]; Projects of Special Zone for National Defense
   Science and Technology Innovation; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [3102017AX010]; Open Research Fund of Key Laboratory of
   Spectral Imaging Technology, Chinese Academy of Sciences
FX This work was supported by the National Natural Science Foundation of
   China under Grant U1864204 and 61773316, Natural Science Foundation of
   Shaanxi Province under Grant 2018KJXX-024, Projects of Special Zone for
   National Defense Science and Technology Innovation, Fundamental Research
   Funds for the Central Universities under Grant 3102017AX010, and Open
   Research Fund of Key Laboratory of Spectral Imaging Technology, Chinese
   Academy of Sciences.
CR Adao T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111110
   Aggarwal HK, 2016, IEEE J-STARS, V9, P4257, DOI 10.1109/JSTARS.2016.2521898
   Aptoula E, 2016, IEEE T GEOSCI REMOTE, V54, P3208, DOI 10.1109/TGRS.2015.2513424
   Awad M, 2014, ECOL INFORM, V24, P60, DOI 10.1016/j.ecoinf.2014.07.004
   Baisantry M, 2012, DEFENCE SCI J, V62, P236, DOI 10.14429/dsj.62.1072
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bovolo F, 2011, INT GEOSCI REMOTE SE, P233, DOI 10.1109/IGARSS.2011.6048935
   Datt B, 2003, IEEE T GEOSCI REMOTE, V41, P1246, DOI 10.1109/TGRS.2003.813206
   de Jong K. L., 2018, ARXIV181205815
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eismann MT, 2008, IEEE T GEOSCI REMOTE, V46, P237, DOI 10.1109/TGRS.2007.907973
   El Amin AM, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P812, DOI 10.1109/ICIVC.2017.7984667
   Erturk A, 2016, IEEE J-STARS, V9, P708, DOI 10.1109/JSTARS.2015.2477431
   Folkman M, 2001, P SOC PHOTO-OPT INS, V4151, P40, DOI 10.1117/12.417022
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Jakovels D, 2014, PROC SPIE, V9245, DOI 10.1117/12.2067151
   Kennedy RE, 2009, REMOTE SENS ENVIRON, V113, P1382, DOI 10.1016/j.rse.2008.07.018
   Kingma D., 2014, 14126980 ARXIV
   Kruse FA, 2003, IEEE T GEOSCI REMOTE, V41, P1388, DOI 10.1109/TGRS.2003.812908
   Le Hegarat-Mascle S, 2005, REMOTE SENS ENVIRON, V95, P464, DOI 10.1016/j.rse.2005.01.011
   Lee S., 2017, P IEEE INT C COMP VI
   Li C, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101600
   Li YB, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P7041
   Liu SC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101008
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Ma N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030693
   Malila W., 1980, CHANGE VECTOR ANAL A
   Mandic I, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020034
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Pearlman JS, 2003, IEEE T GEOSCI REMOTE, V41, P1160, DOI 10.1109/TGRS.2003.815018
   Seydi ST, 2018, APPL GEOMAT, V10, P65, DOI 10.1007/s12518-018-0206-6
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh D, 2008, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN MICROWAVE THEORY AND APPLICATIONS, PROCEEDINGS, P419, DOI 10.1109/AMTA.2008.4763244
   Song A, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111827
   Thonfeld F, 2016, INT J APPL EARTH OBS, V50, P131, DOI 10.1016/j.jag.2016.03.009
   Uezato T., 2018, ARXIV180411132
   Wang JY, 2017, IEEE GEOSCI REMOTE S, V14, P2062, DOI 10.1109/LGRS.2017.2751082
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P911, DOI 10.1109/TGRS.2018.2862899
   Wang Q, 2020, IEEE T PATTERN ANAL, V42, P46, DOI 10.1109/TPAMI.2018.2875002
   Wang Q, 2019, IEEE T NEUR NET LEAR, V30, P1581, DOI 10.1109/TNNLS.2018.2868836
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE T GEOSCI REMOTE, V56, P5910, DOI 10.1109/TGRS.2018.2828161
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Yuan Y, 2016, IEEE T CYBERNETICS, V46, P3123, DOI 10.1109/TCYB.2015.2497711
   Yuan Y, 2016, IEEE T GEOSCI REMOTE, V54, P1431, DOI 10.1109/TGRS.2015.2480866
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang LF, 2014, IEEE T GEOSCI REMOTE, V52, P4955, DOI 10.1109/TGRS.2013.2286195
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhou J, 2016, IEEE T GEOSCI REMOTE, V54, P6497, DOI 10.1109/TGRS.2016.2585495
   Zhu LX, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020272
   Zhuang HF, 2016, IEEE GEOSCI REMOTE S, V13, P681, DOI 10.1109/LGRS.2016.2536058
NR 60
TC 38
Z9 39
U1 15
U2 38
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 1
PY 2019
VL 11
IS 3
AR 258
DI 10.3390/rs11030258
PG 17
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA HN1JX
UT WOS:000459944400046
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Zhang, WX
   Lu, XQ
AF Zhang, Wuxia
   Lu, Xiaoqiang
TI The Spectral-Spatial Joint Learning for Change Detection in
   Multispectral Imagery
SO REMOTE SENSING
LA English
DT Article
DE multispectral imagery; spectral-spatial representation; Siamese CNN;
   feature fusion; discrimination learning; change detection
ID UNSUPERVISED CHANGE DETECTION; URBAN CHANGE DETECTION; THEORETICAL
   FRAMEWORK; FEATURE-EXTRACTION; CLASSIFICATION; REGISTRATION; ALGORITHMS;
   NETWORKS; SUBSPACE
AB Change detection is one of the most important applications in the remote sensing domain. More and more attention is focused on deep neural network based change detection methods. However, many deep neural networks based methods did not take both the spectral and spatial information into account. Moreover, the underlying information of fused features is not fully explored. To address the above-mentioned problems, a Spectral-Spatial Joint Learning Network (SSJLN) is proposed. SSJLN contains three parts: spectral-spatial joint representation, feature fusion, and discrimination learning. First, the spectral-spatial joint representation is extracted from the network similar to the Siamese CNN (S-CNN). Second, the above-extracted features are fused to represent the difference information that proves to be effective for the change detection task. Third, the discrimination learning is presented to explore the underlying information of obtained fused features to better represent the discrimination. Moreover, we present a new loss function that considers both the losses of the spectral-spatial joint representation procedure and the discrimination learning procedure. The effectiveness of our proposed SSJLN is verified on four real data sets. Extensive experimental results show that our proposed SSJLN can outperform the other state-of-the-art change detection methods.
C1 [Zhang, Wuxia; Lu, Xiaoqiang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol, Xian 710119, Shaanxi, Peoples R China.
   [Zhang, Wuxia] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP Lu, XQ (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Key Lab Spectral Imaging Technol, Xian 710119, Shaanxi, Peoples R China.
EM wuxiazhang100@126.com; luxiaoqiang@opt.ac.cn
OI Zhang, Wuxia/0000-0002-0759-2489
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772510, 61761130079]; Key Research Program
   of Frontier Sciences, CAS [QYZDY-SSW-JSC044]; Young Top-notch Talent
   Program of Chinese Academy of Sciences [QYZDB-SSW-JSC015]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61761130079, in part by the Key Research
   Program of Frontier Sciences, CAS under Grant QYZDY-SSW-JSC044, in part
   by the National Natural Science Foundation of China under Grant
   61772510, and in part by the Young Top-notch Talent Program of Chinese
   Academy of Sciences under Grant QYZDB-SSW-JSC015.
CR Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Canty MJ, 2008, REMOTE SENS ENVIRON, V112, P1025, DOI 10.1016/j.rse.2007.07.013
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Hadsell Raia, 2006, P 2006 IEEE COMP VIS, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hinton G.E., 2010, ICML, P807, DOI DOI 10.0RG/PAPERS/432.PDF
   Hong Oh， Jae, 2015, [JOURNAL OF THE KOREAN SOCIETY OF SURVEY,GEODESY,PHOTOGRAMMETRY, AND CARTOGRAPHY, 한국측량학회지], V33, P259, DOI 10.7848/ksgpc.2015.33.4.259
   Hou B, 2017, IEEE GEOSCI REMOTE S, V14, P2418, DOI 10.1109/LGRS.2017.2766840
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Huang XM, 2014, INT J APPL EARTH OBS, V29, P78, DOI 10.1016/j.jag.2014.01.004
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Liu B, 2018, IEEE T GEOSCI REMOTE, V56, P1909, DOI 10.1109/TGRS.2017.2769673
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Melekhov I, 2016, INT C PATT RECOG, P378, DOI 10.1109/ICPR.2016.7899663
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Munoz-Mari J, 2010, IEEE T GEOSCI REMOTE, V48, P3188, DOI 10.1109/TGRS.2010.2045764
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Rokni K, 2014, REMOTE SENS-BASEL, V6, P4173, DOI 10.3390/rs6054173
   Tian Yurun, 2017, P IEEE C COMP VIS PA
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Wu K, 2017, IEEE GEOSCI REMOTE S, V14, P1750, DOI 10.1109/LGRS.2017.2733558
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zanetti M, 2018, IEEE T GEOSCI REMOTE, V56, P1129, DOI 10.1109/TGRS.2017.2759663
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang ZY, 2013, IEEE GEOSCI REMOTE S, V10, P791, DOI 10.1109/LGRS.2012.2224314
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 43
TC 25
Z9 25
U1 8
U2 28
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD FEB 1
PY 2019
VL 11
IS 3
AR 240
DI 10.3390/rs11030240
PG 17
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA HN1JX
UT WOS:000459944400028
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Zhang, MY
   Xu, GL
   Chen, KM
   Yan, ML
   Sun, X
AF Zhang, Mengya
   Xu, Guangluan
   Chen, Keming
   Yan, Menglong
   Sun, Xian
TI Triplet-Based Semantic Relation Learning for Aerial Remote Sensing Image
   Change Detection
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; optical aerial images; semantic relation; siamese
   semantic network; triplet loss function
AB This letter presents a novel supervised change detection method based on a deep siamese semantic network framework, which is trained by using improved triplet loss function for optical aerial images. The proposed framework can not only extract features directly from image pairs which include multiscale information and are more abstract as well as robust, but also enhance the interclass separability and the intraclass inseparability by learning semantic relation. The feature vectors of the pixels pair with the same label are closer, and at the same time, the feature vectors of the pixels with different labels are farther from each other. Moreover, we use the distance of the feature map to detect the changes on the difference map between the image pair. Binarized change map can be obtained by a simple threshold. Experiments on optical aerial image data set validate that the proposed approach produces comparable, even better results, favorably to the state-of-the-art methods in terms of F-measure.
C1 [Zhang, Mengya; Xu, Guangluan; Chen, Keming; Yan, Menglong; Sun, Xian] Chinese Acad Sci, Key Lab Technol Geospatial Informat Proc & Applic, Inst Elect, Beijing 100190, Peoples R China.
   [Zhang, Mengya] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
RP Chen, KM (corresponding author), Chinese Acad Sci, Key Lab Technol Geospatial Informat Proc & Applic, Inst Elect, Beijing 100190, Peoples R China.
EM kmchen.ie@gmail.com
OI Sun, Xian/0000-0002-0038-9816; Zhang, Mengya/0000-0003-2806-8413
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61302170]
FX The work of K. Chen was supported by the National Natural Science
   Foundation of China under Grant 61302170.
CR Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Chen L., 2017, RETHINKING ATROUS CO
   Chen Liang-Chieh, 2016, DEEPLAB SEMANTIC IMA
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Huo CL, 2016, IEEE J-STARS, V9, P3384, DOI 10.1109/JSTARS.2016.2569598
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P3978, DOI 10.1109/TGRS.2007.907109
NR 15
TC 31
Z9 32
U1 9
U2 48
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD FEB
PY 2019
VL 16
IS 2
BP 266
EP 270
DI 10.1109/LGRS.2018.2869608
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HJ7EJ
UT WOS:000457356600022
DA 2022-01-04
ER

PT J
AU Mou, LC
   Bruzzone, L
   Zhu, XX
AF Mou, Lichao
   Bruzzone, Lorenzo
   Zhu, Xiao Xiang
TI Learning Spectral-Spatial-Temporal Features via a Recurrent
   Convolutional Neural Network for Change Detection in Multispectral
   Imagery
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; long short-term memory (LSTM); multitemporal image
   analysis; recurrent convolutional neural network (ReCNN)
ID LAND-COVER TRANSITIONS; DATA FUSION; RESOLUTION; MAD
AB Change detection is one of the central problems in earth observation and was extensively investigated over recent decades. In this paper, we propose a novel recurrent convolutional neural network (ReCNN) architecture, which is trained to learn a joint spectral-spatial-temporal feature representation in a unified framework for change detection in multispectral images. To this end, we bring together a convolutional neural network and a recurrent neural network into one end-to-end network. The former is able to generate rich spectral-spatial feature representations, while the latter effectively analyzes temporal dependence in bitemporal images. In comparison with previous approaches to change detection, the proposed network architecture possesses three distinctive properties: 1) it is end-to-end trainable, in contrast to most existing methods whose components are separately trained or computed; 2) it naturally harnesses spatial information that has been proven to be beneficial to change detection task; and 3) it is capable of adaptively learning the temporal dependence between multitemporal images, unlike most of the algorithms that use fairly simple operation like image differencing or stacking. As far as we know, this is the first time that a recurrent convolutional network architecture has been proposed for multitemporal remote sensing image analysis. The proposed network is validated on real multispectral data sets. Both visual and quantitative analyses of the experimental results demonstrate competitive performance in the proposed mode.
C1 [Mou, Lichao; Zhu, Xiao Xiang] German Aerosp Ctr, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
   [Mou, Lichao; Zhu, Xiao Xiang] Tech Univ Munich, Signal Proc Earth Observat, D-80333 Munich, Germany.
   [Bruzzone, Lorenzo] Univ Trento, Dept Informat Engn & Comp Sci, I-38122 Trento, Italy.
RP Zhu, XX (corresponding author), German Aerosp Ctr, Remote Sensing Technol Inst, D-82234 Wessling, Germany.
EM lichao.mou@dlr.de; lorenzo.bruzzone@unitn.it; xiao.zhu@dlr.de
RI Zhu, Xiao Xiang/ABE-7138-2020; Bruzzone, Lorenzo/A-2076-2012
OI Zhu, Xiao Xiang/0000-0001-5530-3613; Bruzzone,
   Lorenzo/0000-0002-6036-459X
FU China Scholarship CouncilChina Scholarship Council; European Research
   Council through the European Unions Horizon 2020 Research and Innovation
   Programme [ERC-2016-StG-714087]; Helmholtz AssociationHelmholtz
   Association [VH-NG-1018]
FX This work was supported in part by the China Scholarship Council and the
   European Research Council through the European Unions Horizon 2020
   Research and Innovation Programme under Grant ERC-2016-StG-714087 and in
   part by the Helmholtz Association through the Framework of the Young
   Investigators Group "SiPEO" under Grant VH-NG-1018.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2015, IEEE GEOSC REM SEN M, V3, P8, DOI 10.1109/MGRS.2015.2443494
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2004, PATTERN RECOGN LETT, V25, P1491, DOI 10.1016/j.patrec.2004.06.002
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Bruzzone L, 2002, IEEE T GEOSCI REMOTE, V40, P1984, DOI 10.1109/TGRS.2002.803794
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1350, DOI 10.1109/36.763299
   Chen Liang-Chieh, 2016, DEEPLAB SEMANTIC IMA
   Collins JB, 1996, REMOTE SENS ENVIRON, V56, P66, DOI 10.1016/0034-4257(95)00233-2
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Dozat T., INCORPORATING NESTER
   Erturk A, 2016, IEEE J-STARS, V9, P708, DOI 10.1109/JSTARS.2015.2477431
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Graves A, 2013, GENERATING SEQUENCES
   He NJ, 2018, IEEE T GEOSCI REMOTE, V56, P6899, DOI 10.1109/TGRS.2018.2845668
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Holschneider M, 1989, WAVELETS TIME FREQUE
   Hu J, 2017, J THERM ANAL CALORIM, V128, P1251, DOI 10.1007/s10973-017-6107-9
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Hua Y., 2018, RECURRENTLY EXPLORIN
   Hughes L. H., 2018, IDENTIFYING CORRES P
   Kingma D.P., 2015, P IEEE INT C LEARN R
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li X, 1998, INT J REMOTE SENS, V19, P1501, DOI 10.1080/014311698215315
   Li Y., 2016, REMOTE SENS, V18, P1527
   Liang BQ, 2011, IEEE J-STARS, V4, P43, DOI 10.1109/JSTARS.2010.2060316
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P645, DOI 10.1109/TGRS.2016.2612821
   Malila W. A., 1980, P MACH PROC REM SENS
   Mou L, 2017, IEEE J-STARS, V10, P3435, DOI 10.1109/JSTARS.2017.2696823
   Mou L., 2018, IM2HEIGHT HEIGHT EST
   Mou L., 2017, P 2017 JOINT URB REM, P1
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P391, DOI 10.1109/TGRS.2017.2748160
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Mou LC, 2016, INT GEOSCI REMOTE SE, P1823, DOI 10.1109/IGARSS.2016.7729468
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Russwurm M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7040129
   Russwurm M, 2017, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2017.193
   Simonyan K., 2015, P IEEE INT C LEARN R
   Song WW, 2018, IEEE T GEOSCI REMOTE, V56, P3173, DOI 10.1109/TGRS.2018.2794326
   Sutskever Ilya, 2013, P INT C MACH LEARN, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Volpi M, 2017, IEEE T GEOSCI REMOTE, V55, P881, DOI 10.1109/TGRS.2016.2616585
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030298
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Yang J, 2012, REMOTE SENS ENVIRON, V119, P62, DOI 10.1016/j.rse.2011.12.004
   Yokoya N, 2017, IEEE T GEOSCI REMOTE, V55, P2842, DOI 10.1109/TGRS.2017.2655115
   Zanetti M, 2015, IEEE T IMAGE PROCESS, V24, P5004, DOI 10.1109/TIP.2015.2474710
   Zhu J, 2018, IEEE GEOSCI REMOTE S, V15, P1254, DOI 10.1109/LGRS.2018.2830403
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 56
TC 134
Z9 143
U1 46
U2 150
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD FEB
PY 2019
VL 57
IS 2
BP 924
EP 935
DI 10.1109/TGRS.2018.2863224
PG 12
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HJ1PR
UT WOS:000456936500023
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Liu, RC
   Cheng, ZH
   Zhang, LL
   Li, JX
AF Liu, Ruochen
   Cheng, Zhihong
   Zhang, Langlang
   Li, Jianxia
TI Remote Sensing Image Change Detection Based on Information Transmission
   and Attention Mechanism
SO IEEE ACCESS
LA English
DT Article
DE Feature extraction; Logic gates; Information processing; Remote sensing;
   Deep learning; Recurrent neural networks; Remote sensing image; change
   detection; deep neural network; information transmission; attention
   mechanism
AB Change detection is one of the core issues of earth observation and has been extensively studied in recent decades. This paper presents a novel deep neural network architecture based on information transmission and attention mechanism. Existing methods rely on a simple mechanism for independently encoding bi-temporal images to obtain their representation vectors. In view of the fact that these methods do not make full use of the rich information between bi-temporal images, we introduce the information transmission module in the design of DNN structure for doing the transmission and interaction of information. In addition, we introduce the attention mechanism behind the information transmission module to give the corresponding attention weight to each temporal image feature so as to enhance the change information of the image, which noticeably improves final prediction. The proposed network is validated on real remote sensing image data sets. Both visual and quantitative analyses of the experimental results demonstrate competitiveness of the proposed method.
C1 [Liu, Ruochen; Cheng, Zhihong; Zhang, Langlang; Li, Jianxia] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
RP Liu, RC (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
EM ruochenliu@xidian.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61876141, 61373111, 61272279, 61103119,
   61203303]; Provincial Natural Science Foundation of Shaanxi of China
   [2019JZ-26]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876141, Grant 61373111, Grant
   61272279, Grant 61103119, and Grant 61203303, and in part by the
   Provincial Natural Science Foundation of Shaanxi of China under Grant
   2019JZ-26.
CR Agarwal A, 2012, ANN STAT, V40, P1171, DOI 10.1214/12-AOS1000
   Aly AA, 2016, SOLID EARTH, V7, P713, DOI 10.5194/se-7-713-2016
   [Anonymous], 2013, PREPRINT ARXIV 1308, DOI DOI 10.1145/2661829.2661935.ISSN
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chinchor N., 1992, P 4 MESS UND C, P22, DOI DOI 10.3115/1072064.1072067
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kingma D., 2014, 14126980 ARXIV
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Lyu HB, 2016, INT GEOSCI REMOTE SE, P5157, DOI [10.1109/IGARSS.2016.7730344, 10.1109/IGARSS.2016.7730345]
   Mou LC, 2019, IEEE T GEOSCI REMOTE, V57, P924, DOI 10.1109/TGRS.2018.2863224
   Plank B., 2014, ARXIV160405529
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Yin Wenpeng, 2015, ARXIV PREPRINT ARXIV
   Zhan, 2016, J COMPUT THEOR NANOS, V13, P3757, DOI DOI 10.1166/jctn.2016.5208
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhuang HF, 2018, EUR J REMOTE SENS, V51, P723, DOI 10.1080/22797254.2018.1482523
NR 26
TC 11
Z9 12
U1 5
U2 11
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 156349
EP 156359
DI 10.1109/ACCESS.2019.2947286
PG 11
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA JN8TY
UT WOS:000497165400083
OA gold
DA 2022-01-04
ER

PT J
AU Xu, L
   Jing, WP
   Song, HB
   Chen, GS
AF Xu, Lu
   Jing, Weipeng
   Song, Houbing
   Chen, Guangsheng
TI High-Resolution Remote Sensing Image Change Detection Combined With
   Pixel-Level and Object-Level
SO IEEE ACCESS
LA English
DT Article
DE Change detection; random forest; remote sensing; semantic segmentation;
   U-net
ID AUTOMATIC CHANGE DETECTION; LAND
AB High-resolution remote sensing images are abundant in texture information, and the detection method of the change of pixel-level mainly analyzes the spectral information of the image, which has certain limitations. In this paper, a high-resolution remote sensing image change detection method combining pixel and object levels is proposed to solve the problem that many pepper and salt phenomenon and false detection in the change detection of pixel-level and object-level change detection method are cumbersome for image segmentation process. We integrate the multi-dimensional features of high-resolution remote sensing images and use random forest classifiers to classify to obtain the pixel-level change detection results. Then, we use the improved U-net network to semantically segment the post-phase remote sensing image to obtain the image object segmentation result. Finally, the consequences of pixel-level change detection and image object segmentation result are fused to obtain the image changing area and the unchanging area. The experimental results demonstrate that the algorithm has a higher accuracy rate and detection precision.
C1 [Xu, Lu; Jing, Weipeng; Chen, Guangsheng] Northeast Forestry Univ, Coll Informat & Comp Engn, Harbin 150040, Heilongjiang, Peoples R China.
   [Song, Houbing] Embry Riddle Aeronaut Univ, Dept Elect Comp Software & Syst Engn, Daytona Beach, FL 32114 USA.
RP Song, HB (corresponding author), Embry Riddle Aeronaut Univ, Dept Elect Comp Software & Syst Engn, Daytona Beach, FL 32114 USA.
EM songh4@erau.edu
RI Song, Houbing/E-3628-2010
OI Song, Houbing/0000-0003-2631-9223
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [31770768]; Natural Science Foundation of
   Heilongjiang Province of ChinaNatural Science Foundation of Heilongjiang
   Province [F2017001]; Heilongjiang Province Applied Technology Research
   and Development Program Major Project [GA18B301]; China State Forestry
   Administration Forestry Industry Public Welfare Project [201504307]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 31770768, in part by the Natural Science
   Foundation of Heilongjiang Province of China under Grant F2017001, in
   part by the Heilongjiang Province Applied Technology Research and
   Development Program Major Project under Grant GA18B301, and in part by
   the China State Forestry Administration Forestry Industry Public Welfare
   Project under Grant 201504307.
CR Brox, 2015, ARXIV150504597, V9351, P234, DOI DOI 10.1007/978-3-319-24574-4_28
   Cao G, 2014, INT J REMOTE SENS, V35, P6255, DOI 10.1080/01431161.2014.951740
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   [佃袁勇 Dian Yuanyong], 2014, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V39, P906
   Dou Fangzheng, 2018, Computer Engineering, V44, P294, DOI 10.3969/j.issn.1000-3428.2018.04.047
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   GIRSHICK R, 2014, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   [侯群群 Hou Qunqun], 2013, [国土资源遥感, Remote Sensing for Land & Resources], V25, P26
   Hu JR, 2013, IEEE J-STARS, V6, P1913, DOI 10.1109/JSTARS.2012.2228469
   Jiang  B., IEEE INTERNET THINGS
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90
   Leichtle T, 2017, INT J APPL EARTH OBS, V54, P15, DOI 10.1016/j.jag.2016.08.010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Quan Wei-peng, 2015, Electronics Optics & Control, V22, P45, DOI 10.3969/j.issn.1671-637X.2015.03
   Rodriguez-Galiano VF, 2012, ISPRS J PHOTOGRAMM, V67, P93, DOI 10.1016/j.isprsjprs.2011.11.002
   Shu Z, 2018, IEEE GEOSCI REMOTE S, V15, P1100, DOI 10.1109/LGRS.2018.2822760
   Sun KM, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL IX, P383
   Tang K., 2016, SCI SURV MAPPING, V42, P106
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   [佟国峰 Tong Guofeng], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1561
   [王琰 Wang Yan], 2012, [国土资源遥感, Remote Sensing for Land & Resources], P43
   Xiao M. H., 2018, B SURV MAPPING, P121
   [肖明虹 Xiao Minghong], 2018, [测绘通报, Bulletin of Surveying and Mapping], P93
   Xiao PF, 2016, ISPRS J PHOTOGRAMM, V119, P402, DOI 10.1016/j.isprsjprs.2016.07.003
   Zhang JX, 2007, ISPRS J PHOTOGRAMM, V62, P461, DOI 10.1016/j.isprsjprs.2007.07.002
   [赵敏 Zhao Min], 2018, [遥感学报, Journal of Remote Sensing], V22, P119
   [赵忠明 Zhao Zhongming], 2016, [遥感学报, Journal of Remote Sensing], V20, P1110
   Zisserman, 2015, ICLR, P1
   Zou WT, 2019, IEEE ACCESS, V7, P46621, DOI 10.1109/ACCESS.2019.2907999
NR 34
TC 22
Z9 23
U1 39
U2 59
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 78909
EP 78918
DI 10.1109/ACCESS.2019.2922839
PG 10
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA IG5BZ
UT WOS:000473819800001
OA gold
DA 2022-01-04
ER

PT J
AU Lei, Y
   Liu, XD
   Shi, J
   Lei, C
   Wang, J
AF Lei, Yu
   Liu, Xiaodong
   Shi, Jiao
   Lei, Chao
   Wang, Jing
TI Multiscale Superpixel Segmentation With Deep Features for Change
   Detection
SO IEEE ACCESS
LA English
DT Article
DE Change detection; multiscale superpixel segmentation; deep neural
   networks; difference representation learning
ID UNSUPERVISED CHANGE DETECTION; BUILDING CHANGE DETECTION; MULTITEMPORAL
   SAR IMAGES; NEURAL-NETWORK; CLASSIFICATION; REPRESENTATION
AB In this paper, a novel change detection technique is proposed based on multiscale superpixel segmentation and stacked denoising autoencoders (SDAE). This approach is designed to achieve superpixel-based change detection, in which the basic analysis unit is between pixel-based and object-based ones. Given two original images, the difference image (DI) is obtained by conventional DI generation methods. Then, we propose a multiscale superpixel segmentation which is guided by the changing degrees estimated from the DI. Different from traditional multiscale superpixel, the proposed multiscale superpixel segmentation is employed in a single map. In the proposed method, SDAE is used to learn the difference representation between bi-temporal superpixels. Bi-temporal superpixels are stacked and fed into SDAE for its pre-training, and then SDAE is fine-tuned according to pseudo labels generated by traditional unsupervised methods. After fine-tuned with back propagation, the SDAE can be used to classify all superpixel pairs into changed or unchanged ones. The experimental results on real remote sensing datasets have demonstrated the effectiveness of the proposed approach.
C1 [Lei, Yu; Liu, Xiaodong; Shi, Jiao] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.
   [Lei, Yu; Shi, Jiao] Northwestern Polytech Univ Shenzhen, Res & Dev Inst, Shenzhen 518057, Peoples R China.
   [Lei, Chao] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Jing] Xidian Univ, Xidian Univ Lib, Xian 710071, Shaanxi, Peoples R China.
RP Shi, J (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Shaanxi, Peoples R China.; Shi, J (corresponding author), Northwestern Polytech Univ Shenzhen, Res & Dev Inst, Shenzhen 518057, Peoples R China.
EM jiaoshi@nwpu.edu.cn
FU Shenzhen Research and Development Foundation [JCYJ20170306153943097];
   National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61603299, 61602385]
FX This work was supported in part by the Shenzhen Research and Development
   Foundation under Grant JCYJ20170306153943097, and in part by the
   National Natural Science Foundation of China under Grant 61603299 and
   Grant 61602385.
CR Azzouzi SA, 2017, IEEE ACCESS, V5, P9065, DOI 10.1109/ACCESS.2017.2700405
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Barreto TLM, 2016, IEEE J-STARS, V9, P5436, DOI 10.1109/JSTARS.2016.2621818
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Carotenuto V, 2016, IEEE T GEOSCI REMOTE, V54, P36, DOI 10.1109/TGRS.2015.2449332
   Carvalho LMT, 2001, INT J REMOTE SENS, V22, P3871, DOI 10.1080/01431160110069836
   Chatelain F, 2008, IEEE T IMAGE PROCESS, V17, P249, DOI 10.1109/TIP.2008.916047
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Durieux L, 2008, ISPRS J PHOTOGRAMM, V63, P399, DOI 10.1016/j.isprsjprs.2008.01.005
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Fu ZL, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081289
   Gong JY, 2008, SCI CHINA SER E, V51, P110, DOI 10.1007/s11431-008-6017-y
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hedjam R, 2016, IEEE T GEOSCI REMOTE, V54, P6997, DOI 10.1109/TGRS.2016.2593982
   Hinton GE, 2010, PHILOS T R SOC B, V365, P177, DOI 10.1098/rstb.2009.0200
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Huang X, 2014, IEEE J-STARS, V7, P105, DOI 10.1109/JSTARS.2013.2252423
   Hutchinson B, 2013, IEEE T PATTERN ANAL, V35, P1944, DOI 10.1109/TPAMI.2012.268
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kuruoglu EE, 2004, IEEE T IMAGE PROCESS, V13, P527, DOI 10.1109/TIP.2003.818017
   Li XD, 2016, IEEE T GEOSCI REMOTE, V54, P3822, DOI 10.1109/TGRS.2016.2528583
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Miller O, 2005, PATTERN RECOGN, V38, P1976, DOI 10.1016/j.patcog.2004.07.010
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Salakhutdinov R, 2013, IEEE T PATTERN ANAL, V35, P1958, DOI 10.1109/TPAMI.2012.269
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Tang YQ, 2013, IEEE GEOSCI REMOTE S, V10, P1060, DOI 10.1109/LGRS.2012.2228626
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang KF, 2018, IEEE ACCESS, V6, P15505, DOI 10.1109/ACCESS.2018.2812880
   Xiao RL, 2018, IEEE ACCESS, V6, P35915, DOI 10.1109/ACCESS.2018.2849110
   Yu HY, 2017, IEEE GEOSCI REMOTE S, V14, P2142, DOI 10.1109/LGRS.2017.2755061
   Zhang P., 2017, P 26 INT JOINT C ART, P3413
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhang SZ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020139
   Zhou YJ, 2015, IEEE T IMAGE PROCESS, V24, P3834, DOI 10.1109/TIP.2015.2449552
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
NR 56
TC 20
Z9 21
U1 4
U2 17
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2019
VL 7
BP 36600
EP 36616
DI 10.1109/ACCESS.2019.2902613
PG 17
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA HS4YU
UT WOS:000463877700001
OA gold
DA 2022-01-04
ER

PT J
AU Wang, Q
   Yuan, ZH
   Du, Q
   Li, XL
AF Wang, Qi
   Yuan, Zhenghang
   Du, Qian
   Li, Xuelong
TI GETNET: A General End-to-End 2-D CNN Framework for Hyperspectral Image
   Change Detection
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE 2-D convolutional neural network (CNN); change detection (CD); deep
   learning; hyperspectral image (HSI); mixed-affinity matrix; spectral
   unmixing
ID UNSUPERVISED CHANGE DETECTION; CHANGE VECTOR ANALYSIS; RECOGNITION; PCA;
   MAD
AB Change detection (CD) is an important application of remote sensing, which provides timely change information about large-scale Earth surface. With the emergence of hyperspectral imagery, CD technology has been greatly promoted, as hyperspectral data with high spectral resolution are capable of detecting finer changes than using the traditional multispectral imagery. Nevertheless, the high dimension of the hyperspectral data makes it difficult to implement traditional CD algorithms. Besides, endmember abundance information at subpixel level is often not fully utilized. In order to better handle high-dimension problem and explore abundance information, this paper presents a general end-to-end 2-D convolutional neural network (CNN) framework for hyperspectral image CD (HSI-CD). The main contributions of this paper are threefold: 1) mixed-affinity matrix that integrates subpixel representation is introduced to mine more cross-channel gradient features and fuse multisource information; 2) 2-D CNN is designed to learn the discriminative features effectively from the multisource data at a higher level and enhance the generalization ability of the proposed CD algorithm; and 3) the new HSI-CD data set is designed for objective comparison of different methods. Experimental results on real hyperspectral data sets demonstrate that the proposed method outperforms most of the state of the arts.
C1 [Wang, Qi] Northwestern Polytech Univ, Sch Comp Sci, Ctr OPT IMagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China.
   [Wang, Qi] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Shaanxi, Peoples R China.
   [Yuan, Zhenghang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Yuan, Zhenghang] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39762 USA.
   [Li, Xuelong] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
   [Li, Xuelong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Ctr OPT IMagery Anal & Learning, Xian 710072, Shaanxi, Peoples R China.; Wang, Q (corresponding author), Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Shaanxi, Peoples R China.
EM crabwq@gmail.com; zhenghangyuan@mail.nwpu.edu.cn; du@ece.msstate.edu;
   xuelongli@opt.ac.cn
RI Li, Xuelong/Z-3785-2019; Li, Xuelong/ABF-3381-2020
OI Li, Xuelong/0000-0002-0019-4197; Wang, Qi/0000-0002-7028-4956
FU National Key R&D Program of China [2017YFB1002202]; National Natural
   Science Foundation of ChinaNational Natural Science Foundation of China
   (NSFC) [61773316]; Natural Science Foundation of Shaanxi ProvinceNatural
   Science Foundation of Shaanxi Province [2018KJXX-024]; Fundamental
   Research Funds for the Central UniversitiesFundamental Research Funds
   for the Central Universities [3102017AX010]; Key Laboratory of Spectral
   Imaging Technology, Chinese Academy of Sciences
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2017YFB1002202, in part by the National Natural Science
   Foundation of China under Grant 61773316, in part by the Natural Science
   Foundation of Shaanxi Province under Grant 2018KJXX-024, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   3102017AX010, and in part by the Open Research Fund of Key Laboratory of
   Spectral Imaging Technology, Chinese Academy of Sciences.
CR Baisantry M, 2012, DEFENCE SCI J, V62, P236, DOI 10.14429/dsj.62.1072
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen J, 2013, IEEE T SIGNAL PROCES, V61, P480, DOI 10.1109/TSP.2012.2222390
   Chen Z, 2015, INT GEOSCI REMOTE SE, P1662, DOI 10.1109/IGARSS.2015.7326105
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Erturk A., 2015, IEEE J-STARS, V9, P708
   Erturk A, 2016, INT GEOSCI REMOTE SE, P3370, DOI 10.1109/IGARSS.2016.7729871
   Erturk A, 2015, IEEE GEOSCI REMOTE S, V12, P1252, DOI 10.1109/LGRS.2015.2390973
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   Han Y, 2017, J SENSORS, V2017, DOI 10.1155/2017/9702612
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Hsieh CC, 2006, INT GEOSCI REMOTE SE, P775, DOI 10.1109/IGARSS.2006.199
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Koltunov A, 2007, REMOTE SENS ENVIRON, V110, P18, DOI 10.1016/j.rse.2007.02.010
   Le T. T., 2017, P INT C GEOSP TECHN, P152
   Liu SC, 2015, INT GEOSCI REMOTE SE, P4165, DOI 10.1109/IGARSS.2015.7326743
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Malila W.A, 1980, P LARS S, P385
   Nemmour H, 2006, ISPRS J PHOTOGRAMM, V61, P125, DOI 10.1016/j.isprsjprs.2006.09.004
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ren H, 2003, IEEE T AERO ELEC SYS, V39, P1232, DOI 10.1109/TAES.2003.1261124
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Usha S. G. A., 2017, J ASIAN SCI RES, V7, P206
   Wang Q, 2018, IEEE T GEOSCI REMOTE, V56, P5910, DOI 10.1109/TGRS.2018.2828161
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Yu J, 2017, INT J REMOTE SENS, V38, P773, DOI 10.1080/01431161.2016.1271475
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 35
TC 176
Z9 177
U1 41
U2 212
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD JAN
PY 2019
VL 57
IS 1
BP 3
EP 13
DI 10.1109/TGRS.2018.2849692
PG 11
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HG6JZ
UT WOS:000455089000001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Hyperspectral remote sensing image change detection based on tensor and
   deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor model; Deep learning; Support tensor machine; Hyperspectral
   remote sensing images; Change detection
AB Considering the bottleneck in improving the performance of the existing multi-temporal hyperspectral remote sensing (HSRS) image change detection methods, a HSRS image change detection solution based on tensor and deep learning is proposed in this study. At first, a tensor-based information model (TFS-Cube) of underlying features change in HSRS images is established. The wavelet texture feature change, spectral feature change and spatio-temporal autocorrelation coefficient of different-temporal related pixels are combined with three-order tensor, so as to make full use of the underlying features change information of HSRS images, optimize the organization mode and maintain the integrity of constraints between different underlying features. Secondly, a restricted Boltzmann Machine based on three-order tensor (Tensor3-RBM) is designed. The input, output and unsupervised learning of TFS-Cube tensor data are realized by multi-linear operations in Tensor3-RBMs. A large number of unlabeled samples are trained layer by layer through multilayer Tensor3-RBMs. Finally, the traditional BP neural network on the top layer of deep belief network (DBN) is replaced with support tensor machine (STM), and a deep belief network with multi-layer Tensor3-RBM and STM (TRS-DBN) is constructed. A small number of labeled samples are used for supervised learning and TRS-DBN global parameters optimization to improve the accuracy of TRS-DBN change detection. Two types of HSRS images from different sensors, AVIRIS and EO-1 Hyperion, are used as the data sources (double-temporal). Four representative experimental regions are randomly selected from the two areas covered by AVIRIS and EO-1 Hyperion HSRS images respectively (two regions in each area) to detect the land use changes. Experimental results demonstrate that TRS-DBN has higher change detection accuracy than similar methods and a good automation level. (C) 2018 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
RP Huang, FH (corresponding author), Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
EM fenghuait@sina.com; thfeng@uncc.edu
FU National Natural Science Foundation of China (NSFC)National Natural
   Science Foundation of China (NSFC) [41501451]; Program for New Century
   Excellent Talents in Fujian Province UniversitiesProgram for New Century
   Excellent Talents in University (NCET) [MinjiaoKe [2016]23]; Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities [MinjiaoKe [2015]54]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), the Program for New Century Excellent Talents in
   Fujian Province Universities (MinjiaoKe [2016]23) and the Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities (MinjiaoKe [2015]54). The authors would like to thank
   Zhengyuan Mao and Yinan He for their assistance, suggestions, and
   discussions.
CR Bezdek J. C., 2002, LECT NOTES COMPUT SC, V4, P288
   Borah S, 2007, J FOOD ENG, V79, P629, DOI 10.1016/j.jfoodeng.2006.02.022
   Cai Y. Y., 2010, W CHINA EXPLORAT ENG, V7, P131
   Chen H. J., 2014, China Patent, Patent No. [201410039584.3, 201410039584]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Du Q., 2012, 4 WORKSH HYP IM SIGN
   Erttirk A., 2017, IEEE GEOSCI REMOTE S, V6, P1252
   Feng J.H., 2007, BEIJING SURV MAPP, V3, P19
   Guo D, 2005, FORESTRY MACHINERY W, V33, P21
   Guo X., 2015, TENSOR BASED IMAGE N
   Guo X., 2013, ACTA GEOD CARTOGR SI, V2, P267
   [何宇婷 HE Yuting], 2008, [遥感技术与应用, Remote Sensing Technology and Application], V23, P571
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   Huang F. H., 2016, INT J EARTH SCI ENG, V5, P2096
   [黄恺 Huang Kai], 2016, [遥感信息, Remote Sensing Information], V31, P37
   [黄昕 HUANG Xin], 2006, [武汉大学学报. 信息科学版, Geomatics and information science of wuhan university.], V31, P66
   Jiang B. T., 2012, Patent No. [China Patent, 201210247785. 3, 201210247785]
   Kamarianakis Y, 2005, COMPUT GEOSCI-UK, V31, P119, DOI 10.1016/j.cageo.2004.05.012
   Kang Y., 2015, INSTRUM TECHN SENS, V4, P92
   Li Xiaolong, 2014, Journal of Frontiers of Computer Science and Technology, V8, P305, DOI 10.3778/j.issn.1673-9418.1306023
   [陆成韬 Lu Chengtao], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P633
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   [吕启 Lu Qi], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1911
   Lv G., 2014, COMPUT APPL SOFTW, V31, P213
   MA WY, 1995, P IEEE INT C IM PROC
   Manian V, 1998, PATTERN RECOGN, V31, P1937, DOI 10.1016/S0031-3203(98)00053-3
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Qi GL, 2016, IEEE IJCNN, P389, DOI 10.1109/IJCNN.2016.7727225
   REYNOLDS KM, 1988, PHYTOPATHOLOGY, V78, P240, DOI 10.1094/Phyto-78-240
   Sun Y. F., 2017, China Patent, Patent No. [201710141534. X, 201710141534]
   [王宇红 Wang Yuhong], 2016, [化工学报, CIESC Journal], V67, P5163
   Wang ZZ, 2008, IEEE T IMAGE PROCESS, V17, P1421, DOI 10.1109/TIP.2008.926150
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   [武辰 Wu Chen], 2012, [遥感学报, Journal of Remote Sensing], V16, P545
   Yoo HY, 2009, INT J REMOTE SENS, V30, P6219, DOI 10.1080/01431160902842359
   [曾奎 Zeng Kui], 2014, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V50, P219
   Zhang L. F., 2013, TENSOR REPRESENTATIO
   Zhao L, 2012, J CENTRAL S U SCI TE, V10, P365
NR 39
TC 27
Z9 29
U1 6
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 233
EP 244
DI 10.1016/j.jvcir.2018.11.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
SC Computer Science
GA HK1MD
UT WOS:000457668100024
DA 2022-01-04
ER

PT J
AU Gong, MG
   Yang, YL
   Zhan, T
   Niu, XD
   Li, SW
AF Gong, Maoguo
   Yang, Yuelei
   Zhan, Tao
   Niu, Xudong
   Li, Shuwei
TI A Generative Discriminatory Classified Network for Change Detection in
   Multispectral Imagery
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; deep learning; generative adversarial networks (GANs);
   multispectral imagery
ID UNSUPERVISED CHANGE DETECTION
AB Multispectral image change detection based on deep learning generally needs a large amount of training data. However, it is difficult and expensive to mark a large amount of labeled data. To deal with this problem, we propose a generative discriminatory classified network (GDCN) for multispectral image change detection, in which labeled data, unlabeled data, and new fake data generated by generative adversarial networks are used. The GDCN consists of a discriminatory classified network (DCN) and a generator. The DCN divides the input data into changed class, unchanged class, and extra class, i.e., fake class. The generator recovers the real data from input noises to provide additional training samples so as to boost the performance of the DCN. Finally, the bitemporal multispectral images are input to the DCN to get the final change map. Experimental results on the real multispectral imagery datasets demonstrate that the proposed GDCN trained by unlabeled data and a small amount of labeled data can achieve competitive performance compared with existing methods.
C1 [Gong, Maoguo; Yang, Yuelei; Zhan, Tao; Niu, Xudong] Xidian Univ, Sch Elect Engn, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
   [Li, Shuwei] Southeast Univ, Sch Elect Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Sch Elect Engn, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org; 1259437724@qq.com; OMEGAZhanT@gmail.com;
   xudong.niu@qq.com; 840142797@qq.com
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Key Research and
   Development Program of China [2017YFB0802200]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393, in part by the National Key
   Research and Development Program of China under Grant 2017YFB0802200,
   and in part by the Key Research and Development Program of Shaanxi
   Province under Grant 2018ZDXM-GY-045.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Chintala S., 2016, ARXIV151106434
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Glorot X., 2011, P 14 INT C ART INT S, P315, DOI DOI 10.1.1.208.6449
   Gokaraju B., 2015, 2015 IEEE APPL IM PA 2015 IEEE APPL IM PA, P1
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huszar F., 2015, ARXIV151105101
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kolassa J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111179
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu L., 2008, P INT WORKSH ED TECH, V1, P353
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Odena A., 2016, ARXIV160601583
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papernot N., 2016, ARXIV161005755
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Salimans Tim, 2016, ADV NEURAL INFORM PR, V29, P2234
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Springenberg, 2015, ARXIV151106390
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhu Jun-Yan, 2017, ARXIV170310593
NR 44
TC 24
Z9 25
U1 8
U2 39
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JAN
PY 2019
VL 12
IS 1
SI SI
BP 321
EP 333
DI 10.1109/JSTARS.2018.2887108
PG 13
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA HJ3MD
UT WOS:000457074900026
DA 2022-01-04
ER

PT J
AU Niu, XD
   Gong, MG
   Zhan, T
   Yang, YL
AF Niu, Xudong
   Gong, Maoguo
   Zhan, Tao
   Yang, Yuelei
TI A Conditional Adversarial Network for Change Detection in Heterogeneous
   Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; conditional generative adversarial networks (cGANs);
   heterogeneous images; synthetic aperture radar (SAR)
AB Due to the distinct statistical properties in cross-sensor images, change detection in heterogeneous images is much more challenging than in homogeneous images. In this letter, we adopt a conditional generative adversarial network (cGAN) to transform the heterogeneous synthetic aperture radar (SAR) and optical images into some space where their information has a more consistent representation, making the direct comparison feasible. Our proposed framework contains a cGAN-based translation network that aims to translate the optical image with the SAR image as a target, and an approximation network that approximates the SAR image to the translated one by reducing their pixelwise difference. The two networks are updated alternately and when they are both trained well, the two translated and approximated images can be considered as homogeneous, from which the final change map can be acquired by direct comparison. Theoretical analysis and experimental results demonstrate the effectiveness and robustness of the proposed framework.
C1 [Niu, Xudong; Gong, Maoguo; Zhan, Tao; Yang, Yuelei] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Program for Support of
   Top-Notch Young Professionals of China; National Key Research and
   Development Program of China [2017YFB0802200]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393, in part by the National
   Program for Support of Top-Notch Young Professionals of China, in part
   by the National Key Research and Development Program of China under
   Grant 2017YFB0802200, and in part by the Key Research and Development
   Program of Shaanxi Province under Grant 2018ZDXM-GY-045.
CR Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Ioffe S., 2015, ARXIV150203167, P448
   Isola Phillip, 2016, IMAGE TO IMAGE TRANS
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Oliver C., 2004, UNDERSTANDING SYNTHE
   Osindero, 2014, ARXIV14111784, DOI DOI 10.1017/CB09781139058452
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
NR 14
TC 42
Z9 44
U1 9
U2 40
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD JAN
PY 2019
VL 16
IS 1
BP 45
EP 49
DI 10.1109/LGRS.2018.2868704
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA HG7OP
UT WOS:000455181800010
DA 2022-01-04
ER

PT J
AU Zhan, T
   Gong, MG
   Liu, J
   Zhang, PZ
AF Zhan, Tao
   Gong, Maoguo
   Liu, Jia
   Zhang, Puzhao
TI Iterative feature mapping network for detecting multiple changes in
   multi-source remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Iterative feature mapping network; Hierarchical
   clustering analysis; Multiple changes; Multi-source images
ID UNSUPERVISED CHANGE DETECTION; NEURAL-NETWORKS; SET
AB Owing to the rapid development of remote sensing technology, various types of data can be easily acquired at present. However, it has become an important but more challenging task for effectively highlighting changes occurring on the land surface from these available data. In this paper, we propose an iterative feature mapping network learning framework for identifying multiple changes with focus on multi-source images, which are often obtained from sensors with different imaging modalities. Firstly, high-level and robust feature representations are extracted from multi-source images via unsupervised feature learning. Then, on this basis, an iterative feature mapping network is established to transform these features into a common high-dimensional feature space. It aims to learn more discriminative features by shrinking the difference between the paired features of unchanged positions while enlarging that of changed ones. Note that the network parameters are learned by optimizing a well-designed objective function, and the whole learning process is fully unsupervised. Finally, based on a hierarchical tree for clustering analysis, all possible change classes can be detected accurately. In addition, the proposed framework is found to be also suitable for change detection in homogeneous images. The impressive experimental results obtained over different types of remote sensing images demonstrate the effectiveness and robustness of the proposed model.
C1 [Zhan, Tao; Gong, Maoguo; Liu, Jia; Zhang, Puzhao] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org
RI Liu, Jia/P-9706-2018
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Program for Support of
   Top-notch Young Professionals of China; National Key Research and
   Development Program of China [2017YFB0802200]; Key Research and
   Development Program of Shaanxi Province [2018ZDXM-GY-045]
FX The authors wish to thank the editors and anonymous reviewers for their
   valuable comments and helpful suggestions which greatly improved the
   paper's quality. This work was supported by the National Natural Science
   Foundation of China (Grant no. 61772393), the National Program for
   Support of Top-notch Young Professionals of China, the National Key
   Research and Development Program of China (Grant no. 2017YFB0802200),
   and the Key Research and Development Program of Shaanxi Province (Grant
   no. 2018ZDXM-GY-045).
CR Bazaraa M. S., 2013, NONLINEAR PROGRAMMIN
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Chinchor N, 1993, PROC 5 MESSAGE UNDER, P69, DOI DOI 10.3115/1072017.1072026
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   Gil-Yepes JL, 2016, ISPRS J PHOTOGRAMM, V121, P77, DOI 10.1016/j.isprsjprs.2016.08.010
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Meddens AJH, 2013, REMOTE SENS ENVIRON, V132, P49, DOI 10.1016/j.rse.2013.01.002
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Prendes J, 2015, INT CONF ACOUST SPEE, P1513, DOI 10.1109/ICASSP.2015.7178223
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stuhlsatz A, 2012, IEEE T NEUR NET LEAR, V23, P596, DOI 10.1109/TNNLS.2012.2183645
   Taubenbock H, 2012, REMOTE SENS ENVIRON, V117, P162, DOI 10.1016/j.rse.2011.09.015
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Volpi M, 2015, ISPRS J PHOTOGRAMM, V107, P50, DOI 10.1016/j.isprsjprs.2015.02.005
   Xue SF, 2014, IEEE-ACM T AUDIO SPE, V22, P1713, DOI 10.1109/TASLP.2014.2346313
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
NR 42
TC 19
Z9 19
U1 5
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD DEC
PY 2018
VL 146
BP 38
EP 51
DI 10.1016/j.isprsjprs.2018.09.002
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA HE6FT
UT WOS:000453499400004
DA 2022-01-04
ER

PT J
AU Song, A
   Choi, J
   Han, Y
   Kim, Y
AF Song, Ahram
   Choi, Jaewan
   Han, Youkyung
   Kim, Yongil
TI Change Detection in Hyperspectral Images Using Recurrent 3D Fully
   Convolutional Networks
SO REMOTE SENSING
LA English
DT Article
DE change detection; fully convolutional network; 3D convolution;
   convolutional LSTM; hyperspectral image
ID NEURAL-NETWORKS; CLASSIFICATION; DISTANCE; MAD
AB Hyperspectral change detection (CD) can be effectively performed using deep-learning networks. Although these approaches require qualified training samples, it is difficult to obtain ground-truth data in the real world. Preserving spatial information during training is difficult due to structural limitations. To solve such problems, our study proposed a novel CD method for hyperspectral images (HSIs), including sample generation and a deep-learning network, called the recurrent three-dimensional (3D) fully convolutional network (Re3FCN), which merged the advantages of a 3D fully convolutional network (FCN) and a convolutional long short-term memory (ConvLSTM). Principal component analysis (PCA) and the spectral correlation angle (SCA) were used to generate training samples with high probabilities of being changed or unchanged. The strategy assisted in training fewer samples of representative feature expression. The Re3FCN was mainly comprised of spectral-spatial and temporal modules. Particularly, a spectral-spatial module with a 3D convolutional layer extracts the spectral-spatial features from the HSIs simultaneously, whilst a temporal module with ConvLSTM records and analyzes the multi-temporal HSI change information. The study first proposed a simple and effective method to generate samples for network training. This method can be applied effectively to cases with no training samples. Re3FCN can perform end-to-end detection for binary and multiple changes. Moreover, Re3FCN can receive multi-temporal HSIs directly as input without learning the characteristics of multiple changes. Finally, the network could extract joint spectral-spatial-temporal features and it preserved the spatial structure during the learning process through the fully convolutional structure. This study was the first to use a 3D FCN and a ConvLSTM for the remote-sensing CD. To demonstrate the effectiveness of the proposed CD method, we performed binary and multi-class CD experiments. Results revealed that the Re3FCN outperformed the other conventional methods, such as change vector analysis, iteratively reweighted multivariate alteration detection, PCA-SCA, FCN, and the combination of 2D convolutional layers-fully connected LSTM.
C1 [Song, Ahram; Kim, Yongil] Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
   [Choi, Jaewan] Chungbuk Natl Univ, Sch Civil Engn, 1 Chungdae Ro, Cheongju 28644, Chungbuk, South Korea.
   [Han, Youkyung] Kyungpook Natl Univ, Sch Convergence & Fusion Syst Engn, Sangju 37224, South Korea.
RP Kim, Y (corresponding author), Seoul Natl Univ, Dept Civil & Environm Engn, 1 Gwanak Ro, Seoul 08826, South Korea.
EM aram200@snu.ac.kr; jaewanchoi@chungbuk.ac.kr; han602@knu.ac.kr;
   yik@snu.ac.kr
OI song, ahram/0000-0002-9190-2848; Han, Youkyung/0000-0001-6586-8503;
   Choi, Jaewan/0000-0003-3967-6481
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [NRF-2016R1A2B4016301, 18SIUE-B148326-01]; Satellite Information
   Utilization Center Establishment Program by Ministry of Land,
   Infrastructure and Transport of Korean government
FX This research was supported by the National Research Foundation of Korea
   (NRF) funded by the Korean government (MSIT) (grant no.
   NRF-2016R1A2B4016301) and by a grant (18SIUE-B148326-01) from Satellite
   Information Utilization Center Establishment Program by Ministry of
   Land, Infrastructure and Transport of Korean government.
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Adao T, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111110
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700
   Bengio Y., 2006, ADV NEURAL INFORM PR, V19, P153
   Cao XY, 2018, IEEE T IMAGE PROCESS, V27, P2354, DOI 10.1109/TIP.2018.2799324
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Chein-I Chang, 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P509, DOI 10.1109/IGARSS.1999.773549
   Chen L., 2015, P INT C LEARN REPR I
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   De Carvalho O.A., 2000, P 9 AIRB EARTH SCI W
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Du Q., P 2012 4 WORKSH HYP, P1, DOI [10.1109/WHISPERS.2012.6874223, DOI 10.1109/WHISPERS.2012.6874223]
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   FUNG T, 1987, PHOTOGRAMM ENG REM S, V53, P1649
   Gao F, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050435
   Han Y, 2017, J SENSORS, V2017, DOI 10.1155/2017/9702612
   Hasanlou M, 2018, INT J REMOTE SENS, V39, P7029, DOI 10.1080/01431161.2018.1466079
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Khanday W.A., 2016, ASIAN J TECHNOL MANA, V6, P54
   KRUSE FA, 1993, REMOTE SENS ENVIRON, V44, P145, DOI 10.1016/0034-4257(93)90013-N
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liu, 2015, THESIS
   Liu SC, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9101008
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Mou L., 2018, ARXIV180302642
   Neville R.A., 1999, 4 INT AIRB REM SENS, P891
   Nielsen AA, 1998, REMOTE SENS ENVIRON, V64, P1, DOI 10.1016/S0034-4257(97)00162-4
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ortiz-Rivera V., 2006, P SPIE 2006 ALG TECH
   Pu R, 2008, ENVIRON MONIT ASSESS, V140, P15, DOI 10.1007/s10661-007-9843-7
   Robila SA, 2004, INT GEOSCI REMOTE SE, P3233
   Rumelhart G.E., 1986, PARALLEL DISTRIBUTED, P318, DOI [DOI 10.1016/B978-1-4832-1446-7.50035-2, DOI 10.1007/978-0-387-39940-9_3246]
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Santurkar, 2018, ARXIV180511604
   Shi AY, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0397-0
   Sicong Liu, 2014, 2014 IEEE Geoscience and Remote Sensing Symposium. (IGARSS). Proceedings, P4656, DOI 10.1109/IGARSS.2014.6947531
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Singh S, 2014, SADHANA-ACAD P ENG S, V39, P1311, DOI 10.1007/s12046-014-0286-x
   Song XL, 2011, PROCEDIA ENVIRON SCI, V11, P238, DOI 10.1016/j.proenv.2011.12.037
   Valipour S, 2017, IEEE WINT CONF APPL, P29, DOI 10.1109/WACV.2017.11
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Xingjian S., 2015, ADV NEURAL INFORM PR, P802
   Yang XF, 2018, IEEE T GEOSCI REMOTE, V56, P5408, DOI 10.1109/TGRS.2018.2815613
   Yu F., 2016, P 2016 INT C LEARN R
   Yu L, 2016, FRONT COMPUT SCI-CHI, V10, P292, DOI 10.1007/s11704-015-4103-4
   Yuan Y, 2015, NEUROCOMPUTING, V148, P363, DOI 10.1016/j.neucom.2014.06.024
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 55
TC 50
Z9 50
U1 12
U2 39
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD NOV
PY 2018
VL 10
IS 11
AR 1827
DI 10.3390/rs10111827
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA HC3WO
UT WOS:000451733800158
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Wiratama, W
   Lee, J
   Park, SE
   Sim, D
AF Wiratama, Wahyu
   Lee, Jongseok
   Park, Sang-Eun
   Sim, Donggyu
TI Dual-Dense Convolution Network for Change Detection of High-Resolution
   Panchromatic Imagery
SO APPLIED SCIENCES-BASEL
LA English
DT Article
DE change detection; convolutional network; deep learning; panchromatic;
   remote sensing
ID FUZZY C-MEANS; LAND-COVER
AB This paper presents a robust change detection algorithm for high-resolution panchromatic imagery using a proposed dual-dense convolutional network (DCN). In this work, a joint structure of two deep convolutional networks with dense connectivity in convolution layers is designed in order to accomplish change detection for satellite images acquired at different times. The proposed network model detects pixel-wise temporal change based on local characteristics by incorporating information from neighboring pixels. Dense connection in convolution layers is designed to reuse preceding feature maps by connecting them to all subsequent layers. Dual networks are incorporated by measuring the dissimilarity of two temporal images. In the proposed algorithm for change detection, a contrastive loss function is used in a learning stage by running over multiple pairs of samples. According to our evaluation, we found that the proposed framework achieves better detection performance than conventional algorithms, in area under the curve (AUC) of 0.97, percentage correct classification (PCC) of 99%, and Kappa of 69, on average.
C1 [Wiratama, Wahyu; Lee, Jongseok; Sim, Donggyu] Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
   [Park, Sang-Eun] Sejong Univ, Dept Geoinformat Engn, Seoul 143747, South Korea.
RP Sim, D (corresponding author), Kwangwoon Univ, Dept Comp Engn, Seoul 139701, South Korea.
EM wiratama@kw.ac.kr; suk2080@kw.ac.kr; separk@sejong.ac.kr; dgsim@kw.ac.kr
OI Sim, Donggyu/0000-0002-2794-9932
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program [IITP-2018-2016-0-00288];
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2018R1A2B2008238]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program (IITP-2018-2016-0-00288) supervised by the IITP (Institute for
   Information & communications Technology Promotion) and Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science, ICT & Future Planning
   (NRF-2018R1A2B2008238).
CR Bauer M. E., 1996, REMOTE SENSING REV, V13, P207, DOI DOI 10.1080/02757259609532305
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bi CJ, 2014, INT CONF CLOUD COMPU, P327, DOI 10.1109/CCIS.2014.7175753
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   El Amin AM, 2016, PROC SPIE, V0011, DOI 10.1117/12.2243798
   FITZGERALD RW, 1994, REMOTE SENS ENVIRON, V47, P362, DOI 10.1016/0034-4257(94)90103-1
   Gao F., 2015, P INT C CIRC SYST CA
   Glorot X., 2010, UNDERSTANDING DIFFIC, VVolume 9, P249, DOI DOI 10.1177/1753193409103364.
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo Z, 2017, GISCI REMOTE SENS, V54, P38, DOI 10.1080/15481603.2016.1250328
   Habib T, 2009, IEEE GEOSCI REMOTE S, V6, P606, DOI 10.1109/LGRS.2009.2020306
   Hadsell R., 2006, P 2006 IEEE COMP SOC
   Hao M, 2017, MULTIMED TOOLS APPL, V76, P20081, DOI 10.1007/s11042-017-4354-1
   Hao M, 2013, REMOTE SENS LETT, V4, P1185, DOI 10.1080/2150704X.2013.858841
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SL, 2017, GISCI REMOTE SENS, V54, P495, DOI 10.1080/15481603.2017.1286727
   Ioffe S., 2015, P INT C MACH LEARN
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Singh K.K., 2013, P IEEE PIMRC, P1
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Yoo H.-J., 2015, IEIE T SMART PROCESS, V4, P35, DOI DOI 10.5573/IEIESPC.2015.4.1.035
   Yu H, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121233
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 31
TC 20
Z9 20
U1 3
U2 12
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2076-3417
J9 APPL SCI-BASEL
JI Appl. Sci.-Basel
PD OCT
PY 2018
VL 8
IS 10
AR 1785
DI 10.3390/app8101785
PG 13
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
SC Chemistry; Engineering; Materials Science; Physics
GA GY5WG
UT WOS:000448653700080
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Zhan, T
   Gong, MG
   Jiang, XM
   Li, SW
AF Zhan, Tao
   Gong, Maoguo
   Jiang, Xiangming
   Li, Shuwei
TI Log-Based Transformation Feature Learning for Change Detection in
   Heterogeneous Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; feature learning (FL); heterogeneous images;
   logarithmic transformation
ID UNSUPERVISED CHANGE DETECTION; REMOTELY-SENSED IMAGES; NETWORK
AB With the rapid development of remote sensing technology, how to accurately detect changes that have occurred on the land surface has been a critical task, particularly when images come from different satellite sensors. In this letter, we propose an unsupervised change detection method for heterogeneous synthetic aperture radar (SAR) and optical images based on the logarithmic transformation feature learning framework. First, the logarithmic transformation is applied to the SAR image that aims to achieve similar statistical distribution properties as the optical image. Then, high-level feature representations can be learned from the transformed image pair via joint feature extraction, which are used to select reliable samples for training a neural network classifier. When it is trained well, a robust change map can be obtained, thus identifying changed regions accurately. The experimental results on three real heterogeneous data sets demonstrate the effectiveness and superiority of the proposed method compared with other existing state-of-the-art approaches.
C1 [Zhan, Tao; Gong, Maoguo; Jiang, Xiangming] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
   [Li, Shuwei] Southeast Univ, Sch Elect Sci & Engn, Nanjing 210096, Jiangsu, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org
RI Jiang, Xiangming/AAY-9275-2020; Jiang, Xiangming/G-3307-2018; Jiang,
   Xiangming/N-4780-2019
OI Jiang, Xiangming/0000-0002-4650-1308; Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393]; National Program for Support of
   Top-notch Young Professionals of China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393 and in part by the National
   Program for Support of Top-notch Young Professionals of China.
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Brunner D, 2010, IEEE T GEOSCI REMOTE, V48, P2403, DOI 10.1109/TGRS.2009.2038274
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Daszykowski M, 2001, CHEMOMETR INTELL LAB, V56, P83, DOI 10.1016/S0169-7439(01)00111-3
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Gong MG, 2017, IEEE T GEOSCI REMOTE, V55, P2658, DOI 10.1109/TGRS.2017.2650198
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kenneth R. C., 1996, DIGITAL IMAGE PROCES
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Oliver C., 1998, UNDERSTANDING SYNTHE
   Roy M, 2014, INFORM SCIENCES, V269, P35, DOI 10.1016/j.ins.2014.01.037
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Solano-Correa YT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040533
   Touati R, 2018, IEEE T GEOSCI REMOTE, V56, P1046, DOI 10.1109/TGRS.2017.2758359
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Volpi M, 2013, INT J APPL EARTH OBS, V20, P77, DOI 10.1016/j.jag.2011.10.013
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Zhao W, 2017, IEEE T GEOSCI REMOTE, V55, P7066, DOI 10.1109/TGRS.2017.2739800
NR 22
TC 27
Z9 27
U1 5
U2 32
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD SEP
PY 2018
VL 15
IS 9
BP 1352
EP 1356
DI 10.1109/LGRS.2018.2843385
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA GR9FB
UT WOS:000443051700009
DA 2022-01-04
ER

PT J
AU Su, LZ
   Cao, X
AF Su, Linzhi
   Cao, Xin
TI Fuzzy autoencoder for multiple change detection in remote sensing images
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; fuzzy number; fuzzy autoencoder; fuzzy neural
   networks; remote sensing
ID UNSUPERVISED CHANGE DETECTION; URBAN CHANGE DETECTION; NEURAL-NETWORK;
   SAR IMAGES; REPRESENTATION; MODEL
AB This paper establishes the fuzzy autoencoder (FAE) to detect multiple changes between two one-dimensional multitemporal images. Different from the traditional approaches based on the pixel intensity, FAE includes a multilayer structure through self-reconstruction to extract the feature from an image. Due to the existence of noise in the images, the raw data tend to be corrupted and fail to detect the real changes. Therefore, the fuzzy number is introduced to the autoencoder to establish the FAE which is able to suppress the noise and learn robust features. In this way, the information in the fuzzy domain is introduced into the input, and in practice the fuzzy domain is discretized to facilitate the calculation. In addition, the weighted Frobenius norm is used to establish the loss function which can be minimized to achieve the optimal parameters. The framework is highlighted by the newly designed FAE. As the fuzzy number is introduced into the autoencoder, more information concerning the fuzzy domain is taken into consideration and thus the impact brought by the noise is relieved to a large extent. Hence, the FAE can generate robust features, enhancing its performance on deep feature representation learning. Several tests on three datasets show us the proper parameter settings, and the experimental results from the FAE framework and the other compared approaches demonstrate its effectiveness and robustness in terms of accuracy and elapsed time. (c) 2018 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Su, Linzhi; Cao, Xin] Northwest Univ, Sch Informat & Technol, Xuefu Ave, Xian, Shaanxi, Peoples R China.
RP Cao, X (corresponding author), Northwest Univ, Sch Informat & Technol, Xuefu Ave, Xian, Shaanxi, Peoples R China.
EM xin_cao@163.com
FU Program of the National Natural Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [61701403]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2017JQ6006]
FX This work was supported by the Program of the National Natural Science
   Foundation of China under Grant No. 61701403 and the Natural Science
   Basic Research Plan in Shaanxi Province of China under Grant No.
   2017JQ6006.
CR Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Bengio Y, 2000, ADV NEUR IN, V12, P400
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2013, IEEE T GEOSCI REMOTE, V51, P2042, DOI 10.1109/TGRS.2012.2223219
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   BUCKLEY JJ, 2003, FUZZY PROBABILITIES
   Chang CH, 2015, IEEE T NEUR NET LEAR, V26, P2477, DOI 10.1109/TNNLS.2014.2387439
   Chen CLP, 2015, IEEE T FUZZY SYST, V23, P2163, DOI 10.1109/TFUZZ.2015.2406889
   Chen LC, 2010, J APPL REMOTE SENS, V4, DOI 10.1117/1.3525560
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   DIJKMAN JG, 1983, J MATH ANAL APPL, V92, P301, DOI 10.1016/0022-247X(83)90253-6
   Ghofrani Z, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083646
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hao PY, 2008, IEEE T FUZZY SYST, V16, P428, DOI 10.1109/TFUZZ.2007.896359
   Huo CL, 2016, IEEE J-STARS, V9, P3384, DOI 10.1109/JSTARS.2016.2569598
   Juang CF, 2015, IEEE T FUZZY SYST, V23, P1474, DOI 10.1109/TFUZZ.2014.2362547
   Juang CF, 2008, IEEE T FUZZY SYST, V16, P1411, DOI 10.1109/TFUZZ.2008.925907
   Kim CJ, 2015, IEEE T FUZZY SYST, V23, P677, DOI 10.1109/TFUZZ.2014.2321771
   Lee JS, 2009, OPT SCI ENG-CRC, P1
   Li HC, 2018, ELECTRON LETT, V54, P892, DOI 10.1049/el.2018.1269
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Lin FJ, 2014, IEEE T FUZZY SYST, V22, P1598, DOI 10.1109/TFUZZ.2014.2300168
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Malfait F., 2014, J APPL REMOTE SENS, V8
   Marchesi S, 2010, IEEE T IMAGE PROCESS, V19, P1877, DOI 10.1109/TIP.2010.2045070
   Mohammadzadeh A, 2014, IEEE T FUZZY SYST, V22, P1301, DOI 10.1109/TFUZZ.2013.2291568
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Neagoe VE, 2014, IEEE J-STARS, V7, P3525, DOI 10.1109/JSTARS.2014.2330808
   Rubio-Solis A, 2015, IEEE T FUZZY SYST, V23, P457, DOI 10.1109/TFUZZ.2014.2315656
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Su LZ, 2016, IEEE IJCNN, P1269, DOI 10.1109/IJCNN.2016.7727343
   Subudhi BN, 2014, OPT LASER TECHNOL, V57, P284, DOI 10.1016/j.optlastec.2013.10.003
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang N, 2015, IEEE T FUZZY SYST, V23, P1414, DOI 10.1109/TFUZZ.2014.2362144
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 46
TC 7
Z9 7
U1 7
U2 51
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD AUG 31
PY 2018
VL 12
IS 3
AR 035014
DI 10.1117/1.JRS.12.035014
PG 23
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA GS1UE
UT WOS:000443317900001
DA 2022-01-04
ER

PT J
AU Chen, Z
   Zhang, YF
   Ouyang, C
   Zhang, F
   Ma, J
AF Chen, Zhong
   Zhang, Yifei
   Ouyang, Chao
   Zhang, Feng
   Ma, Jie
TI Automated Landslides Detection for Mountain Cities Using Multi-Temporal
   Remote Sensing Imagery
SO SENSORS
LA English
DT Article
DE landslides detection; remote sensing images; change detection; Deep
   Convolution Neural Network; Spatial Temporal Context Learning
ID RECOGNITION; INDEX
AB Landslides that take place in mountain cities tend to cause huge casualties and economic losses, and a precise survey of landslide areas is a critical task for disaster emergency. However, because of the complicated appearance of the nature, it is difficult to find a spatial regularity that only relates to landslides, thus landslides detection based on only spatial information or artificial features usually performs poorly. In this paper, an automated landslides detection approach that is aiming at mountain cities has been proposed based on pre-and post-event remote sensing images, it mainly utilizes the knowledge of landslide-related surface covering changes, and makes full use of the temporal and spatial information. A change detection method using Deep Convolution Neural Network (DCNN) was introduced to extract the areas where drastic alterations have taken place; then, focusing on the changed areas, the Spatial Temporal Context Learning (STCL) was conducted to identify the landslides areas; finally, we use slope degree which is derived from digital elevation model (DEM) to make the result more reliable, and the change of DEMis used for making the detected areas more complete. The approach was applied to detecting the landslides in Shenzhen, Zhouqu County and Beichuan County in China, and a quantitative accuracy assessment has been taken. The assessment indicates that this approach can guarantee less commission error of landslide areal extentwhich is below 17.6% and achieves a quality percentage above 61.1%, and for landslide areas, the detection percentage is also competitive, the experimental results proves the feasibility and accuracy of the proposed approach for the detection landslides in mountain cities.
C1 [Chen, Zhong; Zhang, Yifei; Ouyang, Chao; Zhang, Feng; Ma, Jie] Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Hubei, Peoples R China.
RP Zhang, YF (corresponding author), Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Hubei, Peoples R China.
EM henpacked@163.com; zhang_yifei@hust.edu.cn; ouyangchao16@hust.edu.cn;
   M201572329@hust.edu.cn; majie@mail.hust.edu.cn
FU China Aerospace Science Industry Corp.
FX The paper was supported by the Space Support Technology Funds from China
   Aerospace Science & Industry Corp.
CR Aksoy B, 2012, COMPUT GEOSCI-UK, V38, P87, DOI 10.1016/j.cageo.2011.05.010
   Barlow J, 2006, PHOTOGRAMM ENG REM S, V72, P687, DOI 10.14358/PERS.72.6.687
   Basu S, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820816
   Behling R, 2014, REMOTE SENS-BASEL, V6, P8026, DOI 10.3390/rs6098026
   Behling R, 2014, REMOTE SENS-BASEL, V6, P2572, DOI 10.3390/rs6032572
   Bluche T, 2013, PROC INT CONF DOC, P285, DOI 10.1109/ICDAR.2013.64
   Chang YL, 2007, IEEE T GEOSCI REMOTE, V45, P1697, DOI 10.1109/TGRS.2007.895832
   Cheng G, 2013, INT J REMOTE SENS, V34, P45, DOI 10.1080/01431161.2012.705443
   Cheng KS, 2004, ADV SPACE RES-SERIES, V33, P296, DOI 10.1016/S0273-1177(03)00471-X
   Cruden DM., 1996, LANDSLIDES INVESTIGA, pp. 36
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344
   Hervas J, 2003, GEOMORPHOLOGY, V54, P63, DOI 10.1016/S0169-555X(03)00056-4
   Holbling D, 2012, REMOTE SENS-BASEL, V4, P1310, DOI 10.3390/rs4051310
   Keefer DK, 2007, SCIENCE, V316, P1136, DOI 10.1126/science.1143308
   Khairunniza-Bejo S, 2010, INT J REMOTE SENS, V31, P6033, DOI 10.1080/01431160903376365
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lacroix P, 2013, REMOTE SENS-BASEL, V5, P2590, DOI 10.3390/rs5062590
   Lee S, 2006, ADV SPACE RES, V38, P2261, DOI 10.1016/j.asr.2006.03.036
   Lu P, 2011, IEEE GEOSCI REMOTE S, V8, P701, DOI 10.1109/LGRS.2010.2101045
   Martha TR, 2012, ISPRS J PHOTOGRAMM, V67, P105, DOI 10.1016/j.isprsjprs.2011.11.004
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mondini AC, 2011, REMOTE SENS ENVIRON, V115, P1743, DOI 10.1016/j.rse.2011.03.006
   Mondini AC, 2013, GEOMORPHOLOGY, V201, P135, DOI 10.1016/j.geomorph.2013.06.015
   Pascale S, 2012, INT J AGRIC ENVIRON, V3, P14, DOI 10.4018/jaeis.2012010102
   Pesaresi M, 2008, IEEE J-STARS, V1, P180, DOI 10.1109/JSTARS.2008.2002869
   Pradhan B, 2010, ENVIRON EARTH SCI, V60, P1037, DOI 10.1007/s12665-009-0245-8
   Rau JY, 2014, IEEE T GEOSCI REMOTE, V52, P1336, DOI 10.1109/TGRS.2013.2250293
   Rouse J.W., 1973, MONITORING VERNAL AD
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   van Westen CJ, 2008, ENG GEOL, V102, P112, DOI 10.1016/j.enggeo.2008.03.010
   Weston J., 2008, P 25 ICML, P160, DOI [10.1145/1390156.1390177, 10.1145/ 1390156.1390177, DOI 10.1145/1390156.1390177]
   Yin YP, 2009, LANDSLIDES, V6, P139, DOI 10.1007/s10346-009-0148-5
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
NR 34
TC 27
Z9 28
U1 5
U2 35
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 1424-8220
J9 SENSORS-BASEL
JI Sensors
PD MAR
PY 2018
VL 18
IS 3
AR 821
DI 10.3390/s18030821
PG 18
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
SC Chemistry; Engineering; Instruments & Instrumentation
GA GB1IU
UT WOS:000428805300142
PM 29522424
OA Green Published, Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Kong, YL
   Huang, QQ
   Wang, CY
   Chen, JB
   Chen, JS
   He, DX
AF Kong, Yun-Long
   Huang, Qingqing
   Wang, Chengyi
   Chen, Jingbo
   Chen, Jiansheng
   He, Dongxu
TI Long Short-Term Memory Neural Networks for Online Disturbance Detection
   in Satellite Image Time Series
SO REMOTE SENSING
LA English
DT Article
DE long short-term memory; LSTM; recurrent neural network; RNN; online
   disturbance detection; satellite image time series; SITS
ID CLASSIFICATION; VEGETATION
AB A satellite image time series (SITS) contains a significant amount of temporal information. By analysing this type of data, the pattern of the changes in the object of concern can be explored. The natural change in the Earth's surface is relatively slow and exhibits a pronounced pattern. Some natural events (for example, fires, floods, plant diseases, and insect pests) and human activities (for example, deforestation and urbanisation) will disturb this pattern and cause a relatively profound change on the Earth's surface. These events are usually referred to as disturbances. However, disturbances in ecosystems are not easy to detect from SITS data, because SITS contain combined information on disturbances, phenological variations and noise in remote sensing data. In this paper, a novel framework is proposed for online disturbance detection from SITS. The framework is based on long short-term memory (LSTM) networks. First, LSTM networks are trained by historical SITS. The trained LSTM networks are then used to predict new time series data. Last, the predicted data are compared with real data, and the noticeable deviations reveal disturbances. Experimental results using 16-day compositions of the moderate resolution imaging spectroradiometer (MOD13Q1) illustrate the effectiveness and stability of the proposed approach for online disturbance detection.
C1 [Kong, Yun-Long; Huang, Qingqing; Wang, Chengyi; Chen, Jingbo; Chen, Jiansheng; He, Dongxu] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100101, Peoples R China.
RP Huang, QQ (corresponding author), Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100101, Peoples R China.
EM kongyl@radi.ac.cn; huangqq@radi.ac.cn; wangcy@radi.ac.cn;
   chenjb@radi.ac.cn; chenjs@radi.ac.cn; hedx@radi.ac.cn
RI Wang, Chengyi/AAZ-2450-2021
FU National Key Research and Development Program of China [2016YFB0502503];
   "135" Strategy Planning of the Institute of Remote Sensing and Digital
   Earth, Chinese Academy of Sciences [Y7SG0800CX]; National Science and
   Technology Major Project of China [30-Y20A04-9001-17/18,
   21-Y20A06-9001-17/18]
FX This work is jointly supported by the National Key Research and
   Development Program of China (grant no. 2016YFB0502503), the "135"
   Strategy Planning of the Institute of Remote Sensing and Digital Earth,
   Chinese Academy of Sciences (grant no. Y7SG0800CX), the National Science
   and Technology Major Project of China (grant no. 30-Y20A04-9001-17/18
   and grant no. 21-Y20A06-9001-17/18).
CR Audhkhasi K., 2013, INT JOINT C NEUR NET, P2738
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bellon B, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060600
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boriah, 2010, THESIS
   Chattopadhyay C, 2014, INT J MULTIMED INF R, V3, P15, DOI 10.1007/s13735-013-0042-8
   Chen MC, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATICS, MANAGEMENT ENGINEERING AND INDUSTRIAL APPLICATION (IMEIA 2016), P1, DOI 10.1109/PLASMA.2016.7534032
   Chuvieco E, 2002, INT J REMOTE SENS, V23, P5103, DOI 10.1080/01431160210153129
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fang Y., 2006, P 6 IEEE INT C DAT M
   Gomez C, 2016, ISPRS J PHOTOGRAMM, V116, P55, DOI 10.1016/j.isprsjprs.2016.03.008
   Grobler TL, 2013, IEEE GEOSCI REMOTE S, V10, P332, DOI 10.1109/LGRS.2012.2205556
   Han P, 2010, MATH COMPUT MODEL, V51, P1398, DOI 10.1016/j.mcm.2009.10.031
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1, DOI 10.1162/neco.1997.9.1.1
   Kuenzer C, 2013, REMOTE SENS-BASEL, V5, P687, DOI 10.3390/rs5020687
   Lahmiri S, 2016, EXPERT SYST APPL, V55, P268, DOI 10.1016/j.eswa.2016.02.025
   Langkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li SM, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1842-2
   Lu Y., 2017, INT C COMP VIS ICCV, P22
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma XL, 2015, TRANSPORT RES C-EMER, V54, P187, DOI 10.1016/j.trc.2015.03.014
   Mosca A., 2017, P ESANN 2017 P EUR S
   PINTY B, 1992, VEGETATIO, V101, P15, DOI 10.1007/BF00031911
   Rheinwalt A, 2016, CLIM DYNAM, V46, P1065, DOI 10.1007/s00382-015-2632-z
   Russwurm M, 2017, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2017.193
   Sharon I, 2013, GENOME RES, V23, P111, DOI 10.1101/gr.142315.112
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Verbesselt J, 2012, REMOTE SENS ENVIRON, V123, P98, DOI 10.1016/j.rse.2012.02.022
   Verbesselt J, 2010, REMOTE SENS ENVIRON, V114, P106, DOI 10.1016/j.rse.2009.08.014
   Wu H., 2017, REMOTE SENS, V9
   You JX, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4559
   Yu PS, 2017, J HYDROL, V552, P92, DOI 10.1016/j.jhydrol.2017.06.020
   Yuan Y, 2015, REMOTE SENS-BASEL, V7, P15318, DOI 10.3390/rs71115318
   Zeyer A., 2017, P 2017 IEEE INT C AC, P3
   Zhang XY, 2003, REMOTE SENS ENVIRON, V84, P471, DOI 10.1016/S0034-4257(02)00135-9
   Zhu Z, 2017, ISPRS J PHOTOGRAMM, V130, P370, DOI 10.1016/j.isprsjprs.2017.06.013
NR 38
TC 34
Z9 34
U1 9
U2 21
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2018
VL 10
IS 3
AR 452
DI 10.3390/rs10030452
PG 13
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA GA4DP
UT WOS:000428280100098
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Lyu, HB
   Lu, H
   Mou, LC
   Li, WY
   Wright, J
   Li, XC
   Li, XL
   Zhu, XX
   Wang, J
   Yu, L
   Gong, P
AF Lyu, Haobo
   Lu, Hui
   Mou, Lichao
   Li, Wenyu
   Wright, Jonathon
   Li, Xuecao
   Li, Xinlu
   Zhu, Xiao Xiang
   Wang, Jie
   Yu, Le
   Gong, Peng
TI Long-Term Annual Mapping of Four Cities on Different Continents by
   Applying a Deep Information Learning Method to Landsat Data
SO REMOTE SENSING
LA English
DT Article
DE urban mapping; deep learning; recurrent neural network; transfer
   learning; long time series
ID PRIMARY PRODUCTIVITY; COVER CHANGE; URBAN AREAS; CHINA; CLASSIFICATION;
   DYNAMICS; URBANIZATION; CONSEQUENCES; ALGORITHMS; GROSS
AB Urbanization is a substantial contributor to anthropogenic environmental change, and often occurs at a rapid pace that demands frequent and accurate monitoring. Time series of satellite imagery collected at fine spatial resolution using stable spectral bands over decades are most desirable for this purpose. In practice, however, temporal spectral variance arising from variations in atmospheric conditions, sensor calibration, cloud cover, and other factors complicates extraction of consistent information on changes in urban land cover. Moreover, the construction and application of effective training samples is time-consuming, especially at continental and global scales. Here, we propose a new framework for satellite-based mapping of urban areas based on transfer learning and deep learning techniques. We apply this method to Landsat observations collected during 1984-2016 and extract annual records of urban areas in four cities in the temperate zone (Beijing, New York, Melbourne, and Munich). The method is trained using observations of Beijing collected in 1999, and then used to map urban areas in all target cities for the entire 1984-2016 period. The method addresses two central challenges in long term detection of urban change: temporal spectral variance and a scarcity of training samples. First, we use a recurrent neural network to minimize seasonal urban spectral variance. Second, we introduce an automated transfer strategy to maximize information gain from limited training samples when applied to new target cities in similar climate zones. Compared with other state-of-the-art methods, our method achieved comparable or even better accuracy: the average change detection accuracy during 1984-2016 is 89% for Beijing, 94% for New York, 93% for Melbourne, and 89% for Munich, and the overall accuracy of single-year urban maps is approximately 96 +/- 3% among the four target cities. The results demonstrate the practical potential and suitability of the proposed framework. The method is a promising tool for detecting urban change in massive remote sensing data sets with limited training data.
C1 [Lyu, Haobo; Lu, Hui; Li, Wenyu; Wright, Jonathon; Li, Xinlu; Yu, Le; Gong, Peng] Tsinghua Univ, Dept Earth Syst Sci, Key Lab Earth Syst Modeling, Minist Educ, Beijing 100084, Peoples R China.
   [Lu, Hui; Wright, Jonathon; Yu, Le; Gong, Peng] Joint Ctr Global Change Studies, Beijing 100875, Peoples R China.
   [Mou, Lichao; Zhu, Xiao Xiang] German Aerosp Ctr DLR, Remote Sensing Technol Inst IMF, D-82234 Wessling, Germany.
   [Mou, Lichao; Zhu, Xiao Xiang] TUM, Signal Proc Earth Observat, D-80333 Munich, Germany.
   [Li, Xuecao] Iowa State Univ, Dept Geol & Atmospher Sci, Ames, IA 50014 USA.
   [Li, Xinlu] Chinese Acad Sci, Natl Space Sci Ctr, Beijing 10019, Peoples R China.
   [Wang, Jie] Chinese Acad Sci, Inst Remote Sensing Applicat, State Key Lab Remote Sensing Sci, Beijing 100101, Peoples R China.
RP Lu, H (corresponding author), Tsinghua Univ, Dept Earth Syst Sci, Key Lab Earth Syst Modeling, Minist Educ, Beijing 100084, Peoples R China.; Lu, H (corresponding author), Joint Ctr Global Change Studies, Beijing 100875, Peoples R China.
EM lvhb15@mails.tsinghua.edu.cn; luhui@tsinghua.edu.cn; lichao.mou@dlr.de;
   li-wy15@mails.tsinghua.edu.cn; jswright@mail.tsinghua.edu.cn;
   xuecaoli@iastate.edu; xinlulee@126.com; xiao.zhu@dlr.de;
   sohuwangjie@163.com; leyu@tsinghua.edu.cn; penggong@mail.tsinghua.edu.cn
RI li, xuecao/L-3807-2018; Yu, Le/C-3701-2008; Gong, Peng/AAM-1516-2021;
   Lu, Hui/H-4349-2011
OI li, xuecao/0000-0002-6942-0746; Yu, Le/0000-0003-3115-2042; Gong,
   Peng/0000-0003-1513-3765; Lu, Hui/0000-0003-1640-239X; Wright,
   Jonathon/0000-0001-6551-7017
FU National Basic Research Program of ChinaNational Basic Research Program
   of China [2015CB953703]; National Key Research and Development Program
   of China [2017YFA0603703]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [91537210,
   91747101]; European Research Council (ERC) under the European
   UnionEuropean Research Council (ERC) [ERC-2016-StG-714087]; Helmholtz
   AssociationHelmholtz Association [VH-NG-1018]; China Scholarship
   CouncilChina Scholarship Council
FX This work was jointly supported by the National Basic Research Program
   of China (No. 2015CB953703), the National Key Research and Development
   Program of China (2017YFA0603703), and the National Natural Science
   Foundation of China (91537210 & 91747101). Computational resources for
   this work were provided by the Tsinghua National Laboratory for
   Information Science and Technology. Contributions by Lichao Mou and Xiao
   Xiang Zhu have been supported by the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation program
   (grant agreement No. [ERC-2016-StG-714087], Acronym: So2Sat), the
   Helmholtz Association under the framework of the Young Investigators
   Group "SiPEO" (VH-NG-1018, www.sipeo.bgu.tum.de) and the China
   Scholarship Council. The authors are grateful to the USGS for providing
   Landsat data support, and acknowledge Pauline Lovell and Arthur
   Cracknell for their kind help and comments on this paper.
CR ARAI K, 1992, INT J REMOTE SENS, V13, P2039, DOI 10.1080/01431169208904251
   Bartholomew D. J., 2011, STRUCT EQU MODELING, V18, P686
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao X, 2009, REMOTE SENS ENVIRON, V113, P2205, DOI 10.1016/j.rse.2009.06.001
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   Cracknell AP, 2015, INT J REMOTE SENS, V36, P262, DOI 10.1080/01431161.2014.995278
   Cracknell AP, 2013, INT J REMOTE SENS, V34, P7400, DOI 10.1080/01431161.2013.820367
   Cutler A, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P157, DOI 10.1007/978-1-4419-9326-7_5
   Feyisa GL, 2016, REMOTE SENS ENVIRON, V175, P14, DOI 10.1016/j.rse.2015.12.026
   Foley JA, 2005, SCIENCE, V309, P570, DOI 10.1126/science.1111772
   GONG P, 1990, PHOTOGRAMM ENG REM S, V56, P67
   Gong P, 2013, INT J REMOTE SENS, V34, P2607, DOI 10.1080/01431161.2012.748992
   Gorelick N, 2017, REMOTE SENS ENVIRON, V202, P18, DOI 10.1016/j.rse.2017.06.031
   Grey WMF, 2003, REMOTE SENS ENVIRON, V87, P16, DOI 10.1016/S0034-4257(03)00142-1
   Grimm NB, 2008, SCIENCE, V319, P756, DOI 10.1126/science.1150195
   Hinton, 2012, COURSERA NEURAL NETW, V4, P26
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735
   Homer C, 2004, PHOTOGRAMM ENG REM S, V70, P829, DOI 10.14358/PERS.70.7.829
   HOWARTH PJ, 1983, REMOTE SENS ENVIRON, V13, P149, DOI 10.1016/0034-4257(83)90019-6
   Jean N, 2016, SCIENCE, V353, P790, DOI 10.1126/science.aaf7894
   Lambin EF, 2001, GLOBAL ENVIRON CHANG, V11, P261, DOI 10.1016/S0959-3780(01)00007-3
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li CC, 2017, SCI BULL, V62, P508, DOI 10.1016/j.scib.2017.03.011
   Li CC, 2014, REMOTE SENS-BASEL, V6, P964, DOI 10.3390/rs6020964
   Li XX, 2016, REMOTE SENS ENVIRON, V174, P233, DOI 10.1016/j.rse.2015.12.022
   Li XC, 2015, REMOTE SENS ENVIRON, V166, P78, DOI 10.1016/j.rse.2015.06.007
   Lu DS, 2008, REMOTE SENS ENVIRON, V112, P3668, DOI 10.1016/j.rse.2008.05.009
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma T, 2012, REMOTE SENS ENVIRON, V124, P99, DOI 10.1016/j.rse.2012.04.018
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Masek JG, 2006, IEEE GEOSCI REMOTE S, V3, P68, DOI 10.1109/LGRS.2005.857030
   McGilvray A, 2016, NATURE, V538, pS58, DOI 10.1038/538S58a
   Mertes CM, 2015, REMOTE SENS ENVIRON, V158, P331, DOI 10.1016/j.rse.2014.09.023
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Schneider A, 2014, ENVIRON RES LETT, V9, DOI 10.1088/1748-9326/9/2/024008
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Schneider A, 2010, REMOTE SENS ENVIRON, V114, P1733, DOI 10.1016/j.rse.2010.03.003
   Sexton JO, 2013, REMOTE SENS ENVIRON, V129, P42, DOI 10.1016/j.rse.2012.10.025
   Shahtahmassebi AR, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070682
   Shi LF, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111148
   Song XP, 2016, REMOTE SENS ENVIRON, V175, P1, DOI 10.1016/j.rse.2015.12.027
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Tuske Z, 2015, INT CONF ACOUST SPEE, P4285, DOI 10.1109/ICASSP.2015.7178779
   Wang L, 2012, CHINESE SCI BULL, V57, P2802, DOI 10.1007/s11434-012-5235-7
   Xian G, 2011, PHOTOGRAMM ENG REM S, V77, P758
   Xie M., 2015, ARXIV 2015CSCV151000 ARXIV 2015CSCV151000
   Yang C, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9121222
   Yang LM, 2003, CAN J REMOTE SENS, V29, P230, DOI 10.5589/m02-098
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu CQ, 2017, SCI BULL, V62, P83, DOI 10.1016/j.scib.2016.12.006
   Zhang QL, 2015, REMOTE SENS-BASEL, V7, P11887, DOI 10.3390/rs70911887
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
NR 56
TC 32
Z9 32
U1 7
U2 41
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
EI 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2018
VL 10
IS 3
AR 471
DI 10.3390/rs10030471
PG 23
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA GA4DP
UT WOS:000428280100117
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Planinsic, P
   Gleich, D
AF Planinsic, Peter
   Gleich, Dusan
TI Temporal Change Detection in SAR Images Using Log Cumulants and Stacked
   Autoencoder
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection algorithms; feature extraction; image processing;
   neural networks; synthetic aperture radar (SAR)
ID UNSUPERVISED CHANGE DETECTION; SOIL-MOISTURE RETRIEVAL; REAL TIME
   DETECTION; ALLOCATION DISAGREEMENT; BEETLE INFESTATION; SEGMENTATION;
   QUANTITY; ENERGY; SERIES
AB This letter proposes a change detection algorithm for damage assessment caused by fires in Ireland using Sentinel 1 data. The novelty, in this letter, is a feature extraction within tunable Q discrete wavelet transform (TQWT) using higher order log cumulants of fractional Fourier transform (FrFT), which were fed into a stacked autoencoder (SAE) to distinguish changed and unchanged areas. The extracted features were used to train the SAE layerwise using an unsupervised learning algorithm. After training the decoding layer was replaced by a logistic regression layer to perform supervised fine-tuning and classification. The proposed algorithm was compared with the algorithm that used log cumulants of FrFT within the oriented dual-tree wavelet transform using support vector machine (SVM) classifier. The experimental results showed that the proposed combination of algorithms decreased the overall error (OE) for real synthetic aperture radar images by 6%, when TQWT was used instead of oriented dual-tree wavelet transform and OE was decreased by another 5% when SAE was used instead of the SVM classifier.
C1 [Planinsic, Peter; Gleich, Dusan] Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
RP Gleich, D (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
EM dusan.gleich@uni-mb.si
FU Slovenian Research Agency under Research ProgramSlovenian Research
   Agency - Slovenia [P2-0065]
FX The work was supported by the Slovenian Research Agency under Research
   Program P2-0065.
CR Akbarizadeh G, 2012, IEEE T GEOSCI REMOTE, V50, P4358, DOI 10.1109/TGRS.2012.2194787
   AlEnzi V, 2011, COMM COM INF SC, V188, P426
   ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   Anees A, 2014, IEEE GEOSCI REMOTE S, V11, P1717, DOI 10.1109/LGRS.2014.2306712
   Anees A, 2014, IEEE J-STARS, V7, P3713, DOI 10.1109/JSTARS.2014.2330830
   Atto AM, 2016, IEEE T GEOSCI REMOTE, V54, P6606, DOI 10.1109/TGRS.2016.2587626
   Balenzano A, 2011, IEEE J-STARS, V4, P439, DOI 10.1109/JSTARS.2010.2052916
   Bottou Leon, 1998, ON LINE LEARNING NEU, V17, P142
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Cui SY, 2012, IEEE J-STARS, V5, P1095, DOI 10.1109/JSTARS.2012.2200655
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Dutta R, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.150241
   Dutta R, 2013, SCI REP-UK, V3, DOI 10.1038/srep03188
   Geng J, 2015, IEEE GEOSCI REMOTE S, V12, P2351, DOI 10.1109/LGRS.2015.2478256
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Heit P, 1977, Health Educ, V8, P2
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hornacek M, 2012, IEEE J-STARS, V5, P1303, DOI 10.1109/JSTARS.2012.2190136
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ma JJ, 2012, IEEE GEOSCI REMOTE S, V9, P1122, DOI 10.1109/LGRS.2012.2191387
   Nicolas J. -M., 2012, TRAIT SIGNAL, V3
   Pontius RG, 2011, INT J REMOTE SENS, V32, P4407, DOI 10.1080/01431161.2011.552923
   Rahmani M, 2015, IET COMPUT VIS, V9, P629, DOI 10.1049/iet-cvi.2014.0295
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Stein A, 2005, IEEE T GEOSCI REMOTE, V43, P852, DOI 10.1109/TGRS.2005.843569
   Tirandaz Z, 2016, IEEE J-STARS, V9, P1244, DOI 10.1109/JSTARS.2015.2492552
   Volpi M, 2012, IEEE GEOSCI REMOTE S, V9, P1026, DOI 10.1109/LGRS.2012.2189092
   Warrens MJ, 2015, INT J REMOTE SENS, V36, P5959, DOI 10.1080/01431161.2015.1110265
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
NR 32
TC 16
Z9 16
U1 7
U2 35
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD FEB
PY 2018
VL 15
IS 2
BP 297
EP 301
DI 10.1109/LGRS.2017.2786344
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FU1MY
UT WOS:000423615300028
DA 2022-01-04
ER

PT J
AU Song, F
   Yang, ZQ
   Gao, XY
   Dan, TT
   Yang, Y
   Zhao, WJ
   Yu, R
AF Song, Fei
   Yang, Zhuoqian
   Gao, Xueyan
   Dan, Tingting
   Yang, Yang
   Zhao, Wanjing
   Yu, Rui
TI Multi-Scale Feature Based Land Cover Change Detection in Mountainous
   Terrain Using Multi-Temporal and Multi-Sensor Remote Sensing Images
SO IEEE ACCESS
LA English
DT Article
DE LULC change; multi-scale feature description; inliers; L2E; fuzzy
   C-Means classifier
ID POINT SET REGISTRATION; CULTIVATED LAND
AB Land use and land cover (LULC) change is frequent in mountainous terrain of southern China. Although remote sensing technology has become an important tool for gathering and monitoring LULC dynamics, image pairs can occur scale changes, noises, geometrical distortions, and illuminated variations if these are acquired from different types of sensors (e.g., satellites). Meanwhile, how to design an efficient land cover change detection algorithm that ensures a high detection rate remains a critical and challenging step. To address these problems, we propose a robust multi-temporal change detection framework for land cover change in mountainous terrain which contains the following contributions. i) To transform multi-temporal remote sensing image pairs acquired by different type of sensors into the same coordinate system by image registration, a multi-scale feature description is generated using layers formed via a pretrained VGG network. ii) A gradually increasing selection of inliers is defined for improving the robustness of feature points registration, and L-2-minimizing estimate (L2E)-based energy optimization is formulated to calculate a reasonable position in a reproducing kernel Hilbert space. iii) Fuzzy C-Means classifier is adopted to generate a similarity matrix between image pair of geometric correction, and a robust and contractive change map is built through feature similarity analysis. Extensive experiments on multi-temporal image pairs taken by different type of satellites (e.g., Chinese GF and Landsat) or small unmanned aerial vehicles are conducted. Experimental results show that our method provides better performances in most cases after comparing with the five state-of-the-art image registration methods and the four state-of-the-art change detection methods.
C1 [Song, Fei; Gao, Xueyan; Dan, Tingting; Yang, Yang; Zhao, Wanjing; Yu, Rui] Yunnan Normal Univ, Sch Informat Sci & Technol, Kunming 650500, Yunnan, Peoples R China.
   [Song, Fei; Gao, Xueyan; Dan, Tingting; Yang, Yang; Zhao, Wanjing; Yu, Rui] Minist Educ Peoples Republ China, Engn Res Ctr GIS Technol Western China, Kunming 650500, Yunnan, Peoples R China.
   [Song, Fei; Gao, Xueyan; Dan, Tingting; Yang, Yang; Zhao, Wanjing; Yu, Rui] Yunnan Normal Univ, Sch Informat Sci, Lab Pattern Recognit & Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
   [Yang, Zhuoqian] Beihang Univ, Coll Software, Beijing 100083, Peoples R China.
RP Yang, Y (corresponding author), Yunnan Normal Univ, Sch Informat Sci & Technol, Kunming 650500, Yunnan, Peoples R China.; Yang, Y (corresponding author), Minist Educ Peoples Republ China, Engn Res Ctr GIS Technol Western China, Kunming 650500, Yunnan, Peoples R China.; Yang, Y (corresponding author), Yunnan Normal Univ, Sch Informat Sci, Lab Pattern Recognit & Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
EM yyang_ynu@163.com
OI Yang, Zhuoqian/0000-0002-5410-8282; song, fei/0000-0003-0636-8343
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41661080]; Scientific Research Foundation of
   Yunnan Provincial Department of Education [2018Y037]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41661080 and in part by the Scientific
   Research Foundation of Yunnan Provincial Department of Education under
   Grant 2018Y037.
CR Azzouzi SA, 2017, IEEE ACCESS, V5, P9065, DOI 10.1109/ACCESS.2017.2700405
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bohg J, 2010, ROBOT AUTON SYST, V58, P362, DOI 10.1016/j.robot.2009.10.003
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Dan TT, 2018, J APPL REMOTE SENS, V12, DOI 10.1117/1.JRS.12.035006
   De Alban JDT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020306
   Silveira EMD, 2018, INT J REMOTE SENS, V39, P2597, DOI 10.1080/01431161.2018.1430397
   GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004
   Gu YJ, 2016, INFRARED PHYS TECHN, V76, P386, DOI 10.1016/j.infrared.2016.03.019
   Hinton G. E., 2012, NEURAL NETWORKS TRIC, P599, DOI DOI 10.1007/978-3-642-35289-8_32
   Hinton G. E., 2002, TRAINING PRODUCTS EX
   Ji SL, 2008, STOCH PROC APPL, V118, P952, DOI 10.1016/j.spa.2007.07.005
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   Kun Y, 2017, SCIENCE, V358, P1263, DOI 10.1126/science.aar5020
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lozano-Diez A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182580
   Lv ZY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111112
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, PATTERN RECOGN, V48, P772, DOI 10.1016/j.patcog.2014.09.005
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Markovsky I, 2008, AUTOMATICA, V44, P891, DOI 10.1016/j.automatica.2007.09.011
   Milas AS, 2017, INT J REMOTE SENS, V38, P3084, DOI 10.1080/01431161.2016.1274449
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Permatasari P.A., 2016, 2 INT S LAPAN IPB SA, V33, P27, DOI DOI 10.1016/j.proenv.2016.03.053
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   Song F, 2018, INT J REMOTE SENS, V39, P7201, DOI 10.1080/01431161.2018.1516051
   Uamkasem Budsaba, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P838, DOI 10.1109/ICASI.2017.7988564
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang YF, 2015, REMOTE SENS LETT, V6, P794, DOI 10.1080/2150704X.2015.1081304
   Wei ZQ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090904
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu YY, 2016, ENVIRON MONIT ASSESS, V188, DOI 10.1007/s10661-015-5069-2
   Xiao RL, 2018, IEEE ACCESS, V6, P35915, DOI 10.1109/ACCESS.2018.2849110
   Yang K, 2018, SCI TOTAL ENVIRON, V624, P859, DOI 10.1016/j.scitotenv.2017.12.119
   Yang K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060581
   Yang Y, 2015, PATTERN RECOGN, V48, P156, DOI 10.1016/j.patcog.2014.06.017
   YUILLE AL, 1989, INT J COMPUT VISION, V3, P155, DOI 10.1007/BF00126430
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang S, 2018, PATTERN RECOGN, V80, P183, DOI 10.1016/j.patcog.2018.03.004
   Zhang S, 2018, IEEE GEOSCI REMOTE S, V15, P592, DOI 10.1109/LGRS.2018.2796136
   Zhang S, 2017, IEEE I CONF COMP VIS, P2688, DOI 10.1109/ICCV.2017.291
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 46
TC 7
Z9 8
U1 3
U2 8
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 2169-3536
J9 IEEE ACCESS
JI IEEE Access
PY 2018
VL 6
BP 77494
EP 77508
DI 10.1109/ACCESS.2018.2883254
PG 15
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
SC Computer Science; Engineering; Telecommunications
GA HG1PQ
UT WOS:000454731300001
OA gold
DA 2022-01-04
ER

PT J
AU Branson, S
   Wegner, JD
   Hall, D
   Lang, N
   Schindler, K
   Perona, P
AF Branson, Steve
   Wegner, Jan Dirk
   Hall, David
   Lang, Nico
   Schindler, Konrad
   Perona, Pietro
TI From Google Maps to a fine-grained catalog of street trees
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Deep learning; Image interpretation; Urban areas; Street trees; Very
   high resolution
ID SPECIES CLASSIFICATION; RECOGNITION; LEAF; EXTRACTION; FOREST; SCALE;
   SHAPE
AB Up-to-date catalogs of the urban tree population are of importance for municipalities to monitor and improve quality of life in cities. Despite much research on automation of tree mapping, mainly relying on dedicated airborne LiDAR or hyperspectral campaigns, tree detection and species recognition is still mostly done manually in practice. We present a fully automated tree detection and species recognition pipeline that can process thousands of trees within a few hours using publicly available aerial and street view images of Google Maps (TM). These data provide rich information from different viewpoints and at different scales from global tree shapes to bark textures. Our work-flow is built around a supervised classification that automatically learns the most discriminative features from thousands of trees and corresponding, publicly available tree inventory data. In addition, we introduce a change tracker that recognizes changes of individual trees at city-scale, which is essential to keep an urban tree inventory up-to-date. The system takes street-level images of the same tree location at two different times and classifies the type of change (e.g., tree has been removed). Drawing on recent advances in computer vision and machine learning, we apply convolutional neural networks (CNN) for all classification tasks. We propose the following pipeline: download all available panoramas and overhead images of an area of interest, detect trees per image and combine multi-view detections in a probabilistic framework, adding prior knowledge; recognize fine-grained species of detected trees. In a later, separate module, track trees over time, detect significant changes and classify the type of change. We believe this is the first work to exploit publicly available image data for city-scale street tree detection, species recognition and change tracking, exhaustively over several square kilometers, respectively many thousands of trees. Experiments in the city of Pasadena, California, USA show that we can detect >70% of the street trees, assign correct species to >80% for 40 different species, and correctly detect and classify changes in >90% of the cases. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.
C1 [Branson, Steve; Hall, David; Perona, Pietro] CALTECH, Computat Vis Lab, Pasadena, CA 91125 USA.
   [Wegner, Jan Dirk; Lang, Nico; Schindler, Konrad] Swiss Fed Inst Technol, Photogrammetry & Remote Sensing, Zurich, Switzerland.
RP Wegner, JD (corresponding author), Swiss Fed Inst Technol, Photogrammetry & Remote Sensing, Zurich, Switzerland.
EM jan.wegner@geod.baug.ethz.ch
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Altwaijry H., 2016, P IEEE C COMP VIS PA
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   Blaschko M., 2011, INT C EN MIN METH CO
   Boujemaa, 2013, ACM INT C MULT, P423, DOI DOI 10.1145/2502081.2502251
   Brandtberg T, 1998, MACH VISION APPL, V11, P64, DOI 10.1007/s001380050091
   Brandtberg T, 2007, ISPRS J PHOTOGRAMM, V61, P325, DOI 10.1016/j.isprsjprs.2006.10.006
   Branson S, 2013, PROC CVPR IEEE, P1806, DOI 10.1109/CVPR.2013.236
   Clark ML, 2005, REMOTE SENS ENVIRON, V96, P375, DOI 10.1016/j.rse.2005.03.009
   Cozad S., 2005, STRATUM CASE STUDY E
   Darrell T, 2014, CAFFE CONVOLUTIONAL, DOI DOI 10.1145/2647868
   Du JX, 2007, APPL MATH COMPUT, V185, P883, DOI 10.1016/j.amc.2006.07.072
   Duan K., 2013, IEEE C COMP VIS PATT, P580
   Efros, 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587784
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goeau H., 2014, P INT C MULT RETR, DOI DOI 10.1145/2578726.2582618F
   Hadsell Raia, 2006, P IEEE COMP SOC C CO, V2, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Heikkinen V, 2011, IEEE T GEOSCI REMOTE, V49, P4539, DOI 10.1109/TGRS.2011.2141143
   Heinzel J, 2012, INT J APPL EARTH OBS, V18, P101, DOI 10.1016/j.jag.2012.01.025
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hirschmugl M, 2007, REMOTE SENS ENVIRON, V110, P533, DOI 10.1016/j.rse.2007.02.029
   Jaakkola A, 2010, ISPRS J PHOTOGRAMM, V65, P514, DOI 10.1016/j.isprsjprs.2010.08.002
   Jia D, 2013, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2013.81
   Kaartinen H, 2012, REMOTE SENS-BASEL, V4, P950, DOI 10.3390/rs4040950
   Kohli P, 2009, INT J COMPUT VISION, V82, P302, DOI 10.1007/s11263-008-0202-0
   Korpela I, 2011, REMOTE SENS ENVIRON, V115, P2062, DOI 10.1016/j.rse.2011.04.008
   Krahenbahl P., 2011, C NEUR INF PROC SYST
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lafarge F, 2012, INT J COMPUT VISION, V99, P69, DOI 10.1007/s11263-012-0517-8
   Lafarge F, 2010, IEEE T PATTERN ANAL, V32, P1597, DOI 10.1109/TPAMI.2009.152
   Lahivaara T, 2014, IEEE T GEOSCI REMOTE, V52, P2690, DOI 10.1109/TGRS.2013.2264548
   Larsen M, 2011, INT J REMOTE SENS, V32, P5827, DOI 10.1080/01431161.2010.507790
   Leckie DG, 2005, REMOTE SENS ENVIRON, V94, P311, DOI 10.1016/j.rse.2004.10.011
   Lin TY, 2015, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2015.7299135
   Majdik AL, 2013, IEEE INT C INT ROBOT, P3979, DOI 10.1109/IROS.2013.6696925
   Malik J., 2014, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2014.81
   McPherson EG, 2016, URBAN FOR URBAN GREE, V17, P104, DOI 10.1016/j.ufug.2016.03.013
   Mouine S, 2013, LECT NOTES COMPUT SC, V7950, P205, DOI 10.1007/978-3-642-39094-4_24
   Nowak David J., 2002, Journal of Arboriculture, V28, P194
   Paris C, 2015, IEEE T GEOSCI REMOTE, V53, P467, DOI 10.1109/TGRS.2014.2324016
   Pauleit S., 2005, URBAN FORESTS TREES, P49, DOI DOI 10.1007/3-540-27684-X
   Pu RL, 2012, REMOTE SENS ENVIRON, V124, P516, DOI 10.1016/j.rse.2012.06.011
   Qin Y., 2014, IEEE INT GEOSC REM S
   Rabinovich A., 2015, PROC CVPR IEEE, P1, DOI [10.1109/CVPR.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Reitberger J, 2009, ISPRS J PHOTOGRAMM, V64, P561, DOI 10.1016/j.isprsjprs.2009.04.002
   Ren SQ, 2015, ADV NEUR IN, V28
   Ren Shaoqing, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romana LA, 2017, URBAN FOR URBAN GREE, V22, P124, DOI 10.1016/j.ufug.2017.02.001
   Roth KL, 2015, REMOTE SENS ENVIRON, V167, P135, DOI 10.1016/j.rse.2015.05.007
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seitz, 2014, INT C 3D VIS, V1, P525
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Soheilian, 2012, 22 ISPRS C TECHN COM, V3, P245, DOI [DOI 10.5194/ISPRSANNALS-I-3-245-2012, 10.5194/isprsannals-I-3-245-2012]
   Straub B. M., 2003, ISPRS ARCH PHOTOGRAM
   Sun Q, 2015, ADV NEUR IN, V28
   Wah C, 2011, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2011.6126539
   Waser LT, 2011, REMOTE SENS ENVIRON, V115, P76, DOI 10.1016/j.rse.2010.08.006
   Wegner JD, 2016, PROC CVPR IEEE, P6014, DOI 10.1109/CVPR.2016.647
   Wegner JD, 2015, ISPRS J PHOTOGRAMM, V108, P128, DOI 10.1016/j.isprsjprs.2015.07.002
   Yang L, 2009, ACM GIS 09
   Yao W, 2012, REMOTE SENS ENVIRON, V123, P368, DOI 10.1016/j.rse.2012.03.027
   Zhang JJ, 2014, ISPRS J PHOTOGRAMM, V98, P44, DOI 10.1016/j.isprsjprs.2014.08.007
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
NR 68
TC 44
Z9 45
U1 8
U2 68
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JAN
PY 2018
VL 135
BP 13
EP 30
DI 10.1016/j.isprsjprs.2017.11.008
PG 18
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA FU5LV
UT WOS:000423895100002
OA Green Submitted, Green Accepted
DA 2022-01-04
ER

PT J
AU Wang, Q
   Zhang, XD
   Chen, GZ
   Dai, F
   Gong, YF
   Zhu, K
AF Wang, Qing
   Zhang, Xiaodong
   Chen, Guanzhou
   Dai, Fan
   Gong, Yuanfu
   Zhu, Kun
TI Change detection based on Faster R-CNN for high-resolution remote
   sensing images
SO REMOTE SENSING LETTERS
LA English
DT Article
ID FOREST CHANGE DETECTION; CLASSIFICATION
AB Change detection is of great significance in remote sensing. The advent of high-resolution remote sensing images has greatly increased our ability to monitor land use and land cover changes from space. At the same time, high-resolution remote sensing images present a new challenge over other satellite systems, in which time-consuming and tiresome manual procedures must be needed to identify the land use and land cover changes. In recent years, deep learning (DL) has been widely used in the fields of natural image target detection, speech recognition, face recognition, etc., and has achieved great success. Some scholars have applied DL to remote sensing image classification and change detection, but seldomly to high-resolution remote sensing images change detection. In this letter, faster region-based convolutional neural networks (Faster R-CNN) is applied to the detection of high-resolution remote sensing image change. Compared with several traditional and other DL-based change detection methods, our proposed methods based on Faster R-CNN achieve higher overall accuracy and Kappa coefficient in our experiments. In particular, our methods can reduce a large number of false changes.
C1 [Wang, Qing; Zhang, Xiaodong; Chen, Guanzhou; Dai, Fan; Gong, Yuanfu; Zhu, Kun] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Hubei, Peoples R China.
   [Wang, Qing] Yangtze Univ, Sch Geosci, Wuhan, Hubei, Peoples R China.
RP Zhang, XD (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Hubei, Peoples R China.
EM zxdlmars@whu.edu.cn
OI Zhu, Kun/0000-0001-6279-9215; Chen, Guanzhou/0000-0003-0733-9122
FU LIESMARS Special Research Funding; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities
FX This work is supported in part by the funding from the LIESMARS Special
   Research Funding and in part by the Fundamental Research Funds for the
   Central Universities.
CR ALLEN DM, 1974, TECHNOMETRICS, V16, P125, DOI 10.2307/1267500
   Ball JE, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.042609
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Colditz RR, 2012, INT J REMOTE SENS, V33, P6426, DOI 10.1080/01431161.2012.688148
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lyu HB, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030471
   Lyu HB, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060506
   Maggiori E, 2016, INT GEOSCI REMOTE SE, P5071, DOI 10.1109/IGARSS.2016.7730322
   Ordonez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Ren SQ, 2015, ADV NEUR IN, V28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Tian J, 2013, ISPRS J PHOTOGRAMM, V79, P226, DOI 10.1016/j.isprsjprs.2013.02.017
   [佟国峰 Tong Guofeng], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1561
   Zhan Y, 2017, IEEE GEOSCI REMOTE S, V14, P1845, DOI 10.1109/LGRS.2017.2738149
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhou Q. M., 2011, GEOMATICS WORLD, V18, P23
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 28
TC 45
Z9 48
U1 19
U2 131
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 2150-704X
EI 2150-7058
J9 REMOTE SENS LETT
JI Remote Sens. Lett.
PY 2018
VL 9
IS 10
BP 923
EP 932
DI 10.1080/2150704X.2018.1492172
PG 10
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA GR2RT
UT WOS:000442429300001
DA 2022-01-04
ER

PT J
AU Zhao, W
   Wang, ZR
   Gong, MG
   Liu, J
AF Zhao, Wei
   Wang, Zhirui
   Gong, Maoguo
   Liu, Jia
TI Discriminative Feature Learning for Unsupervised Change Detection in
   Heterogeneous Images Based on a Coupled Neural Network
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; deep neural network; features extracting;
   heterogeneous images
ID REMOTE-SENSING IMAGES; URBAN CHANGE DETECTION; CHANGE-VECTOR ANALYSIS;
   LAND-COVER; SAR DATA; ALGORITHM
AB With the application requirement, the technique for change detection based on heterogeneous remote sensing images is paid more attention. However, detecting changes between two heterogeneous images is challenging as they cannot be compared in low-dimensional space. In this paper, we construct an approximately symmetric deep neural network with two sides containing the same number of coupled layers to transform the two images into the same feature space. The two images are connected with the two sides and transformed into the same feature space, in which their features are more discriminative and the difference image can be generated by comparing paired features pixel by pixel. The network is first built by stacked restricted Boltzmann machines, and then, the parameters are updated in a special way based on clustering. The special way, motivated by that two heterogeneous images share the same reality in unchanged areas and retain respective properties in changed areas, shrinks the distance between paired features transformed from unchanged positions, and enlarges the distance between paired features extracted from changed positions. It is achieved through introducing two types of labels and updating parameters by adaptively changed learning rate. This is different from the existing methods based on deep learning that just do operations on positions predicted to be unchanged and extract only one type of labels. The whole process is completely unsupervised without any priori knowledge. Besides, the method can also be applied to homogeneous images. We test our method on heterogeneous images and homogeneous images. The proposed method achieves quite high accuracy.
C1 [Zhao, Wei] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Zhirui; Gong, Maoguo; Liu, Jia] Xidian Univ, Joint Int Res Lab Intelligent Percept & Computat, Int Res Ctr Intelligent Percept & Computat, Minist Educ,Key Lab Intelligent Percept & Image U, Xian 710071, Shaanxi, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Joint Int Res Lab Intelligent Percept & Computat, Int Res Ctr Intelligent Percept & Computat, Minist Educ,Key Lab Intelligent Percept & Image U, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org
RI Liu, Jia/P-9706-2018
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61422209, 61672409]; National Program for
   Support of Top-Notch Young Professionals of China; Shaanxi Major Basic
   Research Project of China [2017ZDJC-31]; National Key Research and
   Development Program of China [2017YFB0802200]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61422209 and Grant 61672409, in part by
   the National Program for Support of Top-Notch Young Professionals of
   China, in part by the Shaanxi Major Basic Research Project of China
   under Grant 2017ZDJC-31, and in part by the National Key Research and
   Development Program of China under Grant 2017YFB0802200.
CR Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   BRENNAN RL, 1981, EDUC PSYCHOL MEAS, V41, P687, DOI 10.1177/001316448104100307
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   CHAVEZ PS, 1994, PHOTOGRAMM ENG REM S, V60, P571
   Chen F.-C., 1990, IEEE Control Systems Magazine, V10, P44, DOI 10.1109/37.55123
   Coates A., 2011, P 14 INT C ART INT S, P215, DOI DOI 10.1109/ICDAR.2011.95
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gueguen L, 2016, IEEE T GEOSCI REMOTE, V54, P3378, DOI 10.1109/TGRS.2016.2516402
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HIROSE Y, 1991, NEURAL NETWORKS, V4, P61, DOI 10.1016/0893-6080(91)90032-Z
   Hong Oh， Jae, 2015, [JOURNAL OF THE KOREAN SOCIETY OF SURVEY,GEODESY,PHOTOGRAMMETRY, AND CARTOGRAPHY, 한국측량학회지], V33, P259, DOI 10.7848/ksgpc.2015.33.4.259
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   HORIKAWA S, 1992, IEEE T NEURAL NETWOR, V3, P801, DOI 10.1109/72.159069
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   JENSEN JR, 1987, PHOTOGRAMM ENG REM S, V53, P521
   Johnson RD, 1998, INT J REMOTE SENS, V19, P411, DOI 10.1080/014311698216062
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Larochelle H., 2008, P 25 INT C MACH LEAR, P536, DOI DOI 10.1145/1390156.1390224
   Liu J, 2018, IEEE T NEUR NET LEAR, V29, P545, DOI 10.1109/TNNLS.2016.2636227
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Menz G., 2012, ADV REMOTE SENS, V1, P74, DOI DOI 10.4236/ars.2012.13008
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   RIGNOT EJM, 1993, IEEE T GEOSCI REMOTE, V31, P896, DOI 10.1109/36.239913
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Rumelhart DE, 1986, LEARNING INTERNAL RE
   Salakhutdinov Ruslan, 2007, P 24 INT C MACH LEAR, P791, DOI DOI 10.1145/1273496.1273596
   Smolensky P., 1986, INFORM PROCESSING DY
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
   Wang Q, 2013, COMPUT VIS IMAGE UND, V117, P1748, DOI 10.1016/j.cviu.2013.07.002
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   [熊金波 Xiong Jinbo], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1399
   Yousif O, 2014, IEEE J-STARS, V7, P4288, DOI 10.1109/JSTARS.2014.2347171
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 39
TC 38
Z9 39
U1 11
U2 50
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD DEC
PY 2017
VL 55
IS 12
BP 7066
EP 7080
DI 10.1109/TGRS.2017.2739800
PG 15
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FP1HT
UT WOS:000417363100031
DA 2022-01-04
ER

PT J
AU Gong, MG
   Niu, XD
   Zhang, PZ
   Li, ZT
AF Gong, Maoguo
   Niu, Xudong
   Zhang, Puzhao
   Li, Zhetao
TI Generative Adversarial Networks for Change Detection in Multispectral
   Imagery
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; change vector analysis (CVA); generative adversarial
   networks (GANs); multispectral images
ID FRAMEWORK
AB Change detection can be treated as a generative learning procedure, in which the connection between bitemporal images and the desired change map can be modeled as a generative one. In this letter, we propose an unsupervised change detection method based on generative adversarial networks (GANs), which has the ability of recovering the training data distribution from noise input. Here, the joint distribution of the two images to be detected is taken as input and an initial difference image (DI), generated by traditional change detection method such as change vector analysis, is used to provide prior knowledge for sampling the training data based on Bayesian theorem and GAN's min-max game theory. Through the continuous adversarial learning, the shared mapping function between the training data and their corresponding image patches can be built in GAN's generator, from which a better DI can be generated. Finally, an unsupervised clustering algorithm is used to analyze the better DI to obtain the desired binary change map. Theoretical analysis and experimental results demonstrate the effectiveness and robustness of the proposed method.
C1 [Gong, Maoguo; Niu, Xudong; Zhang, Puzhao] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
   [Li, Zhetao] Xiangtan Univ, Coll Informat Engn, Xiangtan 411105, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
EM gong@ieee.org; liztchina@hotmail.com
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61772393, 61422209]; National Program for
   Support of Top-notch Young Professionals of China; National Key Research
   and Development Program of China [2017YFB0802200]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61772393 and Grant 61422209, in part by
   the National Program for Support of Top-notch Young Professionals of
   China, and in part by the National Key Research and Development Program
   of China under Grant 2017YFB0802200.
CR Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Chinchor N, 1993, PROC 5 MESSAGE UNDER, P69, DOI DOI 10.3115/1072017.1072026
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, IEEE T GEOSCI REMOTE, V52, P4328, DOI 10.1109/TGRS.2013.2281391
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Kingma D. P., 2013, AUTOENCODING VARIATI
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Radford A., 2015, COMPUTER SCI
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Wang Q, 2017, IEEE GEOSCI REMOTE S, V14, P2077, DOI 10.1109/LGRS.2017.2751559
   Wang Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI 10.1109/TNNLS.2015.2477537
NR 16
TC 51
Z9 54
U1 9
U2 54
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD DEC
PY 2017
VL 14
IS 12
BP 2310
EP 2314
DI 10.1109/LGRS.2017.2762694
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FQ1KK
UT WOS:000418116500028
DA 2022-01-04
ER

PT J
AU Hou, B
   Wang, YH
   Liu, QJ
AF Hou, Bin
   Wang, Yunhong
   Liu, Qingjie
TI Change Detection Based on Deep Features and Low Rank
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection (CD); convolutional neural network (CNN); low rank;
   remote sensing (RS); visual saliency
ID NEURAL-NETWORKS; IMAGE; CLASSIFICATION
AB In this letter, we address the problem of change detection for remote sensing images from the perspective of visual saliency computation. The proposed method incorporates low-rank-based saliency computation and deep feature representation. First, multilevel convolutional neural network (CNN) features are extracted for superpixels generated using SLIC, in which a fixed-size CNN feature can be formed to represent each superpixel. Then, low-rank decomposition is applied to the change features of the two input images to generate saliency maps that indicate change probabilities of each pixel. Finally, binarized change map can be obtained with a simple threshold. To deal with scale variations, a multiscale fusion strategy is employed to produce more reliable detection results. Extensive experiments on Google Earth and GF-2 images demonstrate the feasibility and effectiveness of the proposed method.
C1 [Hou, Bin; Wang, Yunhong; Liu, Qingjie] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
RP Liu, QJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM qingje.liu@buaa.edu.cn
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61601011, 61421003]
FX This work was supported by the Natural Science Foundation of China under
   Grant 61601011 and Grant 61421003.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bovolo F, 2009, IEEE GEOSCI REMOTE S, V6, P33, DOI 10.1109/LGRS.2008.2007429
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hou B, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091377
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ma L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090761
   Marmanis D, 2016, IEEE GEOSCI REMOTE S, V13, P105, DOI 10.1109/LGRS.2015.2499239
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Rao, 2009, ADV NEURAL INFORM PR, P2080
   Rui Huang, 2015, 2015 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT). Proceedings, P1, DOI 10.1109/ISGT.2015.7131826
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Song HO, 2015, IEEE T PATTERN ANAL, V37, P1001, DOI 10.1109/TPAMI.2014.2353631
   Wang B, 2015, IEEE GEOSCI REMOTE S, V12, P1151, DOI 10.1109/LGRS.2014.2386878
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Zhang QC, 2016, INT GEOSCI REMOTE SE, P661, DOI 10.1109/IGARSS.2016.7729166
   Zisserman A, 2015, P INT C LEARN REPR, P1
NR 28
TC 36
Z9 37
U1 3
U2 33
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD DEC
PY 2017
VL 14
IS 12
BP 2418
EP 2422
DI 10.1109/LGRS.2017.2766840
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FQ1KK
UT WOS:000418116500050
DA 2022-01-04
ER

PT J
AU Liu, T
   Li, Y
   Cao, Y
   Shen, Q
AF Liu, Tao
   Li, Ying
   Cao, Ying
   Shen, Qiang
TI Change detection in multitemporal synthetic aperture radar images using
   dual-channel convolutional neural network
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE change detection; SAR image; dual-channel convolutional neural network;
   deep learning
ID SAR
AB This paper proposes a model of dual-channel convolutional neural network (CNN) that is designed for change detection in SAR images, in an effort to acquire higher detection accuracy and lower misclassification rate. This network model contains two parallel CNN channels, which can extract deep features from two multitemporal SAR images. For comparison and validation, the proposed method is tested along with other change detection algorithms on both simulated SAR images and real-world SAR images captured by different sensors. The experimental results demonstrate that the presented method outperforms the state-of-the-art techniques by a considerable margin. (C) 2017 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Liu, Tao; Li, Ying; Cao, Ying] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Shen, Qiang] Aberystwyth Univ, Inst Math Phys & Comp Sci, Dept Comp Sci, Aberystwyth, Dyfed, Wales.
RP Li, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
EM lybyp@nwpu.edu.cn
RI Shen, Qiang/AAT-3377-2020
OI Shen, Qiang/0000-0001-9333-4605
FU National Key Research and Development Program of China [2016YFB0502502];
   Foundation Project for Advanced Research Field [614023804016HK03002];
   Shannxi International Scientific and Technological Cooperation Project
   [2017KW-006]
FX This work was supported by the National Key Research and Development
   Program of China (Grant No. 2016YFB0502502), Foundation Project for
   Advanced Research Field (Grant No. 614023804016HK03002), and Shannxi
   International Scientific and Technological Cooperation Project (Grant
   No. 2017KW-006). The authors are grateful to the editor and reviewers
   for their constructive comments that have helped to improve this work
   significantly. All the authors made significant contributions to this
   work. Professor Ying Li and Tao Liu devised the approach and analyzed
   the data; Professor Qiang Shen helped design the experiments and
   provided advice for the preparation and revision of the work; Ying Cao
   performed the experiments and provided detailed revisions for this work
   especially in the training of DC-CNN.
CR Almeida R, 2007, INT J REMOTE SENS, V28, P1383, DOI 10.1080/01431160600754591
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Kang M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010192
   Kuchay N. A., 2014, T I INDIAN GEOGR, V36, P110
   LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143
   Lecun Y., 2015, J MACH LEARN RES, V17, P2287
   Leng B., 2015, INF SCI, V366, P188
   LI Y, 2017, REMOTE SENS BASEL, V9
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Lu J, 2014, REMOTE SENS LETT, V5, P240, DOI 10.1080/2150704X.2014.898190
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Muller U, 2005, NIPS, P739
   Plank S, 2014, REMOTE SENS-BASEL, V6, P4870, DOI 10.3390/rs6064870
   Plchot O, 2016, INT CONF ACOUST SPEE, P5090, DOI 10.1109/ICASSP.2016.7472647
   Singh D, 2008, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN MICROWAVE THEORY AND APPLICATIONS, PROCEEDINGS, P419, DOI 10.1109/AMTA.2008.4763244
   Topouzelis K., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V4880, P77, DOI 10.1117/12.462518
   Xiong BL, 2012, REMOTE SENS LETT, V3, P267, DOI 10.1080/01431161.2011.572093
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zhang P, 2017, PROC SPIE, V0245, DOI 10.1117/12.2267070
NR 25
TC 15
Z9 15
U1 2
U2 46
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD OCT 12
PY 2017
VL 11
AR 042615
DI 10.1117/1.JRS.11.042615
PG 13
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA FJ5IC
UT WOS:000412783800001
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Zhan, Y
   Fu, K
   Yan, ML
   Sun, X
   Wang, HQ
   Qiu, XS
AF Zhan, Yang
   Fu, Kun
   Yan, Menglong
   Sun, Xian
   Wang, Hongqi
   Qiu, Xiaosong
TI Change Detection Based on Deep Siamese Convolutional Network for Optical
   Aerial Images
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; deep convolutional network; optical aerial images;
   siamese network
AB In this letter, we propose a novel supervised change detection method based on a deep siamese convolutional network for optical aerial images. We train a siamese convolutional network using the weighted contrastive loss. The novelty of the method is that the siamese network is learned to extract features directly from the image pairs. Compared with hand-crafted features used by the conventional change detection method, the extracted features are more abstract and robust. Furthermore, because of the advantage of the weighted contrastive loss function, the features have a unique property: the feature vectors of the changed pixel pair are far away from each other, while the ones of the unchanged pixel pair are close. Therefore, we use the distance of the feature vectors to detect changes between the image pair. Simple threshold segmentation on the distance map can even obtain good performance. For improvement, we use a k-nearest neighbor approach to update the initial result. Experimental results show that the proposed method produces results comparable, even better, with the two state-of-the-art methods in terms of F-measure.
C1 [Zhan, Yang; Fu, Kun; Yan, Menglong; Sun, Xian; Wang, Hongqi] Chinese Acad Sci, Inst Elect, Key Lab Technol Geospatial Informat Proc & Applic, Beijing 100190, Peoples R China.
   [Zhan, Yang; Qiu, Xiaosong] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Qiu, Xiaosong] Chinese Acad Sci, Inst Elect, State Key Lab Transducer Technol, Beijing 100190, Peoples R China.
RP Fu, K (corresponding author), Chinese Acad Sci, Inst Elect, Key Lab Technol Geospatial Informat Proc & Applic, Beijing 100190, Peoples R China.
EM fukun@mail.ie.ac.cn
OI fu, kun/0000-0002-0450-6469
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41301493]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 41301493.
CR Benedek C, 2015, ISPRS J PHOTOGRAMM, V107, P22, DOI 10.1016/j.isprsjprs.2015.02.006
   Benedek C, 2009, IEEE T GEOSCI REMOTE, V47, P3416, DOI 10.1109/TGRS.2009.2022633
   Benedek C, 2008, INT C PATT RECOG, P1686
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Hadsell Raia, 2006, P 2006 IEEE COMP VIS, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Liu J., IEEE T NEURAL NETW L
   Singh P, 2014, INT C PATT RECOG, P924, DOI 10.1109/ICPR.2014.169
   Touazi A, 2015, INT CONF INTELL SYST, P98, DOI 10.1109/ISDA.2015.7489208
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P3978, DOI 10.1109/TGRS.2007.907109
NR 15
TC 138
Z9 141
U1 23
U2 89
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2017
VL 14
IS 10
BP 1845
EP 1849
DI 10.1109/LGRS.2017.2738149
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FL1FX
UT WOS:000413961200040
DA 2022-01-04
ER

PT J
AU Wu, K
   Zhong, YF
   Wang, XM
   Sun, WW
AF Wu, Ke
   Zhong, Yanfei
   Wang, Xianmin
   Sun, Weiwei
TI A Novel Approach to Subpixel Land-Cover Change Detection Based on a
   Supervised Back-Propagation Neural Network for Remotely Sensed Images
   With Different Resolutions
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Back-propagation neural network (BPNN); change detection; soft
   classification (SC); subpixel mapping (SPM)
ID INFORMATION; SCALE
AB Extracting subpixel land-cover change detection (SLCCD) information is important when multitemporal remotely sensed images with different resolutions are available. The general steps are as follows. First, soft classification is applied to a low-resolution (LR) image to generate the proportion of each class. Second, the proportion differences are produced by the use of another high-resolution (HR) image and used as the input of subpixel mapping. Finally, a subpixel sharpened difference map can be generated. However, the prior HR land-cover map is only used to compare with the enhanced map of LR image for change detection, which leads to a nonideal SLCCD result. In this letter, we present a new approach based on a back-propagation neural network (BPNN) with a HR map (BPNN_HRM), in which a supervised model is introduced into SLCCD for the first time. The known information of the HR land-cover map is adequately employed to train the BPNN, whether it predates or postdates the LR image, so that a subpixel change detection map can be effectively generated. In order to evaluate the performance of the proposed algorithm, it was compared with four state-of-the-art methods. The experimental results confirm that the BPNN_HRM method outperforms the other traditional methods in providing a more detailed map for change detection.
C1 [Wu, Ke; Wang, Xianmin] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Hubei, Peoples R China.
   [Zhong, Yanfei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Hubei, Peoples R China.
   [Sun, Weiwei] Ningbo Univ, Dept Geog & Spatial Informat Tech, Ningbo 315211, Zhejiang, Peoples R China.
RP Wu, K (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Hubei, Peoples R China.
EM tingke2000@126.com; zhongyanfei@whu.edu.cn; xianminwang@163.com;
   sunweiwei@nbu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61372153, 41372341]; Natural Science
   Foundation of Hubei Province, ChinaNatural Science Foundation of Hubei
   Province [2014CFA052]; Fundamental Research Funds for the Central
   Universities, China University of Geosciences, WuhanFundamental Research
   Funds for the Central Universities [CUGL140410, 26420160125]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61372153 and Grant 41372341, in part by
   the Natural Science Foundation of Hubei Province, China under Grant
   2014CFA052, and in part by the Fundamental Research Funds for the
   Central Universities, China University of Geosciences, Wuhan, under
   Grant CUGL140410 and Grant 26420160125.
CR Atkinson PM, 1997, INT J REMOTE SENS, V18, P917, DOI 10.1080/014311697217224
   Chang C.-I., 2003, HYPERSPECTRAL IMAGIN
   Gu YF, 2008, IEEE T GEOSCI REMOTE, V46, P1347, DOI 10.1109/TGRS.2008.917270
   Haertel V, 2004, INT J REMOTE SENS, V25, P5473, DOI 10.1080/01431160412331269751
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Le Hegarat-Mascle S, 2005, REMOTE SENS ENVIRON, V95, P464, DOI 10.1016/j.rse.2005.01.011
   Li XD, 2016, IEEE T GEOSCI REMOTE, V54, P3822, DOI 10.1109/TGRS.2016.2528583
   Li XD, 2015, PHOTOGRAMM ENG REM S, V81, P59, DOI 10.14358/PERS.81.1.59
   Ling F, 2013, REMOTE SENS LETT, V4, P629, DOI 10.1080/2150704X.2013.781284
   Ling F, 2011, IEEE GEOSCI REMOTE S, V8, P182, DOI 10.1109/LGRS.2010.2055034
   Mertens KC, 2004, REMOTE SENS ENVIRON, V91, P225, DOI 10.1016/j.rse.2004.03.003
   Nigussie D, 2011, INT J REMOTE SENS, V32, P7203, DOI 10.1080/01431161.2010.519740
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   van Oort PAJ, 2007, REMOTE SENS ENVIRON, V108, P1, DOI 10.1016/j.rse.2006.10.012
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Wang Q, 2014, COMPUT VIS IMAGE UND, V124, P22, DOI 10.1016/j.cviu.2014.03.002
   Wang Q, 2014, NEUROCOMPUTING, V131, P357, DOI 10.1016/j.neucom.2013.10.007
   Wang QM, 2015, IEEE J-STARS, V8, P1339, DOI 10.1109/JSTARS.2014.2355832
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Wu K, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.097299
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zortea M, 2009, IEEE GEOSCI REMOTE S, V6, P787, DOI 10.1109/LGRS.2009.2025520
NR 22
TC 14
Z9 15
U1 3
U2 31
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD OCT
PY 2017
VL 14
IS 10
BP 1750
EP 1754
DI 10.1109/LGRS.2017.2733558
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FL1FX
UT WOS:000413961200021
DA 2022-01-04
ER

PT J
AU Khan, SH
   He, XM
   Porikli, F
   Bennamoun, M
AF Khan, Salman H.
   He, Xuming
   Porikli, Fatih
   Bennamoun, Mohammed
TI Forest Change Detection in Incomplete Satellite Images With Deep Neural
   Networks
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; deep learning; image inpainting; multitemporal
   spectral data; remote sensing
ID LAND-COVER CHANGE; CLOUD REMOVAL; SHADOW DETECTION; BRDF CORRECTION;
   CLASSIFICATION; REGRESSION; FREQUENCY; FUSION; TRENDS; MODEL
AB Land cover change monitoring is an important task from the perspective of regional resource monitoring, disaster management, land development, and environmental planning. In this paper, we analyze imagery data from remote sensing satellites to detect forest cover changes over a period of 29 years (1987-2015). Since the original data are severely incomplete and contaminated with artifacts, we first devise a spatiotemporal inpainting mechanism to recover the missing surface reflectance information. The spatial filling process makes use of the available data of the nearby temporal instances followed by a sparse encoding-based reconstruction. We formulate the change detection task as a region classification problem. We build a multiresolution profile (MRP) of the target area and generate a candidate set of bounding-box proposals that enclose potential change regions. In contrast to existing methods that use handcrafted features, we automatically learn region representations using a deep neural network in a data-driven fashion. Based on these highly discriminative representations, we determine forest changes and predict their onset and offset timings by labeling the candidate set of proposals. Our approach achieves the state-of-the-art average patch classification rate of 91.6% (an improvement of similar to 16%) and the mean onset/offset prediction error of 4.9 months (an error reduction of five months) compared with a strong baseline. We also qualitatively analyze the detected changes in the unlabeled image regions, which demonstrate that the proposed forest change detection approach is scalable to new regions.
C1 [Khan, Salman H.; He, Xuming] Data61 CSIRO, Canberra, ACT 0200, Australia.
   [Khan, Salman H.; He, Xuming; Porikli, Fatih] Australian Natl Univ, Canberra, ACT 0200, Australia.
   [He, Xuming] ShanghaiTech Univ, Shanghai 200031, Peoples R China.
   [Bennamoun, Mohammed] Univ Western Australia, Crawley, WA 6009, Australia.
RP Khan, SH (corresponding author), Data61 CSIRO, Canberra, ACT 0200, Australia.
EM salman.khan@anu.edu.au; salman.khan@anu.edu.au; xuming.he@anu.edu.au;
   fatih.porikli@anu.edu.au
RI Bennamoun, Mohammed/C-2789-2013; Khan, Salman Hameed/M-4834-2016
OI Bennamoun, Mohammed/0000-0002-6603-3257; Khan, Salman
   Hameed/0000-0002-9502-1749
FU NVIDIA Corporation
FX The authors would like to thank Geoscience Australia for providing the
   data and expert annotations. They would also like to thank the support
   of NVIDIA Corporation with the donation of the Tesla K40 GPU used for
   this paper.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Araya YH, 2008, WIT TRANS BUILT ENV, V100, P233, DOI 10.2495/GEO080231
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   De Chant T, 2009, PHOTOGRAMM ENG REM S, V75, P1005, DOI 10.14358/PERS.75.8.1005
   Dollar P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Fablet R., 2015, P IEEE INT GEOSC REM
   Griffiths P, 2010, REMOTE SENS ENVIRON, V114, P426, DOI 10.1016/j.rse.2009.09.012
   Guay KC, 2014, GLOBAL CHANGE BIOL, V20, P3147, DOI 10.1111/gcb.12647
   Gueguen L, 2015, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2015.7298737
   Hansen MC, 2012, REMOTE SENS ENVIRON, V122, P66, DOI 10.1016/j.rse.2011.08.024
   Hayat M, 2016, IEEE T IMAGE PROCESS, V25, P4829, DOI 10.1109/TIP.2016.2599292
   Helmer EH, 2005, PHOTOGRAMM ENG REM S, V71, P1079, DOI 10.14358/PERS.71.9.1079
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V170, P121, DOI 10.1016/j.rse.2015.09.004
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang B, 2015, IEEE GEOSCI REMOTE S, V12, P1046, DOI 10.1109/LGRS.2014.2377476
   Huang CQ, 2008, REMOTE SENS ENVIRON, V112, P970, DOI 10.1016/j.rse.2007.07.023
   Huang CQ, 2010, REMOTE SENS ENVIRON, V114, P183, DOI 10.1016/j.rse.2009.08.017
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Irish RR, 2006, PHOTOGRAMM ENG REM S, V72, P1179, DOI 10.14358/PERS.72.10.1179
   Irish RR, 2000, P SOC PHOTO-OPT INS, V4049, P348, DOI 10.1117/12.410358
   Jianya G., 2008, INT ARCH PHOTOGRAMM, V37, P757, DOI DOI 10.1080/01431168908903939
   Jiao QJ, 2007, P SOC PHOTO-OPT INS, V6790, P79029, DOI 10.1117/12.750462
   Kawabata A, 2001, INT J REMOTE SENS, V22, P1377, DOI 10.1080/01431160119381
   Kennedy RE, 2010, REMOTE SENS ENVIRON, V114, P2897, DOI 10.1016/j.rse.2010.07.008
   Khan S. H., 2015, COST SENSITIVE LEARN
   Khan S.Z., 2017, P INT C RES INN INF, P1, DOI [10.1109/ICRIIS.2017.8002451, DOI 10.1109/ICRIIS.2017.8002451]
   Khan SH, 2016, IEEE T IMAGE PROCESS, V25, P3372, DOI 10.1109/TIP.2016.2567076
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Langkvist M, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8040329
   Lefebvre A., 2008, P IEEE INT GEOSC REM, V4
   Lehmann EA, 2013, INT J APPL EARTH OBS, V21, P453, DOI 10.1016/j.jag.2012.06.005
   Li FQ, 2012, REMOTE SENS ENVIRON, V124, P756, DOI 10.1016/j.rse.2012.06.018
   Li FQ, 2010, IEEE J-STARS, V3, P257, DOI 10.1109/JSTARS.2010.2042281
   Lin CH, 2014, IEEE T GEOSCI REMOTE, V52, P163, DOI 10.1109/TGRS.2012.2237408
   Lin CH, 2013, IEEE T GEOSCI REMOTE, V51, P232, DOI 10.1109/TGRS.2012.2197682
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Longley PA, 2002, PROG HUM GEOG, V26, P231, DOI 10.1191/0309132502ph366pr
   Lorenzi L, 2011, IEEE GEOSCI REMOTE S, V8, P914, DOI 10.1109/LGRS.2011.2141112
   Lunetta RS, 2004, REMOTE SENS ENVIRON, V89, P444, DOI 10.1016/j.rse.2003.10.022
   Maalouf A, 2009, IEEE T GEOSCI REMOTE, V47, P2363, DOI 10.1109/TGRS.2008.2010454
   Mahiny AS, 2007, PHOTOGRAMM ENG REM S, V73, P361, DOI 10.14358/PERS.73.4.361
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Martin B. W., 2013, P SOC PHOTO-OPT INS, V8747
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   Montreal Process Implementation Group for Australia and National Forest Inventory Steering Committee, 2013, TECH REP
   Nackaerts K, 2005, INT J REMOTE SENS, V26, P839, DOI 10.1080/0143116032000160462
   Nordberg ML, 2005, LAND DEGRAD DEV, V16, P139, DOI 10.1002/ldr.660
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Pijanowski BC, 2005, INT J GEOGR INF SCI, V19, P197, DOI 10.1080/13658810410001713416
   Pringle MJ, 2009, ISPRS J PHOTOGRAMM, V64, P654, DOI 10.1016/j.isprsjprs.2009.06.001
   Roy DP, 2008, REMOTE SENS ENVIRON, V112, P3112, DOI 10.1016/j.rse.2008.03.009
   Shen HF, 2016, REMOTE SENS ENVIRON, V172, P109, DOI 10.1016/j.rse.2015.11.005
   Tomowski D, 2011, 2011 Proceedings of Joint Urban Remote Sensing Event (JURSE 2011), P329, DOI 10.1109/JURSE.2011.5764786
   Tseng DC, 2008, APPL MATH COMPUT, V205, P584, DOI 10.1016/j.amc.2008.05.050
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A, 2010, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2010.5539949
   Versluis A, 2010, GEOCARTO INT, V25, P85, DOI 10.1080/10106040902977584
   Wang J, 2015, INT J REMOTE SENS, V36, P3144, DOI 10.1080/01431161.2015.1054049
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xian G, 2009, REMOTE SENS ENVIRON, V113, P1133, DOI 10.1016/j.rse.2009.02.004
   Zhang CR, 2009, INT J REMOTE SENS, V30, P2173, DOI 10.1080/01431160802549294
   Zhu Z, 2012, REMOTE SENS ENVIRON, V118, P83, DOI 10.1016/j.rse.2011.10.028
   Zisserman A., 2015, 14091556 ARXIV, DOI DOI 10.1109/CVPR.2015.7298594
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 69
TC 63
Z9 64
U1 15
U2 96
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2017
VL 55
IS 9
BP 5407
EP 5423
DI 10.1109/TGRS.2017.2707528
PG 17
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA FE6VI
UT WOS:000408346600046
DA 2022-01-04
ER

PT J
AU Gong, MG
   Yang, HL
   Zhang, PZ
AF Gong, Maoguo
   Yang, Hailun
   Zhang, Puzhao
TI Feature learning and change feature classification based on deep
   learning for ternary change detection in SAR images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Ternary change detection; Deep learning; Synthetic aperture radar;
   Representation learning; Sparse autoencoder; Convolutional neural
   networks
ID LOG-RATIO IMAGE; REPRESENTATION; MODEL
AB Ternary change detection aims to detect changes and group the changes into positive change and negative change. It is of great significance in the joint interpretation of spatial-temporal synthetic aperture radar images. In this study, sparse autoencoder, convolutional neural networks (CNN) and unsupervised clustering are combined to solve ternary change detection problem without any supervison. Firstly, sparse autoencoder is used to transform log-ratio difference image into a suitable feature space for extracting key changes and suppressing outliers and noise. And then the learned features are clustered into three classes, which are taken as the pseudo labels for training a CNN model as change feature classifier. The reliable training samples for CNN are selected from the feature maps learned by sparse autoencoder with certain selection rules. Having training samples and the corresponding pseudo labels, the CNN model can be trained by using back propagation with stochastic gradient descent. During its training procedure, CNN is driven to learn the concept of change, and more powerful model is established to distinguish different types of changes. Unlike the traditional methods, the proposed framework integrates the merits of sparse autoencoder and CNN to learn more robust difference representations and the concept of change for ternary change detection. Experimental results on real datasets validate the effectiveness and superiority of the proposed framework. (C) 2017 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.
C1 [Gong, Maoguo; Yang, Hailun; Zhang, Puzhao] Xidian Univ, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi Provinc, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Shaanxi Provinc, Peoples R China.
EM gong@ieee.org
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61422209]; National Program for Support of
   Top-notch Young Professionals of China; Specialized Research Fund for
   the Doctoral Program of Higher EducationSpecialized Research Fund for
   the Doctoral Program of Higher Education (SRFDP) [20130203110011]
FX The authors wish to thank the editors and anonymous reviewers for their
   valuable comments and helpful suggestions which greatly improved the
   paper's quality. This work was supported by the National Natural Science
   Foundation of China (Grant No. 61422209), the National Program for
   Support of Top-notch Young Professionals of China, and the Specialized
   Research Fund for the Doctoral Program of Higher Education (Grant No.
   20130203110011).
CR Arel I, 2010, IEEE COMPUT INTELL M, V5, P13, DOI 10.1109/MCI.2010.938364
   Ban YF, 2012, IEEE J-STARS, V5, P1087, DOI 10.1109/JSTARS.2012.2201135
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bengio Y., 2011, P 28 INT C MACH LEAR, P513, DOI DOI 10.1177/1753193411430810
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bezdek J. C., 2013, PATTERN RECOGNITION
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Brunner D, 2010, INT GEOSCI REMOTE SE, P3210, DOI 10.1109/IGARSS.2010.5651416
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2015, IEEE T NEUR NET LEAR, V26, P3263, DOI 10.1109/TNNLS.2015.2469673
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Haixia Yang, 2014, 2014 IEEE Geoscience and Remote Sensing Symposium. (IGARSS). Proceedings, P4272, DOI 10.1109/IGARSS.2014.6947433
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Jia L, 2015, IEEE T GEOSCI REMOTE, V53, P3960, DOI 10.1109/TGRS.2015.2388495
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li N, 2014, IEEE J-STARS, V7, P3200, DOI 10.1109/JSTARS.2014.2345417
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Lu J, 2015, IEEE J-STARS, V8, P3486, DOI 10.1109/JSTARS.2015.2416635
   Mas JF, 1999, INT J REMOTE SENS, V20, P139, DOI 10.1080/014311699213659
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519
   Shin HC, 2013, IEEE T PATTERN ANAL, V35, P1930, DOI 10.1109/TPAMI.2012.277
   Su LZ, 2017, PATTERN RECOGN, V66, P213, DOI 10.1016/j.patcog.2017.01.002
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang YT, 2014, IEEE T FUZZY SYST, V22, P1557, DOI 10.1109/TFUZZ.2014.2298244
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Yu P, 2012, IEEE T GEOSCI REMOTE, V50, P1302, DOI 10.1109/TGRS.2011.2164085
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 49
TC 91
Z9 98
U1 15
U2 109
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUL
PY 2017
VL 129
BP 212
EP 225
DI 10.1016/j.isprsjprs.2017.05.001
PG 14
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA EY3GW
UT WOS:000403860600017
DA 2022-01-04
ER

PT J
AU Gao, F
   Liu, XP
   Dong, JY
   Zhong, GQ
   Jian, MW
AF Gao, Feng
   Liu, Xiaopeng
   Dong, Junyu
   Zhong, Guoqiang
   Jian, Muwei
TI Change Detection in SAR Images Based on Deep Semi-NMF and SVD Networks
SO REMOTE SENSING
LA English
DT Article
DE change detection; synthetic aperture radar; nonnegative matrix
   factorization; SVD networks; fuzzy c-means; Deep Semi-NMF
ID UNSUPERVISED CHANGE DETECTION; LIBRARY; FUSION
AB With the development of Earth observation programs, more and more multi-temporal synthetic aperture radar (SAR) data are available from remote sensing platforms. Therefore, it is demanding to develop unsupervised methods for SAR image change detection. Recently, deep learning-based methods have displayed promising performance for remote sensing image analysis. However, these methods can only provide excellent performance when the number of training samples is sufficiently large. In this paper, a novel simple method for SAR image change detection is proposed. The proposed method uses two singular value decomposition (SVD) analyses to learn the non-linear relations between multi-temporal images. By this means, the proposed method can generate more representative feature expressions with fewer samples. Therefore, it provides a simple yet effective way to be designed and trained easily. Firstly, deep semi-nonnegative matrix factorization (Deep Semi-NMF) is utilized to select pixels that have a high probability of being changed or unchanged as samples. Next, image patches centered at these sample pixels are generated from the input multi-temporal SAR images. Then, we build SVD networks, which are comprised of two SVD convolutional layers and one histogram feature generation layer. Finally, pixels in both multi-temporal SAR images are classified by the SVD networks, and then the final change map can be obtained. The experimental results of three SAR datasets have demonstrated the effectiveness and robustness of the proposed method.
C1 [Gao, Feng; Liu, Xiaopeng; Dong, Junyu; Zhong, Guoqiang; Jian, Muwei] Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Peoples R China.
RP Dong, JY (corresponding author), Ocean Univ China, Coll Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM gaofeng@ouc.edu.cn; simonlinux@sohu.com; dongjunyu@ouc.edu.cn;
   gqzhong@ouc.edu.cn; jianmuwei@ouc.edu.cn
RI Jian, Muwei/Q-8319-2018
OI Jian, Muwei/0000-0002-4249-2264; Gao, Feng/0000-0002-1825-328X
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41606198, 41576011]; China Postdoctoral
   Science FoundationChina Postdoctoral Science Foundation [2015M582140];
   Shandong Province Natural Science Foundation of China [ZR2016FB02]
FX The authors would like to thank the editors and anonymous reviewers for
   their valuable comments and helpful suggestions, which greatly improved
   the quality of the paper. This work was supported in part by the
   National Natural Science Foundation of China under Grant 41606198,
   41576011), by the China Postdoctoral Science Foundation under Grant
   2015M582140, and by the Shandong Province Natural Science Foundation of
   China under Grant ZR2016FB02.
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bujor F, 2004, IEEE T GEOSCI REMOTE, V42, P2073, DOI 10.1109/TGRS.2004.835304
   Celik T, 2010, SIGNAL PROCESS, V90, P1471, DOI 10.1016/j.sigpro.2009.10.018
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, ISPRS J PHOTOGRAMM, V93, P123, DOI 10.1016/j.isprsjprs.2014.04.010
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guillamet D, 2003, PATTERN RECOGN LETT, V24, P2447, DOI 10.1016/S0167-8655(03)00089-8
   Hou B, 2014, IEEE J-STARS, V7, P3297, DOI 10.1109/JSTARS.2014.2328344
   Hsu CC, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P628
   Hu HT, 2014, IEEE J-STARS, V7, P3248, DOI 10.1109/JSTARS.2014.2344017
   Huang S, 2014, IEEE IMAGE PROC, P5951, DOI 10.1109/ICIP.2014.7026201
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Liu J., 2017, IEEE T NEURAL NETWOR, V28, P1
   Liu J, 2016, SOFT COMPUT, V20, P4645, DOI 10.1007/s00500-014-1460-0
   Liu R, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060464
   Lv PY, 2016, IEEE GEOSCI REMOTE S, V13, P1965, DOI 10.1109/LGRS.2016.2619163
   Meganem I, 2014, IEEE T SIGNAL PROCES, V62, P1822, DOI 10.1109/TSP.2014.2306181
   Navarro A, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060525
   Othman AA, 2013, REMOTE SENS-BASEL, V5, P1024, DOI 10.3390/rs5031024
   Pan B, 2017, IEEE J-STARS, V10, P1975, DOI 10.1109/JSTARS.2017.2655516
   Pettinato S, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.084684
   Shao P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030264
   Tewolde MG, 2011, REMOTE SENS-BASEL, V3, P2148, DOI 10.3390/rs3102148
   Trigeorgis G, 2014, PR MACH LEARN RES, V32, P1692
   Wang Y, 2016, IEEE GEOSCI REMOTE S, V13, P931, DOI 10.1109/LGRS.2016.2554606
   Yang YT, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083639
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
   Zhong YF, 2015, IEEE GEOSCI REMOTE S, V12, P537, DOI 10.1109/LGRS.2014.2349937
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 41
TC 23
Z9 25
U1 6
U2 41
PU MDPI
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAY
PY 2017
VL 9
IS 5
AR 435
DI 10.3390/rs9050435
PG 20
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA EW5VD
UT WOS:000402573700038
OA gold, Green Submitted
DA 2022-01-04
ER

PT J
AU Gong, MG
   Zhan, T
   Zhang, PZ
   Miao, QG
AF Gong, Maoguo
   Zhan, Tao
   Zhang, Puzhao
   Miao, Qiguang
TI Superpixel-Based Difference Representation Learning for Change Detection
   in Multispectral Remote Sensing Images
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE Change detection; difference representation learning; multispectral
   images; neural network; superpixel segmentation
ID UNSUPERVISED CHANGE DETECTION; NEURAL-NETWORKS; CLASSIFICATION;
   ALGORITHM; FRAMEWORK
AB With the rapid technological development of various satellite sensors, high-resolution remotely sensed imagery has been an important source of data for change detection in land cover transition. However, it is still a challenging problem to effectively exploit the available spectral information to highlight changes. In this paper, we present a novel change detection framework for high-resolution remote sensing images, which incorporates superpixel-based change feature extraction and hierarchical difference representation learning by neural networks. First, highly homogenous and compact image superpixels are generated using superpixel segmentation, which makes these image blocks adhere well to image boundaries. Second, the change features are extracted to represent the difference information using spectrum, texture, and spatial features between the corresponding superpixels. Third, motivated by the fact that deep neural network has the ability to learn from data sets that have few labeled data, we use it to learn the semantic difference between the changed and unchanged pixels. The labeled data can be selected from the bitemporal multispectral images via a preclassification map generated in advance. And then, a neural network is built to learn the difference and classify the uncertain samples into changed or unchanged ones. Finally, a robust and high-contrast change detection result can be obtained from the network. The experimental results on the real data sets demonstrate its effectiveness, feasibility, and superiority of the proposed technique.
C1 [Gong, Maoguo; Zhan, Tao; Zhang, Puzhao; Miao, Qiguang] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Minist Educ,Key Lab Intelligent Percept & Image U, Xian 710071, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Joint Int Res Lab Intelligent Percept & Computat, Minist Educ,Key Lab Intelligent Percept & Image U, Xian 710071, Peoples R China.
EM gong@ieee.org
OI Zhan, Tao/0000-0002-9283-4488
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61422209]; National Program for Support of
   Top-notch Young Professionals of China; Specialized Research Fund for
   the Doctoral Program of Higher EducationSpecialized Research Fund for
   the Doctoral Program of Higher Education (SRFDP) [20130203110011]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61422209, in part by the National
   Program for Support of Top-notch Young Professionals of China, and in
   part by the Specialized Research Fund for the Doctoral Program of Higher
   Education under Grant 20130203110011.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Addink EA, 2012, INT J APPL EARTH OBS, V15, P1, DOI 10.1016/j.jag.2011.12.001
   Aguirre-Gutierrez J, 2012, APPL GEOGR, V34, P29, DOI 10.1016/j.apgeog.2011.10.010
   Akata Z, 2014, IEEE T PATTERN ANAL, V36, P507, DOI 10.1109/TPAMI.2013.146
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bock Michael, 2005, Journal for Nature Conservation (Jena), V13, P75, DOI 10.1016/j.jnc.2004.12.002
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Bovolo F, 2008, IEEE T GEOSCI REMOTE, V46, P2070, DOI 10.1109/TGRS.2008.916643
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen ZY, 2016, IEEE T GEOSCI REMOTE, V54, P103, DOI 10.1109/TGRS.2015.2451002
   Chinchor N, 1993, PROC 5 MESSAGE UNDER, P69, DOI DOI 10.3115/1072017.1072026
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P4186, DOI 10.1109/TGRS.2015.2392755
   Fu KR, 2013, SIGNAL PROCESS-IMAGE, V28, P1448, DOI 10.1016/j.image.2013.07.005
   Gokaraju B., 2015, 2015 IEEE APPL IM PA 2015 IEEE APPL IM PA, P1
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2016, IEEE T GEOSCI REMOTE, V54, P7077, DOI 10.1109/TGRS.2016.2594952
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hinton G. E., 2012, NEURAL NETWORKS TRIC, P599, DOI DOI 10.1007/978-3-642-35289-8_32
   Hinton G. E., 2012, ADV NEURAL INFORM PR, P1097, DOI DOI 10.1145/3065386
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu Baotian, 2014, ADV NEURAL INFORM PR, P2042
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Le, 2014, ADV NEURAL INFORM PR, P3104
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2016, APPL SOFT COMPUT, V46, P767, DOI 10.1016/j.asoc.2015.10.044
   Li ST, 2016, IEEE T GEOSCI REMOTE, V54, P7416, DOI 10.1109/TGRS.2016.2603190
   Lin ML, 2013, IEEE T NEUR NET LEAR, V24, P647, DOI 10.1109/TNNLS.2012.2228231
   Liu B, 2013, IEEE T GEOSCI REMOTE, V51, P907, DOI 10.1109/TGRS.2012.2203358
   Liu J., 2014, SOFT COMPUT, V20, P1
   Lu T, 2016, IEEE T GEOSCI REMOTE, V54, P7122, DOI 10.1109/TGRS.2016.2596260
   Moser G, 2013, P IEEE, V101, P631, DOI 10.1109/JPROC.2012.2211551
   Neagoe V, 2014, INT GEOSCI REMOTE SE, P1437, DOI 10.1109/IGARSS.2014.6946706
   Neagoe VE, 2014, IEEE J-STARS, V7, P3525, DOI 10.1109/JSTARS.2014.2330808
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Wang Wei, 2009, Guizhou Agricultural Sciences, P1
   Weston J., 2008, P 25 ICML, P160, DOI [10.1145/1390156.1390177, 10.1145/ 1390156.1390177, DOI 10.1145/1390156.1390177]
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang H, 2016, IEEE GEOSCI REMOTE S, V13, P1666, DOI 10.1109/LGRS.2016.2601930
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 55
TC 92
Z9 97
U1 11
U2 121
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD MAY
PY 2017
VL 55
IS 5
BP 2658
EP 2673
DI 10.1109/TGRS.2017.2650198
PG 16
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA ET0HT
UT WOS:000399943400016
DA 2022-01-04
ER

PT J
AU Wu, K
   Du, Q
   Wang, Y
   Yang, YT
AF Wu, Ke
   Du, Qian
   Wang, Yi
   Yang, Yetao
TI Supervised Sub-Pixel Mapping for Change Detection from Remotely Sensed
   Images with Different Resolutions
SO REMOTE SENSING
LA English
DT Article
DE soft classification; sub-pixel mapping (SPM); back-propagation neural
   network (BPNN); change detection
ID LAND-COVER CHANGE; SPECTRAL MIXTURE ANALYSIS; UNSUPERVISED CHANGE
   DETECTION; HOPFIELD NEURAL-NETWORK; FRACTION IMAGES; INFORMATION;
   ALGORITHMS
AB Due to the relatively low temporal resolutions of high spatial resolution (HR) remotely sensed images, land-cover change detection (LCCD) may have to use multi-temporal images with different resolutions. The low spatial resolution (LR) images often have high temporal repetition rates, but they contain a large number of mixed pixels, which may seriously limit their capability in change detection. Soft classification (SC) can produce the proportional fractions of land-covers, on which sub-pixel mapping (SPM) can construct fine resolution land-cover maps to reduce the low-spatial-resolution-problem to some extent. Thus, in this paper, sub-pixel land-cover change detection with the use of different resolution images (SLCCD_DR) is addressed based on SC and SPM. Previously, endmember combinations within pixels are ignored in the LR image, which may result in flawed fractional differences. Meanwhile, the information of a known HR land-cover map is insignificantly treated in the SPM models, which leads to a reluctant SLCCD_DR result. In order to overcome these issues, a novel approach based on a back propagation neural network (BPNN) with different resolution images (BPNN_DR) is proposed in this paper. Firstly, endmember variability per pixel is considered during the SC process to ensure the high accuracy of the derived proportional fractional difference image. After that, the BPNN-based SPM model is constructed by a complete supervised framework. It takes full advantage of the prior known HR image, whether it predates or postdates the LR image, to train the BPNN, so that a sub-pixel change detection map is generated effectively. The proposed BPNN_DR is compared with four state-of-the-art methods at different scale factors. The experimental results using both synthetic data and real images demonstrated that it can outperform with a more detailed change detection map being produced.
C1 [Wu, Ke; Wang, Yi; Yang, Yetao] China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
   [Du, Qian] Mississippi State Univ, Dept Elect & Comp Engn, Starkville, MS 39759 USA.
RP Wu, K (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Wuhan 430074, Peoples R China.
EM tingke2000@126.com; du@ece.msstate.edu; cug.yi.wang@gmail.com;
   yyt98032@163.com
RI Wang, Yi/J-2321-2019
OI Wang, Yi/0000-0002-1347-7030; Wu, Ke/0000-0001-9692-4221
FU Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [61372153, 41372341]; Natural Science Foundation of
   Hubei Province, ChinaNatural Science Foundation of Hubei Province
   [2014CFA052]; Fundamental Research Funds for the Central Universities,
   China University of Geosciences (Wuhan)Fundamental Research Funds for
   the Central Universities [CUGL140410, 26420160125]
FX The research is funded in part by the Natural Science Foundation of
   China (61372153, 41372341); the Natural Science Foundation of Hubei
   Province, China (2014CFA052); the Fundamental Research Funds for the
   Central Universities, China University of Geosciences (Wuhan)
   (CUGL140410, 26420160125).
CR Anderson LO, 2005, INT J REMOTE SENS, V26, P2251, DOI 10.1080/01431160310001620795
   Atkinson P.M., 2001, P 6 INT C GEOC BRISB
   Atkinson PM, 1997, INT J REMOTE SENS, V18, P917, DOI 10.1080/014311697217224
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   Franke J, 2009, REMOTE SENS ENVIRON, V113, P1712, DOI 10.1016/j.rse.2009.03.018
   Gu YF, 2008, IEEE T GEOSCI REMOTE, V46, P1347, DOI 10.1109/TGRS.2008.917270
   Haertel V, 2004, INT J REMOTE SENS, V25, P5473, DOI 10.1080/01431160412331269751
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   IRIE B, 1988, P IEEE INT C NEUR NE
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   Le Hegarat-Mascle S, 2005, REMOTE SENS ENVIRON, V95, P464, DOI 10.1016/j.rse.2005.01.011
   Le Hegarat-Mascle S, 2004, REMOTE SENS ENVIRON, V91, P390, DOI 10.1016/j.rse.2004.04.001
   Li XD, 2016, IEEE T GEOSCI REMOTE, V54, P3822, DOI 10.1109/TGRS.2016.2528583
   Li XD, 2014, ISPRS J PHOTOGRAMM, V93, P76, DOI 10.1016/j.isprsjprs.2014.03.013
   Ling F, 2013, REMOTE SENS LETT, V4, P629, DOI 10.1080/2150704X.2013.781284
   Ling F, 2012, IEEE GEOSCI REMOTE S, V9, P408, DOI 10.1109/LGRS.2011.2169934
   Ling F, 2011, IEEE GEOSCI REMOTE S, V8, P182, DOI 10.1109/LGRS.2010.2055034
   Liu WG, 2005, REMOTE SENS ENVIRON, V94, P145, DOI 10.1016/j.rse.2004.09.004
   Lu DS, 2004, CAN J REMOTE SENS, V30, P87, DOI 10.5589/m03-055
   Mertens KC, 2004, REMOTE SENS ENVIRON, V91, P225, DOI 10.1016/j.rse.2004.03.003
   Mertens KC, 2003, INT J REMOTE SENS, V24, P4241, DOI 10.1080/01431160310001595073
   Nigussie D, 2011, INT J REMOTE SENS, V32, P7203, DOI 10.1080/01431161.2010.519740
   Olofsson P, 2013, REMOTE SENS ENVIRON, V129, P122, DOI 10.1016/j.rse.2012.10.031
   Powell RL, 2007, REMOTE SENS ENVIRON, V106, P253, DOI 10.1016/j.rse.2006.09.005
   Tatem AJ, 2001, IEEE T GEOSCI REMOTE, V39, P781, DOI 10.1109/36.917895
   Thornton MW, 2007, COMPUT GEOSCI-UK, V33, P1261, DOI 10.1016/j.cageo.2007.05.010
   TURNER BL, 1994, AMBIO, V23, P91
   van Oort PAJ, 2007, REMOTE SENS ENVIRON, V108, P1, DOI 10.1016/j.rse.2006.10.012
   VanderMeer F, 1997, INT J REMOTE SENS, V18, P1197, DOI 10.1080/014311697218674
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Wang QM, 2015, IEEE J-STARS, V8, P1339, DOI 10.1109/JSTARS.2014.2355832
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Wu K, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.097299
   Yang LM, 2003, PHOTOGRAMM ENG REM S, V69, P1003, DOI 10.14358/PERS.69.9.1003
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zortea M, 2009, IEEE GEOSCI REMOTE S, V6, P787, DOI 10.1109/LGRS.2009.2025520
NR 38
TC 26
Z9 28
U1 8
U2 27
PU MDPI AG
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD MAR
PY 2017
VL 9
IS 3
AR 284
DI 10.3390/rs9030284
PG 17
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA ER3SZ
UT WOS:000398720100098
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Cao, G
   Wang, BS
   Xavier, HC
   Yang, D
   Southworth, J
AF Cao, Guo
   Wang, Bisheng
   Xavier, Haro-Carrion
   Yang, Di
   Southworth, Jane
TI A new difference image creation method based on deep neural networks for
   change detection in remote-sensing images
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID UNSUPERVISED CHANGE DETECTION; REPRESENTATION; FUSION
AB In this article, we propose a novel difference image (DI) creation method for unsupervised change detection in multi-temporal multi-spectral remote-sensing images based on deep learning theory. First, we apply deep belief network to learn local and high-level features from the local neighbour of a given pixel in an unsupervised manner. Second, a back propagation algorithm is improved to build a DI based on selected training samples, which can highlight the difference on changed regions and suppress the false changes on unchanged regions. Finally, we get the change trajectory map using simple clustering analysis. The proposed scheme is tested on three remote-sensing data sets. Qualitative and quantitative evaluations show its superior performance compared to the traditional pixel-level and texture-level-based approaches.
C1 [Cao, Guo; Wang, Bisheng] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Cao, Guo; Xavier, Haro-Carrion; Yang, Di; Southworth, Jane] Univ Florida, Dept Geog, Gainesville, FL 32611 USA.
RP Cao, G (corresponding author), Univ Florida, Dept Geog, Gainesville, FL 32611 USA.
EM caoguo@njust.edu.cn
RI Yang, Di/AAF-3017-2019; Haro-Carrion, Xavier/K-7789-2019
OI Yang, Di/0000-0002-4010-6163; Haro-Carrion, Xavier/0000-0002-8048-5380
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61371168]
FX This work is supported by the National Natural Science Foundation of
   China [Grant No. 61371168].
CR Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Cao G, 2016, INT J REMOTE SENS, V37, P1173, DOI 10.1080/01431161.2016.1148284
   Celik T, 2011, IEEE T GEOSCI REMOTE, V49, P706, DOI 10.1109/TGRS.2010.2066979
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen B, 2013, IEEE T PATTERN ANAL, V35, P1887, DOI 10.1109/TPAMI.2013.19
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Falco N, 2013, IEEE GEOSCI REMOTE S, V10, P636, DOI 10.1109/LGRS.2012.2222340
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Gong MG, 2016, IEEE T NEUR NET LEAR, V27, P125, DOI 10.1109/TNNLS.2015.2435783
   Gong MG, 2014, ISPRS J PHOTOGRAMM, V93, P123, DOI 10.1016/j.isprsjprs.2014.04.010
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   He PF, 2014, REMOTE SENS LETT, V5, P396, DOI 10.1080/2150704X.2014.912766
   Hinton, 2009, ARTIF INTELL, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Hinton GE., 2005, CONTRASTIVE DIVERGEN, V10, P33
   Huo CL, 2010, IEEE GEOSCI REMOTE S, V7, P118, DOI 10.1109/LGRS.2009.2028438
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582
   Jungho I., 2017, REMOTE SENS ENVIRON, V106, P2007
   Kempeneers P, 2012, IEEE T GEOSCI REMOTE, V50, P3327, DOI 10.1109/TGRS.2011.2181854
   Li XD, 2016, IEEE T GEOSCI REMOTE, V54, P3822, DOI 10.1109/TGRS.2016.2528583
   Luus FPS, 2015, IEEE GEOSCI REMOTE S, V12, P2448, DOI 10.1109/LGRS.2015.2483680
   Shi W. R., 2015, J EVID BASED COMPLEM, V2015, P1, DOI DOI 10.1016/J.0CEAN-ENG.2015.07.064.ISSN
   Tan K, 2016, IEEE J-STARS, V9, P3439, DOI 10.1109/JSTARS.2016.2541678
   Vakalopoulou M, 2015, INT GEOSCI REMOTE SE, P1873, DOI 10.1109/IGARSS.2015.7326158
   Wang Y, 2016, IEEE GEOSCI REMOTE S, V13, P931, DOI 10.1109/LGRS.2016.2554606
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 30
TC 20
Z9 23
U1 11
U2 55
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PY 2017
VL 38
IS 23
BP 7161
EP 7175
DI 10.1080/01431161.2017.1371861
PG 15
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA FJ2HN
UT WOS:000412545900035
DA 2022-01-04
ER

PT J
AU Zhang, H
   Gong, MG
   Zhang, PZ
   Su, LZ
   Shi, J
AF Zhang, Hui
   Gong, Maoguo
   Zhang, Puzhao
   Su, Linzhi
   Shi, Jiao
TI Feature-Level Change Detection Using Deep Representation and Feature
   Change Analysis for Multispectral Imagery
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; change vector analysis (CVA); cosine angle distance
   (CAD); deep belief networks (DBNs); multi-spectral images
AB Due to the noise interference and redundancy in multispectral images, it is promising to transform the available spectral channels into a suitable feature space for relieving noise and reducing the redundancy. The booming of deep learning provides a flexible tool to learn abstract and invariant features directly from the data in their raw forms. In this letter, we propose an unsupervised change detection technique for multispectral images, in which we combine deep belief networks (DBNs) and feature change analysis to highlight changes. First, a DBN is established to capture the key information for discrimination and suppress the irrelevant variations. Second, we map bitemporal change feature into a 2-D polar domain to characterize the change information. Finally, an unsupervised clustering algorithm is adopted to distinguish the changed and unchanged pixels, and then, the changed types can be identified by classifying the changed pixels into several classes according to the directions of feature changes. The experimental results demonstrate the effectiveness and robustness of the proposed method.
C1 [Zhang, Hui; Gong, Maoguo; Zhang, Puzhao; Su, Linzhi; Shi, Jiao] Xidian Univ, Minist Educ China, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
   [Zhang, Hui] Xidian Univ, Sch Microelect, Dept Integrated Circuit Design & Integrated Syst, Xian 710071, Peoples R China.
   [Shi, Jiao] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Minist Educ China, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
EM gong@ieee.org
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61273317, 61422209]; National Program for
   the Support of Top-Notch Young Professionals of China; Specialized
   Research Fund for the Doctoral Program of Higher EducationSpecialized
   Research Fund for the Doctoral Program of Higher Education (SRFDP)
   [20130203110011]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61273317 and Grant 61422209, by the
   National Program for the Support of Top-Notch Young Professionals of
   China, and by the Specialized Research Fund for the Doctoral Program of
   Higher Education under Grant 20130203110011.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Eismann MT, 2008, IEEE T GEOSCI REMOTE, V46, P237, DOI 10.1109/TGRS.2007.907973
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Korenius T, 2007, INFORM SCIENCES, V177, P4893, DOI 10.1016/j.ins.2007.05.027
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kuremoto T, 2014, NEUROCOMPUTING, V137, P47, DOI 10.1016/j.neucom.2013.03.047
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Oyedotun Oyebade K., 2015, International Journal of Intelligent Systems and Applications, V7, P1, DOI 10.5815/ijisa.2015.07.01
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
NR 13
TC 66
Z9 66
U1 12
U2 66
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD NOV
PY 2016
VL 13
IS 11
BP 1666
EP 1670
DI 10.1109/LGRS.2016.2601930
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA EA0DL
UT WOS:000386255600016
DA 2022-01-04
ER

PT J
AU Lyu, HB
   Lu, H
   Mou, LC
AF Lyu, Haobo
   Lu, Hui
   Mou, Lichao
TI Learning a Transferable Change Rule from a Recurrent Neural Network for
   Land Cover Change Detection
SO REMOTE SENSING
LA English
DT Article
DE change detection; LSTM model; transferability; multi-spectral image;
   recurrent neural network
ID REMOTELY-SENSED DATA; UNSUPERVISED CHANGE DETECTION; TIME-SERIES;
   HYPERSPECTRAL IMAGES; SATELLITE DATA; CLASSIFICATION; RECOGNITION; MODEL
AB When exploited in remote sensing analysis, a reliable change rule with transfer ability can detect changes accurately and be applied widely. However, in practice, the complexity of land cover changes makes it difficult to use only one change rule or change feature learned from a given multi-temporal dataset to detect any other new target images without applying other learning processes. In this study, we consider the design of an efficient change rule having transferability to detect both binary and multi-class changes. The proposed method relies on an improved Long Short-Term Memory (LSTM) model to acquire and record the change information of long-term sequence remote sensing data. In particular, a core memory cell is utilized to learn the change rule from the information concerning binary changes or multi-class changes. Three gates are utilized to control the input, output and update of the LSTM model for optimization. In addition, the learned rule can be applied to detect changes and transfer the change rule from one learned image to another new target multi-temporal image. In this study, binary experiments, transfer experiments and multi-class change experiments are exploited to demonstrate the superiority of our method. Three contributions of this work can be summarized as follows: (1) the proposed method can learn an effective change rule to provide reliable change information for multi-temporal images; (2) the learned change rule has good transferability for detecting changes in new target images without any extra learning process, and the new target images should have a multi-spectral distribution similar to that of the training images; and (3) to the authors' best knowledge, this is the first time that deep learning in recurrent neural networks is exploited for change detection. In addition, under the framework of the proposed method, changes can be detected under both binary detection and multi-class change detection.
C1 [Lyu, Haobo; Lu, Hui] Tsinghua Univ, Ctr Earth Syst Sci, Minist Educ, Key Lab Earth Syst Modeling, Beijing 100084, Peoples R China.
   [Lu, Hui] Joint Ctr Global Change Studies, Beijing 100875, Peoples R China.
   [Mou, Lichao] German Aerosp Ctr DLR, Remote Sensing Technol Inst IMF, D-82234 Wessling, Germany.
   [Mou, Lichao] TUM, Signal Proc Earth Observat SiPEO, D-80333 Munich, Germany.
RP Lu, H (corresponding author), Tsinghua Univ, Ctr Earth Syst Sci, Minist Educ, Key Lab Earth Syst Modeling, Beijing 100084, Peoples R China.; Lu, H (corresponding author), Joint Ctr Global Change Studies, Beijing 100875, Peoples R China.
EM lvhb15@mails.tsinghua.edu.cn; luhui@tsinghua.edu.cn; lichao.mou@dlr.de
RI Lu, Hui/H-4349-2011
OI Lu, Hui/0000-0003-1640-239X
FU National Basic Research Program of ChinaNational Basic Research Program
   of China [2015CB953703]; National Natural Science Foundation of
   ChinaNational Natural Science Foundation of China (NSFC) [41371328,
   91537210, 51190092]; Beijing Higher Education Young Elite Teacher
   Project [YETP0132]; Tsinghua National Laboratory for Information Science
   and Technology
FX This work was jointly supported by the National Basic Research Program
   of China (Grant No. 2015CB953703), the National Natural Science
   Foundation of China (Nos. 41371328, 91537210 and 51190092) and the
   Beijing Higher Education Young Elite Teacher Project (YETP0132). The
   computation in this work is supported by the Tsinghua National
   Laboratory for Information Science and Technology.
CR Basnet B, 2015, REMOTE SENS-BASEL, V7, P6683, DOI 10.3390/rs70606683
   Bouaraba A, 2014, IEEE GEOSCI REMOTE S, V11, P1817, DOI 10.1109/LGRS.2014.2310493
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Brillante C, 2016, NONLINEAR DYNAM, V84, P1479, DOI 10.1007/s11071-015-2583-2
   Byun Y, 2015, REMOTE SENS-BASEL, V7, P10347, DOI 10.3390/rs70810347
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CHREN WA, 1995, IEEE INT SYMP CIRC S, V1, P401
   Chung J., 2015, ARXIV150204390
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   de Morsier F, 2013, IEEE T GEOSCI REMOTE, V51, P1939, DOI 10.1109/TGRS.2012.2236683
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Deng JS, 2008, INT J REMOTE SENS, V29, P4823, DOI 10.1080/01431160801950162
   Ding K, 2015, IEEE GEOSCI REMOTE S, V12, P577, DOI 10.1109/LGRS.2014.2351807
   Erturk A., 2015, IEEE J-STARS, V9, P708
   FU X, 2014, IEEE T NEUR NET LEAR, V26, P1900, DOI DOI 10.1109/TNNLS.2014.2361267
   Ganchev TD, 2015, EXPERT SYST APPL, V42, P6098, DOI 10.1016/j.eswa.2015.03.036
   Hermosilla T, 2015, REMOTE SENS ENVIRON, V170, P121, DOI 10.1016/j.rse.2015.09.004
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Huang XM, 2014, INT J APPL EARTH OBS, V29, P78, DOI 10.1016/j.jag.2014.01.004
   Koltunov A, 2007, REMOTE SENS ENVIRON, V110, P18, DOI 10.1016/j.rse.2007.02.010
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Meola J, 2012, IEEE T GEOSCI REMOTE, V50, P3693, DOI 10.1109/TGRS.2012.2186305
   Nielsen AA, 2007, IEEE T IMAGE PROCESS, V16, P463, DOI 10.1109/TIP.2006.888195
   Ordonez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Pacella M, 2007, COMPUT IND ENG, V52, P502, DOI 10.1016/j.cie.2007.03.003
   Pal M, 2003, REMOTE SENS ENVIRON, V86, P554, DOI 10.1016/S0034-4257(03)00132-9
   Parmentier B, 2014, REMOTE SENS-BASEL, V6, P8639, DOI 10.3390/rs6098639
   Pascanu R., 2013, INT C MACH LEARN, P1310
   Robson BA, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8010067
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shah-Hosseini R, 2015, REMOTE SENS-BASEL, V7, P12829, DOI 10.3390/rs71012829
   Shapiro AC, 2015, REMOTE SENS-BASEL, V7, P16504, DOI 10.3390/rs71215838
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sinha P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020107
   Ubeyli ED, 2008, COMPUT BIOL MED, V38, P401, DOI 10.1016/j.compbiomed.2008.01.002
   Wen DW, 2016, IEEE T GEOSCI REMOTE, V54, P609, DOI 10.1109/TGRS.2015.2463075
   Wu C, 2014, IEEE T GEOSCI REMOTE, V52, P2858, DOI 10.1109/TGRS.2013.2266673
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   Yuan Y, 2015, REMOTE SENS-BASEL, V7, P15318, DOI 10.3390/rs71115318
   Yuan Y, 2015, IEEE T NEUR NET LEAR, V26, P2222, DOI 10.1109/TNNLS.2014.2359471
NR 41
TC 138
Z9 143
U1 24
U2 134
PU MDPI AG
PI BASEL
PA ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN 2072-4292
J9 REMOTE SENS-BASEL
JI Remote Sens.
PD JUN
PY 2016
VL 8
IS 6
AR 506
DI 10.3390/rs8060506
PG 22
WC Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging
   Science & Photographic Technology
GA DR6BE
UT WOS:000379985300065
OA Green Submitted, gold
DA 2022-01-04
ER

PT J
AU Liu, R
   Jia, ZH
   Qin, XZ
   Yang, J
   Kasabov, N
AF Liu, Rui
   Jia, Zhenhong
   Qin, Xizhong
   Yang, Jie
   Kasabov, Nikola
TI SAR Image Change Detection Method Based on Pulse-Coupled Neural Network
SO JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING
LA English
DT Article
DE Change detection; Remote sensing image; Global dictionary; Pulse-coupled
   neural network (PCNN)
ID ALGORITHMS
AB The study proposes a new algorithm for change detection of SAR images based on segmentation to improve the accuracy of the SAR image change detection. The ratio method is used to acquire the difference image (DI). Then, the global dictionary is applied to address the image denoising problem. Finally, change mask is obtained by pulse-coupled neural network (PCNN). The results of the experiment show that the proposed method improves accuracy.
C1 [Liu, Rui; Jia, Zhenhong; Qin, Xizhong] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200400, Peoples R China.
   [Kasabov, Nikola] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 1020, New Zealand.
RP Jia, ZH (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
EM jzhh9009@sohu.com
OI Kasabov, Nikola/0000-0003-4433-7521
FU International Cooperative Research and Personnel Training Projects of
   the Ministry of the Ministry of Education of the People's Republic of
   China [DICE2014-2029]
FX This work was supported in part by International Cooperative Research
   and Personnel Training Projects of the Ministry of the Ministry of
   Education of the People's Republic of China [Grant number
   DICE2014-2029].
CR Bergeaud F, 1996, COMPUT APPL MATH, V15, P97
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   FUKUSHIMA K, 1988, COMPUTER, V21, P65, DOI 10.1109/2.32
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE GEOSCI REMOTE S, V9, P307, DOI 10.1109/LGRS.2011.2167211
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li HY, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1635, DOI 10.1109/ICARCV.2008.4795771
   Liu M, 2014, IEEE T GEOSCI REMOTE, V52, P7483, DOI 10.1109/TGRS.2014.2310451
   Ma YS, 2011, INT J PROD RES, V49, P7007, DOI 10.1080/00207543.2010.495089
   Pacifici F, 2010, IEEE GEOSCI REMOTE S, V7, P58, DOI 10.1109/LGRS.2009.2021780
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Wang F, 2013, IEEE GEOSCI REMOTE S, V10, P697, DOI 10.1109/LGRS.2012.2219494
   Wang YD, 2014, J INDIAN SOC REMOTE, V42, P621, DOI 10.1007/s12524-014-0361-0
   Zhang XH, 2013, IEEE GEOSCI REMOTE S, V10, P14, DOI 10.1109/LGRS.2012.2189867
   Zhao Z., 2014, IOP C SERIES EARTH E, V17, P682
   Zhong YF, 2015, IEEE GEOSCI REMOTE S, V12, P537, DOI 10.1109/LGRS.2014.2349937
NR 18
TC 2
Z9 2
U1 2
U2 31
PU SPRINGER
PI NEW YORK
PA ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN 0255-660X
EI 0974-3006
J9 J INDIAN SOC REMOTE
JI J. Indian Soc. Remote Sens.
PD JUN
PY 2016
VL 44
IS 3
BP 443
EP 450
DI 10.1007/s12524-015-0507-8
PG 8
WC Environmental Sciences; Remote Sensing
SC Environmental Sciences & Ecology; Remote Sensing
GA DR2NS
UT WOS:000379741800014
DA 2022-01-04
ER

PT J
AU Zhang, PZ
   Gong, MG
   Su, LZ
   Liu, J
   Li, ZZ
AF Zhang, Puzhao
   Gong, Maoguo
   Su, Linzhi
   Liu, Jia
   Li, Zhizhou
TI Change detection based on deep feature representation and mapping
   transformation for multi-spatial-resolution remote sensing images
SO ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING
LA English
DT Article
DE Change detection; Spatial-resolution; Denoising autoencoder; Stacked
   denoising autoencoder; Deep neural networks; Feature transformation
ID AUTOMATIC CHANGE DETECTION; MULTITEMPORAL SAR IMAGES; FOREST CHANGE
   DETECTION; LAND-COVER CHANGE; TIME-SERIES; URBAN AREAS; CLASSIFICATION;
   ALGORITHMS; NETWORK; RADAR
AB Multi-spatial-resolution change detection is a newly proposed issue and it is of great significance in remote sensing, environmental and land use monitoring, etc. Though multi-spatial-resolution image pair are two kinds of representations of the same reality, they are often incommensurable superficially due to their different modalities and properties. In this paper, we present a novel multi-spatial resolution change detection framework, which incorporates deep-architecture-based unsupervised feature learning and mapping-based feature change analysis. Firstly, we transform multi-resolution image-pair into the same pixel-resolution through co-registration, followed by details recovery, which is designed to remedy the spatial details lost in the registration. Secondly, the denoising autoencoder is stacked to learn local and high-level representation/feature from the local neighborhood of the given pixel, in an unsupervised fashion. Thirdly, motivated by the fact that multi-resolution image-pair share the same reality in the unchanged regions, we try to explore the inner relationships between them by building a mapping neural network. And it can be used to learn a mapping function based on the most-unlikely-changed feature-pairs, which are selected from all the feature-pairs via a coarse initial change map generated in advance. The learned mapping function can bridge the different representations and highlight changes. Finally, we can build a robust and contractive change map through feature similarity analysis, and the change detection result is obtained through the segmentation of the final change map. Experiments are carried out on four real datasets, and the results confirmed the effectiveness and superiority of the proposed method. (C) 2016 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.
C1 [Zhang, Puzhao; Gong, Maoguo; Su, Linzhi; Liu, Jia; Li, Zhizhou] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Shaanxi Provinc, Peoples R China.
RP Gong, MG (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Int Res Ctr Intelligent Percept & Computat, Xian 710071, Shaanxi Provinc, Peoples R China.
EM gong@ieee.org
RI Liu, Jia/P-9706-2018
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [61273317, 61422209]; National Program for
   Support of Top-notch Young Professionals of China; Specialized Research
   Fund for the Doctoral Program of Higher EducationSpecialized Research
   Fund for the Doctoral Program of Higher Education (SRFDP)
   [20130203110011]
FX The authors wish to thank the editors and anonymous reviewers for their
   valuable comments and helpful suggestions which greatly improved the
   paper's quality. This work was supported by the National Natural Science
   Foundation of China (Grant nos. 61273317, 61422209), the National
   Program for Support of Top-notch Young Professionals of China, and the
   Specialized Research Fund for the Doctoral Program of Higher Education
   (Grant no. 20130203110011).
CR Alberga V, 2009, REMOTE SENS-BASEL, V1, P122, DOI 10.3390/rs1030122
   Allender E., 1996, Foundations of Software Technology and Theoretical Computer Science. 16th Conference Proceedings, P1
   Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bengio, 2011, P 28 INT C MACH LEAR, P833
   Bengio Y., 2007, LARGE SCALE KERNEL M, P1, DOI [DOI 10.7551/MITPRESS/7496.003.0016, DOI 10.1038/NATURE14539]
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bernhard S., 2007, P ADV NEUR INF PROC, V19, P153, DOI DOI 10.7551/mitpress/7503.003.0024
   Bosc M, 2003, NEUROIMAGE, V20, P643, DOI 10.1016/S1053-8119(03)00406-3
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Camps-Valls G, 2008, IEEE T GEOSCI REMOTE, V46, P1822, DOI 10.1109/TGRS.2008.916201
   Carotenuto V, 2015, IEEE T GEOSCI REMOTE, V53, P3294, DOI 10.1109/TGRS.2014.2372900
   Carvalho OA, 2011, REMOTE SENS-BASEL, V3, P2473, DOI 10.3390/rs3112473
   Chen G, 2012, INT J REMOTE SENS, V33, P4434, DOI 10.1080/01431161.2011.648285
   Chen J, 2013, ISPRS J PHOTOGRAMM, V85, P1, DOI 10.1016/j.isprsjprs.2013.07.009
   Chinchor N., 1992, P 4 MESS UND C, P22, DOI DOI 10.3115/1072064.1072067
   Coates A., 2011, P 14 INT C ART INT S, P215, DOI DOI 10.1109/ICDAR.2011.95
   Colditz RR, 2012, INT J REMOTE SENS, V33, P6426, DOI 10.1080/01431161.2012.688148
   Demir B, 2013, IEEE T GEOSCI REMOTE, V51, P300, DOI 10.1109/TGRS.2012.2195727
   Desclee B, 2006, REMOTE SENS ENVIRON, V102, P1, DOI 10.1016/j.rse.2006.01.013
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Doxani G, 2012, INT J APPL EARTH OBS, V15, P38, DOI 10.1016/j.jag.2011.07.002
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gao F, 2012, INT J REMOTE SENS, V33, P7609, DOI 10.1080/01431161.2012.700424
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Hadsell R, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P628, DOI 10.1109/IROS.2008.4651217
   Hebel M, 2013, ISPRS J PHOTOGRAMM, V86, P52, DOI 10.1016/j.isprsjprs.2013.09.005
   Hecheltjen A, 2014, REMOTE SENS DIGIT IM, V18, P145, DOI 10.1007/978-94-007-7969-3_10
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hulley G, 2014, REMOTE SENS ENVIRON, V140, P755, DOI 10.1016/j.rse.2013.10.014
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P1432, DOI 10.1109/TGRS.2007.893568
   Jensen J. R., 1987, PHOTOGRAMM ENG REMOT
   Jin SM, 2013, REMOTE SENS ENVIRON, V132, P159, DOI 10.1016/j.rse.2013.01.012
   Kit O, 2013, ISPRS J PHOTOGRAMM, V83, P130, DOI 10.1016/j.isprsjprs.2013.06.009
   Klaric MN, 2013, IEEE T GEOSCI REMOTE, V51, P2067, DOI 10.1109/TGRS.2013.2243840
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Le Hegarat-Mascle S, 2005, REMOTE SENS ENVIRON, V95, P464, DOI 10.1016/j.rse.2005.01.011
   Lee H., 2008, NIPS, P873
   Li XD, 2015, PHOTOGRAMM ENG REM S, V81, P59, DOI 10.14358/PERS.81.1.59
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Schneider A, 2012, REMOTE SENS ENVIRON, V124, P689, DOI 10.1016/j.rse.2012.06.006
   Stramondo S, 2006, INT J REMOTE SENS, V27, P4433, DOI 10.1080/01431160600675895
   Tang JX, 2015, IEEE T GEOSCI REMOTE, V53, P1174, DOI 10.1109/TGRS.2014.2335751
   Teo TA, 2013, INT J REMOTE SENS, V34, P968, DOI 10.1080/01431161.2012.714504
   Tewkesbury AP, 2015, REMOTE SENS ENVIRON, V160, P1, DOI 10.1016/j.rse.2015.01.006
   Tian J, 2013, ISPRS J PHOTOGRAMM, V79, P226, DOI 10.1016/j.isprsjprs.2013.02.017
   Vincent P., 2008, P 25 INT C MACH LEAR, V1096, P1103, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Weston J., 2008, P 25 ICML, P160, DOI [10.1145/1390156.1390177, 10.1145/ 1390156.1390177, DOI 10.1145/1390156.1390177]
   Xian G, 2010, REMOTE SENS ENVIRON, V114, P1676, DOI 10.1016/j.rse.2010.02.018
   Xu Y., 2013, 8 INT S MULT IM PROC
   Yousif O, 2013, IEEE T GEOSCI REMOTE, V51, P2032, DOI 10.1109/TGRS.2013.2245900
   Zhu Z, 2014, REMOTE SENS ENVIRON, V144, P152, DOI 10.1016/j.rse.2014.01.011
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
   Zou W. Y., 2011, WORKSH DEEP LEARN UN
NR 60
TC 153
Z9 160
U1 29
U2 259
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0924-2716
EI 1872-8235
J9 ISPRS J PHOTOGRAMM
JI ISPRS-J. Photogramm. Remote Sens.
PD JUN
PY 2016
VL 116
BP 24
EP 41
DI 10.1016/j.isprsjprs.2016.02.013
PG 18
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA DK0TH
UT WOS:000374624600003
DA 2022-01-04
ER

PT J
AU Chen, H
   Hua, Y
   Ren, QL
   Zhang, Y
AF Chen, Hao
   Hua, Yi
   Ren, Qinglong
   Zhang, Ye
TI Comprehensive analysis of regional human-driven environmental change
   with multitemporal remote sensing images using observed object-specified
   dynamic Bayesian network
SO JOURNAL OF APPLIED REMOTE SENSING
LA English
DT Article
DE remote sensing image; comprehensive analysis; dynamic Bayesian network;
   multitemporal data processing
ID UNSUPERVISED CHANGE DETECTION; LAND-COVER TRANSITIONS; NEURAL-NETWORKS;
   VEGETATION CHANGES; INFORMATION; CLASSIFICATION; RECOGNITION; SYSTEM
AB Traditional remote sensing change-detection algorithms only generate change-detection map and few quantitative evaluation indicators as the results, but they are unable to provide comprehensive analysis and further understanding of the detected changes. Aiming to assess regional development, we develop a comprehensive analysis method for human-driven environmental change by multitemporal remote sensing images. In order to adapt to analyze the time-varying multiple changed objects, an observed object-specified dynamic Bayesian network (i.e., OOS-DBN) is first proposed to adjust DBN structure and variables. Using semantic analysis for the relationship between multiple changed objects and regional development, all levels of situations and evidences (i.e., detected attributes of changed objects) are extracted as hidden variables and observed variables and inputted to OOS-DBN. Furthermore, conditional probabilities are computed by levels and time slices in OOS-DBN, resulting in the comprehensive analysis results. The experiments on the coastal region in Huludao, China, from 2003 to 2014 demonstrate that comprehensive analysis of changes reflecting that reclamation, construction of infrastructure, and New Huludao port contributed to the regional development. During four time slices, this region experienced rapid and medium-speed development, whose corresponding probabilities are 0.90, 0.87, 0.41, and 0.54, respectively, which is consistent with our field surveys. (C) 2016 Society of Photo-Optical Instrumentation Engineers (SPIE)
C1 [Chen, Hao; Hua, Yi; Ren, Qinglong; Zhang, Ye] Harbin Inst Technol, Dept Informat Engn, West Dazhi St 92, Harbin 150001, Peoples R China.
RP Chen, H (corresponding author), Harbin Inst Technol, Dept Informat Engn, West Dazhi St 92, Harbin 150001, Peoples R China.
EM hit_hao@hit.edu.cn
FU National High Technology Research and Development Program of China (863
   Program)National High Technology Research and Development Program of
   China [2012AA12A405]; National Science Foundation of ChinaNational
   Natural Science Foundation of China (NSFC) [61102159]
FX This work was supported in part by a grant from the National High
   Technology Research and Development Program of China (863 Program) (No.
   2012AA12A405) and the National Science Foundation of China (No.
   61102159).
CR An L, 2013, IEEE J EM SEL TOP C, V3, P155, DOI 10.1109/JETCAS.2013.2256752
   Anees A, 2014, IEEE J-STARS, V7, P3713, DOI 10.1109/JSTARS.2014.2330830
   Bagan H, 2010, IEEE J-STARS, V3, P168, DOI 10.1109/JSTARS.2010.2046627
   Bovolo F, 2012, IEEE T GEOSCI REMOTE, V50, P2196, DOI 10.1109/TGRS.2011.2171493
   Bruzzone L, 2000, INT J REMOTE SENS, V21, P817, DOI 10.1080/014311600210614
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2010, IEEE GEOSCI REMOTE S, V7, P386, DOI 10.1109/LGRS.2009.2037024
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   CHAVEZ PS, 1994, PHOTOGRAMM ENG REM S, V60, P571
   Chen JW, 2013, J MAR SCI TECH-TAIW, V21, P442, DOI 10.6119/JMST-012-0709-2
   Chesnokova O, 2013, IEEE GEOSCI REMOTE S, V10, P303, DOI 10.1109/LGRS.2012.2203783
   CIHLAR J, 1992, INT J REMOTE SENS, V13, P401, DOI 10.1080/01431169208904045
   Demir B, 2012, IEEE T GEOSCI REMOTE, V50, P1930, DOI 10.1109/TGRS.2011.2168534
   Du PJ, 2012, IEEE J-STARS, V5, P1076, DOI 10.1109/JSTARS.2012.2200879
   Durbha SS, 2010, IEEE GEOSCI REMOTE S, V7, P43, DOI 10.1109/LGRS.2009.2028585
   Fernandez-Prieto D, 2011, IEEE T GEOSCI REMOTE, V49, P5016, DOI 10.1109/TGRS.2011.2154336
   Ghosh A, 2013, IEEE T IMAGE PROCESS, V22, P3087, DOI 10.1109/TIP.2013.2259833
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Gueguen L, 2011, IEEE T GEOSCI REMOTE, V49, P4503, DOI 10.1109/TGRS.2011.2141999
   Hame T, 1998, INT J REMOTE SENS, V19, P1079, DOI 10.1080/014311698215612
   Jia L, 2015, IEEE T GEOSCI REMOTE, V53, P3960, DOI 10.1109/TGRS.2015.2388495
   Klaric MN, 2013, IEEE T GEOSCI REMOTE, V51, P2067, DOI 10.1109/TGRS.2013.2243840
   Latifovic R, 2014, IEEE J-STARS, V7, P3380, DOI 10.1109/JSTARS.2014.2321058
   Li J, 2004, IEEE T GEOSCI REMOTE, V42, P673, DOI 10.1109/TGRS.2004.824221
   Liu SC, 2015, IEEE T GEOSCI REMOTE, V53, P244, DOI 10.1109/TGRS.2014.2321277
   Maiti A, 2015, IEEE T NANOBIOSCI, V14, P95, DOI 10.1109/TNB.2014.2361838
   Qu YH, 2014, IEEE J-STARS, V7, P222, DOI 10.1109/JSTARS.2013.2259472
   Richards J., 2006, REMOTE SENSING DIGIT
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Shah VP, 2007, IEEE T GEOSCI REMOTE, V45, P875, DOI 10.1109/TGRS.2007.892005
   Shah VP, 2010, IEEE GEOSCI REMOTE S, V7, P18, DOI 10.1109/LGRS.2009.2020519
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Wang ZW, 2011, IEEE T SIGNAL PROCES, V59, P1553, DOI 10.1109/TSP.2010.2103071
NR 35
TC 4
Z9 4
U1 5
U2 29
PU SPIE-SOC PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
PI BELLINGHAM
PA 1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98225 USA
SN 1931-3195
J9 J APPL REMOTE SENS
JI J. Appl. Remote Sens.
PD MAR 7
PY 2016
VL 10
AR 016021
DI 10.1117/1.JRS.10.016021
PG 23
WC Environmental Sciences; Remote Sensing; Imaging Science & Photographic
   Technology
SC Environmental Sciences & Ecology; Remote Sensing; Imaging Science &
   Photographic Technology
GA DJ4NU
UT WOS:000374183800001
DA 2022-01-04
ER

PT J
AU Wang, QM
   Shi, WZ
   Atkinson, PM
   Li, ZB
AF Wang, Qunming
   Shi, Wenzhong
   Atkinson, Peter M.
   Li, Zhongbin
TI Land Cover Change Detection at Subpixel Resolution With a Hopfield
   Neural Network
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Hopfield neural network (HNN); land cover change detection (LCCD);
   subpixel mapping (SPM); super-resolution mapping
ID MARKOV-RANDOM-FIELD; REMOTELY-SENSED IMAGES; SPECTRAL MIXTURE ANALYSIS;
   PIXEL-SWAPPING ALGORITHM; HYPERSPECTRAL IMAGES; SPATIAL-RESOLUTION;
   ATTRACTION MODEL; FRACTION IMAGES; SENSING IMAGES; SHIFTED IMAGES
AB In this paper, a new subpixel resolution land cover change detection (LCCD) method based on the Hopfield neural network (HNN) is proposed. The new method borrows information from a known fine spatial resolution land cover map (FSRM) representing one date for subpixel mapping (SPM) from a coarse spatial resolution image on another, closer date. It is implemented by using the thematic information in the FSRM to modify the initialization of neuron values in the original HNN. The predicted SPM result was compared to the original FSRM to achieve subpixel resolution LCCD. The proposed method was compared with the original unmodified HNN method as well as six state-of-the-art methods for LCCD. To explore the effect of uncertainty in spectral unmixing, which mainly originates from spectral separability in the input, coarse image, and the point spread function (PSF) of the sensor, a set of synthetic multispectral images with different class separabilities and PSFs was used in experiments. It was found that the proposed LCCD method (i.e., HNN with an FSRM) can separate more real changes from noise and produce more accurate LCCD results than the state-of-the-art methods. The advantage of the proposed method is more evident when the class separability is small and the variance in the PSF is large, that is, the uncertainty in spectral unmixing is large. Furthermore, the utilization of an FSRM can expedite the HNN-based processing required for LCCD. The advantage of the proposed method was also validated by applying to a set of real Landsat-Moderate Resolution Imaging Spectroradiometer (MODIS) images.
C1 [Wang, Qunming; Li, Zhongbin] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Kowloon, Hong Kong, Peoples R China.
   [Shi, Wenzhong] Hong Kong Polytech Univ, Kowloon, Hong Kong, Peoples R China.
   [Shi, Wenzhong] Wuhan Univ, Wuhan 430072, Peoples R China.
   [Atkinson, Peter M.] Univ Southampton, Geog & Environm, Southampton SO17 1BJ, Hants, England.
RP Shi, WZ (corresponding author), Hong Kong Polytech Univ, Kowloon, Hong Kong, Peoples R China.
EM wqm11111@126.com; lswzshi@polyu.edu.hk; P.M.Atkinson@soton.ac.uk;
   lzbtongji@gmail.com
FU Research Grants Council, Hong KongHong Kong Research Grants Council
   [PolyU 5249/12E]; Ministry of Science and Technology of ChinaMinistry of
   Science and Technology, China [2012BAJ15B04, 2012AA12A305]; National
   Natural Science Foundation of ChinaNational Natural Science Foundation
   of China (NSFC) [41331175]
FX This work was supported in part by the Research Grants Council, Hong
   Kong, under Grant PolyU 5249/12E, in part by the Ministry of Science and
   Technology of China under Grant 2012BAJ15B04 and Project 2012AA12A305,
   and in part by the National Natural Science Foundation of China under
   Grant 41331175.
CR Anderson LO, 2005, INT J REMOTE SENS, V26, P2251, DOI 10.1080/01431160310001620795
   Ardila JP, 2011, ISPRS J PHOTOGRAMM, V66, P762, DOI 10.1016/j.isprsjprs.2011.08.002
   Atkinson P. M., 2006, REMOTE SENSING IMAGE, P51
   Atkinson PM, 2013, INT J APPL EARTH OBS, V22, P106, DOI 10.1016/j.jag.2012.04.012
   Atkinson PM, 2009, INT J REMOTE SENS, V30, P5293, DOI 10.1080/01431160903131034
   Atkinson PM, 2005, PHOTOGRAMM ENG REM S, V71, P839, DOI 10.14358/PERS.71.7.839
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Boucher A, 2008, IEEE T GEOSCI REMOTE, V46, P272, DOI 10.1109/TGRS.2007.907102
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Collins M, 2004, IEEE GEOSCI REMOTE S, V1, P318, DOI 10.1109/LGRS.2004.836258
   Foody GM, 2007, PHOTOGRAMM ENG REM S, V73, P923, DOI 10.14358/PERS.73.8.923
   Foody GM, 2005, INT J REMOTE SENS, V26, P5381, DOI 10.1080/01431160500213292
   Gao F, 2006, IEEE T GEOSCI REMOTE, V44, P2207, DOI 10.1109/TGRS.2006.872081
   Ge Y, 2009, IEEE T GEOSCI REMOTE, V47, P2155, DOI 10.1109/TGRS.2008.2010863
   Gu YF, 2008, IEEE T GEOSCI REMOTE, V46, P1347, DOI 10.1109/TGRS.2008.917270
   Haertel V, 2004, INT J REMOTE SENS, V25, P5473, DOI 10.1080/01431160412331269751
   Halimi A, 2011, IEEE T GEOSCI REMOTE, V49, P4153, DOI 10.1109/TGRS.2010.2098414
   Hilker T, 2009, REMOTE SENS ENVIRON, V113, P1613, DOI 10.1016/j.rse.2009.03.007
   Hussain M, 2013, ISPRS J PHOTOGRAMM, V80, P91, DOI 10.1016/j.isprsjprs.2013.03.006
   Jia XP, 2014, IEEE J-STARS, V7, P1947, DOI 10.1109/JSTARS.2013.2264313
   Jin HR, 2012, INT J REMOTE SENS, V33, P7747, DOI 10.1080/01431161.2012.702234
   Kasetkasem T, 2005, REMOTE SENS ENVIRON, V96, P302, DOI 10.1016/j.rse.2005.02.006
   Li XD, 2014, IEEE T GEOSCI REMOTE, V52, P2810, DOI 10.1109/TGRS.2013.2266345
   Li XD, 2014, IEEE J-STARS, V7, P29, DOI 10.1109/JSTARS.2013.2264828
   Li XD, 2012, INT J REMOTE SENS, V33, P7886, DOI 10.1080/01431161.2012.703347
   Ling F, 2013, REMOTE SENS LETT, V4, P629, DOI 10.1080/2150704X.2013.781284
   Ling F, 2011, IEEE GEOSCI REMOTE S, V8, P182, DOI 10.1109/LGRS.2010.2055034
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lu DS, 2004, CAN J REMOTE SENS, V30, P87, DOI 10.5589/m03-055
   Macleod RD, 1998, PHOTOGRAMM ENG REM S, V64, P207
   Mahmood Z, 2013, IEEE J-STARS, V6, P779, DOI 10.1109/JSTARS.2012.2236539
   Makido Y, 2007, PHOTOGRAMM ENG REM S, V73, P1233, DOI 10.14358/PERS.73.11.1233
   Mertens KC, 2004, REMOTE SENS ENVIRON, V91, P225, DOI 10.1016/j.rse.2004.03.003
   Mertens KC, 2003, INT J REMOTE SENS, V24, P4241, DOI 10.1080/01431160310001595073
   Mertens KC, 2006, INT J REMOTE SENS, V27, P3293, DOI 10.1080/01431160500497127
   Muad AM, 2012, IEEE J-STARS, V5, P1418, DOI 10.1109/JSTARS.2012.2191145
   Nguyen MQ, 2006, IEEE T GEOSCI REMOTE, V44, P736, DOI 10.1109/TGRS.2005.861752
   Nigussie D, 2011, INT J REMOTE SENS, V32, P7203, DOI 10.1080/01431161.2010.519740
   Shao Y, 2011, IEEE J-STARS, V4, P336, DOI 10.1109/JSTARS.2010.2062173
   Shen ZQ, 2009, PHOTOGRAMM ENG REM S, V75, P557, DOI 10.14358/PERS.75.5.557
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Song HH, 2013, IEEE T GEOSCI REMOTE, V51, P1883, DOI 10.1109/TGRS.2012.2213095
   Su YF, 2012, IEEE J-STARS, V5, P1428, DOI 10.1109/JSTARS.2012.2216514
   Tatem A. J., 2001, INT J APPL EARTH OBS, V3, P184, DOI DOI 10.1016/S0303-2434(01)85010-8
   Tatem AJ, 2001, IEEE T GEOSCI REMOTE, V39, P781, DOI 10.1109/36.917895
   Tatem AJ, 2002, REMOTE SENS ENVIRON, V79, P1, DOI 10.1016/S0034-4257(01)00229-2
   Tolpekin VA, 2009, IEEE T GEOSCI REMOTE, V47, P3283, DOI 10.1109/TGRS.2009.2019126
   Tong XH, 2013, IEEE T GEOSCI REMOTE, V51, P2799, DOI 10.1109/TGRS.2012.2218612
   Van der Meer F, 2012, INT J REMOTE SENS, V33, P5644, DOI 10.1080/01431161.2012.666363
   Verhoeye J, 2002, REMOTE SENS ENVIRON, V79, P96, DOI 10.1016/S0034-4257(01)00242-5
   Villa A, 2013, PATTERN RECOGN, V46, P1556, DOI 10.1016/j.patcog.2012.10.030
   Wang LG, 2013, IEEE T GEOSCI REMOTE, V51, P3558, DOI 10.1109/TGRS.2012.2225841
   Wang LG, 2013, IEEE GEOSCI REMOTE S, V10, P598, DOI 10.1109/LGRS.2012.2215573
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P1692, DOI 10.1109/TGRS.2014.2346535
   Wang QM, 2015, IEEE T GEOSCI REMOTE, V53, P309, DOI 10.1109/TGRS.2014.2321834
   Wang QM, 2014, ISPRS J PHOTOGRAMM, V92, P1, DOI 10.1016/j.isprsjprs.2014.02.012
   Wang QM, 2014, IEEE T GEOSCI REMOTE, V52, P2940, DOI 10.1109/TGRS.2013.2267802
   Wang QM, 2014, IEEE GEOSCI REMOTE S, V11, P798, DOI 10.1109/LGRS.2013.2279138
   Wang QM, 2014, IEEE J-STARS, V7, P327, DOI 10.1109/JSTARS.2013.2262927
   Wang QM, 2012, INT J REMOTE SENS, V33, P6480, DOI 10.1080/01431161.2012.690541
   Xu X, 2014, NEUROCOMPUTING, V134, P79, DOI 10.1016/j.neucom.2012.12.078
   Xu Y, 2014, IEEE GEOSCI REMOTE S, V11, P474, DOI 10.1109/LGRS.2013.2268153
   Zhang LP, 2008, NEUROCOMPUTING, V71, P2046, DOI 10.1016/j.neucom.2007.08.033
   Zhong YF, 2012, IEEE T SYST MAN CY B, V42, P1306, DOI 10.1109/TSMCB.2012.2189561
   Zhu XL, 2010, REMOTE SENS ENVIRON, V114, P2610, DOI 10.1016/j.rse.2010.05.032
NR 65
TC 48
Z9 49
U1 4
U2 59
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD MAR
PY 2015
VL 8
IS 3
BP 1339
EP 1352
DI 10.1109/JSTARS.2014.2355832
PG 14
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA CF1BS
UT WOS:000352279200036
DA 2022-01-04
ER

PT J
AU Zhong, YF
   Liu, WF
   Zhao, J
   Zhang, LP
AF Zhong, Yanfei
   Liu, Wenfeng
   Zhao, Ji
   Zhang, Liangpei
TI Change Detection Based on Pulse-Coupled Neural Networks and the NMI
   Feature for High Spatial Resolution Remote Sensing Imagery
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Change detection; high spatial resolution (HSR) imagery; normalized
   moment of inertia (NMI) feature; pulse-coupled neural networks (PCNN);
   remote sensing
ID UNSUPERVISED CHANGE DETECTION; SATELLITE IMAGERY; SEGMENTATION;
   TRANSLATION; FRAMEWORK; ROTATION; SCALE; PCNN
AB In this letter, a change detection algorithm based on pulse-coupled neural networks (PCNN) and the normalized moment of inertia (NMI) feature is proposed for high spatial resolution (HSR) remote sensing imagery. To better analyze a large remote sensing image, the whole image is divided into blocks by the use of a deblocking mechanism. The PCNN model is utilized to obtain the initial binary image, and the NMI feature is calculated based on the binary image to detect the hot spot changed areas. Finally, the changed areas are processed by expectation-maximization to obtain the final change map. The experimental results using QuickBird and IKONOS images demonstrate that the proposed algorithm has the ability to provide better change detection results for HSR images than the traditional PCNN change detection algorithms.
C1 [Zhong, Yanfei; Liu, Wenfeng; Zhao, Ji; Zhang, Liangpei] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
RP Zhong, YF (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
EM zhongyanfei@whu.edu.cn; liufeng4652177@163.com; zhaoji2015@gmail.com;
   zlp62@whu.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [41371344]; Foundation for the Author of
   National Excellent Doctoral Dissertation of the People's Republic of
   China (FANEDD)Foundation for the Author of National Excellent Doctoral
   Dissertation of China [201052]; Fundamental Research Funds for the
   Central UniversitiesFundamental Research Funds for the Central
   Universities [2042014kf00231]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 41371344, by the Foundation for the
   Author of National Excellent Doctoral Dissertation of the People's
   Republic of China (FANEDD) under Grant 201052, and by the Fundamental
   Research Funds for the Central Universities under Grant 2042014kf00231.
CR Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2013, P IEEE, V101, P609, DOI 10.1109/JPROC.2012.2197169
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Chen Y, 2011, IEEE T NEURAL NETWOR, V22, P880, DOI 10.1109/TNN.2011.2128880
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Ekblad U, 2004, SIGNAL PROCESS, V84, P1131, DOI 10.1016/j.sigpro.2004.03.012
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Karvonen JA, 2004, IEEE T GEOSCI REMOTE, V42, P1566, DOI 10.1109/TGRS.2004.828179
   Klaric MN, 2013, IEEE T GEOSCI REMOTE, V51, P2067, DOI 10.1109/TGRS.2013.2243840
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Lindblad T., 2005, IMAGE PROCESSING USI
   Mura MD, 2008, IEEE GEOSCI REMOTE S, V5, P433, DOI 10.1109/LGRS.2008.917726
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Pacifici F, 2010, IEEE GEOSCI REMOTE S, V7, P58, DOI 10.1109/LGRS.2009.2021780
   Torres-Mendez LA, 2000, IEEE T SYST MAN CY C, V30, P125, DOI 10.1109/5326.827484
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Wang ZB, 2010, IMAGE VISION COMPUT, V28, P5, DOI 10.1016/j.imavis.2009.06.007
   Yetgin Z, 2012, IEEE T GEOSCI REMOTE, V50, P1919, DOI 10.1109/TGRS.2011.2168230
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhang Y, 2011, J OPT SOC AM B, V28, P28, DOI 10.1364/JOSAB.28.000028
NR 24
TC 26
Z9 29
U1 4
U2 54
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD MAR
PY 2015
VL 12
IS 3
BP 537
EP 541
DI 10.1109/LGRS.2014.2349937
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA AT5NE
UT WOS:000344988800020
DA 2022-01-04
ER

PT J
AU Roy, M
   Ghosh, S
   Ghosh, A
AF Roy, Moumita
   Ghosh, Susmita
   Ghosh, Ashish
TI A Neural Approach Under Active Learning Mode for Change Detection in
   Remotely Sensed Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Active learning; change detection; neural networks
ID ALGORITHM
AB In this paper, a change detection technique using neural networks in active learning framework is proposed under the scarcity of labeled patterns. In the present investigation, two variants of radial basis function neural networks and a multilayer perceptron are used as learners. Instead of training the network (or ensemble of networks) with randomly collected labeled patterns, in the proposed work, the network (or ensemble of networks) is iteratively trained with label patterns, collected using the query functions. Here, two query selection strategies are used: uncertainty sampling and query-by-committee. In this way, the most informative set of labeled patterns can be iteratively generated by querying. To evaluate the effectiveness of the proposed approach, the experiments are conducted on multi-temporal remotely sensed images. The results obtained using the proposed active learning framework are found to be encouraging.
C1 [Roy, Moumita; Ghosh, Susmita] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
   [Ghosh, Ashish] Indian Stat Inst, Ctr Soft Comp Res, Kolkata 700108, India.
RP Roy, M (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
EM moumita2009.roy@gmail.com; susmitaghoshju@gmail.com; ash@isical.ac.in
OI Roy, Moumita/0000-0002-4176-5961; GHOSH, SUSMITA/0000-0002-1691-761X;
   GHOSH, ASHISH/0000-0003-1548-5576
FU Council of Scientific and Industrial Research (CSIR), IndiaCouncil of
   Scientific & Industrial Research (CSIR) - India [09/096(0684)2k11-EMR-I]
FX The authors would like to thank the reviewers for their thorough and
   constructive comments which helped to enhance the quality of this paper.
   They are grateful to Prof. L. Bruzzone for providing the data. M. Roy is
   grateful to the Council of Scientific and Industrial Research (CSIR),
   India for providing her a Senior Research Fellowship (No.
   09/096(0684)2k11-EMR-I).
CR Chapelle O., 2006, SEMISUPERVISED LEARN
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1007/BF00993277
   Ghosh A, 2011, INFORM SCIENCES, V181, P699, DOI 10.1016/j.ins.2010.10.016
   Ghosh S, 2009, INT J APPROX REASON, V50, P37, DOI 10.1016/j.ijar.2008.01.008
   Haykin S., 2007, NEURAL NETWORKS COMP, V3rd
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Kuncheva L.I., 2004, COMBINING PATTERN CL
   Lewis D. D., 1994, P INT C MACH LEARN S, P148, DOI DOI 10.1016/B978-1-55860-335-6.50026-X
   Mak MW, 2000, IEEE T NEURAL NETWOR, V11, P961, DOI 10.1109/72.857775
   Olsson F., 2009, T2009 SICS
   Patra S, 2008, FUND INFORM, V84, P429
   Persello C, 2013, IEEE GEOSCI REMOTE S, V10, P736, DOI 10.1109/LGRS.2012.2220516
   Sarimveis H, 2006, ADV ENG SOFTW, V37, P218, DOI 10.1016/j.advengsoft.2005.07.005
   Settles B., 2009, 1648 U WISC
   Settles B., 2008, ADV NEURAL INFORM PR, P1289
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
NR 17
TC 13
Z9 13
U1 2
U2 19
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD APR
PY 2014
VL 7
IS 4
BP 1200
EP 1206
DI 10.1109/JSTARS.2013.2293175
PG 7
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA AG4LB
UT WOS:000335390000018
DA 2022-01-04
ER

PT J
AU Salmon, BP
   Olivier, JC
   Kleynhans, W
   Wessels, KJ
   van den Bergh, F
   Steenkamp, KC
AF Salmon, B. P.
   Olivier, J. C.
   Kleynhans, W.
   Wessels, K. J.
   van den Bergh, F.
   Steenkamp, K. C.
TI The use of a Multilayer Perceptron for detecting new human settlements
   from a time series of MODIS images
SO INTERNATIONAL JOURNAL OF APPLIED EARTH OBSERVATION AND GEOINFORMATION
LA English
DT Article
DE Change detection; Classification; Feedforward neural networks;
   Satellite; Time series
ID LAND-COVER CHANGE; NEURAL-NETWORK; AVHRR DATA; CLASSIFICATION;
   REFLECTANCE; RESOLUTION; ALGORITHM; ALBEDO; MISR
AB This paper presents a novel land cover change detection method that employs a sliding window over hyper-temporal multi-spectral images acquired from the 7 bands of the MODerate-resolution Imaging Spectroradiometer (MODIS) land surface reflectance product. The method uses a Feedforward Multilayer Perceptron (MLP) for supervised change detection that operates on multi-spectral time series extracted with a sliding window from the dataset. The method was evaluated on both real and simulated land cover change examples. The simulated land cover change comprises of concatenated time series that are produced by blending actual time series of pixels from human settlements to those from adjacent areas covered by natural vegetation. The method employs an iteratively retrained MLP to capture all local patterns and to compensate for the time-varying climate change in the geographical area. The iteratively retrained MLP was compared to a classical batch mode trained MLP. Depending on the length of the temporal sliding window used, an overall change detection accuracy between 83% and 90% was achieved. It is shown that a sliding window of 6 months using all 7 bands of MODIS data is sufficient to detect land cover change reliably. Window sizes of 18 months and longer provide minor improvements to classification accuracy and change detection performance at the cost of longer time delays. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Salmon, B. P.; Olivier, J. C.; Kleynhans, W.] Univ Pretoria, Dept Elect Elect & Comp Engn, ZA-0002 Pretoria, South Africa.
   [Wessels, K. J.; van den Bergh, F.; Steenkamp, K. C.] CSIR, Remote Sensing Res Unit, Meraka Inst, ZA-0002 Pretoria, South Africa.
RP Salmon, BP (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, Lynnwood Rd, ZA-0002 Pretoria, South Africa.
EM bsalmon@csir.co.za
FU CSIR Strategic Research Panel
FX The authors would like to thank Willem Marais of the Remote Sensing
   Research Unit (RSRU) at the CSIR, for his many comments and inputs. The
   research was funded by the CSIR Strategic Research Panel. Alex Fortesque
   and Naledzani Mudau of CSIR, Satellite Application Centre (SAC) provided
   data on settlements. The anonymous reviewers are thanked for their
   comments.
CR Bishop Christopher M., 1996, NEURAL NETWORKS PATT
   Braswell BH, 2003, REMOTE SENS ENVIRON, V87, P243, DOI 10.1016/j.rse.2003.06.002
   Carpenter GA, 1999, REMOTE SENS ENVIRON, V70, P326, DOI 10.1016/S0034-4257(99)00051-6
   Chien S, 2005, IEEE INTELL SYST, V20, P16, DOI 10.1109/MIS.2005.40
   DeFries RS, 2002, GLOBAL CHANGE BIOL, V8, P438, DOI 10.1046/j.1365-2486.2002.00483.x
   DeFries RS, 2000, REMOTE SENS ENVIRON, V74, P503, DOI 10.1016/S0034-4257(00)00142-5
   Foley JA, 2005, SCIENCE, V309, P570, DOI 10.1126/science.1111772
   Friedl MA, 2010, REMOTE SENS ENVIRON, V114, P168, DOI 10.1016/j.rse.2009.08.016
   Gopal S, 1999, REMOTE SENS ENVIRON, V67, P230, DOI 10.1016/S0034-4257(98)00088-1
   Hansen MC, 2004, ECOSYSTEMS, V7, P695, DOI 10.1007/s10021-004-0243-3
   Keogh E, 2005, KNOWL INF SYST, V8, P154, DOI 10.1007/s10115-004-0172-7
   Kleynhans W, 2010, IEEE GEOSCI REMOTE S, V7, P381, DOI 10.1109/LGRS.2009.2036578
   Lhermitte S, 2008, REMOTE SENS ENVIRON, V112, P506, DOI 10.1016/j.rse.2007.05.018
   LOVELAND TR, 1995, ANN ASSOC AM GEOGR, V85, P339, DOI 10.1111/j.1467-8306.1995.tb01798.x
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   Lunetta RS, 2006, REMOTE SENS ENVIRON, V105, P142, DOI 10.1016/j.rse.2006.06.018
   Lunetta RS, 2004, REMOTE SENS ENVIRON, V89, P444, DOI 10.1016/j.rse.2003.10.022
   Nemmour H, 2005, EURASIP J APPL SIG P, V2005, P2187, DOI 10.1155/ASP.2005.2187
   Olsson L, 2005, J ARID ENVIRON, V63, P556, DOI 10.1016/j.jaridenv.2005.03.008
   PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684
   Roy DP, 2005, REMOTE SENS ENVIRON, V97, P137, DOI 10.1016/j.rse.2005.04.007
   Salmon BP, 2011, IEEE J-STARS, V4, P327, DOI 10.1109/JSTARS.2010.2053918
   Schaaf CB, 2002, REMOTE SENS ENVIRON, V83, P135, DOI 10.1016/S0034-4257(02)00091-3
   Schafer, 1999, DISCRETE TIME SIGNAL
   TOWNSHEND JRG, 1988, INT J REMOTE SENS, V9, P187, DOI 10.1080/01431168808954847
   Vanacker V, 2005, GLOBAL ECOL BIOGEOGR, V14, P123, DOI 10.1111/j.1466-822X.2005.00136.x
   Vermaak J, 1998, IEEE T POWER SYST, V13, P126, DOI 10.1109/59.651623
   Wang X., 2005, P MACH LEARN CYB 200, V4, P2050
   Wanner W, 1997, J GEOPHYS RES-ATMOS, V102, P17143, DOI 10.1029/96JD03295
   Westra T, 2007, INT J REMOTE SENS, V28, P1595, DOI 10.1080/01431160600887698
NR 31
TC 26
Z9 27
U1 1
U2 16
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0303-2434
J9 INT J APPL EARTH OBS
JI Int. J. Appl. Earth Obs. Geoinf.
PD DEC
PY 2011
VL 13
IS 6
BP 873
EP 883
DI 10.1016/j.jag.2011.06.007
PG 11
WC Remote Sensing
SC Remote Sensing
GA 830ML
UT WOS:000295661000004
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Pacifici, F
   Del Frate, F
AF Pacifici, Fabio
   Del Frate, Fabio
TI Automatic Change Detection in Very High Resolution Images With
   Pulse-Coupled Neural Networks
SO IEEE GEOSCIENCE AND REMOTE SENSING LETTERS
LA English
DT Article
DE Pulse-coupled neural networks (PCNNs); unsupervised change detection;
   very high resolution (VHR) images
ID SEGMENTATION; SAR
AB A novel approach based on pulse-coupled neural networks (PCNNs) for image change detection is presented. PCNNs are based on the implementation of the mechanisms underlying the visual cortex of small mammals, and, with respect to more traditional NNs architectures, such as multilayer perceptron, own interesting advantages. In particular, they are unsupervised and context sensitive. This latter property may be particularly useful when very high resolution images are considered as, in this case, an object analysis might be more suitable than a pixel-based one. The qualitative and more quantitative results are reported. The performance of the algorithm has been evaluated on a pair of QuickBird images taken over the test area of Tor Vergata University, Rome.
C1 [Pacifici, Fabio; Del Frate, Fabio] Univ Roma Tor Vergata, Comp Sci Syst & Prod Engn Dept, I-00133 Rome, Italy.
RP Pacifici, F (corresponding author), Univ Roma Tor Vergata, Comp Sci Syst & Prod Engn Dept, I-00133 Rome, Italy.
EM f.pacifici@disp.uniroma2.it; delfrate@disp.uniroma2.it
RI Del Frate, Fabio/G-1413-2013
CR Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Ghosh S, 2007, IEEE T GEOSCI REMOTE, V45, P778, DOI 10.1109/TGRS.2006.888861
   Gu XD, 2004, PATTERN RECOGN LETT, V25, P1075, DOI 10.1016/j.patrec.2004.03.005
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Karvonen JA, 2004, IEEE T GEOSCI REMOTE, V42, P1566, DOI 10.1109/TGRS.2004.828179
   Kuntimad G, 1999, IEEE T NEURAL NETWOR, V10, P591, DOI 10.1109/72.761716
   Lindblad T., 2005, IMAGE PROCESSING USI
   Mura MD, 2008, IEEE GEOSCI REMOTE S, V5, P433, DOI 10.1109/LGRS.2008.917726
   Pacifici F, 2008, IEEE GEOSCI REMOTE S, V5, P331, DOI 10.1109/LGRS.2008.915939
   Pacifici F, 2007, IEEE T GEOSCI REMOTE, V45, P2940, DOI 10.1109/TGRS.2007.902824
   Waldemark K, 2000, PATTERN RECOGN LETT, V21, P227, DOI 10.1016/S0167-8655(99)00152-X
NR 11
TC 58
Z9 61
U1 1
U2 25
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1545-598X
EI 1558-0571
J9 IEEE GEOSCI REMOTE S
JI IEEE Geosci. Remote Sens. Lett.
PD JAN
PY 2010
VL 7
IS 1
BP 58
EP 62
DI 10.1109/LGRS.2009.2021780
PG 5
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA 575PI
UT WOS:000276079000012
OA Green Submitted
DA 2022-01-04
ER

PT J
AU Tong, XH
   Zhang, X
   Liu, ML
AF Tong, Xiaohua
   Zhang, Xue
   Liu, Miaolong
TI Detection of urban sprawl using a genetic algorithm-evolved artificial
   neural network classification in remote sensing: a case study in Jiading
   and Putuo districts of Shanghai, China
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID LAND-COVER CLASSIFICATION; ACCURACY; IMAGERY
AB Urban sprawl results in the most complex process of land use and land cover change, which in turn has a compound impact on the structure and function of ecosystems in urban areas. The detection of urban sprawl based on remote sensing was studied in two districts of Shanghai, China. The study area includes Jiading district which is one of the fastest developing urban fringe areas, and Putuo district which is one of the downtown areas in Shanghai. The structure of the artificial backpropagation neural network (BPN) classifier was evolved by genetic algorithm (GA), including the connection values between neurons, hidden layer numbers and their neurons, and neuron correction values in all layers. A comparison of the proposed method was made with conventional classification methods such as the minimum distance (MD) classifier, maximum likelihood (ML) classifier and improved backpropagation neural network classifier. The result shows that the proposed approach has higher accuracy and reliability for the classification of remotely sensed data. Therefore, three epochs of Landsat Thematic Mapper (TM) imageries of the study area were selected in 1990, 2000 and 2006, and the changes of urban lands for different time intervals were detected. A comparison of the two districts and their towns was also made, which characterizes urban sprawl in the typical urban fringe and downtown areas of Shanghai.
C1 [Tong, Xiaohua; Zhang, Xue; Liu, Miaolong] Tongji Univ, Dept Surveying & Geoinformat, Shanghai 200092, Peoples R China.
   [Tong, Xiaohua] Tongji Univ, Key Lab Modern Engn Surveying, State Bur Surveying & Mapping, Shanghai 200092, Peoples R China.
RP Tong, XH (corresponding author), Tongji Univ, Dept Surveying & Geoinformat, Shanghai 200092, Peoples R China.
EM xhtong@tongji.edu.cn
FU National Natural Science Foundation of ChinaNational Natural Science
   Foundation of China (NSFC) [40771174]; High-tech Research and
   Development Program of ChinaNational High Technology Research and
   Development Program of China [2009AA12Z131]; Foundation of Shanghai Dawn
   Scholarship and Rising-star Program [07SG24, 08QH14022]
FX We thank the anonymous reviewers for their insight and critical review
   of the manuscript. The work described in this paper was substantially
   supported by the National Natural Science Foundation of China (Project
   No. 40771174), the High-tech Research and Development Program of China
   (Project No. 2009AA12Z131), and Foundation of Shanghai Dawn Scholarship
   and Rising-star Program (Project No. 07SG24 and 08QH14022).
CR Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700
   Bandyopadhyay S, 2002, PATTERN RECOGN, V35, P1197, DOI 10.1016/S0031-3203(01)00108-X
   Bandyopadhyay S, 2001, IEEE T GEOSCI REMOTE, V39, P303, DOI 10.1109/36.905238
   Banko G, 1998, IR98081 IIASA
   Barrios D, 2003, NEURAL COMPUT APPL, V12, P49, DOI 10.1007/s00521-003-0364-1
   Bhattacharya U, 1997, INT J REMOTE SENS, V18, P3379, DOI 10.1080/014311697216937
   Blanco A, 2001, NEURAL NETWORKS, V14, P93, DOI 10.1016/S0893-6080(00)00081-2
   Blanco A, 2000, INT J APPROX REASON, V23, P67, DOI 10.1016/S0888-613X(99)00032-8
   Chen J, 2003, PHOTOGRAMM ENG REM S, V69, P369, DOI 10.14358/PERS.69.4.369
   CHEN KS, 1995, PHOTOGRAMM ENG REM S, V61, P403
   Chipman J. W., 2003, REMOTE SENSING IMAGE
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   El-Gamily HI, 2007, INT J REMOTE SENS, V28, P1773, DOI 10.1080/01431160600784275
   Epstein J, 2002, PHOTOGRAMM ENG REM S, V68, P913
   Erbek FS, 2004, INT J REMOTE SENS, V25, P1733, DOI 10.1080/0143116031000150077
   Fan FL, 2007, SENSORS-BASEL, V7, P1323, DOI 10.3390/s7071323
   Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764
   FOODY GM, 1995, PHOTOGRAMM ENG REM S, V61, P391
   Foody GM, 2004, INT J REMOTE SENS, V25, P3091, DOI 10.1080/01431160310001648019
   Garcia-Pedrajas N, 2003, IEEE T NEURAL NETWOR, V14, P575, DOI 10.1109/TNN.2003.810618
   Garcia-Pedrajas N, 2006, NEURAL NETWORKS, V19, P514, DOI 10.1016/j.neunet.2005.08.014
   Goldberg D. E., 1989, Complex Systems, V3, P153
   Goldberg D. E., 1989, Complex Systems, V3, P129
   Goldberg D.E., 1989, GENETIC ALGORITHMS S
   GONG P, 1992, INT J REMOTE SENS, V13, P773, DOI 10.1080/01431169208904151
   GONG P, 1993, CANADIAN J REMOTE SE, V1, P22
   Im J, 2005, REMOTE SENS ENVIRON, V99, P326, DOI 10.1016/j.rse.2005.09.008
   Janson D. J., 1992, Journal of Systems Engineering, V2, P272
   JANSON DJ, 1993, IEEE EXPERT, V8, P26, DOI 10.1109/64.236478
   Jat MK, 2008, INT J APPL EARTH OBS, V10, P26, DOI 10.1016/j.jag.2007.04.002
   Kavzoglu T, 2003, INT J REMOTE SENS, V24, P4907, DOI 10.1080/0143116031000114851
   Leung FHF, 2003, IEEE T NEURAL NETWOR, V14, P79, DOI 10.1109/TNN.2002.804317
   Ling SH, 2007, SOFT COMPUT, V11, P1033, DOI 10.1007/s00500-007-0151-5
   Liu GP, 1999, IEE P-CONTR THEOR AP, V146, P373, DOI 10.1049/ip-cta:19990501
   Liu ZJ, 2004, FUTURE GENER COMP SY, V20, P1119, DOI 10.1016/j.future.2003.11.024
   Lo CP, 2002, PHOTOGRAMM ENG REM S, V68, P1073
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu DS, 2005, PHOTOGRAMM ENG REM S, V71, P1275, DOI 10.14358/PERS.71.11.1275
   Lyon JG, 1998, PHOTOGRAMM ENG REM S, V64, P143
   Maktav D, 2005, INT J REMOTE SENS, V26, P655, DOI 10.1080/01431160512331316469
   Masek JG, 2000, INT J REMOTE SENS, V21, P3473, DOI 10.1080/014311600750037507
   Maulik U, 2003, IEEE T GEOSCI REMOTE, V41, P1075, DOI 10.1109/TGRS.2003.810924
   Mundia CN, 2005, INT J REMOTE SENS, V26, P2831, DOI 10.1080/01431160500117865
   Nelson T, 2005, INT J REMOTE SENS, V26, P535, DOI 10.1080/01431160512331314065
   Oh SK, 2006, J FRANKLIN I, V343, P125, DOI 10.1016/j.jfranklin.2005.09.005
   Ostermark R, 2000, FUZZY SET SYST, V114, P311, DOI 10.1016/S0165-0114(98)00057-8
   Ozturk N, 2003, ENG COMPUTATION, V20, P979, DOI 10.1108/02644400310502982
   Pal SK, 2001, INT J REMOTE SENS, V22, P2545, DOI 10.1080/01431160120325
   Paola JD, 1997, PHOTOGRAMM ENG REM S, V63, P535
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rumelhart G.E., 1986, PARALLEL DISTRIBUTED, P318, DOI [DOI 10.1016/B978-1-4832-1446-7.50035-2, DOI 10.1007/978-0-387-39940-9_3246]
   Serra P, 2003, INT J REMOTE SENS, V24, P3311, DOI 10.1080/0143116021000021189
   Sexton RS, 2000, DECIS SUPPORT SYST, V30, P11, DOI 10.1016/S0167-9236(00)00086-5
   SHACKELFORD AK, 2003, IEEE T GEOSCIENCE 1, V10, P2354
   Thomas N, 2003, PHOTOGRAMM ENG REM S, V69, P963, DOI 10.14358/PERS.69.9.963
   Toshniwal M, 2005, 2005 IEEE Networking, Sensing and Control Proceedings, P235
   Tsai JT, 2006, IEEE T NEURAL NETWOR, V17, P69, DOI 10.1109/TNN.2005.860885
   Verbeke LPC, 2004, INT J REMOTE SENS, V25, P2747, DOI 10.1080/01431160310001652385
   Walker JS, 2007, PHOTOGRAMM ENG REM S, V73, P577, DOI 10.14358/PERS.73.5.577
   WHITLEY D, 1990, PARALLEL COMPUT, V14, P347, DOI 10.1016/0167-8191(90)90086-O
   Widyanto MR, 2005, APPL SOFT COMPUT, V6, P72, DOI 10.1016/j.asoc.2004.10.008
   Yang H, 2007, ANIMAL, V1, P213, DOI 10.1017/S1751731107257945
   YAO X, 1993, INT J INTELL SYST, V8, P539, DOI 10.1002/int.4550080406
   Yao X, 1993, Int J Neural Syst, V4, P203, DOI 10.1142/S0129065793000171
   Yao X, 1997, IEEE T NEURAL NETWOR, V8, P694, DOI 10.1109/72.572107
   Zhang Q, 2002, INT J REMOTE SENS, V23, P3057, DOI 10.1080/01431160110104728
NR 67
TC 20
Z9 20
U1 1
U2 22
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PY 2010
VL 31
IS 6
BP 1485
EP 1504
DI 10.1080/01431160903475290
PG 20
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA 592OO
UT WOS:000277389100009
DA 2022-01-04
ER

PT J
AU Del Frate, F
   Pacifici, F
   Solimini, D
AF Del Frate, Fabio
   Pacifici, Fabio
   Solimini, Domenico
TI Monitoring Urban Land Cover in Rome, Italy, and Its Changes by
   Single-Polarization Multitemporal SAR Images
SO IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE
   SENSING
LA English
DT Article
DE Change detection; coherence; feature contribution; land-cover
   classification; neural networks; synthetic aperture radar; texture;
   urban development
ID NEURAL-NETWORKS; AUTOMATIC CLASSIFICATION; TEXTURAL FEATURES;
   ENVIRONMENTS; SELECTION
AB This study contributes an assessment of the potential of single-polarization decametric synthetic aperture radar (SAR) images in classifying land cover within and around large urban areas and in monitoring their changes. The decision task is performed on a pixel basis and is carried out by supervise neural network algorithms fed by radar image features including backscattering intensity, coherence and textural parameters. Two configurations are considered: a short-term classification and change detection scheme intended for providing information in near-real time and a long-term scheme aimed at observing the urban changes at year time scales. We use a pair of interferometric images for the short-term case, while the long-term exercise utilizes two interferometric pairs and a fifth single acquisition. The images are acquired by the ERS SAR in late winter, spring and early summer over 836 square kilometers including Rome, Italy, and its surroundings. The accuracy of the short-term algorithm in discriminating seven types of surface is higher than 86%, while the accuracy of the long-term algorithm is beyond 88%. The many changes undergone by Rome from 1994 to 1999 have been identified by the postclassification comparison change detection procedure. The pixel-by-pixel analysis of the results has been carried out for a 160 square kilometers test area, obtaining a correct detection above 82% (less than 18% missed alarms and 0.3% false alarms).
C1 [Del Frate, Fabio; Pacifici, Fabio; Solimini, Domenico] Univ Roma Tor Vergata, Dept Comp Syst & Prod Engn DISP, I-00133 Rome, Italy.
RP Del Frate, F (corresponding author), Univ Roma Tor Vergata, Dept Comp Syst & Prod Engn DISP, I-00133 Rome, Italy.
EM del-frate@disp.uniroma2.it; f.pacifici@disp.uniroma2.it;
   solimini@disp.uniroma2.it
RI Del Frate, Fabio/G-1413-2013
CR Al-Janobi A, 2001, PATTERN RECOGN, V34, P171, DOI 10.1016/S0031-3203(99)00206-X
   Arzandeh S, 2002, CAN J REMOTE SENS, V28, P653, DOI 10.5589/m02-061
   BAN Y, 2007, URB REM SENS JOINT E
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P293, DOI 10.1109/36.377929
   BASILI P, 1994, INT J REMOTE SENS, V15, P2887, DOI 10.1080/01431169408954290
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   BENNANI Y, 2000, INT J NEURAL SYST, V10, P379
   Bishop C, 1995, NEURAL NETWORKS PATT
   Born M., 1959, PRINCIPLES OPTICS
   Bruzzone L, 2004, IEEE T GEOSCI REMOTE, V42, P1321, DOI 10.1109/TGRS.2004.826821
   Castel T, 2000, REMOTE SENS ENVIRON, V73, P73, DOI 10.1016/S0034-4257(00)00083-3
   Chen C, 2006, INT J REMOTE SENS, V27, P1367, DOI 10.1080/01431160500421507
   Chini M, 2008, IEEE T GEOSCI REMOTE, V46, P1812, DOI 10.1109/TGRS.2008.916223
   Cibas T, 1996, NEUROCOMPUTING, V12, P223, DOI 10.1016/0925-2312(95)00121-2
   Clausi DA, 2004, IEEE T GEOSCI REMOTE, V42, P215, DOI 10.1109/TGRS.2003.817218
   Cossu R., 1988, PIXEL, V1, P21
   Del Frate F, 2002, IEEE T GEOSCI REMOTE, V40, P2263, DOI 10.1109/TGRS.2002.803622
   Del Frate F, 2000, IEEE T GEOSCI REMOTE, V38, P2282, DOI 10.1109/36.868885
   Del Frate F, 2007, IEEE T GEOSCI REMOTE, V45, P800, DOI 10.1109/TGRS.2007.892009
   Dell'Acqua F, 2003, IEEE T GEOSCI REMOTE, V41, P153, DOI 10.1109/TGRS.2002.807754
   Dell'Acqua F, 2006, INT J REMOTE SENS, V27, P3797, DOI 10.1080/01431160600557572
   Engdahl ME, 2003, IEEE T GEOSCI REMOTE, V41, P1620, DOI 10.1109/TGRS.2003.813271
   Gasca E, 2006, PATTERN RECOGN, V39, P313, DOI 10.1016/j.patcog.2005.09.002
   Gimeno M, 2004, INT J REMOTE SENS, V25, P4873, DOI 10.1080/01431160412331269715
   Gomes DG, 2007, COMPUT COMMUN, V30, P2236, DOI 10.1016/j.comcom.2007.05.005
   Grey WMF, 2003, REMOTE SENS ENVIRON, V87, P16, DOI 10.1016/S0034-4257(03)00142-1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   Hoen EW, 2000, IEEE T GEOSCI REMOTE, V38, P2571, DOI 10.1109/36.885204
   Kavzoglu T, 1999, INT J REMOTE SENS, V20, P2787, DOI 10.1080/014311699211796
   Kurosu T, 1999, IEEE T GEOSCI REMOTE, V37, P227, DOI 10.1109/36.739157
   Kurvonen L, 1999, IEEE T GEOSCI REMOTE, V37, P680, DOI 10.1109/36.752185
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   Oliver C., 1998, UNDERSTANDING SYNTHE
   Pacifici F, 2008, IEEE GEOSCI REMOTE S, V5, P331, DOI 10.1109/LGRS.2008.915939
   RAGG T, 1997, NT C AD NAT COMP ALG
   Santoro M, 2007, IEEE T GEOSCI REMOTE, V45, P2600, DOI 10.1109/TGRS.2007.897420
   SHANMUGAN KS, 1981, IEEE T GEOSCI REMOTE, V19, P153, DOI 10.1109/TGRS.1981.350344
   Strozzi T, 2000, IEEE T GEOSCI REMOTE, V38, P766, DOI 10.1109/36.842005
   SUN CJ, 1983, COMPUT VISION GRAPH, V23, P341, DOI 10.1016/0734-189X(83)90032-4
   Treitz P. M., 2000, Canadian Journal of Remote Sensing, V26, P18
   Tuceryan M., 1993, HDB PATTERN RECOGNIT
   WEGMULLER U, 1995, IEEE T GEOSCI REMOTE, V33, P1153, DOI 10.1109/36.469479
   WEGMUULLER U, 1995, P IEEE GEOSC REM SEN, V1, P544
   ZELL A, SNNS STUTTGART NEURA
NR 45
TC 42
Z9 42
U1 2
U2 22
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 1939-1404
EI 2151-1535
J9 IEEE J-STARS
JI IEEE J. Sel. Top. Appl. Earth Observ. Remote Sens.
PD JUN
PY 2008
VL 1
IS 2
BP 87
EP 97
DI 10.1109/JSTARS.2008.2002221
PG 11
WC Engineering, Electrical & Electronic; Geography, Physical; Remote
   Sensing; Imaging Science & Photographic Technology
SC Engineering; Physical Geography; Remote Sensing; Imaging Science &
   Photographic Technology
GA 437MP
UT WOS:000265491900002
DA 2022-01-04
ER

PT J
AU Pacifici, F
   Del Frate, F
   Solimini, C
   Emery, WJ
AF Pacifici, Fabio
   Del Frate, Fabio
   Solimini, Chiara
   Emery, William J.
TI An innovative neural-net method to detect temporal changes in
   high-resolution optical satellite imagery
SO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING
LA English
DT Article
DE change detection; neural networks (NNs); urban environment; very high
   resolution optical imagery
ID UNSUPERVISED CHANGE DETECTION; CLASSIFICATION; ALGORITHM; NETWORK
AB The advent of new high spatial resolution optical satellite imagery has greatly increased our ability to monitor land cover changes from space. Satellite observations are carried out regularly and continuously, and provide a great deal of insight into the temporal changes of land cover use. High spatial resolution imagery better resolves the details of these changes and makes it possible to overcome the "mixed-pixel" problem that is inherent with more moderate resolution satellite sensors. At the same time, high-resolution imagery presents a new challenge over other satellite systems, in that a relatively large amount of data must be analyzed and corrected for registration and classification errors to identify the land cover changes. To obtain the accuracies that are required by many applications to large areas, very extensive manual work is commonly required to remove the classification errors that are introduced by most methods. To improve on this situation, we have developed a new method for land surface change detection that greatly reduces the human effort that is needed to remove the errors that occur with many classification methods that are applied to high-resolution imagery. This change detection algorithm is based on neural networks, and it is able to exploit in parallel both the multiband and the multitemporal data to discriminate between real changes and false alarms. In general, the classification errors are reduced by a factor of 2-3 using our new method over a simple postclassification comparison based on a neural-network classification of the same images.
C1 Univ Roma Tor Vergata, Dept Informat Syst & Prod, I-00133 Rome, Italy.
   Univ Colorado, Dept Aerosp Engn Sci, Boulder, CO 80309 USA.
RP Pacifici, F (corresponding author), Univ Roma Tor Vergata, Dept Informat Syst & Prod, I-00133 Rome, Italy.
EM f.pacifici@disp.uniroma2.it
RI Del Frate, Fabio/G-1413-2013
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   BISCHOF H, 1992, IEEE T GEOSCI REMOTE, V30, P482, DOI 10.1109/36.142926
   Bishop C, 1995, NEURAL NETWORKS PATT
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Bruzzone L, 1997, IEEE T GEOSCI REMOTE, V35, P858, DOI 10.1109/36.602528
   Del Frate F, 2004, INT GEOSCI REMOTE SE, P1091
   Del Frate F, 2007, IEEE T GEOSCI REMOTE, V45, P800, DOI 10.1109/TGRS.2007.892009
   Jensen JR, 1999, PHOTOGRAMM ENG REM S, V65, P611
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Langevin C, 2004, PROG PLANN, V61, P327, DOI 10.1016/S0305-9006(03)00067-9
   MOLLER MF, 1993, NEURAL NETWORKS, V6, P525, DOI 10.1016/S0893-6080(05)80056-5
   PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684
   *QUICKBIRD IM PROD, 2006, PROD GUID DIGITALGLO
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Stathakis D, 2006, IEEE T GEOSCI REMOTE, V44, P2305, DOI 10.1109/TGRS.2006.872903
   Weber, 1981, P 15 INT S REM SENS, P65
   Wilkinson GG, 2005, IEEE T GEOSCI REMOTE, V43, P433, DOI 10.1109/TGRS.2004.837325
   Yuan D, 1998, REMOTE SENS ENVIRON, V66, P166, DOI 10.1016/S0034-4257(98)00068-6
NR 21
TC 76
Z9 77
U1 4
U2 29
PU IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
PI PISCATAWAY
PA 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
SN 0196-2892
EI 1558-0644
J9 IEEE T GEOSCI REMOTE
JI IEEE Trans. Geosci. Remote Sensing
PD SEP
PY 2007
VL 45
IS 9
BP 2940
EP 2952
DI 10.1109/TGRS.2007.902824
PG 13
WC Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote
   Sensing; Imaging Science & Photographic Technology
SC Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science
   & Photographic Technology
GA 205HU
UT WOS:000249105400021
DA 2022-01-04
ER

PT J
AU Nemmour, H
   Chibani, Y
AF Nemmour, H
   Chibani, Y
TI Fuzzy neural network architecture for change detection in remotely
   sensed imagery
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID CLASSIFICATION
AB This paper aims to propose a change-detection system in remotely sensed imagery based on the combination of fuzzy sets and neural networks. Multitemporal images are directly classified into change and no-change classes using a fuzzy membership model in order to provide complete information about the change. Presently, two fuzzy models derived from the Mahalanobis distance and a fuzzy neural network (FNN) combination are proposed and compared. In order to evaluate the performance of each model, extensive experiments using different performance indicators are carried out on two SPOT HRV images covering a region of Algeria. Results obtained showed that it has a great potential for land-cover change detection since it allows the nature of change to be extracted automatically. Furthermore, the FNN-based model gives the best performance. This model allows a reduced amount of false alarms with higher change detection accuracy.
C1 Univ Sci & Technol, Fac Elect & Comp Sci, Signal Proc Lab, Algiers, Algeria.
RP Chibani, Y (corresponding author), Univ Sci & Technol, Fac Elect & Comp Sci, Signal Proc Lab, Algiers, Algeria.
EM Ychibani@usthb.dz
RI Nemmour, Hassiba/AAC-4941-2019; Nemmour, Hassiba/AAC-2518-2019; Chibani,
   Youcef/AAC-3617-2019
OI Nemmour, Hassiba/0000-0001-6583-5402; Chibani,
   Youcef/0000-0002-7957-7456
CR Bardossy A, 2002, IEEE T GEOSCI REMOTE, V40, P362, DOI 10.1109/36.992798
   Bruzzone L, 1997, INT J REMOTE SENS, V18, P3883, DOI 10.1080/014311697216702
   Carlotto MJ, 1997, IEEE T IMAGE PROCESS, V6, P189, DOI 10.1109/83.552106
   Chen YX, 2003, IEEE INT CONF FUZZY, P789
   Chibani Y, 2003, INT GEOSCI REMOTE SE, P4101
   CHO SB, 1995, INT J APPROX REASON, V13, P359, DOI 10.1016/0888-613X(95)00059-P
   CIVCO DL, 2002, P ASPRS ANN CONV 22
   Congalton RG, 2001, INT J WILDLAND FIRE, V10, P321, DOI 10.1071/WF01031
   Dai XL, 1997, INT GEOSCI REMOTE SE, P1029, DOI 10.1109/IGARSS.1997.615332
   Deer P, 1998, THESIS U ADELAIDE AU
   FOODY GM, 1995, PHOTOGRAMM ENG REM S, V61, P391
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   LAMBIN EF, 1994, REMOTE SENS ENVIRON, V48, P231, DOI 10.1016/0034-4257(94)90144-9
   Nemmour H, 2005, EURASIP J APPL SIG P, V2005, P2187, DOI 10.1155/ASP.2005.2187
   Nemmour H, 2004, PROC SPIE, V5238, P551, DOI 10.1117/12.509934
   NEMMOUR H, 2004, ADV CONCEPTS INTELLI
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Rosin PL, 2001, IEEE T GEOSCI REMOTE, V39, P1978, DOI 10.1109/36.951088
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   TAKAGI H, 1997, INTELLIGENT SYSTEMS, P1
NR 20
TC 24
Z9 28
U1 2
U2 6
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND
SN 0143-1161
EI 1366-5901
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD FEB 20
PY 2006
VL 27
IS 4
BP 705
EP 717
DI 10.1080/01431160500275648
PG 13
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA 029PJ
UT WOS:000236576300005
DA 2022-01-04
ER

PT J
AU Seto, KC
   Liu, WG
AF Seto, KC
   Liu, WG
TI Comparing ARTMAP neural network with the maximum-likelihood classifier
   for detecting urban change
SO PHOTOGRAMMETRIC ENGINEERING AND REMOTE SENSING
LA English
DT Article
ID REMOTELY-SENSED IMAGERY; LAND-USE CHANGE; SENSING DATA; COVER; TM;
   RECOGNITION; SAR; MULTISOURCE; ALGORITHMS; SYSTEM
AB Urbanization has profound effects on the environment at local, regional, and global scales. Effective detection of urban change using remote sensing data will be an essential component of global environmental change research, regional planning, and natural resource management. This paper presents results from an ARTMAP neural network to detect urban change with Landsat TM images from two periods. Classification of urban change, and, in particular, conversion of agriculture to urban, was statistically more accurate with ARTMAP than with a more conventional technique, the Bayesian maximum-likelihood classifier (MLC). The effect of different levels of class aggregation on the performance of change detection was also explored with ARTMAP and MLC. Because ARTMAP explicitly allows "many-to-one" mapping, classification using coarse class resolution and fine class resolution training data generated similar results. Together, these results suggest that ARTMAP can reduce labor and computational costs associated with assembling training data while concurrently generating more accurate urban change-detection results.
C1 Stanford Univ, Dept Geol & Environm Sci, Stanford, CA 94305 USA.
   Stanford Univ, Inst Int Studies, Stanford, CA 94305 USA.
   ACI Worldwide Inc, Riverside, RI 02915 USA.
RP Seto, KC (corresponding author), Stanford Univ, Dept Geol & Environm Sci, Encina Hall E413, Stanford, CA 94305 USA.
EM kseto@stanford.edu; wgliu@crsa.bu.edu
RI Seto, Karen/C-2722-2008
OI Seto, Karen/0000-0002-4928-2446
CR Atkinson PM, 1997, INT J REMOTE SENS, V18, P699, DOI 10.1080/014311697218700
   Barnsley MJ, 1996, PHOTOGRAMM ENG REM S, V62, P949
   BENEDIKTSSON JA, 1990, IEEE T GEOSCI REMOTE, V28, P540, DOI 10.1109/TGRS.1990.572944
   BENEDIKTSSON JA, 1993, INT J REMOTE SENS, V14, P2883, DOI 10.1080/01431169308904316
   CARPENTER GA, 1991, NEURAL NETWORKS, V4, P493, DOI 10.1016/0893-6080(91)90045-7
   CARPENTER GA, 1995, IEEE T NEURAL NETWOR, V6, P1330, DOI 10.1109/72.471374
   CARPENTER GA, 1992, IEEE COMMUN MAG, V30, P38, DOI 10.1109/35.156802
   CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B
   Carpenter GA, 1997, IEEE T GEOSCI REMOTE, V35, P308, DOI 10.1109/36.563271
   Carpenter GA, 1999, REMOTE SENS ENVIRON, V70, P326, DOI 10.1016/S0034-4257(99)00051-6
   CARPENTER KE, 1992, HARVARD LIBR BULL, V3, P5
   Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187
   Dell'Acqua F, 2001, IEEE T GEOSCI REMOTE, V39, P2287, DOI 10.1109/36.957292
   Foody GM, 1997, NEURAL COMPUT APPL, V5, P238, DOI 10.1007/BF01424229
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   Gopal S, 1999, REMOTE SENS ENVIRON, V67, P230, DOI 10.1016/S0034-4257(98)00088-1
   GOPAL S, 2001, GEOGRAPHIC DATA MINI, P315
   GOPAL S, 1994, P DOSES WORKSH NEW T, P55
   Grubler A., 1994, TECHNOLOGY, P287
   Henderson FM, 1997, IEEE T GEOSCI REMOTE, V35, P79, DOI 10.1109/36.551936
   Ito Y, 1999, IEEE T GEOSCI REMOTE, V37, P313, DOI 10.1109/36.739166
   Jensen JR, 1999, PHOTOGRAMM ENG REM S, V65, P611
   Ji CY, 2001, INT J REMOTE SENS, V22, P1441, DOI 10.1080/01431160117207
   Kuplich TM, 2000, INT J REMOTE SENS, V21, P2101, DOI 10.1080/01431160050021321
   Liu WG, 2001, MASSIVE COMP, V2, P201
   Lopez E, 2001, LANDSCAPE URBAN PLAN, V55, P271, DOI 10.1016/S0169-2046(01)00160-8
   Masek JG, 2000, INT J REMOTE SENS, V21, P3473, DOI 10.1080/014311600750037507
   MCGEE TG, 1991, EXTENDED METROPOLIS, P3
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
   Ridd MK, 1998, REMOTE SENS ENVIRON, V63, P95, DOI 10.1016/S0034-4257(97)00112-0
   Rollet R, 1998, INT J REMOTE SENS, V19, P3003, DOI 10.1080/014311698214398
   Seto KC, 2002, INT J REMOTE SENS, V23, P1985, DOI 10.1080/01431160110075532
   Seto KC, 2000, NATURE, V406, P121, DOI 10.1038/35018267
   Song C, 2001, REMOTE SENS ENVIRON, V75, P230, DOI 10.1016/S0034-4257(00)00169-3
   Stefanov WL, 2001, REMOTE SENS ENVIRON, V77, P173, DOI 10.1016/S0034-4257(01)00204-8
   UN, 2001, WORLD POP PROSP 2000
   WEBSTER D, 2001, EDGE SHAPING FUTURE
   Yeh AGO, 2001, PHOTOGRAMM ENG REM S, V67, P83
   Zhang J, 1998, INT J REMOTE SENS, V19, P2721, DOI 10.1080/014311698214479
NR 39
TC 62
Z9 64
U1 1
U2 29
PU AMER SOC PHOTOGRAMMETRY
PI BETHESDA
PA 5410 GROSVENOR LANE SUITE 210, BETHESDA, MD 20814-2160 USA
SN 0099-1112
J9 PHOTOGRAMM ENG REM S
JI Photogramm. Eng. Remote Sens.
PD SEP
PY 2003
VL 69
IS 9
BP 981
EP 990
DI 10.14358/PERS.69.9.981
PG 10
WC Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science & Photographic Technology
SC Physical Geography; Geology; Remote Sensing; Imaging Science &
   Photographic Technology
GA 817RG
UT WOS:000221194000007
DA 2022-01-04
ER

PT J
AU Liu, X
   Lathrop, RG
AF Liu, X
   Lathrop, RG
TI Urban change detection based on an artificial neural network
SO INTERNATIONAL JOURNAL OF REMOTE SENSING
LA English
DT Article
ID CLASSIFICATION; ACCURACY
AB A method based on an artificial neural network (ANN) was developed to detect newly urbanized areas depicted in satellite sensor images. The method uses two Landsat Thematic Mapper (TM) images of a region acquired on different dates as input and supervises the ANN to classify the image data into 'from-to' classes. Principal component analysis (PCA) was applied to extract the salient features and to reduce the dimensionality of the input data prior to the ANN-based change detection. The Levenburg-Marquardt algorithm was used to accelerate the ANN's convergence. Experimental results from a case study show the ANN-based method requires only modest training time but can be 20-30% more accurate than post-classification comparison. PCA not only reduced the computational cost but improved the change detection accuracy as well. The results suggest the practical value of ANN-based change detection.
C1 Univ Calif Santa Barbara, Dept Geog, Santa Barbara, CA 93106 USA.
   Rutgers State Univ, Cook Coll, Ctr Remote Sensing & Spatial Anal, New Brunswick, NJ 08901 USA.
RP Liu, X (corresponding author), Univ Calif Santa Barbara, Dept Geog, Santa Barbara, CA 93106 USA.
CR AZIMISADJADI MR, 1993, IEEE T GEOSCI REMOTE, V31, P511, DOI 10.1109/36.214928
   Benediktsson JA, 1997, INT J REMOTE SENS, V18, P727, DOI 10.1080/014311697218728
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1350, DOI 10.1109/36.763299
   CONGALTON RG, 1991, REMOTE SENS ENVIRON, V37, P35, DOI 10.1016/0034-4257(91)90048-B
   Dai XL, 1999, PHOTOGRAMM ENG REM S, V65, P1187
   Demuth H., 1998, NEURAL NETWORK TOOLB
   Foody GM, 1997, INT J REMOTE SENS, V18, P799, DOI 10.1080/014311697218764
   Gopal S, 1996, IEEE T GEOSCI REMOTE, V34, P398, DOI 10.1109/36.485117
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   PAOLA JD, 1995, INT J REMOTE SENS, V16, P3033, DOI 10.1080/01431169508954607
NR 10
TC 72
Z9 77
U1 2
U2 16
PU TAYLOR & FRANCIS LTD
PI ABINGDON
PA 4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND
SN 0143-1161
J9 INT J REMOTE SENS
JI Int. J. Remote Sens.
PD JUN
PY 2002
VL 23
IS 12
BP 2513
EP 2518
DI 10.1080/01431160110097240
PG 6
WC Remote Sensing; Imaging Science & Photographic Technology
SC Remote Sensing; Imaging Science & Photographic Technology
GA 559FB
UT WOS:000176014000013
DA 2022-01-04
ER

EF